[{"id":"a26dba1745837d214d39192aa8ca3207","title":"SpringBoot源码分析","content":"1 如何搭建SpringBoot源码调试环境1 前言这是 SpringBoot2.1 源码分析专题的第一篇文章，主要讲如何来搭建我们的源码阅读调试环境。如果有经验的小伙伴们可以略过此篇文章。\n\n2 环境安装要求\nIntelliJ IDEA\nJDK1.8\nMaven3.5 以上\n\n\n3 从 Github 上将 SpringBoot 源码项目下载下来首先提供SpringBoot2.1.0的 github 地址： github.com&#x2F;spring-proj…\n因为要进行阅读源码和分析源码项目，我们是不是要在里面写一些注释帮助我们阅读理解源码，因此需要将 SpringBoot 源码项目 fork 到自己的 github 仓库中，然后再利用git clone url命令将已经 fork 到自己 github 仓库的 SpringBoot 源码拉取下来即可。 但由于以上方式往往很慢，通常会超时，所以笔者直接将 SpringBoot 项目直接下载下来，然后再导入 IDEA 中。\n\n\n4 将 SpringBoot 源码项目导入到 IDEA 中将刚才下载的 spring-boot2.1.0.RELEASE 项目选择 maven 方式导入到 IDEA 中，然后一直 next 即可导入完成，注意选择 JDK 版本是 1.8，maven 版本是 3.5+。\n\n此时下载 maven 依赖是一个漫长的等待过程，建议 maven 没有配置（阿-里-云）仓库的小伙伴们配置一下，这样下载速度会快很多。参考配置 maven 使用（阿-里-云）仓库进行配置即可。\n\n5 编译构建 SpringBoot 源码项目此时导入项目后，我们进行编译构建 SpringBoot 源码项目了，在构建之前做两个配置：\n1、我们要禁用 maven 的代码检查，在根 pom.xml 中增加一下配置即可，如下图：\n\n2、可能有的小伙伴们的 pom.xml 文件的 project 标签上显示java.lang.OutOfMemoryError错误，这是因为 IDEA 里的 Maven 的 importer 设置的 JVM 最大堆内存过小而导致的，如下图,此时可参考Maven 依赖包导入错误（IntelliJ IDEA）解决即可。\n\n进行了上面的两点配置后，此时我们就可以直接执行以下 maven 命令来编译构建源码项目了。\nmvn clean install -DskipTests -Pfast\n\n 此时又是漫长的等待，我这里等待 5 分钟左右就显示构建成功了，如下图：\n\n\n6 运行 SpringBoot 自带的 sample因为 SpringBoot 源码中的 spring-boot-samples 模块自带了很多 DEMO 样例，我们可以利用其中的一个 sample 来测试运行刚刚构建的 springboot 源码项目即可。但此时发现 spring-boot-samples 模块是灰色的，如下图：\n\n这是因为 spring-boot-samples 模块没有被添加到根 pom.xml 中，此时将其添加到根 pom.xml 中即可，增加如下配置，如下图：\n 此时我们挑选 spring-boot-samples 模块下的 spring-boot-sample-tomcat 样例项目来测试好了，此时启动SampleTomcatApplication的main函数，启动成功界面如下：\n 然后我们再在浏览器发送一个 HTTP 请求，此时可以看到服务端成功返回响应，说明此时 SpringBoot 源码环境就已经构建成功了，接下来我们就可以进行调试了，如下图：\n\n\n7 动手实践环节前面已经成功构建了 SpringBoot 的源码阅读环境，小伙伴们记得自己动手搭建一套属于自己的 SpringBoot 源码调试环境哦，阅读源码动手调试很重要，嘿嘿。\n2 如何分析SpringBoot源码模块及结构注：该源码分析对应SpringBoot版本为2.1.0.RELEASE\n\n1 前言前面搭建好了自己本地的SpringBoot源码调试环境后，此时我们不要急着下手进入到具体的源码调试细节中，刚开始阅读源码，此时我们一定要对项目结构等有一个整体的认识，然后再进行源码分析调试。推荐阅读下笔者之前写的的分析开源项目源码，我们该如何入手分析？一文，干货满满哦。\n\n2 SpringBoot源码模块一览我们先来对SpringBoot的源码模块来一个大致的了解，如下图：\n\n从上图可以看到，主要有以下四个模块：\n\n**spring-boot-project**：整个SpringBoot框架全部功能在这个模块实现，SpringBoot项目95%的代码都在这里实现，源码总共有25万行左右。\n**spring-boot-samples**：这个是SpringBoot给小伙伴们赠送的福利，里面包含了各种各样使用SpringBoot的简单demo，我们调试阅读源码的时候可以充分利用该模块。\n**spring-boot-sample-invoker**：这个模块应该是跟sample模块有关，注意根pom.xml中有这么一句话：Samples are built via the invoker plugin，该模块无代码。\n**spring-boot-tests**：这个模块SpringBoot的测试模块，跟部署测试和集成测试有关。\n\n因为SpringBoot的全部功能在spring-boot-project模块实现，因此下面重点来介绍下 spring-boot-project 模块。\n\n3 spring-boot-project源码模块详解先来看下 spring-boot-project 整体模块结构，如下图，然后我们再逐个来介绍：\n\n\n1) spring-boot-parent\n这个模块没有代码，是spring-boot模块的父项目，被其他子模块继承。\n\n2) spring-boot\n这个模块是SpringBoot项目的核心，可以说一些基础核心的功能都在这里实现，为SpringBoot的其他模块组件功能提供了支持，主要包括以下核心功能：\n\nSpringApplication类，这个是SpringBoot的启动类，提供了一个静态的run方法来启动程序，该类主要用来创建并且刷新Spring容器ApplicationContext.\n支持选择不同的容器比如Tomcat,Jetty等来作为应用的嵌入容器，这个是SpringBoot的新特性之一。\n外部配置支持，这个指的是我们执行java -jar xxx.jar命令时可以带一些参数，比如执行java -jar demo.jar --server.port=8888来将应用端口修改为8888.\n该模块内置了一些SpringBoot启动时的生命周期事件和一些容器初始化器(ApplicationContext initializers)，来执行一些SpringBoot启动时的初始化逻辑。\n\n\n3) spring-boot-autoconfigure\n这个模块跟SpringBoot的自动配置有关，也是SpringBoot的新特性之一。比如SpringBoot能基于类路径来自动配置某个项目模块，自动配置最为关键的注解是@EnableAutoConfiguration,这个注解能触发Spring上下文的自动配置。另外一个重要的注解是@Conditional。\n\n\n\n\n\n\n\n\n\n举个栗子，若HSQLDB在项目的类路径中，且我们没有配置任何其他数据库的连接，此时自动配置就会自动根据类路径来创建相应的bean。\n除了根据类路径来进行自动配置外，还有根据容器中是否存在某个bean等方式来进行自动配置，这里不会进入到具体细节中。\n4) spring-boot-starters\n这个模块是跟SpringBoot的起步依赖有关，也是SpringBoot的新特性之一。SpringBoot通过提供众多起步依赖降低项目依赖的复杂度。起步依赖其实就是利用maven项目模型将其他相关的依赖给聚合起来，里面各种依赖的版本号都给定义好，避免用户在引入依赖时出现各种版本冲突，方便了我们的使用。\n\n\n\n\n\n\n\n\n\n举个栗子，我们要用到activemq时，此时可以直接引入spring-boot-starter-activemq起步依赖即可，若SpringBoot官网或第三方组织没有提供相应的SpringBoot起步依赖时，此时我们可以进行定制自己的起步依赖。\n注意，该模块没有代码，主要是通过maven的pom.xml来组织各种依赖。\n5) spring-boot-cli\nSpring Boot CLI是一个命令行工具，如果您想使用Spring快速开发，可以使用它。它允许您运行Groovy脚本，这意味着您有一个熟悉的类似Java的语法，而没有那么多样板代码。您还可以引导一个新项目或编写自己的命令。\n\n6) spring-boot-actuator\n这个跟SpringBoot的监控有关，也是SpringBoot的新特性之一。可以通过HTTP端点或JMX等来管理和监控应用。审计、运行状况和度量收集可以自动应用到应用程序。这个监控模块是开箱即用的，提供了一系列端点包括HealthEndpoint, EnvironmentEndpoint和BeansEndpoint等端点。\n\n7) spring-boot-actuator-autoconfigure\n这个模块为监控模块提供自动配置的功能，通常也是根据类路径来进行配置。比如Micrometer存在于类路径中，那么将会自动配置MetricsEndpoint。\n\n8) spring-boot-test\n这个模式是spring-boot的跟测试有关的模块，包含了一些帮助我们测试的核心类和注解（比如@SpringBootTest）。\n\n9) spring-boot-dependencies\n这个模块也没有代码，主要是定义了一些SpringBoot的maven相关的一些依赖及其版本。\n\n10) spring-boot-devtools\n这个模块跟SpringBoot的热部署有关，即修改代码后无需重启应用即生效。\n\n11) spring-boot-docs\n这个模块应该是跟文档相关的模块。\n\n12) spring-boot-properties-migrator\n看到 migrator 这个单词，估计就是跟项目迁移有关，没有去细 究。\n\n13) spring-boot-test-autoconfigure\n这个模块一看就是跟SpringBoot的测试的自动配置有关。\n\n14) spring-boot-tools\n这个模块一看就是SpringBoot的工具相关的模块，提供了加载，maven插件,metadata和后置处理相关的支持。\n上面介绍了这么多spring-boot模块下的子模块，不用慌，我们要进行解读的模块不多，我们真正要看的模块有spring-boot，spring-boot-autoconfigure，spring-boot-starters和spring-boot-actuator模块。\n\n4 用一个思维导图来总结下SpringBoot源码项目的脉络\n\n5 SpringBoot模块之间的pom关系详解前面弄清楚了SpringBoot的各个模块的具体功能，此时我们来看下SpringBoot模块的pom之间的关系是怎样的，因为项目是通过maven构建的，因此还是有必要去研究下这块关系滴。\n先看SpringBoot源码项目的pom关系，如下图：\n 根据上图可得出以下结论：\n\nspring-boot-build(pom.xml)是项目的根pom，其子pom有spring-boot-project(pom.xml)和spring-boot-dependencies(pom.xml)；\nspring-boot-dependencies(pom.xml)主要定义了SpringBoot项目的各种依赖及其版本，其子pom有spring-boot-parent(pom.xml)和spring-boot-starter-parent(pom.xml)；\nspring-boot-project(pom.xml)起到聚合module的作用，其子模块并不继承于它，而是继承于spring-boot-parent(pom.xml)；\nspring-boot-parent(pom.xml)是spring-boot-project(pom.xml)的子module，但继承的父pom为spring-boot-dependencies(pom.xml)，其定义了一些properties等相关的东西。其子pom为spring-boot-project(pom.xml)的子module（注意除去spring-boot-dependencies(pom.xml)），比如有spring-boot(pom.xml),spring-boot-starters(pom.xml)和spring-boot-actuator(pom.xml)等；\nspring-boot-starters(pom.xml)是所有具体起步依赖的父pom，其子pom有spring-boot-starter-data-jdbc(pom.xml)和spring-boot-starter-data-redis(pom.xml)等。\nspring-boot-starter-parent(pom.xml)，是我们的所有具体SpringBoot项目的父pom，比如SpringBoot自带的样例的spring-boot-samples(pom.xml)是继承于它的。\n\nSpringBoot的各模块之间的pom关系有点复杂，确实有点绕，如果看完上面的图片和解释还是不太清楚的话，建议小伙伴们自己打开idea的项目，逐个去捋一下。总之记得SpringBoot的一些父pom无非是做了一些版本管理，聚合模块之间的事情。\n6 小结好了，前面已经把SpringBoot源码项目的各个模块的功能和模块pom之间的关系给捋清楚了，总之刚开始分析项目源码，有一个整体的大局观很重要。\n本来下节想先写SpringBoot的启动流程分析的，但由于之前研究过启动流程，所以就把启动流程分析放后点写了。下一节先对SpringBoot的新特性–自动配置的源码撸起来，因此下一节让我们先来揭开SpringBoot自动配置背后神秘的面纱吧，嘿嘿🤭。\n参考：\n\nhttps://github.com/spring-projects/spring-boot/tree/v2.1.0.RELEASE\nhttps://docs.spring.io/spring-boot/docs/1.5.2.RELEASE/reference/htmlsingle/#cli\n\n3 SpringBoot自动配置的条件注解原理\n1 前言上一篇，我们分析了 SpringBoot 源码结构及各个模块 pom 之间的关系后，那么此篇开始就开始解开 SpringBoot 新特性之一–自动配置的神秘面纱了。因为 SpringBoot 自动配置原理是基于其大量的条件注解ConditionalOnXXX，因此，本节我们先来撸下 Spring 的条件注解的相关源码。\n\n2 SpringBoot 的派生条件注解我们都知道，SpringBoot 自动配置是需要满足相应的条件才会自动配置,因此 SpringBoot 的自动配置大量应用了条件注解ConditionalOnXXX。如下图：\n\n那么上图的条件注解如何使用呢？\n\n\n\n\n\n\n\n\n\n举个栗子，我们来看下如何使用@ConditionalOnClass和@ConditionalOnProperty这两个注解，先看下图代码：\n HelloWorldEnableAutoConfiguration这个自动配置类应用了@ConditionalOnClass和ConditionalOnProperty两个条件注解，那么只有在满足:classpath中存在HelloWorldComponent.class和配置了hello.world.name和hello.world.age属性这两个条件的情况下才会创建HelloWorldComponent这个bean。\n其实 SpringBoot 的@ConditionalOnXXX等条件注解都是派生注解，那么什么是派生注解呢？ 就拿上面的栗子来说，以@ConditionalOnClass(HelloWorldComponent.class)为例，我们打开ConditionalOnClass注解源码，如下：\n@Target(&#123;\n    ElementType.TYPE,\n    ElementType.METHOD\n&#125;)\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Conditional(OnClassCondition.class)\npublic @interface ConditionalOnClass &#123;\n    Class &lt;&lt; ? > [] value() default &#123;&#125;;\n    String[] name() default &#123;&#125;;\n&#125;\n\n可以看到@ConditionalOnClass注解上面又标注了@Conditional(OnClassCondition.class)注解，因此@ConditionalOnClass是@Conditional的派生注解，@Conditional(OnClassCondition.class)和@ConditionalOnClass注解是等价的，即这两个注解标注在某个配置类上的效果是等价的。\n而 SpringBoot 的自动配置原理正是建立在这些大量的派生条件注解@ConditionalOnXXX之上，而这些条件注解的原理跟 Spring 的 Condition 接口有关。因此我们先来研究下 Condition 接口的相关源码。\n\n3 Condition 接口\n3.1 Condition 接口源码分析分析 Condition 接口源码前先看下如何自定义ConditionalOnXXX注解,举个栗子，比如自定义一个@ConditionalOnLinux注解，该注解只有在其属性environment是”linux”才会创建相关的 bean。定义了以下代码：\n/**\n * 实现spring 的Condition接口，并且重写matches()方法，如果@ConditionalOnLinux的注解属性environment是linux就返回true\n *\n */\npublic class LinuxCondition implements Condition &#123;\n\n    @Override\n    public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123;\n        // 获得注解@ConditionalOnLinux的所有属性\n        List &lt; AnnotationAttributes > allAnnotationAttributes = annotationAttributesFromMultiValueMap(\n            metadata.getAllAnnotationAttributes(\n                ConditionalOnLinux.class.getName()));\n        for (AnnotationAttributes annotationAttributes: allAnnotationAttributes) &#123;\n            // 获得注解@ConditionalOnLinux的environment属性\n            String environment = annotationAttributes.getString(\"environment\");\n            // 若environment等于linux，则返回true\n            if (\"linux\".equals(environment)) &#123;\n                return true;\n            &#125;\n        &#125;\n        return false;\n    &#125;\n&#125;\n\n@Target(&#123;\n    ElementType.TYPE,\n    ElementType.METHOD\n&#125;)\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Conditional(LinuxCondition.class)\npublic @interface ConditionalOnLinux &#123;\n    // 标注是哪个环境\n    String environment() default \"\";\n\n&#125;\n\n@Configuration\npublic class ConditionConfig &#123;\n    // 只有`@ConditionalOnLinux`的注解属性`environment`是\"linux\"时才会创建bean\n    @Bean\n    @ConditionalOnLinux(environment = \"linux\")\n    public Environment linuxEnvironment() &#123;\n        return new LinuxEnvironment();\n    &#125;\n&#125;\n\n上面的代码我们捋一下：\n\nLinuxCondition实现了Condition接口并实现了matches方法，而matches方法则判断@ConditionalOnLinux的注解属性environment是否”linux”，是则返回 true，否则 false。\n然后我们再定义了一个注解@ConditionalOnLinux，这个注解是@Conditional的派生注解，与@Conditional(LinuxCondition.class)等价，注意@ConditionalOnLinux注解定义了一个属性environment。而我们最终可以利用LinuxCondition的matches方法中的参数AnnotatedTypeMetadata来获取@ConditionalOnLinux的注解属性environment的值，从而用来判断值是否为 linux”。\n最后我们又定义了一个配置类ConditionConfig，在linuxEnvironment方法上标注了@ConditionalOnLinux(environment = &quot;linux&quot;)。因此，这里只有 LinuxCondition的matches方法返回 true 才会创建bean。\n\n学会了如何自定义@ConditionalOnXXX注解后，我们现在再来看下Condition接口的源码：\n@FunctionalInterface\npublic interface Condition &#123;\n\tboolean matches(ConditionContext context, AnnotatedTypeMetadata metadata);\n&#125;\n\nCondition 接口主要有一个matches方法，该方法决定了是否要注册相应的bean对象。其中matches方法中有两个参数，参数类型分别是ConditionContext和AnnotatedTypeMetadata，这两个参数非常重要。它们分别用来获取一些环境信息和注解元数据从而用在matches方法中判断是否符合条件。\n\n\n\n\n\n\n\n\n\nConditionContext，顾名思义，主要是跟Condition的上下文有关，主要用来获取Registry,BeanFactory,Environment,ResourceLoader和ClassLoader等。那么获取这些用来干什么呢？举个栗子，比如OnResourceCondition需要靠ConditionContext来获取ResourceLoader来加载指定资源，OnClassCondition需要靠ConditionContext来获取ClassLoader来加载指定类等，下面看下其源码：\npublic interface ConditionContext &#123;\n    BeanDefinitionRegistry getRegistry();\n    @Nullable\n    ConfigurableListableBeanFactory getBeanFactory();\n    Environment getEnvironment();\n    ResourceLoader getResourceLoader();\n    @Nullable\n    ClassLoader getClassLoader();\n&#125;\n\n\n\n\n\n\n\n\n\n\nAnnotatedTypeMetadata，这个跟注解元数据有关，利用AnnotatedTypeMetadata可以拿到某个注解的一些元数据，而这些元数据就包含了某个注解里面的属性，比如前面的栗子，利用AnnotatedTypeMetadata可以拿到@ConditionalOnLinux的注解属性environment的值。下面看下其源码：\npublic interface AnnotatedTypeMetadata &#123;\n\tboolean isAnnotated(String annotationName);\n\tMap&lt;String, Object> getAnnotationAttributes(String annotationName);\n\tMap&lt;String, Object> getAnnotationAttributes(String annotationName, boolean classValuesAsString);\n\tMultiValueMap&lt;String, Object> getAllAnnotationAttributes(String annotationName);\n\tMultiValueMap&lt;String, Object> getAllAnnotationAttributes(String annotationName, boolean classValuesAsString);\n&#125;\n\n回到刚才的栗子，我们知道@ConditionalOnLinux注解真正起作用的是Condition接口的具体实现类LinuxCondition的matches方法，那么这个matches方法是在何时被调用的呢？\n通过 idea 调试看调用的栈帧，如下图：\n\n发现是在ConditionEvaluator的shouldSkip方法中调用了LinuxCondition的matches方法，自然我们再去看看ConditionEvaluator的shouldSkip的方法执行了什么逻辑。\n// 这个方法主要是如果是解析阶段则跳过，如果是注册阶段则不跳过\npublic boolean shouldSkip(@Nullable AnnotatedTypeMetadata metadata, @Nullable ConfigurationPhase phase) &#123;\n\t// 若没有被@Conditional或其派生注解所标注，则不会跳过\n\tif (metadata == null || !metadata.isAnnotated(Conditional.class.getName())) &#123;\n\t\treturn false;\n\t&#125;\n\t// 没有指定phase，注意phase可以分为PARSE_CONFIGURATION或REGISTER_BEAN类型\n\tif (phase == null) &#123;\n\t\t// 若标有@Component，@Import，@Bean或@Configuration等注解的话，则说明是PARSE_CONFIGURATION类型\n\t\tif (metadata instanceof AnnotationMetadata &amp;&amp;\n\t\t\t\tConfigurationClassUtils.isConfigurationCandidate((AnnotationMetadata) metadata)) &#123;\n\t\t\treturn shouldSkip(metadata, ConfigurationPhase.PARSE_CONFIGURATION);\n\t\t&#125;\n\t\t// 否则是REGISTER_BEAN类型\n\t\treturn shouldSkip(metadata, ConfigurationPhase.REGISTER_BEAN);\n\t&#125;\n\n\tList&lt;Condition> conditions = new ArrayList&lt;>();\n\t// TODO 获得所有标有@Conditional注解或其派生注解里面的Condition接口实现类并实例化成对象。\n\t// 比如@Conditional(OnBeanCondition.class)则获得OnBeanCondition.class，OnBeanCondition.class往往实现了Condition接口\n\tfor (String[] conditionClasses : getConditionClasses(metadata)) &#123;\n\t\t// 将类实例化成对象\n\t\tfor (String conditionClass : conditionClasses) &#123;\n\t\t\tCondition condition = getCondition(conditionClass, this.context.getClassLoader());\n\t\t\tconditions.add(condition);\n\t\t&#125;\n\t&#125;\n\t// 排序，即按照Condition的优先级进行排序\n\tAnnotationAwareOrderComparator.sort(conditions);\n\n\tfor (Condition condition : conditions) &#123;\n\t\tConfigurationPhase requiredPhase = null;\n\t\tif (condition instanceof ConfigurationCondition) &#123;\n\t\t\t// 从condition中获得对bean是解析还是注册\n\t\t\trequiredPhase = ((ConfigurationCondition) condition).getConfigurationPhase();\n\t\t&#125;\n\t\t// 若requiredPhase为null或获取的阶段类型正是当前阶段类型且不符合condition的matches条件，则跳过\n\t\tif ((requiredPhase == null || requiredPhase == phase) &amp;&amp; !condition.matches(this.context, metadata)) &#123;\n\t\t\treturn true;\n\t\t&#125;\n\t&#125;\n\n\treturn false;\n&#125;\n\nshouldSkip这个方法执行的逻辑主要是如果是解析阶段则跳过，如果是注册阶段则不跳过；如果是在注册阶段即REGISTER_BEAN阶段的话，此时会得到所有的Condition接口的具体实现类并实例化这些实现类，然后再执行下面关键的代码进行判断是否需要跳过。\nif ((requiredPhase == null || requiredPhase == phase) &amp;&amp; !condition.matches(this.context, metadata)) &#123;\n    return true;\n&#125;\n\n上面代码最重要的逻辑是调用了Condition接口的具体实现类的matches方法，若matches返回false，则跳过，不进行注册bean的操作；若matches返回true，则不跳过，进行注册bean的操作；\n好了，Condition的源码分析就到此为止，再往上翻调用方法的话应该就是 Spring 加载bean定义的相关源码了，不属于这里的分析范围。\n\n3.2 Spring 的内置 Condition 接口实现类前面我们学会了如何自定义条件注解及Condition的源码分析，那么我们不禁好奇，Spring 究竟内置了哪些Condition接口的实现类呢？\n那么看下 Spring 的Condition接口的具体实现类的类图：\n\n发现 Spring 内置的Condition接口的具体实现类虽然有多个，但只有ProfileCondition不是测试相关的，因此可以说真正的内置的Condition接口的具体实现类只有ProfileCondition一个，非常非常少,这跟 SpringBoot 的大量派生条件注解形成了鲜明的对比。ProfileCondition大家都知道，是跟环境有关，比如我们平时一般有dev,test和prod环境，而ProfileCondition就是判断我们项目配置了哪个环境的。下面是ProfileCondition的源码，很简单，这里就不分析了。\nclass ProfileCondition implements Condition &#123;\n\t@Override\n\tpublic boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123;\n\t\tMultiValueMap&lt;String, Object> attrs = metadata.getAllAnnotationAttributes(Profile.class.getName());\n\t\tif (attrs != null) &#123;\n\t\t\tfor (Object value : attrs.get(\"value\")) &#123;\n\t\t\t\tif (context.getEnvironment().acceptsProfiles(Profiles.of((String[]) value))) &#123;\n\t\t\t\t\treturn true;\n\t\t\t\t&#125;\n\t\t\t&#125;\n\t\t\treturn false;\n\t\t&#125;\n\t\treturn true;\n\t&#125;\n&#125;\n\n\n4 SpringBootCondition 源码解析前面看到 Spring 对Condition的内置注解可以说只有ProfileCondition一个，但是我们都知道，SpringBoot 则内置了大量的条件注解ConditionalOnXXX。在分析前，我们先来看一下SpringBootCondition的整体类图来个整体的理解，如下图：\n\n可以看到SpringBootCondition作为 SpringBoot 条件注解的基类，处于整个类图的中心，它实现了Condition接口，然后又有很多具体的子类OnXXXCondition,这些OnXXXCondition其实就是@ConditionalOnXXX的条件类。\n我们先来看下SpringBootCondition这个父类是主要做了哪些事情，抽象了哪些共有的逻辑？\nSpringBootConditon实现了Condition接口，作为 SpringBoot 众多条件注解OnXXXCondtion的父类，它的作用主要就是打印一些条件注解评估报告的日志，比如打印哪些配置类是符合条件注解的，哪些是不符合的。打印的日志形式如下图：\n\n 因为SpringBootConditon实现了Condition接口，也实现了matches方法，因此该方法同样也是被ConditionEvaluator的shouldSkip方法中调用，因此我们就以SpringBootConditon的matches方法为入口去进行分析。直接上代码：\n// SpringBootCondition.java\npublic final boolean matches(ConditionContext context,\n\t\t\tAnnotatedTypeMetadata metadata) &#123;\n\t\t// 得到metadata的类名或方法名\n\t\tString classOrMethodName = getClassOrMethodName(metadata);\n\t\ttry &#123;\n\t\t\t// 判断每个配置类的每个条件注解@ConditionalOnXXX是否满足条件，然后记录到ConditionOutcome结果中\n\t\t\t// 注意getMatchOutcome是一个抽象模板方法，交给OnXXXCondition子类去实现\n\t\t\tConditionOutcome outcome = getMatchOutcome(context, metadata);\n\t\t\t// 打印condition评估的日志，哪些条件注解@ConditionalOnXXX是满足条件的，哪些是不满足条件的，这些日志都打印出来\n\t\t\tlogOutcome(classOrMethodName, outcome);\n\t\t\t// 除了打印日志外，这些是否匹配的信息还要记录到ConditionEvaluationReport中\n\t\t\trecordEvaluation(context, classOrMethodName, outcome);\n\t\t\t// 最后返回@ConditionalOnXXX是否满足条件\n\t\t\treturn outcome.isMatch();\n\t\t&#125;\n\t\tcatch (NoClassDefFoundError ex) &#123;\n\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\"Could not evaluate condition on \" + classOrMethodName + \" due to \"\n\t\t\t\t\t\t\t+ ex.getMessage() + \" not \"\n\t\t\t\t\t\t\t+ \"found. Make sure your own configuration does not rely on \"\n\t\t\t\t\t\t\t+ \"that class. This can also happen if you are \"\n\t\t\t\t\t\t\t+ \"@ComponentScanning a springframework package (e.g. if you \"\n\t\t\t\t\t\t\t+ \"put a @ComponentScan in the default package by mistake)\",\n\t\t\t\t\tex);\n\t\t&#125;\n\t\tcatch (RuntimeException ex) &#123;\n\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\"Error processing condition on \" + getName(metadata), ex);\n\t\t&#125;\n\t&#125;\n\n上面代码的注释已经非常详细，我们知道了SpringBootCondition抽象了所有其具体实现类OnXXXCondition的共有逻辑–condition评估信息打印，最重要的是封装了一个模板方法getMatchOutcome(context, metadata)，留给各个OnXXXCondition具体子类去覆盖实现属于自己的判断逻辑，然后再返回相应的匹配结果给SpringBootCondition用于日志打印。\n因此我们知道了SpringBootCondition其实就是用来打印condition评估信息的，对于其他枝节方法我们不必追究过深，免得丢了主线。我们现在的重点是放在交给OnXXXCondition子类实现的模板方法上getMatchOutcome(context, metadata);，因为这个方法将会由很多OnXXXCondition覆盖重写判断逻辑，这里是我们接下来分析的重点。\n因为SpringBootCondition有众多具体实现类，下面只挑OnResourceCondition，OnBeanCondition和OnWebApplicationCondition进行讲解，而AutoConfigurationImportFilter跟自动配置有关，则留到自动配置源码解析的时候再进行分析。\n\n4.1 OnResourceCondition 源码分析现在先来看下一个逻辑及其简单的注解条件类OnResourceCondition，OnResourceCondition继承了SpringBootCondition父类，覆盖了其getMatchOutcome方法，用于@ConditionalOnResource注解指定的资源存在与否。OnResourceCondition的判断逻辑非常简单，主要拿到@ConditionalOnResource注解指定的资源路径后，然后用ResourceLoader根据指定路径去加载看资源存不存在。下面直接看代码:\n先来看下@ConditionalOnResource的代码，\n@Target(&#123; ElementType.TYPE, ElementType.METHOD &#125;)\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Conditional(OnResourceCondition.class)\npublic @interface ConditionalOnResource &#123;\n\n\t/**\n\t * The resources that must be present.\n\t * @return the resource paths that must be present.\n\t */\n\tString[] resources() default &#123;&#125;;\n\n&#125;\n\n再来看OnResourceCondition的代码：\n@Order(Ordered.HIGHEST_PRECEDENCE + 20)\nclass OnResourceCondition extends SpringBootCondition &#123;\n\n\tprivate final ResourceLoader defaultResourceLoader = new DefaultResourceLoader();\n\n\t@Override\n\tpublic ConditionOutcome getMatchOutcome(ConditionContext context,\n\t\t\tAnnotatedTypeMetadata metadata) &#123;\n\t\t// 获得@ConditionalOnResource注解的属性元数据\n\t\tMultiValueMap&lt;String, Object> attributes = metadata\n\t\t\t\t.getAllAnnotationAttributes(ConditionalOnResource.class.getName(), true);\n\t\t// 获得资源加载器，若ConditionContext中有ResourceLoader则用ConditionContext中的，没有则用默认的\n\t\tResourceLoader loader = (context.getResourceLoader() != null)\n\t\t\t\t? context.getResourceLoader() : this.defaultResourceLoader;\n\t\tList&lt;String> locations = new ArrayList&lt;>();\n\t\t// 将@ConditionalOnResource中定义的resources属性值取出来装进locations集合\n\t\tcollectValues(locations, attributes.get(\"resources\"));\n\t\tAssert.isTrue(!locations.isEmpty(),\n\t\t\t\t\"@ConditionalOnResource annotations must specify at \"\n\t\t\t\t\t\t+ \"least one resource location\");\n\t\t// missing集合是装不存在指定资源的资源路径的\n\t\tList&lt;String> missing = new ArrayList&lt;>();\n\t\t// 遍历所有的资源路径，若指定的路径的资源不存在则将其资源路径存进missing集合中\n\t\tfor (String location : locations) &#123;\n\t\t\t// 这里针对有些资源路径是Placeholders的情况，即处理 $&#123;&#125;\n\t\t\tString resource = context.getEnvironment().resolvePlaceholders(location);\n\t\t\tif (!loader.getResource(resource).exists()) &#123;\n\t\t\t\tmissing.add(location);\n\t\t\t&#125;\n\t\t&#125;\n\t\t// 如果存在某个资源不存在，那么则报错\n\t\tif (!missing.isEmpty()) &#123;\n\t\t\treturn ConditionOutcome.noMatch(ConditionMessage\n\t\t\t\t\t.forCondition(ConditionalOnResource.class)\n\t\t\t\t\t.didNotFind(\"resource\", \"resources\").items(Style.QUOTE, missing));\n\t\t&#125;\n\t\t// 所有资源都存在，那么则返回能找到就提的资源\n\t\treturn ConditionOutcome\n\t\t\t\t.match(ConditionMessage.forCondition(ConditionalOnResource.class)\n\t\t\t\t\t\t.found(\"location\", \"locations\").items(locations));\n\t&#125;\n\n\t// 将@ConditionalOnResource中定义的resources属性值取出来装进locations集合\n\tprivate void collectValues(List&lt;String> names, List&lt;Object> values) &#123;\n\t\tfor (Object value : values) &#123;\n\t\t\tfor (Object item : (Object[]) value) &#123;\n\t\t\t\tnames.add((String) item);\n\t\t\t&#125;\n\t\t&#125;\n\t&#125;\n&#125;\n\n可以看到OnResourceCondition的getMatchOutcome方法非常简单，这里不再详述。\n\n4.2 OnBeanCondition 源码分析OnBeanCondition同样继承了FilteringSpringBootCondition父类，覆盖了父类FilteringSpringBootCondition的getOutcomes方法。而FilteringSpringBootCondition又是SpringBootCondition的子类，FilteringSpringBootCondition跟自动配置类过滤有关，这里先不分析。值得注意的是**OnBeanCondition**同样重写了**SpringBootCondition**的**getMatchOutcome**方法，用来判断 Spring 容器中是否存在指定条件的bean。同时是OnBeanCondition是@ConditionalOnBean,@ConditionalOnSingleCandidate和ConditionalOnMissingBean的条件类。\n同样，先来看OnBeanCondition复写父类SpringBootCondition的getMatchOutcome方法的代码：\n@Override\n\tpublic ConditionOutcome getMatchOutcome(ConditionContext context,\n\t\t\tAnnotatedTypeMetadata metadata) &#123;\n\t\tConditionMessage matchMessage = ConditionMessage.empty();\n\t\t// (1)，配置类（metadata）标注@ConditionalOnBean注解的情况\n\t\tif (metadata.isAnnotated(ConditionalOnBean.class.getName())) &#123;\n\t\t\t// 将@ConditionalOnBean注解属性封装进BeanSearchSpec对象中\n\t\t\t// 注意BeanSearchSpec是一个静态内部类，用来存储@ConditionalOnBean和@ConditionalOnMissingBean注解的属性值\n\t\t\tBeanSearchSpec spec = new BeanSearchSpec(context, metadata,\n\t\t\t\t\tConditionalOnBean.class);\n\t\t\t// 调用getMatchingBeans得到符合条件的bean\n\t\t\tMatchResult matchResult = getMatchingBeans(context, spec);\n\t\t\t// 如果不匹配\n\t\t\tif (!matchResult.isAllMatched()) &#123;\n\t\t\t\tString reason = createOnBeanNoMatchReason(matchResult);\n\t\t\t\treturn ConditionOutcome.noMatch(ConditionMessage\n\t\t\t\t\t\t.forCondition(ConditionalOnBean.class, spec).because(reason));\n\t\t\t&#125;\n\t\t\t// 如果匹配\n\t\t\tmatchMessage = matchMessage.andCondition(ConditionalOnBean.class, spec)\n\t\t\t\t\t.found(\"bean\", \"beans\")\n\t\t\t\t\t.items(Style.QUOTE, matchResult.getNamesOfAllMatches());\n\t\t&#125;\n\t\t// (2)，配置类（metadata）标注@ConditionalOnSingleCandidate注解的情况\n\t\tif (metadata.isAnnotated(ConditionalOnSingleCandidate.class.getName())) &#123;\n\t\t\tBeanSearchSpec spec = new SingleCandidateBeanSearchSpec(context, metadata,\n\t\t\t\t\tConditionalOnSingleCandidate.class);\n\t\t\tMatchResult matchResult = getMatchingBeans(context, spec);\n\t\t\tif (!matchResult.isAllMatched()) &#123;\n\t\t\t\treturn ConditionOutcome.noMatch(ConditionMessage\n\t\t\t\t\t\t.forCondition(ConditionalOnSingleCandidate.class, spec)\n\t\t\t\t\t\t.didNotFind(\"any beans\").atAll());\n\t\t\t&#125;\n\t\t\telse if (!hasSingleAutowireCandidate(context.getBeanFactory(),\n\t\t\t\t\tmatchResult.getNamesOfAllMatches(),\n\t\t\t\t\tspec.getStrategy() == SearchStrategy.ALL)) &#123;\n\t\t\t\treturn ConditionOutcome.noMatch(ConditionMessage\n\t\t\t\t\t\t.forCondition(ConditionalOnSingleCandidate.class, spec)\n\t\t\t\t\t\t.didNotFind(\"a primary bean from beans\")\n\t\t\t\t\t\t.items(Style.QUOTE, matchResult.getNamesOfAllMatches()));\n\t\t\t&#125;\n\t\t\tmatchMessage = matchMessage\n\t\t\t\t\t.andCondition(ConditionalOnSingleCandidate.class, spec)\n\t\t\t\t\t.found(\"a primary bean from beans\")\n\t\t\t\t\t.items(Style.QUOTE, matchResult.getNamesOfAllMatches());\n\t\t&#125;\n\t\t// (3)，配置类（metadata）标注@ConditionalOnMissingBean注解的情况\n\t\tif (metadata.isAnnotated(ConditionalOnMissingBean.class.getName())) &#123;\n\t\t\tBeanSearchSpec spec = new BeanSearchSpec(context, metadata,\n\t\t\t\t\tConditionalOnMissingBean.class);\n\t\t\tMatchResult matchResult = getMatchingBeans(context, spec);\n\t\t\tif (matchResult.isAnyMatched()) &#123;\n\t\t\t\tString reason = createOnMissingBeanNoMatchReason(matchResult);\n\t\t\t\treturn ConditionOutcome.noMatch(ConditionMessage\n\t\t\t\t\t\t.forCondition(ConditionalOnMissingBean.class, spec)\n\t\t\t\t\t\t.because(reason));\n\t\t\t&#125;\n\t\t\tmatchMessage = matchMessage.andCondition(ConditionalOnMissingBean.class, spec)\n\t\t\t\t\t.didNotFind(\"any beans\").atAll();\n\t\t&#125;\n\t\t// 最终返回matchMessage\n\t\treturn ConditionOutcome.match(matchMessage);\n\t&#125;\n\n我们可以看到OnBeanCondition类覆盖的getMatchOutcome方法分别处理了标注@ConditionalOnBean,@ConditionalOnSingleCandidate和@ConditionalOnMissingBean注解的情况，分别对应上面代码注释的(1),(2)和(3)处。\n现在我们只看针对@ConditionalOnBean注解的处理逻辑，从上面代码中可以看到若配置类（metadata）标注@ConditionalOnBean注解的话，主要做了以下事情：\n\n将该注解属性提取出来封装进BeanSearchSpec对象中;\n然后调用getMatchingBeans(context, spec)方法来获取是否有匹配的bean；\n最后返回bean的匹配情况；\n\n可以看到最重要的逻辑是第 2 步，那么我们再来看下getMatchingBeans方法，直接上代码：\nprotected final MatchResult getMatchingBeans(ConditionContext context,\n\t\t\tBeanSearchSpec beans) &#123;\n\t\t// 获得Spring容器的beanFactory\n\t\tConfigurableListableBeanFactory beanFactory = context.getBeanFactory();\n\t\t// 判断bean的搜索策略是否是SearchStrategy.ANCESTORS策略\n\t\tif (beans.getStrategy() == SearchStrategy.ANCESTORS) &#123;\n\t\t\tBeanFactory parent = beanFactory.getParentBeanFactory();\n\t\t\tAssert.isInstanceOf(ConfigurableListableBeanFactory.class, parent,\n\t\t\t\t\t\"Unable to use SearchStrategy.PARENTS\");\n\t\t\tbeanFactory = (ConfigurableListableBeanFactory) parent;\n\t\t&#125;\n\t\t// MatchResult用来存储bean的匹配结果\n\t\tMatchResult matchResult = new MatchResult();\n\t\t// 如果bean的搜索策略不是SearchStrategy.CURRENT的话，则置considerHierarchy为true\n\t\tboolean considerHierarchy = beans.getStrategy() != SearchStrategy.CURRENT;\n\t\t// 获取TypeExtractor，TypeExtractor是用来判断bean的类型的\n\t\tTypeExtractor typeExtractor = beans.getTypeExtractor(context.getClassLoader());\n\t\t// 获取是否有被忽略bean类型，若有的话将该bean类型的名称装进beansIgnoredByType集合\n\t\t// 这里主要是针对@ConditionalOnMissingBean的ignored属性\n\t\tList&lt;String> beansIgnoredByType = getNamesOfBeansIgnoredByType(\n\t\t\t\tbeans.getIgnoredTypes(), typeExtractor, beanFactory, context,\n\t\t\t\tconsiderHierarchy);\n\t\t// 遍历bean的所有类型\n\t\tfor (String type : beans.getTypes()) &#123;\n\t\t\t// 调用getBeanNamesForType方法根据bean类型得到所有符合条件的bean类型，并放到typeMatches集合\n\t\t\tCollection&lt;String> typeMatches = getBeanNamesForType(beanFactory, type,\n\t\t\t\t\ttypeExtractor, context.getClassLoader(), considerHierarchy);\n\t\t\t// 移除掉Ignored的类型\n\t\t\ttypeMatches.removeAll(beansIgnoredByType);\n\t\t\t// 若typeMatches为空，那么则说明正在遍历的这个type类型不符合匹配条件，此时用matchResult记录一下这个不符合条件的类型\n\t\t\tif (typeMatches.isEmpty()) &#123;\n\t\t\t\tmatchResult.recordUnmatchedType(type);\n\t\t\t&#125;\n\t\t\t// 若typeMatches不为空，那么则说明正在遍历的这个type类型符合匹配条件，此时用matchResult记录一下这个符合条件的类型\n\t\t\telse &#123;\n\t\t\t\tmatchResult.recordMatchedType(type, typeMatches);\n\t\t\t&#125;\n\t\t&#125;\n\t\t// 这里针对@ConditionalOnBean等注解的annotation属性的处理\n\t\tfor (String annotation : beans.getAnnotations()) &#123;\n\t\t\tList&lt;String> annotationMatches = Arrays\n\t\t\t\t\t.asList(getBeanNamesForAnnotation(beanFactory, annotation,\n\t\t\t\t\t\t\tcontext.getClassLoader(), considerHierarchy));\n\t\t\tannotationMatches.removeAll(beansIgnoredByType);\n\t\t\tif (annotationMatches.isEmpty()) &#123;\n\t\t\t\tmatchResult.recordUnmatchedAnnotation(annotation);\n\t\t\t&#125;\n\t\t\telse &#123;\n\t\t\t\tmatchResult.recordMatchedAnnotation(annotation, annotationMatches);\n\t\t\t&#125;\n\t\t&#125;\n\t\t// 这里针对@ConditionalOnBean等注解的name属性的处理\n\t\tfor (String beanName : beans.getNames()) &#123;\n\t\t\t// beansIgnoredByType集合不包含beanName且beanFactory包含这个bean，则匹配\n\t\t\tif (!beansIgnoredByType.contains(beanName)\n\t\t\t\t\t&amp;&amp; containsBean(beanFactory, beanName, considerHierarchy)) &#123;\n\t\t\t\tmatchResult.recordMatchedName(beanName);\n\t\t\t&#125;\n\t\t\t// 否则，不匹配\n\t\t\telse &#123;\n\t\t\t\tmatchResult.recordUnmatchedName(beanName);\n\t\t\t&#125;\n\t\t&#125;\n\t\t// 最后返回匹配结果\n\t\treturn matchResult;\n\t&#125;\n\n上面的逻辑主要是从 spring 容器中搜索有无指定条件的bean，搜索 Spring 容器搜索 bean 的话有三种搜索策略，分别是CURRENT,ANCESTORS和ALL，分表表示只从当前的context中搜索bean，只从父context中搜索bean和从整个context中搜索bean；定义了搜索策略后，然后再根据BeanSearchSpec对象封装的注解属性分别取指定的容器中查找有无符合条件的bean，然后再进行一些过滤。比如@ConditionalOnMissingBean注解有定义ignored属性值，那么从容器中搜索到有符合条件的bean时，此时还要移除掉ignored指定的bean。\n好了，上面就已经分析了OnBeanCondition这个条件类了，我们坚持主线优先的原则，具体的细节代码不会深究。\n\n4.3 OnWebApplicationConditionOnWebApplicationCondition同样继承了FilteringSpringBootCondition父类，覆盖了父类FilteringSpringBootCondition的getOutcomes方法。而FilteringSpringBootCondition又是SpringBootCondition的子类，FilteringSpringBootCondition跟自动配置类过滤有关，这里先不分析。值得注意的是**OnWebApplicationCondition**同样重写了**SpringBootCondition**的**getMatchOutcome**方法，用来判断当前应用是否 web 应用。同时是OnWebApplicationCondition是@ConditionalOnWebApplication的条件类。\n同样，先来看OnWebApplicationCondition重写SpringBootCondition的getMatchOutcome方法：\npublic ConditionOutcome getMatchOutcome(ConditionContext context,\n\t\t\tAnnotatedTypeMetadata metadata) &#123;\n\t\t// 配置类是否标注有@ConditionalOnWebApplication注解\n\t\tboolean required = metadata\n\t\t\t\t.isAnnotated(ConditionalOnWebApplication.class.getName());\n\t\t// 调用isWebApplication方法返回匹配结果\n\t\tConditionOutcome outcome = isWebApplication(context, metadata, required);\n\t\t// 若有标注@ConditionalOnWebApplication但不符合条件，则返回不匹配\n\t\tif (required &amp;&amp; !outcome.isMatch()) &#123;\n\t\t\treturn ConditionOutcome.noMatch(outcome.getConditionMessage());\n\t\t&#125;\n\t\t// 若没有标注@ConditionalOnWebApplication但符合条件，则返回不匹配\n\t\tif (!required &amp;&amp; outcome.isMatch()) &#123;\n\t\t\treturn ConditionOutcome.noMatch(outcome.getConditionMessage());\n\t\t&#125;\n\t\t// 这里返回匹配的情况，TODO 不过有个疑问：如果没有标注@ConditionalOnWebApplication注解，又不符合条件的话，也会执行到这里，返回匹配？\n\t\treturn ConditionOutcome.match(outcome.getConditionMessage());\n\t&#125;\n\n上面代码的逻辑很简单，主要是调用isWebApplication方法来判断当前应用是否是 web 应用。因此，我们再来看下isWebApplication方法:\nprivate ConditionOutcome isWebApplication(ConditionContext context,\n\t\t\tAnnotatedTypeMetadata metadata, boolean required) &#123;\n\t\t// 调用deduceType方法判断是哪种类型，其中有SERVLET，REACTIVE和ANY类型，其中ANY表示了SERVLET或REACTIVE类型\n\t\tswitch (deduceType(metadata)) &#123;\n\t\t// SERVLET类型\n\t\tcase SERVLET:\n\t\t\treturn isServletWebApplication(context);\n\t\t// REACTIVE类型\n\t\tcase REACTIVE:\n\t\t\treturn isReactiveWebApplication(context);\n\t\tdefault:\n\t\t\treturn isAnyWebApplication(context, required);\n\t\t&#125;\n\t&#125;\n\n在isWebApplication方法中，首先从@ConditionalOnWebApplication注解中获取其定义了什么类型，然后根据不同的类型进入不同的判断逻辑。这里我们只看下SERVLET的情况判断处理，看代码：\nprivate ConditionOutcome isServletWebApplication(ConditionContext context) &#123;\n\t\tConditionMessage.Builder message = ConditionMessage.forCondition(\"\");\n\t\t// 若classpath中不存在org.springframework.web.context.support.GenericWebApplicationContext.class，则返回不匹配\n\t\tif (!ClassNameFilter.isPresent(SERVLET_WEB_APPLICATION_CLASS,\n\t\t\t\tcontext.getClassLoader())) &#123;\n\t\t\treturn ConditionOutcome.noMatch(\n\t\t\t\t\tmessage.didNotFind(\"servlet web application classes\").atAll());\n\t\t&#125;\n\t\t// 若classpath中存在org.springframework.web.context.support.GenericWebApplicationContext.class，那么又分为以下几种匹配的情况\n\t\t// session\n\t\tif (context.getBeanFactory() != null) &#123;\n\t\t\tString[] scopes = context.getBeanFactory().getRegisteredScopeNames();\n\t\t\tif (ObjectUtils.containsElement(scopes, \"session\")) &#123;\n\t\t\t\treturn ConditionOutcome.match(message.foundExactly(\"'session' scope\"));\n\t\t\t&#125;\n\t\t&#125;\n\t\t// ConfigurableWebEnvironment\n\t\tif (context.getEnvironment() instanceof ConfigurableWebEnvironment) &#123;\n\t\t\treturn ConditionOutcome\n\t\t\t\t\t.match(message.foundExactly(\"ConfigurableWebEnvironment\"));\n\t\t&#125;\n\t\t// WebApplicationContext\n\t\tif (context.getResourceLoader() instanceof WebApplicationContext) &#123;\n\t\t\treturn ConditionOutcome.match(message.foundExactly(\"WebApplicationContext\"));\n\t\t&#125;\n\t\t// 若以上三种都不匹配的话，则说明不是一个servlet web application\n\t\treturn ConditionOutcome.noMatch(message.because(\"not a servlet web application\"));\n\t&#125;\n\n对于是SERVLET的情况，首先根据classpath中是否存在org.springframework.web.context.support.GenericWebApplicationContext.class，如果不存在该类，则直接返回不匹配；若存在的话那么又分为以下几种匹配的情况：\n\nsession\nConfigurableWebEnvironment\nWebApplicationContext\n\n若上面三种情况都不匹配，则说明不是一个 servlet web application。\n\n4.4 其他由于 springboot 的OnXXXCondition类实现太多，不可能每个条件类都分析一遍，因此上面只分析了OnResourceCondition,OnBeanCondition和onWebApplicationCondition的源码。我们分析源码不可能把所有代码都通读一遍的，阅读源码的话，只要理解了某个模块的类之间的关系及挑几个有代表性的类分析下就行，不可能一网打尽。\n若有时间的话，推荐看下几个我们常用的条件类的源码：OnPropertyCondition,OnClassCondition和OnExpressionCondition等。\n\n5 如何扩展 SpringBootCondition前文我们知道了如何扩展 Spring 的Condition接口，那么我们该如何扩展 SpringBoot 的SpringBootCondition类呢？\n推荐阅读springboot 之使用 SpringBootCondition获得答案\n4 SpringBoot是如何实现自动配置的？\n1 前言温故而知新，我们来简单回顾一下上篇的内容，上一篇我们分析了 SpringBoot 的条件注解@ConditionalOnXxx 的相关源码，现挑重点总结如下：\n\nSpringBoot 的所有@ConditionalOnXxx的条件类OnXxxCondition都是继承于SpringBootCondition基类，而SpringBootCondition又实现了Condition接口。\nSpringBootCondition基类主要用来打印一些条件注解评估报告的日志,这些条件评估信息全部来源于其子类注解条件类OnXxxCondition，因此其也抽象了一个模板方法getMatchOutcome留给子类去实现来评估其条件注解是否符合条件。\n前一篇我们也还有一个重要的知识点还没分析，那就是跟过滤自动配置类逻辑有关的AutoConfigurationImportFilter接口，这篇文章我们来填一下这个坑。\n\n前面我们分析了跟 SpringBoot 的自动配置息息相关内置条件注解@ConditionalOnXxx后，现在我们就开始来撸 SpringBoot 自动配置的相关源码了。\n\n2 @SpringBootApplication 注解在开始前，我们先想一下，SpringBoot 为何一个标注有@SpringBootApplication注解的启动类通过执行一个简单的run方法就能实现 SpringBoot 大量Starter的自动配置呢？ 其实 SpringBoot 的自动配置就跟@SpringBootApplication这个注解有关，我们先来看下其这个注解的源码：\n@Target(ElementType.TYPE)\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Inherited\n@SpringBootConfiguration\n@EnableAutoConfiguration\n@ComponentScan(excludeFilters = &#123;\n    @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class),\n    @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class)\n&#125;)\npublic @interface SpringBootApplication &#123;\n    // ...省略非关键代码\n&#125;\n\n@SpringBootApplication标注了很多注解，我们可以看到其中跟 SpringBoot 自动配置有关的注解就有一个即@EnableAutoConfiguration，因此，可以肯定的是 SpringBoot 的自动配置肯定跟@EnableAutoConfiguration息息相关(其中@ComponentScan注解的excludeFilters属性也有一个类AutoConfigurationExcludeFilter,这个类跟自动配置也有点关系，但不是我们关注的重点)。 现在我们来打开@EnableAutoConfiguration注解的源码：\n@Target(ElementType.TYPE)\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Inherited\n@AutoConfigurationPackage\n@Import(AutoConfigurationImportSelector.class)\npublic @interface EnableAutoConfiguration &#123;\n\tString ENABLED_OVERRIDE_PROPERTY = \"spring.boot.enableautoconfiguration\";\n\tClass&lt;?>[] exclude() default &#123;&#125;;\n\tString[] excludeName() default &#123;&#125;;\n&#125;\n\n看到@EnableAutoConfiguration注解又标有@AutoConfigurationPackage和@Import(AutoConfigurationImportSelector.class)两个注解，顾名思义，@AutoConfigurationPackage注解肯定跟自动配置的包有关，而AutoConfigurationImportSelector则是跟 SpringBoot 的自动配置选择导入有关（Spring 中的ImportSelector是用来导入配置类的，通常是基于某些条件注解@ConditionalOnXxxx来决定是否导入某个配置类）。\n因此，可以看出AutoConfigurationImportSelector类是我们本篇的重点，因为 SpringBoot 的自动配置肯定有一个配置类，而这个配置类的导入则需要靠AutoConfigurationImportSelector这个哥们来实现。\n接下来我们重点来看AutoConfigurationImportSelector这个类，完了我们再简单分析下@AutoConfigurationPackage这个注解的逻辑。\n\n3 如何去找 SpringBoot 自动配置实现逻辑的入口方法？可以肯定的是 SpringBoot 的自动配置的逻辑肯定与 AutoConfigurationImportSelector 这个类有关，那么我们该如何去找到 SpringBoot 自动配置实现逻辑的入口方法呢？\n在找 SpringBoot 自动配置实现逻辑的入口方法前，我们先来看下AutoConfigurationImportSelector的相关类图，好有个整体的理解。看下图：\n\n可以看到AutoConfigurationImportSelector重点是实现了DeferredImportSelector接口和各种Aware接口，然后DeferredImportSelector接口又继承了ImportSelector接口。\n自然而然的，我们会去关注AutoConfigurationImportSelector复写DeferredImportSelector接口的实现方法selectImports方法，因为selectImports方法跟导入自动配置类有关，而这个方法往往是程序执行的入口方法。经过调试发现selectImports方法很具有迷惑性，selectImports方法跟自动配置相关的逻辑有点关系，但实质关系不大。\n此时剧情的发展好像不太符合常理，此时我们又该如何来找到自动配置逻辑有关的入口方法呢？\n最简单的方法就是在AutoConfigurationImportSelector类的每个方法都打上断点，然后调试看先执行到哪个方法。但是我们可以不这么做，我们回想下，自定义一个Starter的时候我们是不是要在spring.factories配置文件中配置\nEnableAutoConfiguration=XxxAutoConfiguration\n\n因此可以推断，SpringBoot 的自动配置原理肯定跟从spring.factories配置文件中加载自动配置类有关，于是结合AutoConfigurationImportSelector的方法注释，我们找到了getAutoConfigurationEntry方法。于是我们在这个方法里面打上一个断点，此时通过调用栈帧来看下更上层的入口方法在哪里，然后我们再从跟自动配置相关的更上层的入口方法开始分析。\n\n通过图 1 我们可以看到，跟自动配置逻辑相关的入口方法在DeferredImportSelectorGrouping类的getImports方法处，因此我们就从DeferredImportSelectorGrouping类的getImports方法来开始分析 SpringBoot 的自动配置源码好了。\n\n4 分析 SpringBoot 自动配置原理既然找到ConfigurationClassParser.getImports()方法是自动配置相关的入口方法，那么下面我们就来真正分析 SpringBoot 自动配置的源码了。\n先看一下getImports方法代码：\n// ConfigurationClassParser.java\npublic Iterable&lt;Group.Entry> getImports() &#123;\n    // 遍历DeferredImportSelectorHolder对象集合deferredImports，deferredImports集合装了各种ImportSelector，当然这里装的是AutoConfigurationImportSelector\n    for (DeferredImportSelectorHolder deferredImport : this.deferredImports) &#123;\n    \t// 【1】，利用AutoConfigurationGroup的process方法来处理自动配置的相关逻辑，决定导入哪些配置类（这个是我们分析的重点，自动配置的逻辑全在这了）\n    \tthis.group.process(deferredImport.getConfigurationClass().getMetadata(),\n    \t\t\tdeferredImport.getImportSelector());\n    &#125;\n    // 【2】，经过上面的处理后，然后再进行选择导入哪些配置类\n    return this.group.selectImports();\n&#125;\n\n标【1】处的的代码是我们分析的重中之重，自动配置的相关的绝大部分逻辑全在这里了，将在 4.1 分析自动配置的主要逻辑深入分析。那么this.group.process(deferredImport.getConfigurationClass().getMetadata(), deferredImport.getImportSelector())；主要做的事情就是在this.group即AutoConfigurationGroup对象的process方法中，传入的AutoConfigurationImportSelector对象来选择一些符合条件的自动配置类，过滤掉一些不符合条件的自动配置类，就是这么个事情，无他。\n注：\n\nAutoConfigurationGroup：是AutoConfigurationImportSelector的内部类，主要用来处理自动配置相关的逻辑，拥有process和selectImports方法，然后拥有entries和autoConfigurationEntries集合属性，这两个集合分别存储被处理后的符合条件的自动配置类，我们知道这些就足够了；\nAutoConfigurationImportSelector：承担自动配置的绝大部分逻辑，负责选择一些符合条件的自动配置类；\nmetadata:标注在 SpringBoot 启动类上的@SpringBootApplication注解元数据\n\n标【2】的this.group.selectImports的方法主要是针对前面的process方法处理后的自动配置类再进一步有选择的选择导入，将在 4.2 有选择的导入自动配置类这小节深入分析。\n\n4.1 分析自动配置的主要逻辑这里继续深究前面 4 分析 SpringBoot 自动配置原理这节标【1】处的 this.group.process方法是如何处理自动配置相关逻辑的。\n// AutoConfigurationImportSelector$AutoConfigurationGroup.java\n\n// 这里用来处理自动配置类，比如过滤掉不符合匹配条件的自动配置类\npublic void process(AnnotationMetadata annotationMetadata,\n\t\tDeferredImportSelector deferredImportSelector) &#123;\n\tAssert.state(\n\t\t\tdeferredImportSelector instanceof AutoConfigurationImportSelector,\n\t\t\t() -> String.format(\"Only %s implementations are supported, got %s\",\n\t\t\t\t\tAutoConfigurationImportSelector.class.getSimpleName(),\n\t\t\t\t\tdeferredImportSelector.getClass().getName()));\n\t// 【1】,调用getAutoConfigurationEntry方法得到自动配置类放入autoConfigurationEntry对象中\n\tAutoConfigurationEntry autoConfigurationEntry = ((AutoConfigurationImportSelector) deferredImportSelector)\n\t\t\t.getAutoConfigurationEntry(getAutoConfigurationMetadata(),\n\t\t\t\t\tannotationMetadata);\n\t// 【2】，又将封装了自动配置类的autoConfigurationEntry对象装进autoConfigurationEntries集合\n\tthis.autoConfigurationEntries.add(autoConfigurationEntry);\n\t// 【3】，遍历刚获取的自动配置类\n\tfor (String importClassName : autoConfigurationEntry.getConfigurations()) &#123;\n\t\t// 这里符合条件的自动配置类作为key，annotationMetadata作为值放进entries集合\n\t\tthis.entries.putIfAbsent(importClassName, annotationMetadata);\n\t&#125;\n&#125;\n\n上面代码中我们再来看标【1】的方法getAutoConfigurationEntry，这个方法主要是用来获取自动配置类有关，承担了自动配置的主要逻辑。直接上代码：\n// AutoConfigurationImportSelector.java\n\n// 获取符合条件的自动配置类，避免加载不必要的自动配置类从而造成内存浪费\nprotected AutoConfigurationEntry getAutoConfigurationEntry(\n\t\tAutoConfigurationMetadata autoConfigurationMetadata,\n\t\tAnnotationMetadata annotationMetadata) &#123;\n\t// 获取是否有配置spring.boot.enableautoconfiguration属性，默认返回true\n\tif (!isEnabled(annotationMetadata)) &#123;\n\t\treturn EMPTY_ENTRY;\n\t&#125;\n\t// 获得@Congiguration标注的Configuration类即被审视introspectedClass的注解数据，\n\t// 比如：@SpringBootApplication(exclude = FreeMarkerAutoConfiguration.class)\n\t// 将会获取到exclude = FreeMarkerAutoConfiguration.class和excludeName=\"\"的注解数据\n\tAnnotationAttributes attributes = getAttributes(annotationMetadata);\n\t// 【1】得到spring.factories文件配置的所有自动配置类\n\tList&lt;String> configurations = getCandidateConfigurations(annotationMetadata,\n\t\t\tattributes);\n\t// 利用LinkedHashSet移除重复的配置类\n\tconfigurations = removeDuplicates(configurations);\n\t// 得到要排除的自动配置类，比如注解属性exclude的配置类\n\t// 比如：@SpringBootApplication(exclude = FreeMarkerAutoConfiguration.class)\n\t// 将会获取到exclude = FreeMarkerAutoConfiguration.class的注解数据\n\tSet&lt;String> exclusions = getExclusions(annotationMetadata, attributes);\n\t// 检查要被排除的配置类，因为有些不是自动配置类，故要抛出异常\n\tcheckExcludedClasses(configurations, exclusions);\n\t// 【2】将要排除的配置类移除\n\tconfigurations.removeAll(exclusions);\n\t// 【3】因为从spring.factories文件获取的自动配置类太多，如果有些不必要的自动配置类都加载进内存，会造成内存浪费，因此这里需要进行过滤\n\t// 注意这里会调用AutoConfigurationImportFilter的match方法来判断是否符合@ConditionalOnBean,@ConditionalOnClass或@ConditionalOnWebApplication，后面会重点分析一下\n\tconfigurations = filter(configurations, autoConfigurationMetadata);\n\t// 【4】获取了符合条件的自动配置类后，此时触发AutoConfigurationImportEvent事件，\n\t// 目的是告诉ConditionEvaluationReport条件评估报告器对象来记录符合条件的自动配置类\n\t// 该事件什么时候会被触发？--> 在刷新容器时调用invokeBeanFactoryPostProcessors后置处理器时触发\n\tfireAutoConfigurationImportEvents(configurations, exclusions);\n\t// 【5】将符合条件和要排除的自动配置类封装进AutoConfigurationEntry对象，并返回\n\treturn new AutoConfigurationEntry(configurations, exclusions);\n&#125;\n\nAutoConfigurationEntry方法主要做的事情就是获取符合条件的自动配置类，避免加载不必要的自动配置类从而造成内存浪费。我们下面总结下AutoConfigurationEntry方法主要做的事情：\n【1】从spring.factories配置文件中加载EnableAutoConfiguration自动配置类（注意此时是从缓存中拿到的哈）,获取的自动配置类如图 3 所示。这里我们知道该方法做了什么事情就行了，后面还会有一篇文章详述spring.factories的原理；\n【2】若@EnableAutoConfiguration等注解标有要exclude的自动配置类，那么再将这个自动配置类排除掉；\n【3】排除掉要exclude的自动配置类后，然后再调用filter方法进行进一步的过滤，再次排除一些不符合条件的自动配置类；这个在稍后会详细分析。\n【4】经过重重过滤后，此时再触发AutoConfigurationImportEvent事件，告诉ConditionEvaluationReport条件评估报告器对象来记录符合条件的自动配置类；（这个在 6 AutoConfigurationImportListener 这小节详细分析。）\n【5】 最后再将符合条件的自动配置类返回。\n\n总结了AutoConfigurationEntry方法主要的逻辑后，我们再来细看一下AutoConfigurationImportSelector的filter方法：\n// AutoConfigurationImportSelector.java\n\nprivate List&lt;String> filter(List&lt;String> configurations,\n\t\t\tAutoConfigurationMetadata autoConfigurationMetadata) &#123;\n\tlong startTime = System.nanoTime();\n\t// 将从spring.factories中获取的自动配置类转出字符串数组\n\tString[] candidates = StringUtils.toStringArray(configurations);\n\t// 定义skip数组，是否需要跳过。注意skip数组与candidates数组顺序一一对应\n\tboolean[] skip = new boolean[candidates.length];\n\tboolean skipped = false;\n\t// getAutoConfigurationImportFilters方法：拿到OnBeanCondition，OnClassCondition和OnWebApplicationCondition\n\t// 然后遍历这三个条件类去过滤从spring.factories加载的大量配置类\n\tfor (AutoConfigurationImportFilter filter : getAutoConfigurationImportFilters()) &#123;\n\t\t// 调用各种aware方法，将beanClassLoader,beanFactory等注入到filter对象中，\n\t\t// 这里的filter对象即OnBeanCondition，OnClassCondition或OnWebApplicationCondition\n\t\tinvokeAwareMethods(filter);\n\t\t// 判断各种filter来判断每个candidate（这里实质要通过candidate(自动配置类)拿到其标注的\n\t\t// @ConditionalOnClass,@ConditionalOnBean和@ConditionalOnWebApplication里面的注解值）是否匹配，\n\t\t// 注意candidates数组与match数组一一对应\n\t\t/**********************【主线，重点关注】********************************/\n\t\tboolean[] match = filter.match(candidates, autoConfigurationMetadata);\n\t\t// 遍历match数组，注意match顺序跟candidates的自动配置类一一对应\n\t\tfor (int i = 0; i &lt; match.length; i++) &#123;\n\t\t\t// 若有不匹配的话\n\t\t\tif (!match[i]) &#123;\n\t\t\t\t// 不匹配的将记录在skip数组，标志skip[i]为true，也与candidates数组一一对应\n\t\t\t\tskip[i] = true;\n\t\t\t\t// 因为不匹配，将相应的自动配置类置空\n\t\t\t\tcandidates[i] = null;\n\t\t\t\t// 标注skipped为true\n\t\t\t\tskipped = true;\n\t\t\t&#125;\n\t\t&#125;\n\t&#125;\n\t// 这里表示若所有自动配置类经过OnBeanCondition，OnClassCondition和OnWebApplicationCondition过滤后，全部都匹配的话，则全部原样返回\n\tif (!skipped) &#123;\n\t\treturn configurations;\n\t&#125;\n\t// 建立result集合来装匹配的自动配置类\n\tList&lt;String> result = new ArrayList&lt;>(candidates.length);\n\tfor (int i = 0; i &lt; candidates.length; i++) &#123;\n\t\t// 若skip[i]为false，则说明是符合条件的自动配置类，此时添加到result集合中\n\t\tif (!skip[i]) &#123;\n\t\t\tresult.add(candidates[i]);\n\t\t&#125;\n\t&#125;\n\t// 打印日志\n\tif (logger.isTraceEnabled()) &#123;\n\t\tint numberFiltered = configurations.size() - result.size();\n\t\tlogger.trace(\"Filtered \" + numberFiltered + \" auto configuration class in \"\n\t\t\t\t+ TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startTime)\n\t\t\t\t+ \" ms\");\n\t&#125;\n\t// 最后返回符合条件的自动配置类\n\treturn new ArrayList&lt;>(result);\n&#125;\n\nAutoConfigurationImportSelector的filter方法主要做的事情就是调用AutoConfigurationImportFilter接口的match方法来判断每一个自动配置类上的条件注解（若有的话）@ConditionalOnClass,@ConditionalOnBean或@ConditionalOnWebApplication是否满足条件，若满足，则返回 true，说明匹配，若不满足，则返回 false 说明不匹配。\n我们现在知道AutoConfigurationImportSelector的filter方法主要做了什么事情就行了，现在先不用研究的过深，至于AutoConfigurationImportFilter接口的match方法将在 5 AutoConfigurationImportFilter 这小节再详细分析，填补一下我们前一篇条件注解源码分析中留下的坑。\n注意：我们坚持主线优先的原则，其他枝节代码这里不深究，以免丢了主线哈。\n\n4.2 有选择的导入自动配置类这里继续深究前面 4 分析 SpringBoot 自动配置原理这节标【2】处的 this.group.selectImports方法是如何进一步有选择的导入自动配置类的。直接看代码：\n// AutoConfigurationImportSelector$AutoConfigurationGroup.java\n\npublic Iterable&lt;Entry> selectImports() &#123;\n\tif (this.autoConfigurationEntries.isEmpty()) &#123;\n\t\treturn Collections.emptyList();\n\t&#125;\n\t// 这里得到所有要排除的自动配置类的set集合\n\tSet&lt;String> allExclusions = this.autoConfigurationEntries.stream()\n\t\t\t.map(AutoConfigurationEntry::getExclusions)\n\t\t\t.flatMap(Collection::stream).collect(Collectors.toSet());\n\t// 这里得到经过滤后所有符合条件的自动配置类的set集合\n\tSet&lt;String> processedConfigurations = this.autoConfigurationEntries.stream()\n\t\t\t.map(AutoConfigurationEntry::getConfigurations)\n\t\t\t.flatMap(Collection::stream)\n\t\t\t.collect(Collectors.toCollection(LinkedHashSet::new));\n\t// 移除掉要排除的自动配置类\n\tprocessedConfigurations.removeAll(allExclusions);\n\t// 对标注有@Order注解的自动配置类进行排序，\n\treturn sortAutoConfigurations(processedConfigurations,\n\t\t\tgetAutoConfigurationMetadata())\n\t\t\t\t\t.stream()\n\t\t\t\t\t.map((importClassName) -> new Entry(\n\t\t\t\t\t\t\tthis.entries.get(importClassName), importClassName))\n\t\t\t\t\t.collect(Collectors.toList());\n&#125;\n复制代码\n\n可以看到，selectImports方法主要是针对经过排除掉exclude的和被AutoConfigurationImportFilter接口过滤后的满足条件的自动配置类再进一步排除exclude的自动配置类，然后再排序。逻辑很简单，不再详述。\n不过有个疑问，前面已经exclude过一次了，为何这里还要再exclude一次？\n\n5 AutoConfigurationImportFilter这里继续深究前面 4.1 节的 AutoConfigurationImportSelector.filter方法的过滤自动配置类的boolean[] match = filter.match(candidates, autoConfigurationMetadata);这句代码。\n因此我们继续分析AutoConfigurationImportFilter接口，分析其match方法，同时也是对前一篇@ConditionalOnXxx的源码分析文章中留下的坑进行填补。\nAutoConfigurationImportFilter接口只有一个match方法用来过滤不符合条件的自动配置类。\n@FunctionalInterface\npublic interface AutoConfigurationImportFilter &#123;\n    boolean[] match(String[] autoConfigurationClasses,\n    \t\tAutoConfigurationMetadata autoConfigurationMetadata);\n&#125;\n\n同样，在分析AutoConfigurationImportFilter接口的match方法前，我们先来看下其类关系图：\n\n可以看到,AutoConfigurationImportFilter接口有一个具体的实现类FilteringSpringBootCondition，FilteringSpringBootCondition又有三个具体的子类：OnClassCondition,OnBeanCondtition和OnWebApplicationCondition。\n那么这几个类之间的关系是怎样的呢？\nFilteringSpringBootCondition实现了AutoConfigurationImportFilter接口的match方法，然后在FilteringSpringBootCondition的match方法调用getOutcomes这个抽象模板方法返回自动配置类的匹配与否的信息。同时，最重要的是FilteringSpringBootCondition的三个子类OnClassCondition,OnBeanCondtition和OnWebApplicationCondition将会复写这个模板方法实现自己的匹配判断逻辑。\n好了，AutoConfigurationImportFilter接口的整体关系已经清楚了，现在我们再进入其具体实现类FilteringSpringBootCondition的match方法看看是其如何根据条件过滤自动配置类的。\n// FilteringSpringBootCondition.java\n\n@Override\npublic boolean[] match(String[] autoConfigurationClasses,\n\t\tAutoConfigurationMetadata autoConfigurationMetadata) &#123;\n\t// 创建评估报告\n\tConditionEvaluationReport report = ConditionEvaluationReport\n\t\t\t.find(this.beanFactory);\n\t// 注意getOutcomes是模板方法，将spring.factories文件种加载的所有自动配置类传入\n\t// 子类（这里指的是OnClassCondition,OnBeanCondition和OnWebApplicationCondition类）去过滤\n\t// 注意outcomes数组存储的是不匹配的结果，跟autoConfigurationClasses数组一一对应\n\t/*****************************【主线，重点关注】*********************************************/\n\tConditionOutcome[] outcomes = getOutcomes(autoConfigurationClasses,\n\t\t\tautoConfigurationMetadata);\n\tboolean[] match = new boolean[outcomes.length];\n\t// 遍历outcomes,这里outcomes为null则表示匹配，不为null则表示不匹配\n\tfor (int i = 0; i &lt; outcomes.length; i++) &#123;\n\t\tConditionOutcome outcome = outcomes[i];\n\t\tmatch[i] = (outcome == null || outcome.isMatch());\n\t\tif (!match[i] &amp;&amp; outcomes[i] != null) &#123;\n\t\t\t// 这里若有某个类不匹配的话，此时调用父类SpringBootCondition的logOutcome方法打印日志\n\t\t\tlogOutcome(autoConfigurationClasses[i], outcomes[i]);\n\t\t\t// 并将不匹配情况记录到report\n\t\t\tif (report != null) &#123;\n\t\t\t\treport.recordConditionEvaluation(autoConfigurationClasses[i], this,\n\t\t\t\t\t\toutcomes[i]);\n\t\t\t&#125;\n\t\t&#125;\n\t&#125;\n\treturn match;\n&#125;\n\nFilteringSpringBootCondition的match方法主要做的事情还是调用抽象模板方法getOutcomes来根据条件来过滤自动配置类，而复写getOutcomes模板方法的有三个子类，这里不再一一分析，只挑选**OnClassCondition**复写的**getOutcomes**方法进行分析。\n\n5.1 OnClassCondition先直接上OnClassCondition复写的getOutcomes方法的代码：\n// OnClassCondition.java\n\nprotected final ConditionOutcome[] getOutcomes(String[] autoConfigurationClasses,\n\t\tAutoConfigurationMetadata autoConfigurationMetadata) &#123;\n\t// Split the work and perform half in a background thread. Using a single\n\t// additional thread seems to offer the best performance. More threads make\n\t// things worse\n\t// 这里经过测试用两个线程去跑的话性能是最好的，大于两个线程性能反而变差\n\tint split = autoConfigurationClasses.length / 2;\n\t// 【1】开启一个新线程去扫描判断已经加载的一半自动配置类\n\tOutcomesResolver firstHalfResolver = createOutcomesResolver(\n\t\t\tautoConfigurationClasses, 0, split, autoConfigurationMetadata);\n\t// 【2】这里用主线程去扫描判断已经加载的一半自动配置类\n\tOutcomesResolver secondHalfResolver = new StandardOutcomesResolver(\n\t\t\tautoConfigurationClasses, split, autoConfigurationClasses.length,\n\t\t\tautoConfigurationMetadata, getBeanClassLoader());\n\t// 【3】先让主线程去执行解析一半自动配置类是否匹配条件\n\tConditionOutcome[] secondHalf = secondHalfResolver.resolveOutcomes();\n\t// 【4】这里用新开启的线程取解析另一半自动配置类是否匹配\n\t// 注意为了防止主线程执行过快结束，resolveOutcomes方法里面调用了thread.join()来\n\t// 让主线程等待新线程执行结束，因为后面要合并两个线程的解析结果\n\tConditionOutcome[] firstHalf = firstHalfResolver.resolveOutcomes();\n\t// 新建一个ConditionOutcome数组来存储自动配置类的筛选结果\n\tConditionOutcome[] outcomes = new ConditionOutcome[autoConfigurationClasses.length];\n\t// 将前面两个线程的筛选结果分别拷贝进outcomes数组\n\tSystem.arraycopy(firstHalf, 0, outcomes, 0, firstHalf.length);\n\tSystem.arraycopy(secondHalf, 0, outcomes, split, secondHalf.length);\n\t// 返回自动配置类的筛选结果\n\treturn outcomes;\n&#125;\n\n可以看到，OnClassCondition的getOutcomes方法主要解析自动配置类是否符合匹配条件，当然这个匹配条件指自动配置类上的注解@ConditionalOnClass指定的类存不存在于classpath中，存在则返回匹配，不存在则返回不匹配。\n由于解析自动配置类是否匹配比较耗时，因此从上面代码中我们可以看到分别创建了firstHalfResolver和secondHalfResolver两个解析对象，这两个解析对象个分别对应一个线程去解析加载的自动配置类是否符合条件，最终将两个线程的解析自动配置类的匹配结果合并后返回。\n那么自动配置类是否符合条件的解析判断过程又是怎样的呢？现在我们分别来看一下上面代码注释标注的【1】，【2】，【3】和【4】处。\n\n5.1.1 createOutcomesResolver这里对应前面 5.1 节的代码注释标注【1】处的OutcomesResolver firstHalfResolver = createOutcomesResolver(...);的方法：\n// OnClassCondition.java\n\nprivate OutcomesResolver createOutcomesResolver(String[] autoConfigurationClasses,\n\t\tint start, int end, AutoConfigurationMetadata autoConfigurationMetadata) &#123;\n\t// 新建一个StandardOutcomesResolver对象\n\tOutcomesResolver outcomesResolver = new StandardOutcomesResolver(\n\t\t\tautoConfigurationClasses, start, end, autoConfigurationMetadata,\n\t\t\tgetBeanClassLoader());\n\ttry &#123;\n\t\t// new一个ThreadedOutcomesResolver对象，并将StandardOutcomesResolver类型的outcomesResolver对象作为构造器参数传入\n\t\treturn new ThreadedOutcomesResolver(outcomesResolver);\n\t&#125;\n\t// 若上面开启的线程抛出AccessControlException异常，则返回StandardOutcomesResolver对象\n\tcatch (AccessControlException ex) &#123;\n\t\treturn outcomesResolver;\n\t&#125;\n&#125;\n复制代码\n\n可以看到createOutcomesResolver方法创建了一个封装了StandardOutcomesResolver类的ThreadedOutcomesResolver解析对象。 我们再来看下ThreadedOutcomesResolver这个线程解析类封装StandardOutcomesResolver这个对象的目的是什么？我们继续跟进代码：\n// OnClassCondtion.java\n\nprivate ThreadedOutcomesResolver(OutcomesResolver outcomesResolver) &#123;\n\t// 这里开启一个新的线程，这个线程其实还是利用StandardOutcomesResolver的resolveOutcomes方法\n\t// 对自动配置类进行解析判断是否匹配\n\tthis.thread = new Thread(\n\t\t\t() -> this.outcomes = outcomesResolver.resolveOutcomes());\n\t// 开启线程\n\tthis.thread.start();\n&#125;\n复制代码\n\n可以看到在构造ThreadedOutcomesResolver对象时候，原来是开启了一个线程，然后这个线程其实还是调用了刚传进来的StandardOutcomesResolver对象的resolveOutcomes方法去解析自动配置类。具体如何解析呢？稍后我们在分析【3】处代码secondHalfResolver.resolveOutcomes();的时候再深究。\n\n5.1.2 new StandardOutcomesResolver这里对应前面 5.1 节的【2】处的代码OutcomesResolver secondHalfResolver = new StandardOutcomesResolver(...);，逻辑很简单，就是创建了一个StandardOutcomesResolver对象，用于后面解析自动配置类是否匹配，同时，新建的一个线程也是利用它来完成自动配置类的解析的。\n\n5.1.3 StandardOutcomesResolver.resolveOutcomes 方法这里对应前面 5.1 节标注的【3】的代码ConditionOutcome[] secondHalf = secondHalfResolver.resolveOutcomes();。\n这里StandardOutcomesResolver.resolveOutcomes方法承担了解析自动配置类匹配与否的全部逻辑，是我们要重点分析的方法，resolveOutcomes方法最终把解析的自动配置类的结果赋给secondHalf数组。那么它是如何解析自动配置类是否匹配条件的呢？\n// OnClassCondition$StandardOutcomesResolver.java\n\npublic ConditionOutcome[] resolveOutcomes() &#123;\n\t// 再调用getOutcomes方法来解析\n\treturn getOutcomes(this.autoConfigurationClasses, this.start, this.end,\n\t\t\tthis.autoConfigurationMetadata);\n&#125;\n\nprivate ConditionOutcome[] getOutcomes(String[] autoConfigurationClasses,\n\t\tint start, int end, AutoConfigurationMetadata autoConfigurationMetadata) &#123; // 只要autoConfigurationMetadata没有存储相关自动配置类，那么outcome默认为null，则说明匹配\n\tConditionOutcome[] outcomes = new ConditionOutcome[end - start];\n\t// 遍历每一个自动配置类\n\tfor (int i = start; i &lt; end; i++) &#123;\n\t\tString autoConfigurationClass = autoConfigurationClasses[i];\n\t\t// TODO 对于autoConfigurationMetadata有个疑问：为何有些自动配置类的条件注解能被加载到autoConfigurationMetadata，而有些又不能，比如自己定义的一个自动配置类HelloWorldEnableAutoConfiguration就没有被存到autoConfigurationMetadata中\n\t\tif (autoConfigurationClass != null) &#123;\n\t\t\t// 这里取出注解在AutoConfiguration自动配置类类的@ConditionalOnClass注解的指定类的全限定名，\n\t\t\t// 举个栗子，看下面的KafkaStreamsAnnotationDrivenConfiguration这个自动配置类\n\t\t\t/**\n\t\t\t * @ConditionalOnClass(StreamsBuilder.class)\n\t\t\t * class KafkaStreamsAnnotationDrivenConfiguration &#123;\n\t\t\t * // 省略无关代码\n\t\t\t * &#125;\n\t\t\t */\n\t\t\t// 那么取出的就是StreamsBuilder类的全限定名即candidates = org.apache.kafka.streams.StreamsBuilder\n\t\t\tString candidates = autoConfigurationMetadata\n\t\t\t\t\t.get(autoConfigurationClass, \"ConditionalOnClass\"); // 因为这里是处理某个类是否存在于classpath中，所以传入的key是ConditionalOnClass\n\t\t\t// 若自动配置类标有ConditionalOnClass注解且有值，此时调用getOutcome判断是否存在于类路径中\n\t\t\tif (candidates != null) &#123;\n\t\t\t\t// 拿到自动配置类注解@ConditionalOnClass的值后，再调用getOutcome方法去判断匹配结果,若该类存在于类路径，则getOutcome返回null，否则非null\n\t\t\t\t/*******************【主线，重点关注】******************/\n\t\t\t\toutcomes[i - start] = getOutcome(candidates);\n\t\t\t&#125;\n\t\t&#125;\n\t&#125;\n\treturn outcomes;\n&#125;\n复制代码\n\n可以看到StandardOutcomesResolver.resolveOutcomes的方法中再次调用getOutcomes方法，主要是从autoConfigurationMetadata对象中获取到自动配置类上的注解@ConditionalOnClass指定的类的全限定名，然后作为参数传入getOutcome方法用于去类路径加载该类，若能加载到则说明注解@ConditionalOnClass满足条件，此时说明自动配置类匹配成功。\n但是别忘了，这里只是过了@ConditionalOnClass注解这一关，若自动配置类还有其他注解比如@ConditionalOnBean，若该@ConditionalOnBean注解不满足条件的话，同样最终结果是不匹配的。这里扯的有点远，我们回到OnClassCondtion的判断逻辑，继续进入getOutcome方法看它是如何去判断@ConditionalOnClass注解满不满足条件的。\n// OnClassCondition$StandardOutcomesResolver.java\n\n// 返回的outcome记录的是不匹配的情况，不为null，则说明不匹配；为null，则说明匹配\nprivate ConditionOutcome getOutcome(String candidates) &#123;\n\t// candidates的形式为“org.springframework.boot.autoconfigure.aop.AopAutoConfiguration.ConditionalOnClass=org.aspectj.lang.annotation.Aspect,org.aspectj.lang.reflect.Advice,org.aspectj.weaver.AnnotatedElement”\n\ttry &#123;// 自动配置类上@ConditionalOnClass的值只有一个的话，直接调用getOutcome方法判断是否匹配\n\t\tif (!candidates.contains(\",\")) &#123;\n\t\t\t// 看到因为传入的参数是 ClassNameFilter.MISSING，因此可以猜测这里应该是得到不匹配的结果\n\t\t\t/******************【主线，重点关注】********************/\n\t\t\treturn getOutcome(candidates, ClassNameFilter.MISSING,\n\t\t\t\t\tthis.beanClassLoader);\n\t\t&#125;\n\t\t// 自动配置类上@ConditionalOnClass的值有多个的话，则遍历每个值（其值以逗号，分隔）\n\t\tfor (String candidate : StringUtils\n\t\t\t\t.commaDelimitedListToStringArray(candidates)) &#123;\n\t\t\tConditionOutcome outcome = getOutcome(candidate,\n\t\t\t\t\tClassNameFilter.MISSING, this.beanClassLoader);\n\t\t\t// 可以看到，这里只要有一个不匹配的话，则返回不匹配结果\n\t\t\tif (outcome != null) &#123;\n\t\t\t\treturn outcome;\n\t\t\t&#125;\n\t\t&#125;\n\t&#125;\n\tcatch (Exception ex) &#123;\n\t\t// We'll get another chance later\n\t&#125;\n\treturn null;\n&#125;\n复制代码\n\n可以看到，getOutcome方法再次调用重载方法getOutcome进一步去判断注解@ConditionalOnClass指定的类存不存在类路径中，跟着主线继续跟进去：\n// OnClassCondition$StandardOutcomesResolver.java\n\nprivate ConditionOutcome getOutcome(String className,\n\t\tClassNameFilter classNameFilter, ClassLoader classLoader) &#123;\n\t// 调用classNameFilter的matches方法来判断`@ConditionalOnClass`指定的类存不存在类路径中\n\t/******************【主线，重点关注】********************/\n\tif (classNameFilter.matches(className, classLoader)) &#123; // 这里调用classNameFilter去判断className是否存在于类路径中，其中ClassNameFilter又分为PRESENT和MISSING两种;目前只看到ClassNameFilter为MISSING的调用情况，所以默认为true的话记录不匹配信息；若传入ClassNameFilter为PRESENT的话，估计还要再写一个else分支\n\t\treturn ConditionOutcome.noMatch(ConditionMessage\n\t\t\t\t.forCondition(ConditionalOnClass.class)\n\t\t\t\t.didNotFind(\"required class\").items(Style.QUOTE, className));\n\t&#125;\n\treturn null;\n&#125;\n复制代码\n\n我们一层一层的剥，最终剥到了最底层了，这个真的需要足够耐心，没办法，源码只能一点一点的啃，嘿嘿。可以看到最终是调用ClassNameFilter的matches方法来判断@ConditionalOnClass指定的类存不存在类路径中,若不存在的话，则返回不匹配。\n我们继续跟进ClassNameFilter的源码：\n// FilteringSpringBootCondition.java\n\nprotected enum ClassNameFilter &#123;\n\t// 这里表示指定的类存在于类路径中，则返回true\n\tPRESENT &#123;\n\n\t\t@Override\n\t\tpublic boolean matches(String className, ClassLoader classLoader) &#123;\n\t\t\treturn isPresent(className, classLoader);\n\t\t&#125;\n\n\t&#125;,\n\t// 这里表示指定的类不存在于类路径中，则返回true\n\tMISSING &#123;\n\n\t\t@Override\n\t\tpublic boolean matches(String className, ClassLoader classLoader) &#123;\n\t\t\treturn !isPresent(className, classLoader); // 若classpath不存在className这个类，则返回true\n\t\t&#125;\n\n\t&#125;;\n\t// 这又是一个抽象方法，分别被PRESENT和MISSING枚举类实现\n\tpublic abstract boolean matches(String className, ClassLoader classLoader);\n\t// 检查指定的类是否存在于类路径中\n\tpublic static boolean isPresent(String className, ClassLoader classLoader) &#123;\n\t\tif (classLoader == null) &#123;\n\t\t\tclassLoader = ClassUtils.getDefaultClassLoader();\n\t\t&#125;\n\t\t// 利用类加载器去加载相应类，若没有抛出异常则说明类路径中存在该类，此时返回true\n\t\ttry &#123;\n\t\t\tforName(className, classLoader);\n\t\t\treturn true;\n\t\t&#125;// 若不存在于类路径中，此时抛出的异常将catch住，返回false。\n\t\tcatch (Throwable ex) &#123;\n\t\t\treturn false;\n\t\t&#125;\n\t&#125;\n\t// 利用类加载器去加载指定的类\n\tprivate static Class&lt;?> forName(String className, ClassLoader classLoader)\n\t\t\tthrows ClassNotFoundException &#123;\n\t\tif (classLoader != null) &#123;\n\t\t\treturn classLoader.loadClass(className);\n\t\t&#125;\n\t\treturn Class.forName(className);\n\t&#125;\n\n&#125;\n复制代码\n\n\n可以看到ClassNameFilter原来是FilteringSpringBootCondition的一个内部枚举类，其实现了判断指定类是否存在于classpath中的逻辑，这个类很简单，这里不再详述。\n\n5.1.4 ThreadedOutcomesResolver.resolveOutcomes 方法这里对应前面 5.1 节的标注的【4】的代码ConditionOutcome[] firstHalf = firstHalfResolver.resolveOutcomes()。\n前面分析 5.1.3 StandardOutcomesResolver.resolveOutcomes 方法已经刨根追底，陷入细节比较深，现在我们需要跳出来继续看前面标注的【4】的代码ConditionOutcome[] firstHalf = firstHalfResolver.resolveOutcomes()的方法哈。\n这里是用新开启的线程去调用StandardOutcomesResolver.resolveOutcomes方法解析另一半自动配置类是否匹配，因为是新线程，这里很可能会出现这么一种情况：主线程解析完属于自己解析的一半自动配置类后，那么久继续往下跑了，此时不会等待新开启的子线程的。\n因此，为了让主线程解析完后，我们需要让主线程继续等待正在解析的子线程，直到子线程结束。那么我们继续跟进代码区看下ThreadedOutcomesResolver.resolveOutcomes方法是怎样实现让主线程等待子线程的：\n// OnClassCondition$ThreadedOutcomesResolver.java\n\npublic ConditionOutcome[] resolveOutcomes() &#123;\n\ttry &#123;\n\t\t// 调用子线程的Join方法，让主线程等待\n\t\tthis.thread.join();\n\t&#125;\n\tcatch (InterruptedException ex) &#123;\n\t\tThread.currentThread().interrupt();\n\t&#125;\n\t// 若子线程结束后，此时返回子线程的解析结果\n\treturn this.outcomes;\n&#125;\n复制代码\n\n\n可以看到用了Thread.join()方法来让主线程等待正在解析自动配置类的子线程，这里应该也可以用CountDownLatch来让主线程等待子线程结束。最终将子线程解析后的结果赋给firstHalf数组。\n\n5.2 OnBeanCondition 和 OnWebApplicationCondition前面 5.1 OnClassCondition 节深入分析了OnClassCondition是如何过滤自动配置类的，那么自动配置类除了要经过OnClassCondition的过滤，还要经过OnBeanCondition和OnWebApplicationCondition这两个条件类的过滤，这里不再详述，有兴趣的小伙伴可自行分析。\n\n6 AutoConfigurationImportListener这里继续深究前面 4.1 节的 AutoConfigurationImportSelector.getAutoConfigurationEntry方法的触发自动配置类过滤完毕的事件fireAutoConfigurationImportEvents(configurations, exclusions);这句代码。\n我们直接点进fireAutoConfigurationImportEvents方法看看其是如何触发事件的：\n// AutoConfigurationImportSelector.java\n\nprivate void fireAutoConfigurationImportEvents(List&lt;String> configurations,\n\t\tSet&lt;String> exclusions) &#123;\n\t// 从spring.factories总获取到AutoConfigurationImportListener即ConditionEvaluationReportAutoConfigurationImportListener\n\tList&lt;AutoConfigurationImportListener> listeners = getAutoConfigurationImportListeners();\n\tif (!listeners.isEmpty()) &#123;\n\t\t// 新建一个AutoConfigurationImportEvent事件\n\t\tAutoConfigurationImportEvent event = new AutoConfigurationImportEvent(this,\n\t\t\t\tconfigurations, exclusions);\n\t\t// 遍历刚获取到的AutoConfigurationImportListener\n\t\tfor (AutoConfigurationImportListener listener : listeners) &#123;\n\t\t\t// 这里调用各种Aware方法用于触发事件前赋值，比如设置factory,environment等\n\t\t\tinvokeAwareMethods(listener);\n\t\t\t// 真正触发AutoConfigurationImportEvent事件即回调listener的onXXXEveent方法。这里用于记录自动配置类的评估信息\n\t\t\tlistener.onAutoConfigurationImportEvent(event);\n\t\t&#125;\n\t&#125;\n&#125;\n\n\n如上，fireAutoConfigurationImportEvents方法做了以下两件事情：\n1、调用getAutoConfigurationImportListeners方法从spring.factoris配置文件获取实现AutoConfigurationImportListener接口的事件监听器；如下图，可以看到获取的是ConditionEvaluationReportAutoConfigurationImportListener：\n\n2、遍历获取的各个事件监听器，然后调用监听器各种Aware方法给监听器赋值，最后再依次回调事件监听器的onAutoConfigurationImportEvent方法，执行监听事件的逻辑。\n此时我们再来看下ConditionEvaluationReportAutoConfigurationImportListener监听器监听到事件后，它的onAutoConfigurationImportEvent方法究竟做了哪些事情：\n// ConditionEvaluationReportAutoConfigurationImportListener.java\n\npublic void onAutoConfigurationImportEvent(AutoConfigurationImportEvent event) &#123;\n\tif (this.beanFactory != null) &#123;\n\t\t// 获取到条件评估报告器对象\n\t\tConditionEvaluationReport report = ConditionEvaluationReport\n\t\t\t\t.get(this.beanFactory);\n\t\t// 将符合条件的自动配置类记录到unconditionalClasses集合中\n\t\treport.recordEvaluationCandidates(event.getCandidateConfigurations());\n\t\t// 将要exclude的自动配置类记录到exclusions集合中\n\t\treport.recordExclusions(event.getExclusions());\n\t&#125;\n&#125;\n\n\n可以看到，ConditionEvaluationReportAutoConfigurationImportListener监听器监听到事件后，做的事情很简单，只是分别记录下符合条件和被exclude的自动配置类。\n\n7 AutoConfigurationPackages前面已经详述了 SpringBoot 的自动配置原理了，最后的最后，跟 SpringBoot 自动配置有关的注解@AutoConfigurationPackage还没分析，我们来看下这个注解的源码：\n@Target(ElementType.TYPE)\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Inherited\n@Import(AutoConfigurationPackages.Registrar.class)\npublic @interface AutoConfigurationPackage &#123;\n&#125;\n\n\n可以看到@AutoConfigurationPackage注解是跟 SpringBoot 自动配置所在的包相关的，即将 添加该注解的类所在的 package 作为 自动配置 package 进行管理。\n接下来我们再看看AutoConfigurationPackages.Registrar类是干嘛的，直接看源码：\n//AutoConfigurationPackages.Registrar.java\n\nstatic class Registrar implements ImportBeanDefinitionRegistrar, DeterminableImports &#123;\n    @Override\n    public void registerBeanDefinitions(AnnotationMetadata metadata,\n    \t\tBeanDefinitionRegistry registry) &#123;\n    \tregister(registry, new PackageImport(metadata).getPackageName());\n    &#125;\n\n    @Override\n    public Set&lt;Object> determineImports(AnnotationMetadata metadata) &#123;\n    \treturn Collections.singleton(new PackageImport(metadata));\n    &#125;\n&#125;\n\n\n可以看到Registrar类是AutoConfigurationPackages的静态内部类，实现了ImportBeanDefinitionRegistrar和DeterminableImports两个接口。现在我们主要来关注下Registrar实现的registerBeanDefinitions方法,顾名思义，这个方法是注册bean定义的方法。看到它又调用了AutoConfigurationPackages的register方法，继续跟进源码：\n// AutoConfigurationPackages.java\n\npublic static void register(BeanDefinitionRegistry registry, String... packageNames) &#123;\n\tif (registry.containsBeanDefinition(BEAN)) &#123;\n\t\tBeanDefinition beanDefinition = registry.getBeanDefinition(BEAN);\n\t\tConstructorArgumentValues constructorArguments = beanDefinition\n\t\t\t\t.getConstructorArgumentValues();\n\t\tconstructorArguments.addIndexedArgumentValue(0,\n\t\t\t\taddBasePackages(constructorArguments, packageNames));\n\t&#125;\n\telse &#123;\n\t\tGenericBeanDefinition beanDefinition = new GenericBeanDefinition();\n\t\tbeanDefinition.setBeanClass(BasePackages.class);\n\t\tbeanDefinition.getConstructorArgumentValues().addIndexedArgumentValue(0,\n\t\t\t\tpackageNames);\n\t\tbeanDefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);\n\t\tregistry.registerBeanDefinition(BEAN, beanDefinition);\n\t&#125;\n&#125;\n\n\n如上，可以看到register方法注册了一个packageNames即自动配置类注解@EnableAutoConfiguration所在的所在的包名相关的bean。那么注册这个bean的目的是为了什么呢？ 结合官网注释知道，注册这个自动配置包名相关的bean是为了被其他地方引用，比如JPA entity scanner，具体拿来干什么久不知道了，这里不再深究了。\n\n8 小结好了，SpringBoot 的自动配置的源码分析就到这里了，比较长，有些地方也很深入细节，读完需要一定的耐心。\n最后，我们再总结下 SpringBoot 自动配置的原理，主要做了以下事情：\n\n从 spring.factories 配置文件中加载自动配置类；\n加载的自动配置类中排除掉@EnableAutoConfiguration注解的exclude属性指定的自动配置类；\n然后再用AutoConfigurationImportFilter接口去过滤自动配置类是否符合其标注注解（若有标注的话）@ConditionalOnClass,@ConditionalOnBean和@ConditionalOnWebApplication的条件，若都符合的话则返回匹配结果；\n然后触发AutoConfigurationImportEvent事件，告诉ConditionEvaluationReport条件评估报告器对象来分别记录符合条件和exclude的自动配置类。\n最后 spring 再将最后筛选后的自动配置类导入 IOC 容器中\n\n最后留个自己的疑问，还望知道答案的大佬解答，这里表示感谢：\n\n\n\n\n\n\n\n\n\n为了避免加载不必要的自动配置类造成内存浪费，FilteringSpringBootCondition用于过滤spring.factories文件的自动配置类，而FilteringSpringBootCondition为啥只有OnOnBeanCondition,OnClassCondition和onWebApplicationCondition这三个条件类用于过滤，为啥没有onPropertyCondtion，onResourceCondition等条件类来过滤自动配置类呢？\n5 SpringBoot的配置属性值是如何绑定的？\n1 前言温故而知新，我们来简单回顾一下上篇的内容，上一篇我们分析了 SpringBoot 的自动配置的相关源码，自动配置相关源码主要有以下几个重要的步骤：\n\n从 spring.factories 配置文件中加载自动配置类；\n加载的自动配置类中排除掉@EnableAutoConfiguration注解的exclude属性指定的自动配置类；\n然后再用AutoConfigurationImportFilter接口去过滤自动配置类是否符合其标注注解（若有标注的话）@ConditionalOnClass,@ConditionalOnBean和@ConditionalOnWebApplication的条件，若都符合的话则返回匹配结果；\n然后触发AutoConfigurationImportEvent事件，告诉ConditionEvaluationReport条件评估报告器对象来分别记录符合条件和exclude的自动配置类。\n最后 spring 再将最后筛选后的自动配置类导入 IOC 容器中\n\n本篇继续来分析 SpringBoot 的自动配置的相关源码，我们来分析下@EnableConfigurationProperties和@EnableConfigurationProperties这两个注解，来探究下外部配置属性值是如何被绑定到 **@ConfigurationProperties** 注解的类属性中的？\n\n\n\n\n\n\n\n\n\n举个栗子：以配置 web 项目的服务器端口为例，若我们要将服务器端口配置为8081，那么我们会在application.properties配置文件中配置server.port=8081，此时该配置值8081就将会绑定到被@ConfigurationProperties注解的类ServerProperties的属性port上，从而使得配置生效。\n\n2 @EnableConfigurationProperties我们接着前面的设置服务器端口的栗子来分析，我们先直接来看看ServerProperties的源码，应该能找到源码的入口：\n@ConfigurationProperties(prefix = \"server\", ignoreUnknownFields = true)\npublic class ServerProperties &#123;\n\t/**\n\t * Server HTTP port.\n\t */\n\tprivate Integer port;\n\t// ...省略非关键代码\n&#125;\n\n可以看到，ServerProperties类上标注了@ConfigurationProperties这个注解，服务器属性配置前缀为server，是否忽略未知的配置值（ignoreUnknownFields）设置为true。\n那么我们再来看下@ConfigurationProperties这个注解的源码：\n@Target(&#123; ElementType.TYPE, ElementType.METHOD &#125;)\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\npublic @interface ConfigurationProperties &#123;\n\n\t// 前缀别名\n\t@AliasFor(\"prefix\")\n\tString value() default \"\";\n\n\t// 前缀\n\t@AliasFor(\"value\")\n\tString prefix() default \"\";\n\n\t// 忽略无效的配置属性\n\tboolean ignoreInvalidFields() default false;\n\n\t// 忽略未知的配置属性\n\tboolean ignoreUnknownFields() default true;\n&#125;\n\n@ConfigurationProperties这个注解的作用就是将外部配置的配置值绑定到其注解的类的属性上，可以作用于配置类或配置类的方法上。可以看到@ConfigurationProperties注解除了有设置前缀，是否忽略一些不存在或无效的配置等属性等外，这个注解没有其他任何的处理逻辑，可以看到@ConfigurationProperties是一个标志性的注解，源码入口不在这里。\n这里讲的是服务器的自动配置，自然而然的，我们来看下自动配置类ServletWebServerFactoryAutoConfiguration的源码：\n@Configuration\n@EnableConfigurationProperties(ServerProperties.class)\n// ...省略非关键注解\npublic class ServletWebServerFactoryAutoConfiguration &#123;\n\t// ...省略非关键代码\n&#125;\n\n为了突出重点，我已经把ServletWebServerFactoryAutoConfiguration的非关键代码和非关键注解省略掉了。可以看到，ServletWebServerFactoryAutoConfiguration自动配置类中有一个@EnableConfigurationProperties注解，且注解值是前面讲的ServerProperties.class，因此@EnableConfigurationProperties注解肯定就是我们关注的重点了。\n同样，再来看下@EnableConfigurationProperties注解的源码：\n@Target(ElementType.TYPE)\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Import(EnableConfigurationPropertiesImportSelector.class)\npublic @interface EnableConfigurationProperties &#123;\n\n\t// 这个值指定的类就是@ConfigurationProperties注解标注的类，其将会被注册到spring容器中\n\tClass&lt;?>[] value() default &#123;&#125;;\n\n&#125;\n\n@EnableConfigurationProperties注解的主要作用就是为@ConfigurationProperties注解标注的类提供支持，即对将外部配置属性值（比如 application.properties 配置值）绑定到@ConfigurationProperties标注的类的属性中。\n\n\n\n\n\n\n\n\n\n注意：SpringBoot 源码中还存在了ConfigurationPropertiesAutoConfiguration这个自动配置类，同时spring.factories配置文件中的EnableAutoConfiguration接口也配置了ConfigurationPropertiesAutoConfiguration，这个自动配置类上也有@EnableConfigurationProperties这个注解，堆属性绑定进行了默认开启。\n那么，**@EnableConfigurationProperties**这个注解对属性绑定提供怎样的支持呢？\n可以看到@EnableConfigurationProperties这个注解上还标注了@Import(EnableConfigurationPropertiesImportSelector.class)，其导入了EnableConfigurationPropertiesImportSelector，因此可以肯定的是@EnableConfigurationProperties这个注解对属性绑定提供的支持必定跟EnableConfigurationPropertiesImportSelector有关。\n到了这里，EnableConfigurationPropertiesImportSelector这个哥们是我们接下来要分析的对象，那么我们下面继续来分析EnableConfigurationPropertiesImportSelector是如何承担将外部配置属性值绑定到@ConfigurationProperties标注的类的属性中的。\n\n3 EnableConfigurationPropertiesImportSelectorEnableConfigurationPropertiesImportSelector类的作用主要用来处理外部属性绑定的相关逻辑，其实现了ImportSelector接口，我们都知道，实现ImportSelector接口的selectImports方法可以向容器中注册 bean。\n那么，我们来看下EnableConfigurationPropertiesImportSelector覆写的selectImports方法：\n// EnableConfigurationPropertiesImportSelector.java\n\nclass EnableConfigurationPropertiesImportSelector implements ImportSelector &#123;\n        // IMPORTS数组即是要向spring容器中注册的bean\n\tprivate static final String[] IMPORTS = &#123;\n\t\t\tConfigurationPropertiesBeanRegistrar.class.getName(),\n\t\t\tConfigurationPropertiesBindingPostProcessorRegistrar.class.getName() &#125;;\n\n\t@Override\n\tpublic String[] selectImports(AnnotationMetadata metadata) &#123;\n\t\t// 返回ConfigurationPropertiesBeanRegistrar和ConfigurationPropertiesBindingPostProcessorRegistrar的全限定名\n\t\t// 即上面两个类将会被注册到Spring容器中\n\t\treturn IMPORTS;\n\t&#125;\n\n&#125;\n\n可以看到EnableConfigurationPropertiesImportSelector类中的selectImports方法中返回的是IMPORTS数组，而这个IMPORTS是一个常量数组，值是ConfigurationPropertiesBeanRegistrar和ConfigurationPropertiesBindingPostProcessorRegistrar。即EnableConfigurationPropertiesImportSelector的作用是向 Spring 容器中注册了ConfigurationPropertiesBeanRegistrar和ConfigurationPropertiesBindingPostProcessorRegistrar这两个bean。\n我们在EnableConfigurationPropertiesImportSelector类中没看到处理外部属性绑定的相关逻辑，其只是注册了ConfigurationPropertiesBeanRegistrar和ConfigurationPropertiesBindingPostProcessorRegistrar这两个bean,接下来我们再看下注册的这两个bean类。\n\n4 ConfigurationPropertiesBeanRegistrar我们先来看下ConfigurationPropertiesBeanRegistrar这个类。\nConfigurationPropertiesBeanRegistrar是EnableConfigurationPropertiesImportSelector的内部类，其实现了ImportBeanDefinitionRegistrar接口，覆写了registerBeanDefinitions方法。可见，ConfigurationPropertiesBeanRegistrar又是用来注册一些bean definition的，即也是向Spring容器中注册一些 bean。\n先看下ConfigurationPropertiesBeanRegistrar的源码：\n// ConfigurationPropertiesBeanRegistrar$ConfigurationPropertiesBeanRegistrar.java\n\npublic static class ConfigurationPropertiesBeanRegistrar\n\t\t\timplements ImportBeanDefinitionRegistrar &#123;\n\t@Override\n\tpublic void registerBeanDefinitions(AnnotationMetadata metadata,  // metadata是AnnotationMetadataReadingVisitor对象，存储了某个配置类的元数据\n\t\t\tBeanDefinitionRegistry registry) &#123;\n\t\t// （1）得到@EnableConfigurationProperties注解的所有属性值,\n\t\t// 比如@EnableConfigurationProperties(ServerProperties.class),那么得到的值是ServerProperties.class\n\t\t// （2）然后再将得到的@EnableConfigurationProperties注解的所有属性值注册到容器中\n\t\tgetTypes(metadata).forEach((type) -> register(registry,\n\t\t\t\t(ConfigurableListableBeanFactory) registry, type));\n\t&#125;\n&#125;\n\n在ConfigurationPropertiesBeanRegistrar实现的registerBeanDefinitions中，可以看到主要做了两件事：\n\n调用getTypes方法获取@EnableConfigurationProperties注解的属性值XxxProperties；\n调用register方法将获取的属性值XxxProperties注册到Spring容器中，用于以后和外部属性绑定时使用。\n\n我们来看下getTypes方法的源码：\n// ConfigurationPropertiesBeanRegistrar$ConfigurationPropertiesBeanRegistrar.java\n\nprivate List&lt;Class&lt;?>> getTypes(AnnotationMetadata metadata) &#123;\n\t// 得到@EnableConfigurationProperties注解的所有属性值,\n\t// 比如@EnableConfigurationProperties(ServerProperties.class),那么得到的值是ServerProperties.class\n\tMultiValueMap&lt;String, Object> attributes = metadata\n\t\t\t.getAllAnnotationAttributes(\n\t\t\t\t\tEnableConfigurationProperties.class.getName(), false);\n\t// 将属性值取出装进List集合并返回\n\treturn collectClasses((attributes != null) ? attributes.get(\"value\")\n\t\t\t: Collections.emptyList());\n&#125;\n\ngetTypes方法里面的逻辑很简单即将@EnableConfigurationProperties注解里面的属性值XxxProperties（比如ServerProperties.class）取出并装进List集合并返回。\n由getTypes方法拿到@EnableConfigurationProperties注解里面的属性值XxxProperties（比如ServerProperties.class）后，此时再遍历将XxxProperties逐个注册进Spring容器中，我们来看下register方法：\n// ConfigurationPropertiesBeanRegistrar$ConfigurationPropertiesBeanRegistrar.java\n\nprivate void register(BeanDefinitionRegistry registry,\n\t\tConfigurableListableBeanFactory beanFactory, Class&lt;?> type) &#123;\n\t// 得到type的名字，一般用类的全限定名作为bean name\n\tString name = getName(type);\n\t// 根据bean name判断beanFactory容器中是否包含该bean\n\tif (!containsBeanDefinition(beanFactory, name)) &#123;\n\t\t// 若不包含，那么注册bean definition\n\t\tregisterBeanDefinition(registry, name, type);\n\t&#125;\n&#125;\n\n我们再来看下由EnableConfigurationPropertiesImportSelector导入的另一个类ConfigurationPropertiesBindingPostProcessorRegistrar又是干嘛的呢？\n\n5 ConfigurationPropertiesBindingPostProcessorRegistrar可以看到ConfigurationPropertiesBindingPostProcessorRegistrar类名字又是以Registrar单词为结尾，说明其肯定又是导入一些bean definition的。直接看源码：\n// ConfigurationPropertiesBindingPostProcessorRegistrar.java\n\npublic class ConfigurationPropertiesBindingPostProcessorRegistrar\n\t\timplements ImportBeanDefinitionRegistrar &#123;\n\n\t@Override\n\tpublic void registerBeanDefinitions(AnnotationMetadata importingClassMetadata,\n\t\t\tBeanDefinitionRegistry registry) &#123;\n\t\t// 若容器中没有注册ConfigurationPropertiesBindingPostProcessor这个处理属性绑定的后置处理器，\n\t\t// 那么将注册ConfigurationPropertiesBindingPostProcessor和ConfigurationBeanFactoryMetadata这两个bean\n\t\t// 注意onApplicationEnvironmentPreparedEvent事件加载配置属性在先，然后再注册一些后置处理器用来处理这些配置属性\n\t\tif (!registry.containsBeanDefinition(\n\t\t\t\tConfigurationPropertiesBindingPostProcessor.BEAN_NAME)) &#123;\n\t\t\t// (1)注册ConfigurationPropertiesBindingPostProcessor后置处理器，用来对配置属性进行后置处理\n\t\t\tregisterConfigurationPropertiesBindingPostProcessor(registry);\n\t\t\t// (2)注册一个ConfigurationBeanFactoryMetadata类型的bean，\n\t\t\t// 注意ConfigurationBeanFactoryMetadata实现了BeanFactoryPostProcessor，然后其会在postProcessBeanFactory中注册一些元数据\n\t\t\tregisterConfigurationBeanFactoryMetadata(registry);\n\t\t&#125;\n\t&#125;\n\t// 注册ConfigurationPropertiesBindingPostProcessor后置处理器\n\tprivate void registerConfigurationPropertiesBindingPostProcessor(\n\t\t\tBeanDefinitionRegistry registry) &#123;\n\t\tGenericBeanDefinition definition = new GenericBeanDefinition();\n\t\tdefinition.setBeanClass(ConfigurationPropertiesBindingPostProcessor.class);\n\t\tdefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);\n\t\tregistry.registerBeanDefinition(\n\t\t\t\tConfigurationPropertiesBindingPostProcessor.BEAN_NAME, definition);\n\n\t&#125;\n\t// 注册ConfigurationBeanFactoryMetadata后置处理器\n\tprivate void registerConfigurationBeanFactoryMetadata(\n\t\t\tBeanDefinitionRegistry registry) &#123;\n\t\tGenericBeanDefinition definition = new GenericBeanDefinition();\n\t\tdefinition.setBeanClass(ConfigurationBeanFactoryMetadata.class);\n\t\tdefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);\n\t\tregistry.registerBeanDefinition(ConfigurationBeanFactoryMetadata.BEAN_NAME,\n\t\t\t\tdefinition);\n\t&#125;\n\n&#125;\n\nConfigurationPropertiesBindingPostProcessorRegistrar类的逻辑非常简单，主要用来注册外部配置属性绑定相关的后置处理器即ConfigurationBeanFactoryMetadata和ConfigurationPropertiesBindingPostProcessor。\n那么接下来我们再来探究下注册的这两个后置处理器又是执行怎样的后置处理逻辑呢？\n\n6 ConfigurationBeanFactoryMetadata先来看ConfigurationBeanFactoryMetadata这个后置处理器，其实现了BeanFactoryPostProcessor接口的postProcessBeanFactory方法，在初始化bean factory时将@Bean注解的元数据存储起来，以便在后续的外部配置属性绑定的相关逻辑中使用。\n先来看下ConfigurationBeanFactoryMetadata类实现BeanFactoryPostProcessor接口的postProcessBeanFactory方法源码：\n// ConfigurationBeanFactoryMetadata\n\npublic class ConfigurationBeanFactoryMetadata implements BeanFactoryPostProcessor &#123;\n\n\t/**\n\t * The bean name that this class is registered with.\n\t */\n\tpublic static final String BEAN_NAME = ConfigurationBeanFactoryMetadata.class\n\t\t\t.getName();\n\n\tprivate ConfigurableListableBeanFactory beanFactory;\n\t/**\n\t * beansFactoryMetadata集合存储beansFactory的元数据\n\t * key:某个bean的名字  value：FactoryMetadata对象（封装了工厂bean名和工厂方法名）\n\t * 比如下面这个配置类：\n\t *\n\t * @Configuration\n\t * public class ConfigA &#123;\n\t *      @Bean\n\t *      public BeanXXX methodB（configA, ） &#123;\n\t *          return new BeanXXX();\n\t *      &#125;\n\t * &#125;\n\t *\n\t * 那么：key值为\"methodB\"，value为FactoryMetadata（configA, methodB）对象，其bean属性值为\"configA\",method属性值为\"methodB\"\n\t */\n\tprivate final Map&lt;String, FactoryMetadata> beansFactoryMetadata = new HashMap&lt;>();\n\n\t@Override\n\tpublic void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory)\n\t\t\tthrows BeansException &#123;\n\t\tthis.beanFactory = beanFactory;\n\t\t// 遍历beanFactory的beanDefinitionName，即每个bean的名字（比如工厂方法对应的bean名字）\n\t\tfor (String name : beanFactory.getBeanDefinitionNames()) &#123;\n\t\t\t// 根据name得到beanDefinition\n\t\t\tBeanDefinition definition = beanFactory.getBeanDefinition(name);\n\t\t\t// 工厂方法名：一般是注解@Bean的方法名\n\t\t\tString method = definition.getFactoryMethodName();\n\t\t\t// 工厂bean名：一般是注解@Configuration的类名\n\t\t\tString bean = definition.getFactoryBeanName();\n\t\t\tif (method != null &amp;&amp; bean != null) &#123;\n\t\t\t\t// 将beanDefinitionName作为Key，封装了工厂bean名和工厂方法名的FactoryMetadata对象作为value装入beansFactoryMetadata中\n\t\t\t\tthis.beansFactoryMetadata.put(name, new FactoryMetadata(bean, method));\n\t\t\t&#125;\n\t\t&#125;\n\t&#125;\n&#125;\n\n从上面代码可以看到ConfigurationBeanFactoryMetadata类覆写的postProcessBeanFactory方法做的事情就是将工厂Bean（可以理解为@Configuration注解的类）及其@Bean注解的工厂方法的一些元数据缓存到beansFactoryMetadata集合中，以便后续使用，这个后面会详述。\n由上代码中我们看到了ConfigurationBeanFactoryMetadata类的beansFactoryMetadata集合类型是Map&lt;String, FactoryMetadata&gt;，那么我们再来看下封装相关工厂元数据的FactoryMetadata类：\n// ConfigurationBeanFactoryMetadata$FactoryMetadata.java\n\nprivate static class FactoryMetadata &#123;\n\t// @Configuration注解的配置类的类名\n\tprivate final String bean;\n\t// @Bean注解的方法名\n\tprivate final String method;\n\n\tFactoryMetadata(String bean, String method) &#123;\n\t\tthis.bean = bean;\n\t\tthis.method = method;\n\t&#125;\n\n\tpublic String getBean() &#123;\n\t\treturn this.bean;\n\t&#125;\n\n\tpublic String getMethod() &#123;\n\t\treturn this.method;\n\t&#125;\n\n&#125;\n\nFactoryMetadata仅有两个属性bean和method,分别表示@Configuration注解的工厂bean和@Bean注解的工厂方法。\n上面说了那么多，直接举个栗子会更直观：\n/**\n * beansFactoryMetadata集合存储beansFactory的元数据\n * key:某个bean的名字  value：FactoryMetadata对象（封装了工厂bean名和工厂方法名）\n * 比如下面这个配置类：\n *\n * @Configuration\n * public class ConfigA &#123;\n *      @Bean\n *      public BeanXXX methodB（configA, ） &#123;\n *          return new BeanXXX();\n *      &#125;\n * &#125;\n *\n * 那么：key值为\"methodB\"，value为FactoryMetadata（configA, methodB）对象，其bean属性值为\"configA\",method属性值为\"methodB\"\n */\n private final Map&lt;String, FactoryMetadata> beansFactoryMetadata = new HashMap&lt;>();\n\n为了更好理解上面beansFactoryMetadata集合存储的数据是啥，建议最好自己动手调试看看其里面装的是什么哦。总之这里记住一点就好了：ConfigurationBeanFactoryMetadata类的beansFactoryMetadata集合存储的是工厂bean的相关元数据，以便在ConfigurationPropertiesBindingPostProcessor后置处理器中使用。\n\n7 ConfigurationPropertiesBindingPostProcessor我们再来看下ConfigurationPropertiesBindingPostProcessorRegistrar类注册的另外一个后置处理器ConfigurationPropertiesBindingPostProcessor，这个后置处理器就尤其重要了，主要承担了将外部配置属性绑定到**@ConfigurationProperties**注解标注的 XxxProperties 类的属性中（比如application.properties配置文件中设置了server.port=8081,那么8081将会绑定到ServerProperties类的port属性中）的实现逻辑。\n同样，先来看下ConfigurationPropertiesBindingPostProcessor的源码：\n// ConfigurationPropertiesBindingPostProcessor.java\n\npublic class ConfigurationPropertiesBindingPostProcessor implements BeanPostProcessor,\n\tPriorityOrdered, ApplicationContextAware, InitializingBean &#123;\n\t@Override\n\tpublic void afterPropertiesSet() throws Exception &#123;\n\t    // ...这里省略实现代码先\n\t&#125;\n\n\t@Override\n\tpublic Object postProcessBeforeInitialization(Object bean, String beanName) &#123;\n\t    // ...这里省略实现代码先\n\t&#125;\n\n\t// ...省略非关键代码\n&#125;\n\n可以看到ConfigurationPropertiesBindingPostProcessor后置处理器实现了两个重要的接口InitializingBean和BeanPostProcessor。\n我们都知道：\n\nInitializingBean接口的afterPropertiesSet方法会在bean属性赋值后调用，用来执行一些自定义的初始化逻辑比如检查某些强制的属性是否有被赋值，校验某些配置或给一些未被赋值的属性赋值。\nBeanPostProcessor接口是bean的后置处理器，其有postProcessBeforeInitialization和postProcessAfterInitialization两个勾子方法，分别会在bean初始化前后被调用来执行一些后置处理逻辑，比如检查标记接口或是否用代理包装了bean。\n\n同时由上代码可以看到ConfigurationPropertiesBindingPostProcessor后置处理器覆写了InitializingBean的afterPropertiesSet方法和BeanPostProcessor的postProcessBeforeInitialization方法。\n接下来我们再来探究ConfigurationPropertiesBindingPostProcessor后置处理器覆写的两个方法的源码。\n\n7.1 在执行外部属性绑定逻辑前先准备好相关元数据和配置属性绑定器我们先来分析下ConfigurationPropertiesBindingPostProcessor覆写InitializingBean接口的afterPropertiesSet方法：\n// ConfigurationPropertiesBindingPostProcessor.java\n\n        /**\n\t * 配置属性校验器名字\n\t */\n\tpublic static final String VALIDATOR_BEAN_NAME = \"configurationPropertiesValidator\";\n\t/**\n\t * 工厂bean相关元数据\n\t */\n\tprivate ConfigurationBeanFactoryMetadata beanFactoryMetadata;\n\t/**\n\t * 上下文\n\t */\n\tprivate ApplicationContext applicationContext;\n\t/**\n\t * 配置属性绑定器\n\t */\n\tprivate ConfigurationPropertiesBinder configurationPropertiesBinder;\n\n\n    // 这里主要是给beanFactoryMetadata和configurationPropertiesBinder的属性赋值，用于后面的后置处理器方法处理属性绑定的时候用\n\t@Override\n\tpublic void afterPropertiesSet() throws Exception &#123;\n\t\t// We can't use constructor injection of the application context because\n\t\t// it causes eager factory bean initialization\n\t\t// 【1】利用afterPropertiesSet这个勾子方法从容器中获取之前注册的ConfigurationBeanFactoryMetadata对象赋给beanFactoryMetadata属性\n\t\t// （问1）beanFactoryMetadata这个bean是什么时候注册到容器中的？\n\t\t// （答1）在ConfigurationPropertiesBindingPostProcessorRegistrar类的registerBeanDefinitions方法中将beanFactoryMetadata这个bean注册到容器中\n\t\t// （问2）从容器中获取beanFactoryMetadata对象后，什么时候会被用到？\n\t\t// （答2）beanFactoryMetadata对象的beansFactoryMetadata集合保存的工厂bean相关的元数据，在ConfigurationPropertiesBindingPostProcessor类\n\t\t//        要判断某个bean是否有FactoryAnnotation或FactoryMethod时会根据这个beanFactoryMetadata对象的beansFactoryMetadata集合的元数据来查找\n\t\tthis.beanFactoryMetadata = this.applicationContext.getBean(\n\t\t\t\tConfigurationBeanFactoryMetadata.BEAN_NAME,\n\t\t\t\tConfigurationBeanFactoryMetadata.class);\n\t\t// 【2】new一个ConfigurationPropertiesBinder，用于后面的外部属性绑定时使用\n\t\tthis.configurationPropertiesBinder = new ConfigurationPropertiesBinder(\n\t\t\t\tthis.applicationContext, VALIDATOR_BEAN_NAME); // VALIDATOR_BEAN_NAME=\"configurationPropertiesValidator\"\n\t&#125;\n\n可以看到以上代码主要逻辑就是在执行外部属性绑定逻辑前先准备好相关元数据和配置属性绑定器，即从Spring容器中获取到之前注册的ConfigurationBeanFactoryMetadata对象赋给ConfigurationPropertiesBindingPostProcessor后置处理器的beanFactoryMetadata属性,还有就是新建一个ConfigurationPropertiesBinder配置属性绑定器对象并赋值给configurationPropertiesBinder属性。\n我们再来看下ConfigurationPropertiesBinder这个配置属性绑定器对象是如何构造的。\n// ConfigurationPropertiesBinder.java\n\nConfigurationPropertiesBinder(ApplicationContext applicationContext,\n\t\tString validatorBeanName) &#123;\n\tthis.applicationContext = applicationContext;\n\t// 将applicationContext封装到PropertySourcesDeducer对象中并返回\n\tthis.propertySources = new PropertySourcesDeducer(applicationContext)\n\t\t\t.getPropertySources(); // 获取属性源，主要用于在ConfigurableListableBeanFactory的后置处理方法postProcessBeanFactory中处理\n\t// 如果没有配置validator的话，这里一般返回的是null\n\tthis.configurationPropertiesValidator = getConfigurationPropertiesValidator(\n\t\t\tapplicationContext, validatorBeanName);\n\t// 检查实现JSR-303规范的bean校验器相关类在classpath中是否存在\n\tthis.jsr303Present = ConfigurationPropertiesJsr303Validator\n\t\t\t.isJsr303Present(applicationContext);\n&#125;\n\n可以看到在构造ConfigurationPropertiesBinder对象时主要给其相关属性赋值（一般构造器逻辑都是这样）：\n\n给applicationContext属性赋值注入上下文对象；\n给propertySources属性赋值，属性源即外部配置值比如application.properties配置的属性值，注意这里的属性源是由ConfigFileApplicationListener这个监听器负责读取的，ConfigFileApplicationListener将会在后面源码分析章节中详述。\n给configurationPropertiesValidator属性赋值，值来自Spring容器中名为configurationPropertiesValidator的bean。\n给jsr303Present属性赋值，当javax.validation.Validator,javax.validation.ValidatorFactory和javax.validation.bootstrap.GenericBootstrap&quot;这三个类同时存在于classpath中jsr303Present属性值才为true。\n\n\n\n\n\n\n\n\n\n\n关于 JSR303：JSR-303是 JAVA EE 6 中的一项子规范，叫做Bean Validation，Hibernate Validator是Bean Validation的参考实现 。Hibernate Validator提供了JSR 303规范中所有内置constraint 的实现，除此之外还有一些附加的constraint。\n\n7.2 执行真正的外部属性绑定逻辑【主线】前面分析了那么多，发现都还没到外部属性绑定的真正处理逻辑，前面步骤都是在做一些准备性工作，为外部属性绑定做铺垫。\n在执行外部属性绑定逻辑前，准备好了相关元数据和配置属性绑定器后，此时我们再来看看ConfigurationPropertiesBindingPostProcessor实现BeanPostProcessor接口的postProcessBeforeInitialization后置处理方法了，外部属性绑定逻辑都是在这个后置处理方法里实现，是我们关注的重中之重。\n直接看代码：\n// ConfigurationPropertiesBindingPostProcessor.java\n\n// 因为是外部配置属性后置处理器，因此这里对@ConfigurationProperties注解标注的XxxProperties类进行后置处理完成属性绑定\n@Override\npublic Object postProcessBeforeInitialization(Object bean, String beanName)\n\t\tthrows BeansException &#123;\n\t// 注意，BeanPostProcessor后置处理器默认会对所有的bean进行处理，因此需要根据bean的一些条件进行过滤得到最终要处理的目的bean，\n\t// 这里的过滤条件就是判断某个bean是否有@ConfigurationProperties注解\n\t// 【1】从bean上获取@ConfigurationProperties注解,若bean有标注，那么返回该注解；若没有，则返回Null。比如ServerProperty上标注了@ConfigurationProperties注解\n\tConfigurationProperties annotation = getAnnotation(bean, beanName,\n\t\t\tConfigurationProperties.class);\n\t// 【2】若标注有@ConfigurationProperties注解的bean，那么则进行进一步处理：将配置文件的配置注入到bean的属性值中\n\tif (annotation != null) &#123;\n\t\t/********主线，重点关注】********/\n\t\tbind(bean, beanName, annotation);\n\t&#125;\n\t// 【3】返回外部配置属性值绑定后的bean（一般是XxxProperties对象）\n\treturn bean;\n&#125;\n\nConfigurationPropertiesBindingPostProcessor类覆写的postProcessBeforeInitialization方法的做的事情就是将外部属性配置绑定到@ConfigurationProperties注解标注的XxxProperties类上，现关键步骤总结如下：\n\n从bean上获取@ConfigurationProperties注解；\n若标注有@ConfigurationProperties注解的bean，那么则进行进一步的处理：将外部配置属性值绑定到 bean 的属性值中后再返回bean；若没有标注有@ConfigurationProperties注解的bean，那么将直接原样返回bean。\n\n\n\n\n\n\n\n\n\n\n注意：后置处理器默认会对每个容器中的bean进行后置处理，因为这里只针对标注有@ConfigurationProperties注解的bean进行外部属性绑定，因此没有标注@ConfigurationProperties注解的bean将不会被处理。\n接下来我们紧跟主线，再来看下外部配置属性是如何绑定到**@ConfigurationProperties**注解的**XxxProperties**类属性上的呢？\n直接看代码：\n// ConfigurationPropertiesBindingPostProcessor.java\n\nprivate void bind(Object bean, String beanName, ConfigurationProperties annotation) &#123;\n\t// 【1】得到bean的类型，比如ServerPropertie这个bean得到的类型是：org.springframework.boot.autoconfigure.web.ServerProperties\n\tResolvableType type = getBeanType(bean, beanName);\n\t// 【2】获取bean上标注的@Validated注解\n\tValidated validated = getAnnotation(bean, beanName, Validated.class);\n\t// 若标注有@Validated注解的话则跟@ConfigurationProperties注解一起组成一个Annotation数组\n\tAnnotation[] annotations = (validated != null)\n\t\t\t? new Annotation[] &#123; annotation, validated &#125;\n\t\t\t: new Annotation[] &#123; annotation &#125;;\n\t// 【3】返回一个绑定了XxxProperties类的Bindable对象target，这个target对象即被外部属性值注入的目标对象\n\t// （比如封装了标注有@ConfigurationProperties注解的ServerProperties对象的Bindable对象）\n\tBindable&lt;?> target = Bindable.of(type).withExistingValue(bean)\n\t\t\t.withAnnotations(annotations); // 设置annotations属性数组\n\ttry &#123;\n\t\t// 【4】执行外部配置属性绑定逻辑\n\t\t/********【主线，重点关注】********/\n\t\tthis.configurationPropertiesBinder.bind(target);\n\t&#125;\n\tcatch (Exception ex) &#123;\n\t\tthrow new ConfigurationPropertiesBindException(beanName, bean, annotation,\n\t\t\t\tex);\n\t&#125;\n&#125;\n\n\n关键步骤上面代码已经标注【x】，这里在继续讲解外部配置属性绑定的主线逻辑(在 8 ConfigurationPropertiesBinder 这一小节分析 )前先穿插一个知识点，还记得ConfigurationBeanFactoryMetadata覆写的postProcessBeanFactory方法里已经将相关工厂bean的元数据封装到ConfigurationBeanFactoryMetadata类的beansFactoryMetadata集合这一回事吗？\n我们再来看下上面代码中的【1】getBeanType和【2】getAnnotation方法源码：\n// ConfigurationPropertiesBindingPostProcessor.java\n\nprivate ResolvableType getBeanType(Object bean, String beanName) &#123;\n\t// 首先获取有没有工厂方法\n\tMethod factoryMethod = this.beanFactoryMetadata.findFactoryMethod(beanName);\n\t// 若有工厂方法\n\tif (factoryMethod != null) &#123;\n\t\treturn ResolvableType.forMethodReturnType(factoryMethod);\n\t&#125;\n\t// 没有工厂方法，则说明是普通的配置类\n\treturn ResolvableType.forClass(bean.getClass());\n&#125;\n\nprivate &lt;A extends Annotation> A getAnnotation(Object bean, String beanName,\n\t\tClass&lt;A> type) &#123;\n\tA annotation = this.beanFactoryMetadata.findFactoryAnnotation(beanName, type);\n\tif (annotation == null) &#123;\n\t\tannotation = AnnotationUtils.findAnnotation(bean.getClass(), type);\n\t&#125;\n\treturn annotation;\n&#125;\n\n\n注意到上面代码中的beanFactoryMetadata对象没，ConfigurationPropertiesBindingPostProcessor后置处理器的getBeanType和getAnnotation方法分别会调用ConfigurationBeanFactoryMetadata的findFactoryMethod和findFactoryAnnotation方法，而ConfigurationBeanFactoryMetadata的findFactoryMethod和findFactoryAnnotation方法又会依赖存储工厂bean元数据的beansFactoryMetadata集合来寻找是否有FactoryMethod和FactoryAnnotation。因此，到这里我们就知道之ConfigurationBeanFactoryMetadata的beansFactoryMetadata集合存储工厂bean元数据的作用了。\n\n8 ConfigurationPropertiesBinder我们再继续紧跟外部配置属性绑定的主线，继续前面看 7.2 执行真正的外部属性绑定逻辑中的this.configurationPropertiesBinder.bind(target);这句代码：\n// ConfigurationPropertiesBinder.java\n\npublic void bind(Bindable&lt;?> target) &#123;\n\t//【1】得到@ConfigurationProperties注解\n\tConfigurationProperties annotation = target\n\t\t\t.getAnnotation(ConfigurationProperties.class);\n\tAssert.state(annotation != null,\n\t\t\t() -> \"Missing @ConfigurationProperties on \" + target);\n\t// 【2】得到Validator对象集合，用于属性校验\n\tList&lt;Validator> validators = getValidators(target);\n\t// 【3】得到BindHandler对象（默认是IgnoreTopLevelConverterNotFoundBindHandler对象），\n\t// 用于对ConfigurationProperties注解的ignoreUnknownFields等属性的处理\n\tBindHandler bindHandler = getBindHandler(annotation, validators);\n\t// 【4】得到一个Binder对象，并利用其bind方法执行外部属性绑定逻辑\n\t/********************【主线，重点关注】********************/\n\tgetBinder().bind(annotation.prefix(), target, bindHandler);\n&#125;\n\n\n上面代码的主要逻辑是：\n\n先获取target对象（对应XxxProperties类）上的@ConfigurationProperties注解和校验器（若有）;\n然后再根据获取的的@ConfigurationProperties注解和校验器来获得BindHandler对象，BindHandler的作用是用于在属性绑定时来处理一些附件逻辑;在 8.1 节分析.\n最后再获取一个Binder对象，调用其bind方法来执行外部属性绑定的逻辑,在 8.2 节分析.\n\n\n8.1 获取 BindHandler 对象以便在属性绑定时来处理一些附件逻辑我们在看getBindHandler方法的逻辑前先来认识下BindHandler是干啥的。\nBindHandler是一个父类接口，用于在属性绑定时来处理一些附件逻辑。我们先看下BindHandler的类图，好有一个整体的认识：\n\n可以看到AbstractBindHandler作为抽象基类实现了BindHandler接口，其又有四个具体的子类分别是IgnoreTopLevelConverterNotFoundBindHandler,NoUnboundElementsBindHandler,IgnoreErrorsBindHandler和ValidationBindHandler。\n\nIgnoreTopLevelConverterNotFoundBindHandler：在处理外部属性绑定时的默认BindHandler，当属性绑定失败时会忽略最顶层的ConverterNotFoundException；\nNoUnboundElementsBindHandler：用来处理配置文件配置的未知的属性；\nIgnoreErrorsBindHandler：用来忽略无效的配置属性例如类型错误；\nValidationBindHandler：利用校验器对绑定的结果值进行校验。\n\n分析完类关系后，我们再来看下BindHandler接口提供了哪些方法在外部属性绑定时提供一些额外的附件逻辑，直接看代码：\n// BindHandler.java\n\npublic interface BindHandler &#123;\n\n\t/**\n\t * Default no-op bind handler.\n\t */\n\tBindHandler DEFAULT = new BindHandler() &#123;\n\n\t&#125;;\n\n\t// onStart方法在外部属性绑定前被调用\n\tdefault &lt;T> Bindable&lt;T> onStart(ConfigurationPropertyName name, Bindable&lt;T> target,\n\t\t\tBindContext context) &#123;\n\t\treturn target;\n\t&#125;\n\n\t// onSuccess方法在外部属性成功绑定时被调用，该方法能够改变最终返回的属性值或对属性值进行校验\n\tdefault Object onSuccess(ConfigurationPropertyName name, Bindable&lt;?> target,\n\t\t\tBindContext context, Object result) &#123;\n\t\treturn result;\n\t&#125;\n\n\t// onFailure方法在外部属性绑定失败（包括onSuccess方法里的逻辑执行失败）时被调用，\n\t// 该方法可以用来catch住相关异常或者返回一个替代的结果（跟微服务的降级结果有点类似，嘿嘿）\n\tdefault Object onFailure(ConfigurationPropertyName name, Bindable&lt;?> target,\n\t\t\tBindContext context, Exception error) throws Exception &#123;\n\t\tthrow error;\n\t&#125;\n\n\t// 当外部属性绑定结束时（不管绑定成功还是失败）被调用\n\tdefault void onFinish(ConfigurationPropertyName name, Bindable&lt;?> target,\n\t\t\tBindContext context, Object result) throws Exception &#123;\n\t&#125;\n&#125;\n\n\n可以看到BindHandler接口定义了onStart,onSuccess,onFailure和onFinish方法，这四个方法分别会在执行外部属性绑定时的不同时机会被调用，在属性绑定时用来添加一些额外的处理逻辑，比如在onSuccess方法改变最终绑定的属性值或对属性值进行校验，在onFailure方法catch住相关异常或者返回一个替代的绑定的属性值。\n知道了BindHandler是在属性绑定时添加一些额外的附件处理逻辑后，我们再来看下getBindHandler方法的逻辑，直接上代码：\n// ConfigurationPropertiesBinder.java\n\n// 注意BindHandler的设计技巧，应该是责任链模式，非常巧妙，值得借鉴\nprivate BindHandler getBindHandler(ConfigurationProperties annotation,\n\t\tList&lt;Validator> validators) &#123;\n\t// 新建一个IgnoreTopLevelConverterNotFoundBindHandler对象，这是个默认的BindHandler对象\n\tBindHandler handler = new IgnoreTopLevelConverterNotFoundBindHandler();\n\t// 若注解@ConfigurationProperties的ignoreInvalidFields属性设置为true，\n\t// 则说明可以忽略无效的配置属性例如类型错误，此时新建一个IgnoreErrorsBindHandler对象\n\tif (annotation.ignoreInvalidFields()) &#123;\n\t\thandler = new IgnoreErrorsBindHandler(handler);\n\t&#125;\n\t// 若注解@ConfigurationProperties的ignoreUnknownFields属性设置为true，\n\t// 则说明配置文件配置了一些未知的属性配置，此时新建一个ignoreUnknownFields对象\n\tif (!annotation.ignoreUnknownFields()) &#123;\n\t\tUnboundElementsSourceFilter filter = new UnboundElementsSourceFilter();\n\t\thandler = new NoUnboundElementsBindHandler(handler, filter);\n\t&#125;\n\t// 如果@Valid注解不为空，则创建一个ValidationBindHandler对象\n\tif (!validators.isEmpty()) &#123;\n\t\thandler = new ValidationBindHandler(handler,\n\t\t\t\tvalidators.toArray(new Validator[0]));\n\t&#125;\n\t// 遍历获取的ConfigurationPropertiesBindHandlerAdvisor集合，\n\t// ConfigurationPropertiesBindHandlerAdvisor目前只在测试类中有用到\n\tfor (ConfigurationPropertiesBindHandlerAdvisor advisor : getBindHandlerAdvisors()) &#123;\n\t\t// 对handler进一步处理\n\t\thandler = advisor.apply(handler);\n\t&#125;\n\t// 返回handler\n\treturn handler;\n&#125;\n\n\ngetBindHandler方法的逻辑很简单，主要是根据传入的@ConfigurationProperties注解和validators校验器来创建不同的BindHandler具体实现类：\n\n首先new一个IgnoreTopLevelConverterNotFoundBindHandler作为默认的BindHandler;\n若@ConfigurationProperties注解的属性ignoreInvalidFields值为true，那么再new一个IgnoreErrorsBindHandler对象，把刚才新建的IgnoreTopLevelConverterNotFoundBindHandler对象作为构造参数传入赋值给AbstractBindHandler父类的parent属性；\n若@ConfigurationProperties注解的属性ignoreUnknownFields值为false，那么再new一个UnboundElementsSourceFilter对象，把之前构造的BindHandler对象作为构造参数传入赋值给AbstractBindHandler父类的parent属性；\n……以此类推，前一个handler对象作为后一个hangdler对象的构造参数，就这样利用AbstractBindHandler父类的parent属性将每一个handler链起来，最后再得到最终构造的handler。\n\n\n\n\n\n\n\n\n\n\nGET 技巧：上面的这个设计模式是不是很熟悉，这个就是责任链模式。我们学习源码，同时也是学习别人怎么熟练运用设计模式。责任链模式的应用案例有很多，比如Dubbo的各种Filter们（比如AccessLogFilter是用来记录服务的访问日志的，ExceptionFilter是用来处理异常的…），我们一开始学习 java web 时的Servlet的Filter,MyBatis的Plugin们以及Netty的Pipeline都采用了责任链模式。\n我们了解了BindHandler的作用后，再来紧跟主线，看属性绑定是如何绑定的？\n\n8.2 获取 Binder 对象用于进行属性绑定【主线】这里接 8 ConfigurationPropertiesBinder 节代码中标注【4】的主线代码getBinder().bind(annotation.prefix(), target, bindHandler);.\n可以看到这句代码主要做了两件事：\n\n调用getBinder方法获取用于属性绑定的Binder对象；\n调用Binder对象的bind方法进行外部属性绑定到@ConfigurationProperties注解的XxxProperties类的属性上。\n\n那么我们先看下getBinder方法源码：\n// ConfigurationPropertiesBinder.java\n\nprivate Binder getBinder() &#123;\n\t// Binder是一个能绑定ConfigurationPropertySource的容器对象\n\tif (this.binder == null) &#123;\n\t\t// 新建一个Binder对象，这个binder对象封装了ConfigurationPropertySources，\n\t\t// PropertySourcesPlaceholdersResolver，ConversionService和PropertyEditorInitializer对象\n\t\tthis.binder = new Binder(getConfigurationPropertySources(), // 将PropertySources对象封装成SpringConfigurationPropertySources对象并返回\n\t\t\t\tgetPropertySourcesPlaceholdersResolver(), getConversionService(), // 将PropertySources对象封装成PropertySourcesPlaceholdersResolver对象并返回，从容器中获取到ConversionService对象\n\t\t\t\tgetPropertyEditorInitializer()); // 得到Consumer&lt;PropertyEditorRegistry>对象，这些初始化器用来配置property editors，property editors通常可以用来转换值\n\t&#125;\n\t// 返回binder\n\treturn this.binder;\n&#125;\n\n\n可以看到Binder对象封装了ConfigurationPropertySources,PropertySourcesPlaceholdersResolver,ConversionService和PropertyEditorInitializer这四个对象，Binder对象封装了这四个哥们肯定是在后面属性绑定逻辑中会用到，先看下这四个对象是干嘛的：\n\nConfigurationPropertySources:外部配置文件的属性源，由ConfigFileApplicationListener监听器负责触发读取；\nPropertySourcesPlaceholdersResolver:解析属性源中的占位符$&#123;&#125;；\nConversionService:对属性类型进行转换\nPropertyEditorInitializer:用来配置property editors\n\n那么，我们获取了Binder属性绑定器后，再来看下它的bind方法是如何执行属性绑定的。\n// Binder.java\n\npublic &lt;T> BindResult&lt;T> bind(String name, Bindable&lt;T> target, BindHandler handler) &#123;\n\t// ConfigurationPropertyName.of(name)：将name（这里指属性前缀名）封装到ConfigurationPropertyName对象中\n\t// 将外部配置属性绑定到目标对象target中\n\treturn bind(ConfigurationPropertyName.of(name), target, handler);\n&#125;\n\npublic &lt;T> BindResult&lt;T> bind(ConfigurationPropertyName name, Bindable&lt;T> target,\n\t\tBindHandler handler) &#123;\n\tAssert.notNull(name, \"Name must not be null\");\n\tAssert.notNull(target, \"Target must not be null\");\n\thandler = (handler != null) ? handler : BindHandler.DEFAULT;\n\t// Context是Binder的内部类，实现了BindContext，Context可以理解为Binder的上下文，可以用来获取binder的属性比如Binder的sources属性\n\tContext context = new Context();\n\t// 进行属性绑定，并返回绑定属性后的对象bound，注意bound的对象类型是T，T就是@ConfigurationProperties注解的类比如ServerProperties\n\t/********【主线，重点关注】************/\n\tT bound = bind(name, target, handler, context, false);\n\t// 将刚才返回的bound对象封装到BindResult对象中并返回\n\treturn BindResult.of(bound);\n&#125;\n\n\n上面代码中首先创建了一个Context对象，Context是Binder的内部类，为Binder的上下文，利用Context上下文可以获取Binder的属性比如获取Binder的sources属性值并绑定到XxxProperties属性中。然后我们再紧跟主线看下bind(name, target, handler, context, false)方法源码：\n// Binder.java\n\nprotected final &lt;T> T bind(ConfigurationPropertyName name, Bindable&lt;T> target,\n\t\tBindHandler handler, Context context, boolean allowRecursiveBinding) &#123;\n\t// 清空Binder的configurationProperty属性值\n\tcontext.clearConfigurationProperty();\n\ttry &#123;\n\t\t// 【1】调用BindHandler的onStart方法，执行一系列的责任链对象的该方法\n\t\ttarget = handler.onStart(name, target, context);\n\t\tif (target == null) &#123;\n\t\t\treturn null;\n\t\t&#125;// 【2】调用bindObject方法对Bindable对象target的属性进行绑定外部配置的值，并返回赋值给bound对象。\n\t\t// 举个栗子：比如设置了server.port=8888,那么该方法最终会调用Binder.bindProperty方法，最终返回的bound的value值为8888\n\t\t/************【主线：重点关注】***********/\n\t\tObject bound = bindObject(name, target, handler, context,\n\t\t\t\tallowRecursiveBinding);\n\t\t// 【3】封装handleBindResult对象并返回，注意在handleBindResult的构造函数中会调用BindHandler的onSucess，onFinish方法\n\t\treturn handleBindResult(name, target, handler, context, bound);\n\t&#125;\n\tcatch (Exception ex) &#123;\n\t\treturn handleBindError(name, target, handler, context, ex);\n\t&#125;\n&#125;\n\n\n上面代码的注释已经非常详细，这里不再详述。我们接着紧跟主线来看看bindObject方法源码:\n// Binder.java\n\nprivate &lt;T> Object bindObject(ConfigurationPropertyName name, Bindable&lt;T> target,\n\t\tBindHandler handler, Context context, boolean allowRecursiveBinding) &#123;\n\t// 从propertySource中的配置属性，获取ConfigurationProperty对象property即application.properties配置文件中若有相关的配置的话，\n\t// 那么property将不会为null。举个栗子：假如你在配置文件中配置了spring.profiles.active=dev，那么相应property值为dev；否则为null\n\tConfigurationProperty property = findProperty(name, context);\n\t// 若property为null，则不会执行后续的属性绑定相关逻辑\n\tif (property == null &amp;&amp; containsNoDescendantOf(context.getSources(), name)) &#123;\n\t\t// 如果property == null，则返回null\n\t\treturn null;\n\t&#125;\n\t// 根据target类型获取不同的Binder，可以是null（普通的类型一般是Null）,MapBinder,CollectionBinder或ArrayBinder\n\tAggregateBinder&lt;?> aggregateBinder = getAggregateBinder(target, context);\n\t// 若aggregateBinder不为null比如配置了spring.profiles属性（当然包括其子属性比如spring.profiles.active等）\n\tif (aggregateBinder != null) &#123;\n\t\t// 若aggregateBinder不为null，则调用bindAggregate并返回绑定后的对象\n\t\treturn bindAggregate(name, target, handler, context, aggregateBinder);\n\t&#125;\n\t// 若property不为null\n\tif (property != null) &#123;\n\t\ttry &#123;\n\t\t\t// 绑定属性到对象中，比如配置文件中设置了server.port=8888，那么将会最终调用bindProperty方法进行属性设置\n\t\t\treturn bindProperty(target, context, property);\n\t\t&#125;\n\t\tcatch (ConverterNotFoundException ex) &#123;\n\t\t\t// We might still be able to bind it as a bean\n\t\t\tObject bean = bindBean(name, target, handler, context,\n\t\t\t\t\tallowRecursiveBinding);\n\t\t\tif (bean != null) &#123;\n\t\t\t\treturn bean;\n\t\t\t&#125;\n\t\t\tthrow ex;\n\t\t&#125;\n\t&#125;\n\t// 只有@ConfigurationProperties注解的类进行外部属性绑定才会走这里\n\t/***********************【主线，重点关注】****************************/\n\treturn bindBean(name, target, handler, context, allowRecursiveBinding);\n&#125;\n\n\n由上代码中可以看到bindObject中执行属性绑定的逻辑会根据不同的属性类型进入不同的绑定逻辑中，举个栗子：\n\napplication.properties配置文件中配置了spring.profiles.active=dev的话，那么将会进入return bindAggregate(name, target, handler, context, aggregateBinder);这个属性绑定的代码逻辑；\napplication.properties配置文件中配置了server.port=8081的话，那么将会进入return bindBean(name, target, handler, context, allowRecursiveBinding);的属性绑定的逻辑。\n\n因此我们再次紧跟主线，进入@ConfigurationProperties注解的XxxProperties类的属性绑定逻辑中的bindBean方法中：\n// Binder.java\n\nprivate Object bindBean(ConfigurationPropertyName name, Bindable&lt;?> target, // name指的是ConfigurationProperties的前缀名\n\t\tBindHandler handler, Context context, boolean allowRecursiveBinding) &#123;\n\t// 这里做一些ConfigurationPropertyState的相关检查\n\tif (containsNoDescendantOf(context.getSources(), name)\n\t\t\t|| isUnbindableBean(name, target, context)) &#123;\n\t\treturn null;\n\t&#125;// 这里新建一个BeanPropertyBinder的实现类对象，注意这个对象实现了bindProperty方法\n\tBeanPropertyBinder propertyBinder = (propertyName, propertyTarget) -> bind(\n\t\t\tname.append(propertyName), propertyTarget, handler, context, false);\n\t/**\n\t * (propertyName, propertyTarget) -> bind(\n\t * \t\t\t\tname.append(propertyName), propertyTarget, handler, context, false);\n\t * \t等价于\n\t * \tnew BeanPropertyBinder() &#123;\n\t *\t\tObject bindProperty(String propertyName, Bindable&lt;?> target)&#123;\n\t *\t\t\tbind(name.append(propertyName), propertyTarget, handler, context, false);\n\t *\t\t&#125;\n\t * \t&#125;\n\t */\n\t// type类型即@ConfigurationProperties注解标注的XxxProperties类\n\tClass&lt;?> type = target.getType().resolve(Object.class);\n\tif (!allowRecursiveBinding &amp;&amp; context.hasBoundBean(type)) &#123;\n\t\treturn null;\n\t&#125;\n\t// 这里应用了java8的lambda语法，作为没怎么学习java8的lambda语法的我，不怎么好理解下面的逻辑，哈哈\n\t// 真正实现将外部配置属性绑定到@ConfigurationProperties注解的XxxProperties类的属性中的逻辑应该就是在这句lambda代码了\n\t/*******************【主线】***************************/\n\treturn context.withBean(type, () -> &#123;\n\t\tStream&lt;?> boundBeans = BEAN_BINDERS.stream()\n\t\t\t\t.map((b) -> b.bind(name, target, context, propertyBinder));\n\t\treturn boundBeans.filter(Objects::nonNull).findFirst().orElse(null);\n\t&#125;);\n\t// 根据上面的lambda语句翻译如下：\n\t/** 这里的T指的是各种属性绑定对象，比如ServerProperties\n\t * return context.withBean(type, new Supplier&lt;T>() &#123;\n\t * \tT get() &#123;\n\t * \t\tStream&lt;?> boundBeans = BEAN_BINDERS.stream()\n\t * \t\t\t\t\t.map((b) -> b.bind(name, target, context, propertyBinder));\n\t * \t\t\treturn boundBeans.filter(Objects::nonNull).findFirst().orElse(null);\n\t *        &#125;\n\t *  &#125;);\n\t */\n&#125;\n\n\n从上面代码中，我们追根究底来到了外部配置属性绑定到XxxProperties类属性中的比较底层的代码了，可以看到属性绑定的逻辑应该就在上面代码标注【主线】的lambda代码处了。这里就不再详述了，因为这个属于 SpringBoot 的属性绑定Binder的范畴，Binder相关类是 SpringBoot2.0 才出现的，即对之前的属性绑定相关代码进行推翻重写了。属性绑定相关的源码也比较多，后续有需要再另开一篇来分析探究吧。\n\n9 小结好了，外部配置属性值是如何被绑定到XxxProperties类属性上的源码分析就到此结束了，又是蛮长的一篇文章，不知自己表述清楚没，重要步骤现总结下：\n\n首先是@EnableConfigurationProperties注解import了EnableConfigurationPropertiesImportSelector后置处理器；\nEnableConfigurationPropertiesImportSelector后置处理器又向Spring容器中注册了ConfigurationPropertiesBeanRegistrar和ConfigurationPropertiesBindingPostProcessorRegistrar这两个bean；\n其中ConfigurationPropertiesBeanRegistrar向Spring容器中注册了XxxProperties类型的bean；ConfigurationPropertiesBindingPostProcessorRegistrar向Spring容器中注册了ConfigurationBeanFactoryMetadata和ConfigurationPropertiesBindingPostProcessor两个后置处理器；\nConfigurationBeanFactoryMetadata后置处理器在初始化bean factory时将@Bean注解的元数据存储起来，以便在后续的外部配置属性绑定的相关逻辑中使用；\nConfigurationPropertiesBindingPostProcessor后置处理器将外部配置属性值绑定到XxxProperties类属性的逻辑委托给ConfigurationPropertiesBinder对象，然后ConfigurationPropertiesBinder对象又最终将属性绑定的逻辑委托给Binder对象来完成。\n\n可见，重要的是上面的第 5 步。\nPS：本来打算这篇开始分析 SpringBoot 的启动流程的，但是回过头去看看自动配置的相关源码，还有蛮多没有分析的，因此再来一波自动配置相关的源码先。\n6 SpringBoot内置的各种Starter是怎样构建的\n1 温故而知新温故而知新，我们来简单回顾一下上篇的内容，上一篇我们分析了SpringBoot外部配置属性值是如何被绑定到XxxProperties类属性上的相关源码，现将外部属性绑定的重要步骤总结如下：\n\n首先是@EnableConfigurationProperties注解import了EnableConfigurationPropertiesImportSelector后置处理器；\nEnableConfigurationPropertiesImportSelector后置处理器又向Spring容器中注册了ConfigurationPropertiesBeanRegistrar和ConfigurationPropertiesBindingPostProcessorRegistrar这两个bean；\n其中ConfigurationPropertiesBeanRegistrar向Spring容器中注册了XxxProperties类型的bean；ConfigurationPropertiesBindingPostProcessorRegistrar向Spring容器中注册了ConfigurationBeanFactoryMetadata和ConfigurationPropertiesBindingPostProcessor两个后置处理器；\nConfigurationBeanFactoryMetadata后置处理器在初始化bean factory时将@Bean注解的元数据存储起来，以便在后续的外部配置属性绑定的相关逻辑中使用；\nConfigurationPropertiesBindingPostProcessor后置处理器将外部配置属性值绑定到XxxProperties类属性的逻辑委托给ConfigurationPropertiesBinder对象，然后ConfigurationPropertiesBinder对象又最终将属性绑定的逻辑委托给Binder对象来完成。\n\n可见，重要的是上面的第5步。\n\n2 引言我们都知道，SpringBoot内置了各种Starter起步依赖，我们使用非常方便，大大减轻了我们的开发工作。有了Starter起步依赖，我们不用去考虑这个项目需要什么库，这个库的groupId和artifactId是什么？更不用担心引入这个版本的库后会不会跟其他依赖有没有冲突。\n\n\n\n\n\n\n\n\n\n举个栗子：现在我们想开发一个web项目，那么只要引入spring-boot-starter-web这个起步依赖就可以了，不用考虑要引入哪些版本的哪些依赖了。像以前我们还要考虑引入哪些依赖库，比如要引入spring-web和spring-webmvc依赖等；此外，还要考虑引入这些库的哪些版本才不会跟其他库冲突等问题。\n那么我们今天暂时不分析SpringBoot自动配置的源码，由于起步依赖跟自动配置的关系是如影随形的关系，因此本篇先站在maven项目构建的角度来宏观分析下我们平时使用的SpringBoot内置的各种**Starter**是怎样构建的？\n\n3 Maven传递依赖的optional标签在分析SpringBoot内置的各种Starter构建原理前，我们先来认识下Maven的optional标签，因为这个标签起到至关重要的作用。 Maven的optional标签表示可选依赖即不可传递的意思，下面直接举个栗子来说明。\n比如有A,B和C三个库，C依赖B，B依赖A。下面看下这三个库的pom.xml文件：\n// A的pom.xml\n\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?>\n&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n\n\t&lt;groupId>com.ymbj&lt;/groupId>\n        &lt;artifactId>A&lt;/artifactId>\n\t&lt;version>1.0-SNAPSHOT&lt;/version>\n\n&lt;/project>\n复制代码\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?>\n&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n\n\t&lt;groupId>com.ymbj&lt;/groupId>\n        &lt;artifactId>B&lt;/artifactId>\n\t&lt;version>1.0-SNAPSHOT&lt;/version>\n\n    &lt;!--注意是可选依赖-->\n    &lt;dependencies>\n        &lt;dependency>\n            &lt;groupId>com.ymbj&lt;/groupId>\n            &lt;artifactId>A&lt;/artifactId>\n            &lt;version>1.0-SNAPSHOT&lt;/version>\n\t    &lt;optional>true&lt;/optional>\n        &lt;/dependency>\n    &lt;/dependencies>\n\n&lt;/project>\n复制代码\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?>\n&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n\n\t&lt;groupId>com.ymbj&lt;/groupId>\n        &lt;artifactId>C&lt;/artifactId>\n\t&lt;version>1.0-SNAPSHOT&lt;/version>\n\n    &lt;dependencies>\n        &lt;dependency>\n            &lt;groupId>com.ymbj&lt;/groupId>\n            &lt;artifactId>B&lt;/artifactId>\n            &lt;version>1.0-SNAPSHOT&lt;/version>\n        &lt;/dependency>\n    &lt;/dependencies>\n\n&lt;/project>\n\n上面三个A,B和C库的pom.xml可知，B库依赖A库，然后C库又依赖了B库，那么请想一下，Maven打包构建**C**库后，**A**库有没有被引进来？\n答案肯定是没有，因为B库引入A库依赖时使用了&lt;optional&gt;true&lt;/optional&gt;，即将Maven的optional标签值设为了true，此时C库再引入B库依赖时，A库是不会被引入到C库的。\n同时跟Maven传递依赖有关的还有一个exclusions标签，这个表示将某个库的某个子依赖排除掉，这里不再详述。\n\n4 SpringBoot内置的各种Starter是怎样构建的？我们现在来探究SpringBoot内置的各种Starter到底是怎样构建的呢？\n还记得如何分析SpringBoot源码模块及结构？这篇文章分析的SpringBoot内部的模块之间的关系吗？先来回顾一下SpringBoot源码内部模块图：\n图1\n我们都知道，SpringBoot的Starter的构建的原理实质就是自动配置，因此由图1可以看到SpringBoot源码项目内部跟Starter及其自动配置有关的模块有四个：spring-boot-starters,spring-boot-actuator-autoconfigure,spring-boot-autoconfigure和spring-boot-test-autoconfigure。 每个模块的作用请看如何分析SpringBoot源码模块及结构？这篇文章，这里不再赘述。\n那么，spring-boot-starters模块跟后面三个自动配置有关的模块xxx-autoconfigure模块的关系是怎样的呢？\n此时我们先来看看spring-boot-starters模块里面的结构是怎样的？\n图2\n由图2可以看到spring-boot-starters模块包含了SpringBoot内置的各种starter：spring-boot-starter-xxx。由于SpringBoot内置的各种starter太多，以我们常用的spring-boot-starter-web起步依赖来探究好了。\n我们首先看下spring-boot-starter-web模块内部结构：\n图3\n可以看到spring-boot-starter-web模块里面只有.flattened-pom.xml和pom.xml文件，而没有任何代码！有点出乎我们意料。我们都知道若要用到SpringBoot的web功能时引入spring-boot-starter-web起步依赖即可，而现在spring-boot-starter-web模块里面没有一行代码，那么spring-boot-starter-web究竟是如何构建的呢？会不会跟图1所示的spring-boot-autoconfigure自动配置模块有关？\n此时我们就需要看下spring-boot-starter-web模块的pom.xml文件内容：\n图4\n由图4可以看到，spring-boot-starter-web模块依赖了spring-boot-starter,spring-boot-starter-tomcat,spring-web和spring-webmvc等模块，居然没有依赖spring-boot-autoconfigure自动配置模块!\n由于spring-boot-starter-web模块肯定跟spring-boot-autoconfigure自动配置模块有关，所以spring-boot-starter-web模块肯定是间接依赖了spring-boot-autoconfigure自动配置模块。\n图4标有标注”重点关注”的spring-boot-starter模块是绝大部分spring-boot-starter-xxx模块依赖的基础模块，是核心的Starter，包括了自动配置，日志和YAML支持。我们此时来关注下spring-boot-starter的pom.xml文件，也许其依赖了了spring-boot-autoconfigure自动配置模块。\n图5\n由图5可以看到，我们前面的猜想没有错，正是**spring-boot-starter**模块依赖了**spring-boot-autoconfigure**自动配置模块！因此，到了这里我们就可以得出结论了：**_spring-boot-starter-web_**模块没有一行代码，但是其通过**_spring-boot-starter_****_模块_间接**依赖了spring-boot-autoconfigure自动配置模块，从而实现了其起步依赖的功能。\n此时我们再来看下spring-boot-autoconfigure自动配置模块的内部包结构：\n图6\n由图6红框处，我们可以知道spring-boot-starter-web起步依赖的自动配置功能原来是由spring-boot-autoconfigure模块的web包下的类实现的。\n到了这里spring-boot-starter-web起步依赖的构建基本原理我们就搞清楚了，但是还有一个特别重要的关键点我们还没Get到。这个关键点跟Maven的optional标签有的作用有关。\n为了Get到这个点，我们先来思考一个问题：平时我们开发web项目为什么引入了spring-boot-starter-web这个起步依赖后，spring-boot-autoconfigure模块的web相关的自动配置类就会起自动起作用呢？\n我们应该知道，某个自动配置类起作用往往是由于classpath中存在某个类，这里以DispatcherServletAutoConfiguration这个自动配置类为切入点去Get这个点好了。 先看下DispatcherServletAutoConfiguration能够自动配置的条件是啥？\n图7\n由图7所示，DispatcherServletAutoConfiguration能够自动配置的条件之一是@ConditionalOnClass(DispatcherServlet.class)，即只有classpath中存在DispatcherServlet.class这个类，那么DispatcherServletAutoConfiguration自动配置相关逻辑才能起作用。\n而DispatcherServlet这个类是在spring-webmvc这个依赖库中的，如下图所示：\n图8\n此时我们再看下spring-boot-autoconfigure模块的pom.xml文件引入spring-webmvc这个依赖的情况：\n图9\n由图9所示，spring-boot-autoconfigure模块引入的spring-webmvc这个依赖时optional被设置为true，原来是可选依赖。即spring-webmvc这个依赖库只会被导入到spring-boot-autoconfigure模块中，而不会被导入到间接依赖spring-boot-autoconfigure模块的spring-boot-starter-web这个起步依赖中。\n此时，我们再来看看spring-boot-starter-web的pom.xml文件的依赖情况：\n图10\n由图10所示，spring-boot-starter-web起步依赖显式引入了spring-webmvc这个依赖库，即引入spring-webmvc   时没有optional这个标签，又因为DispatcherServlet这个类是在spring-webmvc这个依赖库中的,从而classpath中存在DispatcherServlet这个类，因此DispatcherServletAutoConfiguration这个自动配置类就生效了。当然，web相关的其他自动配置类生效也是这个原理。\n至此，我们也明白了spring-boot-autoconfigure模块为什么要把引入的spring-webmvc这个依赖作为可选依赖了，其目的就是为了在spring-boot-starter-web起步依赖中能显式引入spring-webmvc这个依赖（这个起决定性作用），从而我们开发web项目只要引入了spring-boot-starter-web起步依赖，那么web相关的自动配置类就生效，从而可以开箱即用这个就是spring-boot-starter-web这个起步依赖的构建原理了。\n前面提到的spring-boot-starter-actuator,spring-boot-starter-test及其他内置的spring-boot-starter-xxx的起步依赖的构建原理也是如此，只不过spring-boot-starter-actuator依赖的是spring-boot-actuator-autoconfigure，spring-boot-starter-test依赖的是spring-boot-test-autoconfigure模块罢了，这里不再详述。\n\n\n\n\n\n\n\n\n\n思考：spring-boot-actuator-autoconfigure的pom.xml文件引入了20多个可选依赖，而为什么spring-boot-starter-actuator起步依赖只引入了micrometer-core这个依赖呢？\n\n5 模仿SpringBoot包结构自定义一个Starter前面分析了SpringBoot内置的各种Starter的构建原理，理论联系实践，那么如果能够动手实践一下自定义Starter那就更好了。\n下面提供一个自定义Starter的一个简单Demo，这个Demo完全模仿SpringBoot内置Starter的内部包结构来编写，对于进一步了解SpringBoot内置的各种Starter的构建原理很有帮助。\n下面是这个Demo的github地址，推荐给有兴趣的小伙伴们。 模仿springboot内部结构自定义Starter。此外，如何自定义一个Starter，可以参考下Mybatis的spring-boot-starter是如何编写的。\n\n6 小结好了，SpringBoot内置的各种Starter的构建原理分析就到此结束了，现将关键点总结下：\n\nspring-boot-starter-xxx起步依赖没有一行代码，而是直接或间接依赖了xxx-autoconfigure模块，而xxx-autoconfigure模块承担了spring-boot-starter-xxx起步依赖自动配置的实现；\nxxx-autoconfigure自动配置模块引入了一些可选依赖，这些可选依赖不会被传递到spring-boot-starter-xxx起步依赖中，这是起步依赖构建的关键点；\nspring-boot-starter-xxx起步依赖显式引入了一些对自动配置起作用的可选依赖；\n经过前面3步的准备，我们项目只要引入了某个起步依赖后，就可以开箱即用了，而不用手动去创建一些bean等。\n\n7 SpringBoot的启动流程\n1 温故而知新温故而知新，我们来简单回顾一下上篇的内容，上一篇我们分析了**SpringBoot内置的各种Starter是怎样构建的?**，现将关键点重新回顾总结下：\n\nspring-boot-starter-xxx起步依赖没有一行代码，而是直接或间接依赖了xxx-autoconfigure模块，而xxx-autoconfigure模块承担了spring-boot-starter-xxx起步依赖自动配置的实现；\nxxx-autoconfigure自动配置模块引入了一些可选依赖，这些可选依赖不会被传递到spring-boot-starter-xxx起步依赖中，这是起步依赖构建的关键点；\nspring-boot-starter-xxx起步依赖显式引入了一些对自动配置起作用的可选依赖，因此会触发 xxx-autoconfigure自动配置的逻辑（比如创建某些符合条件的配置bean）；\n经过前面3步的准备，我们项目只要引入了某个起步依赖后，就可以开箱即用了，而不用手动去创建一些bean等。\n\n\n2 引言本来这篇文章会继续SpringBoot自动配置的源码分析的，想分析下spring-boot-starter-web的自动配置的源码是怎样的的。但是考虑到spring-boot-starter-web的自动配置逻辑跟内置Tomcat等有关，因此想以后等分析了SpringBoot的内置Tomcat的相关源码后再来继续分析spring-boot-starter-web的自动配置的源码。\n因此，本篇我们来探究下SpringBoot的启动流程是怎样的？\n\n3 如何编写一个SpringBoot启动类我们都知道，我们运行一个SpringBoot项目，引入相关Starters和相关依赖后，再编写一个启动类，然后在这个启动类标上@SpringBootApplication注解，然后就可以启动运行项目了，如下代码：\n//MainApplication.java\n\n@SpringBootApplication\npublic class MainApplication &#123;\n\tpublic static void main(String[] args) &#123;\n\t\tSpringApplication.run(MainApplication.class, args);\n\t&#125;\n&#125;\n\n如上代码，我们在MainApplication启动类上标注了@SpringBootApplication注解，然后在main函数中调用SpringApplication.run(MainApplication.class, args);这句代码就完成了SpringBoot的启动流程，非常简单。\n\n4 @SpringBootApplication现在我们来分析下标注在启动类上的@SpringBootApplication注解，直接上源码：\n// SpringBootApplication.java \n\n@Target(ElementType.TYPE)\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Inherited\n@SpringBootConfiguration\n@EnableAutoConfiguration\n@ComponentScan(excludeFilters = &#123; // TODO 这两个排除过滤器TypeExcludeFilter和AutoConfigurationExcludeFilter暂不知道啥作用\n\t\t@Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class),\n\t\t@Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)\npublic @interface SpringBootApplication &#123;\n        // 等同于EnableAutoConfiguration注解的exclude属性\n\t@AliasFor(annotation = EnableAutoConfiguration.class)\n\tClass&lt;?>[] exclude() default &#123;&#125;;\n        // 等同于EnableAutoConfiguration注解的excludeName属性\n\t@AliasFor(annotation = EnableAutoConfiguration.class)\n\tString[] excludeName() default &#123;&#125;;\n        // 等同于ComponentScan注解的basePackages属性\n\t@AliasFor(annotation = ComponentScan.class, attribute = \"basePackages\")\n\tString[] scanBasePackages() default &#123;&#125;;\n        // 等同于ComponentScan注解的basePackageClasses属性\n\t@AliasFor(annotation = ComponentScan.class, attribute = \"basePackageClasses\")\n\tClass&lt;?>[] scanBasePackageClasses() default &#123;&#125;;\n&#125;\n\n可以看到，@SpringBootApplication注解是一个组合注解，主要由@SpringBootConfiguration,@EnableAutoConfiguration和@ComponentScan这三个注解组合而成。\n因此@SpringBootApplication注解主要作为一个配置类，能够触发包扫描和自动配置的逻辑，从而使得SpringBoot的相关bean被注册进Spring容器。\n\n5 SpringBoot的启动流程是怎样的？接下来是本篇的重点，我们来分析下SpringBoot的启动流程是怎样的？\n我们接着来看前面main函数里的SpringApplication.run(MainApplication.class, args);这句代码，那么SpringApplication这个类是干嘛的呢？\nSpringApplication类是用来启动SpringBoot项目的，可以在java的main方法中启动，目前我们知道这些就足够了。下面看下SpringApplication.run(MainApplication.class, args);这句代码的源码：\n// SpringApplication.java\n\n// run方法是一个静态方法，用于启动SpringBoot\npublic static ConfigurableApplicationContext run(Class&lt;?> primarySource,\n\t\tString... args) &#123;\n\t// 继续调用静态的run方法\n\treturn run(new Class&lt;?>[] &#123; primarySource &#125;, args);\n&#125;\n\n在上面的静态run方法里又继续调用另一个静态run方法：\n// SpringApplication.java\n\n// run方法是一个静态方法，用于启动SpringBoot\npublic static ConfigurableApplicationContext run(Class&lt;?>[] primarySources,\n\t\tString[] args) &#123;\n\t// 构建一个SpringApplication对象，并调用其run方法来启动\n\treturn new SpringApplication(primarySources).run(args);\n&#125;\n\n如上代码，可以看到构建了一个SpringApplication对象，然后再调用其run方法来启动SpringBoot项目。关于SpringApplication对象是如何构建的，我们后面再分析，现在直接来看下启动流程的源码：\n// SpringApplication.java\n\npublic ConfigurableApplicationContext run(String... args) &#123;\n\t// new 一个StopWatch用于统计run启动过程花了多少时间\n\tStopWatch stopWatch = new StopWatch();\n\t// 开始计时\n\tstopWatch.start();\n\tConfigurableApplicationContext context = null;\n\t// exceptionReporters集合用来存储异常报告器，用来报告SpringBoot启动过程的异常\n\tCollection&lt;SpringBootExceptionReporter> exceptionReporters = new ArrayList&lt;>();\n\t// 配置headless属性，即“java.awt.headless”属性，默认为ture\n\t// 其实是想设置该应用程序,即使没有检测到显示器,也允许其启动.对于服务器来说,是不需要显示器的,所以要这样设置.\n\tconfigureHeadlessProperty();\n\t// 【1】从spring.factories配置文件中加载到EventPublishingRunListener对象并赋值给SpringApplicationRunListeners\n\t// EventPublishingRunListener对象主要用来发射SpringBoot启动过程中内置的一些生命周期事件，标志每个不同启动阶段\n\tSpringApplicationRunListeners listeners = getRunListeners(args);\n\t// 启动SpringApplicationRunListener的监听，表示SpringApplication开始启动。\n\t// 》》》》》发射【ApplicationStartingEvent】事件\n\tlisteners.starting();\n\ttry &#123;\n\t\t// 创建ApplicationArguments对象，封装了args参数\n\t\tApplicationArguments applicationArguments = new DefaultApplicationArguments(\n\t\t\t\targs);\n\t\t// 【2】准备环境变量，包括系统变量，环境变量，命令行参数，默认变量，servlet相关配置变量，随机值，\n\t\t// JNDI属性值，以及配置文件（比如application.properties）等，注意这些环境变量是有优先级的\n\t\t// 》》》》》发射【ApplicationEnvironmentPreparedEvent】事件\n\t\tConfigurableEnvironment environment = prepareEnvironment(listeners,\n\t\t\t\tapplicationArguments);\n\t\t// 配置spring.beaninfo.ignore属性，默认为true，即跳过搜索BeanInfo classes.\n\t\tconfigureIgnoreBeanInfo(environment);\n\t\t// 【3】控制台打印SpringBoot的bannner标志\n\t\tBanner printedBanner = printBanner(environment);\n\t\t// 【4】根据不同类型创建不同类型的spring applicationcontext容器\n\t\t// 因为这里是servlet环境，所以创建的是AnnotationConfigServletWebServerApplicationContext容器对象\n\t\tcontext = createApplicationContext();\n\t\t// 【5】从spring.factories配置文件中加载异常报告期实例，这里加载的是FailureAnalyzers\n\t\t// 注意FailureAnalyzers的构造器要传入ConfigurableApplicationContext，因为要从context中获取beanFactory和environment\n\t\texceptionReporters = getSpringFactoriesInstances(\n\t\t\t\tSpringBootExceptionReporter.class,\n\t\t\t\tnew Class[] &#123; ConfigurableApplicationContext.class &#125;, context); // ConfigurableApplicationContext是AnnotationConfigServletWebServerApplicationContext的父接口\n\t\t// 【6】为刚创建的AnnotationConfigServletWebServerApplicationContext容器对象做一些初始化工作，准备一些容器属性值等\n\t\t// 1）为AnnotationConfigServletWebServerApplicationContext的属性AnnotatedBeanDefinitionReader和ClassPathBeanDefinitionScanner设置environgment属性\n\t\t// 2）根据情况对ApplicationContext应用一些相关的后置处理，比如设置resourceLoader属性等\n\t\t// 3）在容器刷新前调用各个ApplicationContextInitializer的初始化方法，ApplicationContextInitializer是在构建SpringApplication对象时从spring.factories中加载的\n\t\t// 4）》》》》》发射【ApplicationContextInitializedEvent】事件，标志context容器被创建且已准备好\n\t\t// 5）从context容器中获取beanFactory，并向beanFactory中注册一些单例bean，比如applicationArguments，printedBanner\n\t\t// 6）TODO 加载bean到application context，注意这里只是加载了部分bean比如mainApplication这个bean，大部分bean应该是在AbstractApplicationContext.refresh方法中被加载？这里留个疑问先\n\t\t// 7）》》》》》发射【ApplicationPreparedEvent】事件，标志Context容器已经准备完成\n\t\tprepareContext(context, environment, listeners, applicationArguments,\n\t\t\t\tprintedBanner);\n\t\t// 【7】刷新容器，这一步至关重要，以后会在分析Spring源码时详细分析，主要做了以下工作：\n\t\t// 1）在context刷新前做一些准备工作，比如初始化一些属性设置，属性合法性校验和保存容器中的一些早期事件等；\n\t\t// 2）让子类刷新其内部bean factory,注意SpringBoot和Spring启动的情况执行逻辑不一样\n\t\t// 3）对bean factory进行配置，比如配置bean factory的类加载器，后置处理器等\n\t\t// 4）完成bean factory的准备工作后，此时执行一些后置处理逻辑，子类通过重写这个方法来在BeanFactory创建并预准备完成以后做进一步的设置\n\t\t// 在这一步，所有的bean definitions将会被加载，但此时bean还不会被实例化\n\t\t// 5）执行BeanFactoryPostProcessor的方法即调用bean factory的后置处理器：\n\t\t// BeanDefinitionRegistryPostProcessor（触发时机：bean定义注册之前）和BeanFactoryPostProcessor（触发时机：bean定义注册之后bean实例化之前）\n\t\t// 6）注册bean的后置处理器BeanPostProcessor，注意不同接口类型的BeanPostProcessor；在Bean创建前后的执行时机是不一样的\n\t\t// 7）初始化国际化MessageSource相关的组件，比如消息绑定，消息解析等\n\t\t// 8）初始化事件广播器，如果bean factory没有包含事件广播器，那么new一个SimpleApplicationEventMulticaster广播器对象并注册到bean factory中\n\t\t// 9）AbstractApplicationContext定义了一个模板方法onRefresh，留给子类覆写，比如ServletWebServerApplicationContext覆写了该方法来创建内嵌的tomcat容器\n\t\t// 10）注册实现了ApplicationListener接口的监听器，之前已经有了事件广播器，此时就可以派发一些early application events\n\t\t// 11）完成容器bean factory的初始化，并初始化所有剩余的单例bean。这一步非常重要，一些bean postprocessor会在这里调用。\n\t\t// 12）完成容器的刷新工作，并且调用生命周期处理器的onRefresh()方法，并且发布ContextRefreshedEvent事件\n\t\trefreshContext(context);\n\t\t// 【8】执行刷新容器后的后置处理逻辑，注意这里为空方法\n\t\tafterRefresh(context, applicationArguments);\n\t\t// 停止stopWatch计时\n\t\tstopWatch.stop();\n\t\t// 打印日志\n\t\tif (this.logStartupInfo) &#123;\n\t\t\tnew StartupInfoLogger(this.mainApplicationClass)\n\t\t\t\t\t.logStarted(getApplicationLog(), stopWatch);\n\t\t&#125;\n\t\t// 》》》》》发射【ApplicationStartedEvent】事件，标志spring容器已经刷新，此时所有的bean实例都已经加载完毕\n\t\tlisteners.started(context);\n\t\t// 【9】调用ApplicationRunner和CommandLineRunner的run方法，实现spring容器启动后需要做的一些东西比如加载一些业务数据等\n\t\tcallRunners(context, applicationArguments);\n\t&#125;\n\t// 【10】若启动过程中抛出异常，此时用FailureAnalyzers来报告异常\n\t// 并》》》》》发射【ApplicationFailedEvent】事件，标志SpringBoot启动失败\n\tcatch (Throwable ex) &#123;\n\t\thandleRunFailure(context, ex, exceptionReporters, listeners);\n\t\tthrow new IllegalStateException(ex);\n\t&#125;\n\n\ttry &#123;\n\t\t// 》》》》》发射【ApplicationReadyEvent】事件，标志SpringApplication已经正在运行即已经成功启动，可以接收服务请求了。\n\t\tlisteners.running(context);\n\t&#125;\n\t// 若出现异常，此时仅仅报告异常，而不会发射任何事件\n\tcatch (Throwable ex) &#123;\n\t\thandleRunFailure(context, ex, exceptionReporters, null);\n\t\tthrow new IllegalStateException(ex);\n\t&#125;\n\t// 【11】最终返回容器\n\treturn context;\n&#125;\n\n如上代码就是SpringBoot的启动流程了，其中注释也非常详细，主要步骤也已经标注【x】，现将主要步骤总结如下：\n\n从spring.factories配置文件中加载**EventPublishingRunListener**对象，该对象拥有SimpleApplicationEventMulticaster属性，即在SpringBoot启动过程的不同阶段用来发射内置的生命周期事件;\n准备环境变量，包括系统变量，环境变量，命令行参数，默认变量，servlet相关配置变量，随机值以及配置文件（比如application.properties）等;\n控制台打印SpringBoot的**bannner**标志；\n根据不同类型环境创建不同类型的**applicationcontext**容器，因为这里是servlet环境，所以创建的是AnnotationConfigServletWebServerApplicationContext容器对象；\n从spring.factories配置文件中加载**FailureAnalyzers**对象,用来报告SpringBoot启动过程中的异常；\n为刚创建的容器对象做一些初始化工作，准备一些容器属性值等，对ApplicationContext应用一些相关的后置处理和调用各个ApplicationContextInitializer的初始化方法来执行一些初始化逻辑等；\n刷新容器，这一步至关重要。比如调用bean factory的后置处理器，注册BeanPostProcessor后置处理器，初始化事件广播器且广播事件，初始化剩下的单例bean和SpringBoot创建内嵌的Tomcat服务器等等重要且复杂的逻辑都在这里实现，主要步骤可见代码的注释，关于这里的逻辑会在以后的spring源码分析专题详细分析；\n执行刷新容器后的后置处理逻辑，注意这里为空方法；\n调用**ApplicationRunner**和**CommandLineRunner**的run方法，我们实现这两个接口可以在spring容器启动后需要的一些东西比如加载一些业务数据等;\n报告启动异常，即若启动过程中抛出异常，此时用FailureAnalyzers来报告异常;\n最终返回容器对象，这里调用方法没有声明对象来接收。\n\n当然在SpringBoot启动过程中，每个不同的启动阶段会分别发射不同的内置生命周期事件，比如在准备environment前会发射ApplicationStartingEvent事件，在environment准备好后会发射ApplicationEnvironmentPreparedEvent事件，在刷新容器前会发射ApplicationPreparedEvent事件等，总之SpringBoot总共内置了7个生命周期事件，除了标志SpringBoot的不同启动阶段外，同时一些监听器也会监听相应的生命周期事件从而执行一些启动初始化逻辑。\n\n6 小结好了，SpringBoot的启动流程就已经分析完了，这篇内容主要让我们对SpringBoot的启动流程有一个整体的认识，现在还没必要去深究每一个细节，以免丢了主线，现在我们对SpringBoot的启动流程有一个整体的认识即可，关于启动流程的一些重要步骤我们会在以后的源码分析中来深究。\n注：该源码分析对应SpringBoot版本为2.1.0.RELEASE，本文对应的SpringBoot源码解析项目github地址：https://github.com/yuanmabiji/spring-boot-2.1.0.RELEASE\n8 SpringApplication对象是如何构建的？\n1 温故而知新温故而知新，我们来简单回顾一下上篇的内容，上一篇我们分析了SpringBoot的启动流程，现将关键步骤再浓缩总结下：\n\n构建SpringApplication对象，用于启动SpringBoot；\n从spring.factories配置文件中加载EventPublishingRunListener对象用于在不同的启动阶段发射不同的生命周期事件；\n准备环境变量，包括系统变量，环境变量，命令行参数及配置文件（比如application.properties）等；\n创建容器ApplicationContext;\n为第4步创建的容器对象做一些初始化工作，准备一些容器属性值等，同时调用各个ApplicationContextInitializer的初始化方法来执行一些初始化逻辑等；\n刷新容器，这一步至关重要，是重点中的重点，太多复杂逻辑在这里实现；\n调用ApplicationRunner和CommandLineRunner的run方法，可以实现这两个接口在容器启动后来加载一些业务数据等;\n\n在SpringBoot启动过程中，每个不同的启动阶段会分别发射不同的内置生命周期事件，然后相应的监听器会监听这些事件来执行一些初始化逻辑工作比如ConfigFileApplicationListener会监听onApplicationEnvironmentPreparedEvent事件来加载环境变量等。\n\n2 引言上篇文章在讲解SpringBoot的启动流程中，我们有看到新建了一个SpringApplication对象用来启动SpringBoot项目。那么，我们今天就来看看SpringApplication对象的构建过程，同时讲解一下SpringBoot自己实现的SPI机制。\n\n3 SpringApplication对象的构建过程本小节开始讲解SpringApplication对象的构造过程，因为一个对象的构造无非就是在其构造函数里给它的一些成员属性赋值，很少包含其他额外的业务逻辑（当然有时候我们可能也会在构造函数里开启一些线程啥的）。那么，我们先来看下构造SpringApplication对象时需要用到的一些成员属性哈：\n// SpringApplication.java\n\n/**\n * SpringBoot的启动类即包含main函数的主类\n */\nprivate Set&lt;Class&lt;?>> primarySources;\n/**\n * 包含main函数的主类\n */\nprivate Class&lt;?> mainApplicationClass;\n/**\n * 资源加载器\n */\nprivate ResourceLoader resourceLoader;\n/**\n * 应用类型\n */\nprivate WebApplicationType webApplicationType;\n/**\n * 初始化器\n */\nprivate List&lt;ApplicationContextInitializer&lt;?>> initializers;\n/**\n * 监听器\n */\nprivate List&lt;ApplicationListener&lt;?>> listeners;\n\n可以看到构建SpringApplication对象时主要是给上面代码中的六个成员属性赋值，现在我接着来看SpringApplication对象的构造过程。\n我们先回到上一篇文章讲解的构建SpringApplication对象的代码处:\n// SpringApplication.java\n\n// run方法是一个静态方法，用于启动SpringBoot\npublic static ConfigurableApplicationContext run(Class&lt;?>[] primarySources,\n\t\tString[] args) &#123;\n\t// 构建一个SpringApplication对象，并调用其run方法来启动\n\treturn new SpringApplication(primarySources).run(args);\n&#125;\n\n跟进SpringApplication的构造函数中：\n// SpringApplication.java\n\npublic SpringApplication(Class&lt;?>... primarySources) &#123;\n    // 继续调用SpringApplication另一个构造函数\n\tthis(null, primarySources);\n&#125;\n\n继续跟进SpringApplication另一个构造函数：\n// SpringApplication.java\n\npublic SpringApplication(ResourceLoader resourceLoader, Class&lt;?>... primarySources) &#123;\n\t// 【1】给resourceLoader属性赋值，注意传入的resourceLoader参数为null\n\tthis.resourceLoader = resourceLoader;\n\tAssert.notNull(primarySources, \"PrimarySources must not be null\");\n\t// 【2】给primarySources属性赋值，传入的primarySources其实就是SpringApplication.run(MainApplication.class, args);中的MainApplication.class\n\tthis.primarySources = new LinkedHashSet&lt;>(Arrays.asList(primarySources));\n\t// 【3】给webApplicationType属性赋值，根据classpath中存在哪种类型的类来确定是哪种应用类型\n\tthis.webApplicationType = WebApplicationType.deduceFromClasspath();\n\t// 【4】给initializers属性赋值，利用SpringBoot自定义的SPI从spring.factories中加载ApplicationContextInitializer接口的实现类并赋值给initializers属性\n\tsetInitializers((Collection) getSpringFactoriesInstances(\n\t\t\tApplicationContextInitializer.class));\n\t// 【5】给listeners属性赋值，利用SpringBoot自定义的SPI从spring.factories中加载ApplicationListener接口的实现类并赋值给listeners属性\n\tsetListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class));\n\t// 【6】给mainApplicationClass属性赋值，即这里要推断哪个类调用了main函数，然后再赋值给mainApplicationClass属性，用于后面启动流程中打印一些日志。\n\tthis.mainApplicationClass = deduceMainApplicationClass();\n&#125;\n\n可以看到构建SpringApplication对象时其实就是给前面讲的6个SpringApplication类的成员属性赋值而已，做一些初始化工作：\n\n给**resourceLoader**属性赋值，resourceLoader属性，资源加载器，此时传入的resourceLoader参数为null；\n给**primarySources**属性赋值，primarySources属性即SpringApplication.run(MainApplication.class,args);中传入的MainApplication.class，该类为SpringBoot项目的启动类，主要通过该类来扫描Configuration类加载bean；\n给**webApplicationType**属性赋值，webApplicationType属性，代表应用类型，根据classpath存在的相应Application类来判断。因为后面要根据webApplicationType来确定创建哪种Environment对象和创建哪种ApplicationContext，详细分析请见后面的第3.1小节；\n给**initializers**属性赋值，initializers属性为List&lt;ApplicationContextInitializer&lt;?&gt;&gt;集合，利用SpringBoot的SPI机制从spring.factories配置文件中加载，后面在初始化容器的时候会应用这些初始化器来执行一些初始化工作。因为SpringBoot自己实现的SPI机制比较重要，因此独立成一小节来分析，详细分析请见后面的第4小节；\n给**listeners**属性赋值，listeners属性为List&lt;ApplicationListener&lt;?&gt;&gt;集合，同样利用利用SpringBoot的SPI机制从spring.factories配置文件中加载。因为SpringBoot启动过程中会在不同的阶段发射一些事件，所以这些加载的监听器们就是来监听SpringBoot启动过程中的一些生命周期事件的；\n给**mainApplicationClass**属性赋值，mainApplicationClass属性表示包含main函数的类，即这里要推断哪个类调用了main函数，然后把这个类的全限定名赋值给mainApplicationClass属性，用于后面启动流程中打印一些日志，详细分析见后面的第3.2小节。\n\n\n3.1 推断项目应用类型我们接着分析构造SpringApplication对象的第【3】步WebApplicationType.deduceFromClasspath();这句代码：\n// WebApplicationType.java\n\npublic enum WebApplicationType &#123;\n        // 普通的应用\n\tNONE,\n\t// Servlet类型的web应用\n\tSERVLET,\n\t// Reactive类型的web应用\n\tREACTIVE;\n\n\tprivate static final String[] SERVLET_INDICATOR_CLASSES = &#123; \"javax.servlet.Servlet\",\n\t\t\t\"org.springframework.web.context.ConfigurableWebApplicationContext\" &#125;;\n\tprivate static final String WEBMVC_INDICATOR_CLASS = \"org.springframework.\"\n\t\t\t+ \"web.servlet.DispatcherServlet\";\n\tprivate static final String WEBFLUX_INDICATOR_CLASS = \"org.\"\n\t\t\t+ \"springframework.web.reactive.DispatcherHandler\";\n\tprivate static final String JERSEY_INDICATOR_CLASS = \"org.glassfish.jersey.servlet.ServletContainer\";\n\tprivate static final String SERVLET_APPLICATION_CONTEXT_CLASS = \"org.springframework.web.context.WebApplicationContext\";\n\tprivate static final String REACTIVE_APPLICATION_CONTEXT_CLASS = \"org.springframework.boot.web.reactive.context.ReactiveWebApplicationContext\";\n\n\tstatic WebApplicationType deduceFromClasspath() &#123;\n\t\t// 若classpath中不存在\"org.springframework.\" + \"web.servlet.DispatcherServlet\"和\"org.glassfish.jersey.servlet.ServletContainer\"\n\t\t// 则返回WebApplicationType.REACTIVE，表明是reactive应用\n\t\tif (ClassUtils.isPresent(WEBFLUX_INDICATOR_CLASS, null)\n\t\t\t\t&amp;&amp; !ClassUtils.isPresent(WEBMVC_INDICATOR_CLASS, null)\n\t\t\t\t&amp;&amp; !ClassUtils.isPresent(JERSEY_INDICATOR_CLASS, null)) &#123;\n\t\t\treturn WebApplicationType.REACTIVE;\n\t\t&#125;\n\t\t// 若&#123; \"javax.servlet.Servlet\",\n\t\t//       \"org.springframework.web.context.ConfigurableWebApplicationContext\" &#125;\n\t\t// 都不存在在classpath，则说明是不是web应用\n\t\tfor (String className : SERVLET_INDICATOR_CLASSES) &#123;\n\t\t\tif (!ClassUtils.isPresent(className, null)) &#123;\n\t\t\t\treturn WebApplicationType.NONE;\n\t\t\t&#125;\n\t\t&#125;\n\t\t// 最终返回普通的web应用\n\t\treturn WebApplicationType.SERVLET;\n\t&#125;\n&#125;\n\n如上代码，根据classpath判断应用类型，即通过反射加载classpath判断指定的标志类存在与否来分别判断是Reactive应用，Servlet类型的web应用还是普通的应用。\n\n3.2 推断哪个类调用了main函数我们先跳过构造SpringApplication对象的第【4】步和第【5】步，先来分析构造SpringApplication对象的第【6】步this.mainApplicationClass = deduceMainApplicationClass();这句代码：\n// SpringApplication.java\n\nprivate Class&lt;?> deduceMainApplicationClass() &#123;\n\ttry &#123;\n\t\t// 获取StackTraceElement对象数组stackTrace，StackTraceElement对象存储了调用栈相关信息（比如类名，方法名等）\n\t\tStackTraceElement[] stackTrace = new RuntimeException().getStackTrace();\n\t\t// 遍历stackTrace数组\n\t\tfor (StackTraceElement stackTraceElement : stackTrace) &#123;\n\t\t\t// 若stackTraceElement记录的调用方法名等于main\n\t\t\tif (\"main\".equals(stackTraceElement.getMethodName())) &#123;\n\t\t\t\t// 那么就返回stackTraceElement记录的类名即包含main函数的类名\n\t\t\t\treturn Class.forName(stackTraceElement.getClassName());\n\t\t\t&#125;\n\t\t&#125;\n\t&#125;\n\tcatch (ClassNotFoundException ex) &#123;\n\t\t// Swallow and continue\n\t&#125;\n\treturn null;\n&#125;\n\n可以看到deduceMainApplicationClass方法的主要作用就是从StackTraceElement调用栈数组中获取哪个类调用了main方法，然后再返回赋值给mainApplicationClass属性，然后用于后面启动流程中打印一些日志。\n\n4 SpringBoot的SPI机制原理解读由于SpringBoot的SPI机制是一个很重要的知识点，因此这里单独一小节来分析。我们都知道，SpringBoot没有使用Java的SPI机制(Java的SPI机制可以看看笔者的Java是如何实现自己的SPI机制的？,真的是干货满满)，而是自定义实现了一套自己的SPI机制。SpringBoot利用自定义实现的SPI机制可以加载初始化器实现类，监听器实现类和自动配置类等等。如果我们要添加自动配置类或自定义监听器，那么我们很重要的一步就是在spring.factories中进行配置，然后才会被SpringBoot加载。\n好了，那么接下来我们就来重点分析下SpringBoot是如何是实现自己的SPI机制的。\n这里接第3小节的构造SpringApplication对象的第【4】步和第【5】步代码，因为第【4】步和第【5】步都是利用SpringBoot的SPI机制来加载扩展实现类，因此这里只分析第【4】步的setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class));这句代码，看看getSpringFactoriesInstances方法中SpringBoot是如何实现自己的一套SPI来加载ApplicationContextInitializer初始化器接口的扩展实现类的？\n// SpringApplication.java\n\nprivate &lt;T> Collection&lt;T> getSpringFactoriesInstances(Class&lt;T> type) &#123;\n    // 继续调用重载的getSpringFactoriesInstances方法进行加载\n    return getSpringFactoriesInstances(type, new Class&lt;?>[] &#123;&#125;);\n&#125;\n\n继续跟进重载的getSpringFactoriesInstances方法：\n// SpringApplication.java\n\nprivate &lt;T> Collection&lt;T> getSpringFactoriesInstances(Class&lt;T> type,\n\t\tClass&lt;?>[] parameterTypes, Object... args) &#123;\n\t// 【1】获得类加载器\n\tClassLoader classLoader = getClassLoader();\n\t// Use names and ensure unique to protect against duplicates\n\t// 【2】将接口类型和类加载器作为参数传入loadFactoryNames方法，从spring.factories配置文件中进行加载接口实现类\n\tSet&lt;String> names = new LinkedHashSet&lt;>(\n\t\t\tSpringFactoriesLoader.loadFactoryNames(type, classLoader));\n\t// 【3】实例化从spring.factories中加载的接口实现类\n\tList&lt;T> instances = createSpringFactoriesInstances(type, parameterTypes,\n\t\t\tclassLoader, args, names);\n\t// 【4】进行排序\n\tAnnotationAwareOrderComparator.sort(instances);\n\t// 【5】返回加载并实例化好的接口实现类\n\treturn instances;\n&#125;\n\n可以看到，SpringBoot自定义实现的SPI机制代码中最重要的是上面代码的【1】,【2】,【3】步，这3步下面分别进行重点分析。\n\n4.1 获得类加载器还记得Java是如何实现自己的SPI机制的？这篇文章中Java的SPI机制默认是利用线程上下文类加载器去加载扩展类的，那么，SpringBoot自己实现的SPI机制又是利用哪种类加载器去加载**spring.factories**配置文件中的扩展实现类呢？\n我们直接看第【1】步的ClassLoader classLoader = getClassLoader();这句代码，先睹为快：\n// SpringApplication.java\n\npublic ClassLoader getClassLoader() &#123;\n\t// 前面在构造SpringApplicaiton对象时，传入的resourceLoader参数是null，因此不会执行if语句里面的逻辑\n\tif (this.resourceLoader != null) &#123;\n\t\treturn this.resourceLoader.getClassLoader();\n\t&#125;\n\t// 获取默认的类加载器\n\treturn ClassUtils.getDefaultClassLoader();\n&#125;\n\n继续跟进getDefaultClassLoader方法：\n// ClassUtils.java\n\npublic static ClassLoader getDefaultClassLoader() &#123;\n\tClassLoader cl = null;\n\ttry &#123;\n\t        // 【重点】获取线程上下文类加载器\n\t\tcl = Thread.currentThread().getContextClassLoader();\n\t&#125;\n\tcatch (Throwable ex) &#123;\n\t\t// Cannot access thread context ClassLoader - falling back...\n\t&#125;\n\t// 这里的逻辑不会执行\n\tif (cl == null) &#123;\n\t\t// No thread context class loader -> use class loader of this class.\n\t\tcl = ClassUtils.class.getClassLoader();\n\t\tif (cl == null) &#123;\n\t\t\t// getClassLoader() returning null indicates the bootstrap ClassLoader\n\t\t\ttry &#123;\n\t\t\t\tcl = ClassLoader.getSystemClassLoader();\n\t\t\t&#125;\n\t\t\tcatch (Throwable ex) &#123;\n\t\t\t\t// Cannot access system ClassLoader - oh well, maybe the caller can live with null...\n\t\t\t&#125;\n\t\t&#125;\n\t&#125;\n\t// 返回刚才获取的线程上下文类加载器\n\treturn cl;\n&#125;\n\n可以看到，原来SpringBoot的SPI机制中也是用线程上下文类加载器去加载spring.factories文件中的扩展实现类的！\n\n4.2 加载spring.factories配置文件中的SPI扩展类我们再来看下第【2】步中的SpringFactoriesLoader.loadFactoryNames(type, classLoader)这句代码是如何加载spring.factories配置文件中的SPI扩展类的？\n// SpringFactoriesLoader.java\n\npublic static List&lt;String> loadFactoryNames(Class&lt;?> factoryClass, @Nullable ClassLoader classLoader) &#123;\n        // factoryClass即SPI接口，比如ApplicationContextInitializer,EnableAutoConfiguration等接口\n\tString factoryClassName = factoryClass.getName();\n\t// 【主线，重点关注】继续调用loadSpringFactories方法加载SPI扩展类\n\treturn loadSpringFactories(classLoader).getOrDefault(factoryClassName, Collections.emptyList());\n&#125;\n\n继续跟进loadSpringFactories方法：\n// SpringFactoriesLoader.java\n\n/**\n * The location to look for factories.\n * &lt;p>Can be present in multiple JAR files.\n */\npublic static final String FACTORIES_RESOURCE_LOCATION = \"META-INF/spring.factories\";\n\nprivate static Map&lt;String, List&lt;String>> loadSpringFactories(@Nullable ClassLoader classLoader) &#123;\n\t// 以classLoader作为键先从缓存中取，若能取到则直接返回\n\tMultiValueMap&lt;String, String> result = cache.get(classLoader);\n\tif (result != null) &#123;\n\t\treturn result;\n\t&#125;\n\t// 若缓存中无记录，则去spring.factories配置文件中获取\n\ttry &#123;\n\t\t// 这里加载所有jar包中包含\"MATF-INF/spring.factories\"文件的url路径\n\t\tEnumeration&lt;URL> urls = (classLoader != null ?\n\t\t\t\tclassLoader.getResources(FACTORIES_RESOURCE_LOCATION) :\n\t\t\t\tClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION));\n\t\tresult = new LinkedMultiValueMap&lt;>();\n\t\t// 遍历urls路径，将所有spring.factories文件的键值对（key:SPI接口类名 value:SPI扩展类名）\n\t\t// 加载放到 result集合中\n\t\twhile (urls.hasMoreElements()) &#123;\n\t\t\t// 取出一条url\n\t\t\tURL url = urls.nextElement();\n\t\t\t// 将url封装到UrlResource对象中\n\t\t\tUrlResource resource = new UrlResource(url);\n\t\t\t// 利用PropertiesLoaderUtils的loadProperties方法将spring.factories文件键值对内容加载进Properties对象中\n\t\t\tProperties properties = PropertiesLoaderUtils.loadProperties(resource);\n\t\t\t// 遍历刚加载的键值对properties对象\n\t\t\tfor (Map.Entry&lt;?, ?> entry : properties.entrySet()) &#123;\n\t\t\t\t// 取出SPI接口名\n\t\t\t\tString factoryClassName = ((String) entry.getKey()).trim();\n\t\t\t\t// 遍历SPI接口名对应的实现类即SPI扩展类\n\t\t\t\tfor (String factoryName : StringUtils.commaDelimitedListToStringArray((String) entry.getValue())) &#123;\n\t\t\t\t\t// SPI接口名作为key，SPI扩展类作为value放入result中\n\t\t\t\t\tresult.add(factoryClassName, factoryName.trim());\n\t\t\t\t&#125;\n\t\t\t&#125;\n\t\t&#125;\n\t\t// 以classLoader作为key，result作为value放入cache缓存\n\t\tcache.put(classLoader, result);\n\t\t// 最终返回result对象\n\t\treturn result;\n\t&#125;\n\tcatch (IOException ex) &#123;\n\t\tthrow new IllegalArgumentException(\"Unable to load factories from location [\" +\n\t\t\t\tFACTORIES_RESOURCE_LOCATION + \"]\", ex);\n\t&#125;\n&#125;\n\n如上代码，loadSpringFactories方法主要做的事情就是利用之前获取的线程上下文类加载器将classpath中的所有spring.factories配置文件中所有SPI接口的所有扩展实现类给加载出来，然后放入缓存中。注意，这里是一次性加载所有的SPI扩展实现类哈，所以之后根据SPI接口就直接从缓存中获取SPI扩展类了，就不用再次去spring.factories配置文件中获取SPI接口对应的扩展实现类了。比如之后的获取ApplicationListener,FailureAnalyzer和EnableAutoConfiguration接口的扩展实现类都直接从缓存中获取即可。\n\n\n\n\n\n\n\n\n\n思考1： 这里为啥要一次性从spring.factories配置文件中获取所有的扩展类放入缓存中呢？而不是每次都是根据SPI接口去spring.factories配置文件中获取呢？\n\n\n\n\n\n\n\n\n\n思考2： 还记得之前讲的SpringBoot的自动配置源码时提到的AutoConfigurationImportFilter这个接口的作用吗？现在我们应该能更清楚的理解这个接口的作用了吧。\n将所有的SPI扩展实现类加载出来后，此时再调用getOrDefault(factoryClassName, Collections.emptyList())方法根据SPI接口名去筛选当前对应的扩展实现类，比如这里传入的factoryClassName参数名为ApplicationContextInitializer接口，那么这个接口将会作为key从刚才缓存数据中取出ApplicationContextInitializer接口对应的SPI扩展实现类。其中从spring.factories中获取的ApplicationContextInitializer接口对应的所有SPI扩展实现类如下图所示：\n\n\n4.3 实例化从spring.factories中加载的SPI扩展类前面从spring.factories中获取到ApplicationContextInitializer接口对应的所有SPI扩展实现类后，此时会将这些SPI扩展类进行实例化。\n此时我们再来看下前面的第【3】步的实例化代码：List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, \t\t\t\tclassLoader, args, names);。\n// SpringApplication.java\n\nprivate &lt;T> List&lt;T> createSpringFactoriesInstances(Class&lt;T> type,\n\t\tClass&lt;?>[] parameterTypes, ClassLoader classLoader, Object[] args,\n\t\tSet&lt;String> names) &#123;\n\t// 新建instances集合，用于存储稍后实例化后的SPI扩展类对象\n\tList&lt;T> instances = new ArrayList&lt;>(names.size());\n\t// 遍历name集合，names集合存储了所有SPI扩展类的全限定名\n\tfor (String name : names) &#123;\n\t\ttry &#123;\n\t\t\t// 根据全限定名利用反射加载类\n\t\t\tClass&lt;?> instanceClass = ClassUtils.forName(name, classLoader);\n\t\t\t// 断言刚才加载的SPI扩展类是否属于SPI接口类型\n\t\t\tAssert.isAssignable(type, instanceClass);\n\t\t\t// 获得SPI扩展类的构造器\n\t\t\tConstructor&lt;?> constructor = instanceClass\n\t\t\t\t\t.getDeclaredConstructor(parameterTypes);\n\t\t\t// 实例化SPI扩展类\n\t\t\tT instance = (T) BeanUtils.instantiateClass(constructor, args);\n\t\t\t// 添加进instances集合\n\t\t\tinstances.add(instance);\n\t\t&#125;\n\t\tcatch (Throwable ex) &#123;\n\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\"Cannot instantiate \" + type + \" : \" + name, ex);\n\t\t&#125;\n\t&#125;\n\t// 返回\n\treturn instances;\n&#125;\n\n上面代码很简单，主要做的事情就是实例化SPI扩展类。好了，SpringBoot自定义的SPI机制就已经分析完了。\n\n\n\n\n\n\n\n\n\n思考3： SpringBoot为何弃用Java的SPI而自定义了一套SPI？\n\n5 小结好了，本片就到此结束了，先将前面的知识点再总结下：\n\n分析了SpringApplication对象的构造过程；\n分析了SpringBoot自己实现的一套SPI机制。\n\n9 SpringBoot事件监听机制\n1 温故而知新温故而知新，我们来简单回顾一下上篇的内容，上一篇我们分析了SpringApplication 对象的构建过程及 SpringBoot 自己实现的一套 SPI 机制，现将关键步骤再浓缩总结下：\n\nSpringApplication对象的构造过程其实就是给SpringApplication类的6个成员变量赋值；\nSpringBoot 通过以下步骤实现自己的 SPI 机制：\n\n\n1)首先获取线程上下文类加载器;\n2)然后利用上下文类加载器从spring.factories配置文件中加载所有的 SPI 扩展实现类并放入缓存中;\n3)根据 SPI 接口从缓存中取出相应的 SPI 扩展实现类;\n4)实例化从缓存中取出的 SPI 扩展实现类并返回。\n\n\n2 引言在 SpringBoot 启动过程中，每个不同的启动阶段会分别广播不同的内置生命周期事件，然后相应的监听器会监听这些事件来执行一些初始化逻辑工作比如ConfigFileApplicationListener会监听onApplicationEnvironmentPreparedEvent事件来加载配置文件application.properties的环境变量等。\n因此本篇内容将来分析下 SpringBoot 的事件监听机制的源码。\n\n3 SpringBoot 广播内置生命周期事件流程分析为了探究 SpringBoot 广播内置生命周期事件流程，我们再来回顾一下 SpringBoot 的启动流程代码：\n// SpringApplication.java\n\npublic ConfigurableApplicationContext run(String... args) &#123;\n\tStopWatch stopWatch = new StopWatch();\n\tstopWatch.start();\n\tConfigurableApplicationContext context = null;\n\tCollection&lt;SpringBootExceptionReporter> exceptionReporters = new ArrayList&lt;>();\n\tconfigureHeadlessProperty();\n\t// 【0】新建一个SpringApplicationRunListeners对象用于发射SpringBoot启动过程中的生命周期事件\n\tSpringApplicationRunListeners listeners = getRunListeners(args);\n\t// 【1】》》》》》发射【ApplicationStartingEvent】事件，标志SpringApplication开始启动\n\tlisteners.starting();\n\ttry &#123;\n\t\tApplicationArguments applicationArguments = new DefaultApplicationArguments(\n\t\t\t\targs);\n\t\t// 【2】》》》》》发射【ApplicationEnvironmentPreparedEvent】事件，此时会去加载application.properties等配置文件的环境变量，同时也有标志环境变量已经准备好的意思\n\t\tConfigurableEnvironment environment = prepareEnvironment(listeners,\n\t\t\t\tapplicationArguments);\n\t\tconfigureIgnoreBeanInfo(environment);\n\t\tBanner printedBanner = printBanner(environment);\n\t\tcontext = createApplicationContext();\n\t\texceptionReporters = getSpringFactoriesInstances(\n\t\t\t\tSpringBootExceptionReporter.class,\n\t\t\t\tnew Class[] &#123; ConfigurableApplicationContext.class &#125;, context);\n\t\t// 【3】》》》》》发射【ApplicationContextInitializedEvent】事件，标志context容器被创建且已准备好\n\t\t// 【4】》》》》》发射【ApplicationPreparedEvent】事件，标志Context容器已经准备完成\n\t\tprepareContext(context, environment, listeners, applicationArguments,\n\t\t\t\tprintedBanner);\n\t\trefreshContext(context);\n\t\tafterRefresh(context, applicationArguments);\n\t\tstopWatch.stop();\n\t\tif (this.logStartupInfo) &#123;\n\t\t\tnew StartupInfoLogger(this.mainApplicationClass)\n\t\t\t\t\t.logStarted(getApplicationLog(), stopWatch);\n\t\t&#125;\n\t\t// 【5】》》》》》发射【ApplicationStartedEvent】事件，标志spring容器已经刷新，此时所有的bean实例都已经加载完毕\n\t\tlisteners.started(context);\n\t\tcallRunners(context, applicationArguments);\n\t&#125;\n\t// 【6】》》》》》发射【ApplicationFailedEvent】事件，标志SpringBoot启动失败\n\tcatch (Throwable ex) &#123;\n\t\thandleRunFailure(context, ex, exceptionReporters, listeners);\n\t\tthrow new IllegalStateException(ex);\n\t&#125;\n\ttry &#123;\n\t\t// 【7】》》》》》发射【ApplicationReadyEvent】事件，标志SpringApplication已经正在运行即已经成功启动，可以接收服务请求了。\n\t\tlisteners.running(context);\n\t&#125;\n\tcatch (Throwable ex) &#123;\n\t\thandleRunFailure(context, ex, exceptionReporters, null);\n\t\tthrow new IllegalStateException(ex);\n\t&#125;\n\treturn context;\n&#125;\n\n可以看到 SpringBoot 在启动过程中首先会先新建一个SpringApplicationRunListeners对象用于发射 SpringBoot 启动过程中的各种生命周期事件，比如发射ApplicationStartingEvent,ApplicationEnvironmentPreparedEvent和ApplicationContextInitializedEvent等事件，然后相应的监听器会执行一些 SpringBoot 启动过程中的初始化逻辑。那么，监听这些 SpringBoot 的生命周期事件的监听器们是何时被加载实例化的呢？还记得上篇文章在分析SpringApplication的构建过程吗？没错，这些执行初始化逻辑的监听器们正是在SpringApplication的构建过程中根据ApplicationListener接口去spring.factories配置文件中加载并实例化的。\n\n3.1 为广播 SpringBoot 内置生命周期事件做前期准备\n3.1.1 加载 ApplicationListener 监听器实现类我们再来回顾下SpringApplication 对象是如何构建的？ SpringBoot 源码（八）一文中讲到在构建SpringApplication对象时的setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class));这句代码。\n这句代码做的事情就是从spring.factories中加载出ApplicationListener事件监听接口的 SPI 扩展实现类然后添加到SpringApplication对象的listeners集合中，用于后续监听 SpringBoot 启动过程中的事件，来执行一些初始化逻辑工作。\nSpringBoot 启动时的具体监听器们都实现了ApplicationListener接口，其在spring.factories部分配置如下：\n\n不过在调试时，会从所有的 spring.factories 配置文件中加载监听器，最终加载了 10 个监听器。如下图：\n\n\n3.1.2 加载 SPI 扩展类 EventPublishingRunListener前面讲到，在 SpringBoot 的启动过程中首先会先新建一个SpringApplicationRunListeners对象用于发射 SpringBoot 启动过程中的生命周期事件，即我们现在来看下SpringApplicationRunListeners listeners = getRunListeners(args);这句代码：\n// SpringApplication.java\n\nprivate SpringApplicationRunListeners getRunListeners(String[] args) &#123;\n\t// 构造一个由SpringApplication.class和String[].class组成的types\n\tClass&lt;?>[] types = new Class&lt;?>[] &#123; SpringApplication.class, String[].class &#125;;\n\t// 1) 根据SpringApplicationRunListener接口去spring.factories配置文件中加载其SPI扩展实现类\n\t// 2) 构建一个SpringApplicationRunListeners对象并返回\n\treturn new SpringApplicationRunListeners(logger, getSpringFactoriesInstances(\n\t\t\tSpringApplicationRunListener.class, types, this, args));\n&#125;\n\n我们将重点放到getSpringFactoriesInstances( SpringApplicationRunListener.class, types, this, args)这句代码，getSpringFactoriesInstances这个方法我们已经很熟悉，在上一篇分析 SpringBoot 的 SPI 机制时已经详细分析过这个方法。可以看到 SpringBoot 此时又是根据SpringApplicationRunListener这个 SPI 接口去spring.factories中加载相应的 SPI 扩展实现类，我们直接去spring.factories中看看SpringApplicationRunListener有哪些 SPI 实现类：\n由上图可以看到，SpringApplicationRunListener只有EventPublishingRunListener这个 SPI 实现类EventPublishingRunListener这个哥们在 SpringBoot 的启动过程中尤其重要，由其在 SpringBoot 启动过程的不同阶段发射不同的 SpringBoot 的生命周期事件，即**SpringApplicationRunListeners**对象没有承担广播事件的职责，而最终是委托**EventPublishingRunListener**这个哥们来广播事件的。\n因为从spring.factories中加载EventPublishingRunListener类后还会实例化该类，那么我们再跟进EventPublishingRunListener的源码，看看其是如何承担发射 SpringBoot 生命周期事件这一职责的？\n// EventPublishingRunListener.java\n\npublic class EventPublishingRunListener implements SpringApplicationRunListener, Ordered &#123;\n\n\tprivate final SpringApplication application;\n\n\tprivate final String[] args;\n\t/**\n\t * 拥有一个SimpleApplicationEventMulticaster事件广播器来广播事件\n\t */\n\tprivate final SimpleApplicationEventMulticaster initialMulticaster;\n\n\tpublic EventPublishingRunListener(SpringApplication application, String[] args) &#123;\n\t\tthis.application = application;\n\t\tthis.args = args;\n\t\t// 新建一个事件广播器SimpleApplicationEventMulticaster对象\n\t\tthis.initialMulticaster = new SimpleApplicationEventMulticaster();\n\t\t// 遍历在构造SpringApplication对象时从spring.factories配置文件中获取的事件监听器\n\t\tfor (ApplicationListener&lt;?> listener : application.getListeners()) &#123;\n\t\t\t// 将从spring.factories配置文件中获取的事件监听器们添加到事件广播器initialMulticaster对象的相关集合中\n\t\t\tthis.initialMulticaster.addApplicationListener(listener);\n\t\t&#125;\n\t&#125;\n\n\t@Override\n\tpublic int getOrder() &#123;\n\t\treturn 0;\n\t&#125;\n\t// 》》》》》发射【ApplicationStartingEvent】事件\n\t@Override\n\tpublic void starting() &#123;\n\t\tthis.initialMulticaster.multicastEvent(\n\t\t\t\tnew ApplicationStartingEvent(this.application, this.args));\n\t&#125;\n\t// 》》》》》发射【ApplicationEnvironmentPreparedEvent】事件\n\t@Override\n\tpublic void environmentPrepared(ConfigurableEnvironment environment) &#123;\n\t\tthis.initialMulticaster.multicastEvent(new ApplicationEnvironmentPreparedEvent(\n\t\t\t\tthis.application, this.args, environment));\n\t&#125;\n\t// 》》》》》发射【ApplicationContextInitializedEvent】事件\n\t@Override\n\tpublic void contextPrepared(ConfigurableApplicationContext context) &#123;\n\t\tthis.initialMulticaster.multicastEvent(new ApplicationContextInitializedEvent(\n\t\t\t\tthis.application, this.args, context));\n\t&#125;\n\t// 》》》》》发射【ApplicationPreparedEvent】事件\n\t@Override\n\tpublic void contextLoaded(ConfigurableApplicationContext context) &#123;\n\t\tfor (ApplicationListener&lt;?> listener : this.application.getListeners()) &#123;\n\t\t\tif (listener instanceof ApplicationContextAware) &#123;\n\t\t\t\t((ApplicationContextAware) listener).setApplicationContext(context);\n\t\t\t&#125;\n\t\t\tcontext.addApplicationListener(listener);\n\t\t&#125;\n\t\tthis.initialMulticaster.multicastEvent(\n\t\t\t\tnew ApplicationPreparedEvent(this.application, this.args, context));\n\t&#125;\n\t// 》》》》》发射【ApplicationStartedEvent】事件\n\t@Override\n\tpublic void started(ConfigurableApplicationContext context) &#123;\n\t\tcontext.publishEvent(\n\t\t\t\tnew ApplicationStartedEvent(this.application, this.args, context));\n\t&#125;\n\t// 》》》》》发射【ApplicationReadyEvent】事件\n\t@Override\n\tpublic void running(ConfigurableApplicationContext context) &#123;\n\t\tcontext.publishEvent(\n\t\t\t\tnew ApplicationReadyEvent(this.application, this.args, context));\n\t&#125;\n\t// 》》》》》发射【ApplicationFailedEvent】事件\n\t@Override\n\tpublic void failed(ConfigurableApplicationContext context, Throwable exception) &#123;\n\t\tApplicationFailedEvent event = new ApplicationFailedEvent(this.application,\n\t\t\t\tthis.args, context, exception);\n\t\tif (context != null &amp;&amp; context.isActive()) &#123;\n\t\t\t// Listeners have been registered to the application context so we should\n\t\t\t// use it at this point if we can\n\t\t\tcontext.publishEvent(event);\n\t\t&#125;\n\t\telse &#123;\n\t\t\t// An inactive context may not have a multicaster so we use our multicaster to\n\t\t\t// call all of the context's listeners instead\n\t\t\tif (context instanceof AbstractApplicationContext) &#123;\n\t\t\t\tfor (ApplicationListener&lt;?> listener : ((AbstractApplicationContext) context)\n\t\t\t\t\t\t.getApplicationListeners()) &#123;\n\t\t\t\t\tthis.initialMulticaster.addApplicationListener(listener);\n\t\t\t\t&#125;\n\t\t\t&#125;\n\t\t\tthis.initialMulticaster.setErrorHandler(new LoggingErrorHandler());\n\t\t\tthis.initialMulticaster.multicastEvent(event);\n\t\t&#125;\n\t&#125;\n\n\t// ...省略非关键代码\n&#125;\n\n可以看到EventPublishingRunListener类实现了SpringApplicationRunListener接口，SpringApplicationRunListener接口定义了 SpringBoot 启动时发射生命周期事件的接口方法，而EventPublishingRunListener类正是通过实现SpringApplicationRunListener接口的starting,environmentPrepared和contextPrepared等方法来广播 SpringBoot 不同的生命周期事件，我们直接看下SpringApplicationRunListener接口源码好了：\n// SpringApplicationRunListener.java\n\npublic interface SpringApplicationRunListener &#123;\n\n\tvoid starting();\n\n\tvoid environmentPrepared(ConfigurableEnvironment environment);\n\n\tvoid contextPrepared(ConfigurableApplicationContext context);\n\n\tvoid contextLoaded(ConfigurableApplicationContext context);\n\n\tvoid started(ConfigurableApplicationContext context);\n\n\tvoid running(ConfigurableApplicationContext context);\n\n\tvoid failed(ConfigurableApplicationContext context, Throwable exception);\n&#125;\n\n我们再接着分析EventPublishingRunListener这个类，可以看到其有一个重要的成员属性initialMulticaster，该成员属性是SimpleApplicationEventMulticaster类对象，该类正是承担了广播 SpringBoot 启动时生命周期事件的职责,即**EventPublishingRunListener**对象没有承担广播事件的职责，而最终是委托**SimpleApplicationEventMulticaster**这个哥们来广播事件的。 从EventPublishingRunListener的源码中也可以看到在starting,environmentPrepared和contextPrepared等方法中也正是通过调用SimpleApplicationEventMulticaster类对象的multicastEvent方法来广播事件的。\n\n\n\n\n\n\n\n\n\n思考 SpringBoot 启动过程中发射事件时事件广播者是层层委托职责的，起初由SpringApplicationRunListeners对象承担，然后SpringApplicationRunListeners对象将广播事件职责委托给EventPublishingRunListener对象，最终EventPublishingRunListener对象将广播事件的职责委托给SimpleApplicationEventMulticaster对象。为什么要层层委托这么做呢？ 这个值得大家思考。\n前面讲到从spring.factories中加载出EventPublishingRunListener类后会实例化，而实例化必然会通过EventPublishingRunListener的构造函数来进行实例化，因此我们接下来分析下EventPublishingRunListener的构造函数源码：\n// EventPublishingRunListener.java\n\npublic EventPublishingRunListener(SpringApplication application, String[] args) &#123;\n\tthis.application = application;\n\tthis.args = args;\n\t// 新建一个事件广播器SimpleApplicationEventMulticaster对象\n\tthis.initialMulticaster = new SimpleApplicationEventMulticaster();\n\t// 遍历在构造SpringApplication对象时从spring.factories配置文件中获取的事件监听器\n\tfor (ApplicationListener&lt;?> listener : application.getListeners()) &#123;\n\t\t// 将从spring.factories配置文件中获取的事件监听器们添加到事件广播器initialMulticaster对象的相关集合中\n\t\tthis.initialMulticaster.addApplicationListener(listener);\n\t&#125;\n&#125;\n\n可以看到在EventPublishingRunListener的构造函数中有一个for循环会遍历之前从spring.factories中加载的监听器们，然后添加到集合中缓存起来，用于以后广播各种事件时直接从这个集合中取出来即可，而不用再去spring.factories中加载，提高效率。\n\n3.2 广播 SpringBoot 的内置生命周期事件从spring.factories配置文件中加载并实例化EventPublishingRunListener对象后，那么在在 SpringBoot 的启动过程中会发射一系列 SpringBoot 内置的生命周期事件，我们再来回顾下 SpringBoot 启动过程中的源码：\n// SpringApplication.java\n\npublic ConfigurableApplicationContext run(String... args) &#123;\n\tStopWatch stopWatch = new StopWatch();\n\tstopWatch.start();\n\tConfigurableApplicationContext context = null;\n\tCollection&lt;SpringBootExceptionReporter> exceptionReporters = new ArrayList&lt;>();\n\tconfigureHeadlessProperty();\n\t// 【0】新建一个SpringApplicationRunListeners对象用于发射SpringBoot启动过程中的生命周期事件\n\tSpringApplicationRunListeners listeners = getRunListeners(args);\n\t// 【1】》》》》》发射【ApplicationStartingEvent】事件，标志SpringApplication开始启动\n\tlisteners.starting();\n\ttry &#123;\n\t\tApplicationArguments applicationArguments = new DefaultApplicationArguments(\n\t\t\t\targs);\n\t\t// 【2】》》》》》发射【ApplicationEnvironmentPreparedEvent】事件，此时会去加载application.properties等配置文件的环境变量，同时也有标志环境变量已经准备好的意思\n\t\tConfigurableEnvironment environment = prepareEnvironment(listeners,\n\t\t\t\tapplicationArguments);\n\t\tconfigureIgnoreBeanInfo(environment);\n\t\tBanner printedBanner = printBanner(environment);\n\t\tcontext = createApplicationContext();\n\t\texceptionReporters = getSpringFactoriesInstances(\n\t\t\t\tSpringBootExceptionReporter.class,\n\t\t\t\tnew Class[] &#123; ConfigurableApplicationContext.class &#125;, context);\n\t\t// 【3】》》》》》发射【ApplicationContextInitializedEvent】事件，标志context容器被创建且已准备好\n\t\t// 【4】》》》》》发射【ApplicationPreparedEvent】事件，标志Context容器已经准备完成\n\t\tprepareContext(context, environment, listeners, applicationArguments,\n\t\t\t\tprintedBanner);\n\t\trefreshContext(context);\n\t\tafterRefresh(context, applicationArguments);\n\t\tstopWatch.stop();\n\t\tif (this.logStartupInfo) &#123;\n\t\t\tnew StartupInfoLogger(this.mainApplicationClass)\n\t\t\t\t\t.logStarted(getApplicationLog(), stopWatch);\n\t\t&#125;\n\t\t// 【5】》》》》》发射【ApplicationStartedEvent】事件，标志spring容器已经刷新，此时所有的bean实例都已经加载完毕\n\t\tlisteners.started(context);\n\t\tcallRunners(context, applicationArguments);\n\t&#125;\n\t// 【6】》》》》》发射【ApplicationFailedEvent】事件，标志SpringBoot启动失败\n\tcatch (Throwable ex) &#123;\n\t\thandleRunFailure(context, ex, exceptionReporters, listeners);\n\t\tthrow new IllegalStateException(ex);\n\t&#125;\n\ttry &#123;\n\t\t// 【7】》》》》》发射【ApplicationReadyEvent】事件，标志SpringApplication已经正在运行即已经成功启动，可以接收服务请求了。\n\t\tlisteners.running(context);\n\t&#125;\n\tcatch (Throwable ex) &#123;\n\t\thandleRunFailure(context, ex, exceptionReporters, null);\n\t\tthrow new IllegalStateException(ex);\n\t&#125;\n\treturn context;\n&#125;\n\n可以看到在 SpringBoot 的启动过程中总共会发射 7 种不同类型的生命周期事件，来标志 SpringBoot 的不同启动阶段，同时，这些生命周期事件的监听器们也会执行一些启动过程中的初始化逻辑，关于这些监听器的初始化逻辑将在下一篇内容中会分析。以下是 SpringBoot 启动过程中要发射的事件类型，其中ApplicationFailedEvent在 SpringBoot 启动过程中遇到异常才会发射：\n\nApplicationStartingEvent\nApplicationEnvironmentPreparedEvent\nApplicationContextInitializedEvent\nApplicationPreparedEvent\nApplicationStartedEvent\nApplicationFailedEvent\nApplicationReadyEvent\n\n我们以listeners.starting();这句代码为例，看看EventPublishingRunListener对象发射事件的源码：\n// SpringApplicationRunListeners.java\n\npublic void starting() &#123;\n\t// 遍历listeners集合，这里实质取出的就是刚才从spring.factories中取出的SPI实现类EventPublishingRunListener\n\t// 而EventPublishingRunListener对象承担了SpringBoot启动过程中负责广播不同的生命周期事件\n\tfor (SpringApplicationRunListener listener : this.listeners) &#123;\n\t        // 调用EventPublishingRunListener的starting方法来广播ApplicationStartingEvent事件\n\t\tlistener.starting();\n\t&#125;\n&#125;\n\n继续跟进listener.starting();的源码:\nEventPublishingRunListener.java\n\n// 》》》》》发射【ApplicationStartingEvent】事件\npublic void starting() &#123;\n\t// EventPublishingRunListener对象将发布ApplicationStartingEvent这件事情委托给了initialMulticaster对象\n\t// 调用initialMulticaster的multicastEvent方法来发射ApplicationStartingEvent事件\n\tthis.initialMulticaster.multicastEvent(\n\t\t\tnew ApplicationStartingEvent(this.application, this.args));\n&#125;\n\n可以看到，EventPublishingRunListener对象将发布ApplicationStartingEvent这件事情委托给了SimpleApplicationEventMulticaster对象initialMulticaster,,而initialMulticaster对象最终会调用其multicastEvent方法来发射ApplicationStartingEvent事件。关于SimpleApplicationEventMulticaster类如何广播事件，笔者已经在Spring 是如何实现事件监听机制的？ Spring 源码（二）这篇文章已经详细分析，这里不再赘述。\n关于 SpringBoot 启动过程中发射其他生命周期事件的源码这里不再分析\n\n4 SpringBoot 的内置生命周期事件总结好了，前面已经分析了 SpringBoot 启动过程中要发射的各种生命周期事件，下面列一个表格总结下：\n\n\n5 小结SpringBoot 启动过程中广播生命周期事件的源码分析就到此结束了，下一篇会继续介绍监听这些生命周期事件的监听器们。我们再回顾本篇内容总结下关键点：\nSpringBoot 启动过程中会发射 7 种类型的生命周期事件，标志不同的启动阶段，然后相应的监听器会监听这些事件来执行一些初始化逻辑工作。\n\n\n10 SpringBoot内置生命周期事件详解\n1 温故而知新温故而知新，我们来简单回顾一下上篇的内容，上一篇我们分析了SpringBoot 启动时广播生命周期事件的原理，现将关键步骤再浓缩总结下：\n\n为广播 SpringBoot 内置生命周期事件做前期准备：1）首先加载ApplicationListener监听器实现类；2）其次加载 SPI 扩展类EventPublishingRunListener。\nSpringBoot 启动时利用EventPublishingRunListener广播生命周期事件，然后ApplicationListener监听器实现类监听相应的生命周期事件执行一些初始化逻辑的工作。\n\n\n2 引言上篇文章的侧重点是分析了 SpringBoot 启动时广播生命周期事件的原理，此篇文章我们再来详细分析 SpringBoot 内置的 7 种生命周期事件的源码。\n\n3 SpringBoot 生命周期事件源码分析分析 SpringBoot 的生命周期事件，我们先来看一张类结构图：\n\n由上图可以看到事件类之间的关系：\n\n最顶级的父类是 JDK 的事件基类EventObject；\n然后 Spring 的事件基类ApplicationEvent继承了 JDK 的事件基类EventObject；\n其次 SpringBoot 的生命周期事件基类SpringApplicationEvent继承了 Spring 的事件基类ApplicationEvent；\n最后 SpringBoot 具体的 7 个生命周期事件类再继承了 SpringBoot 的生命周期事件基类SpringApplicationEvent。\n\n\n3.1 JDK 的事件基类 EventObjectEventObject类是 JDK 的事件基类，可以说是所有 Java 事件类的基本，即所有的 Java 事件类都直接或间接继承于该类，源码如下：\n// EventObject.java\n\npublic class EventObject implements java.io.Serializable &#123;\n\n    private static final long serialVersionUID = 5516075349620653480L;\n\n    /**\n     * The object on which the Event initially occurred.\n     */\n    protected transient Object  source;\n    /**\n     * Constructs a prototypical Event.\n     *\n     * @param    source    The object on which the Event initially occurred.\n     * @exception  IllegalArgumentException  if source is null.\n     */\n    public EventObject(Object source) &#123;\n        if (source == null)\n            throw new IllegalArgumentException(\"null source\");\n        this.source = source;\n    &#125;\n    /**\n     * The object on which the Event initially occurred.\n     *\n     * @return   The object on which the Event initially occurred.\n     */\n    public Object getSource() &#123;\n        return source;\n    &#125;\n    /**\n     * Returns a String representation of this EventObject.\n     *\n     * @return  A a String representation of this EventObject.\n     */\n    public String toString() &#123;\n        return getClass().getName() + \"[source=\" + source + \"]\";\n    &#125;\n&#125;\n\n可以看到EventObject类只有一个属性source，这个属性是用来记录最初事件是发生在哪个类，举个栗子，比如在 SpringBoot 启动过程中会发射ApplicationStartingEvent事件，而这个事件最初是在SpringApplication类中发射的，因此source就是SpringApplication对象。\n\n3.2 Spring 的事件基类 ApplicationEventApplicationEvent继承了 DK 的事件基类EventObject类，是 Spring 的事件基类，被所有 Spring 的具体事件类继承，源码如下：\n// ApplicationEvent.java\n\n/**\n * Class to be extended by all application events. Abstract as it\n * doesn't make sense for generic events to be published directly.\n *\n * @author Rod Johnson\n * @author Juergen Hoeller\n */\npublic abstract class ApplicationEvent extends EventObject &#123;\n\t/** use serialVersionUID from Spring 1.2 for interoperability. */\n\tprivate static final long serialVersionUID = 7099057708183571937L;\n\t/** System time when the event happened. */\n\tprivate final long timestamp;\n\t/**\n\t * Create a new ApplicationEvent.\n\t * @param source the object on which the event initially occurred (never &#123;@code null&#125;)\n\t */\n\tpublic ApplicationEvent(Object source) &#123;\n\t\tsuper(source);\n\t\tthis.timestamp = System.currentTimeMillis();\n\t&#125;\n\t/**\n\t * Return the system time in milliseconds when the event happened.\n\t */\n\tpublic final long getTimestamp() &#123;\n\t\treturn this.timestamp;\n\t&#125;\n&#125;\n\n可以看到ApplicationEvent有且仅有一个属性timestamp，该属性是用来记录事件发生的时间。\n\n3.3 SpringBoot 的事件基类 SpringApplicationEventSpringApplicationEvent类继承了 Spring 的事件基类ApplicationEvent，是所有 SpringBoot 内置生命周期事件的父类，源码如下：\n/**\n * Base class for &#123;@link ApplicationEvent&#125; related to a &#123;@link SpringApplication&#125;.\n *\n * @author Phillip Webb\n */\n@SuppressWarnings(\"serial\")\npublic abstract class SpringApplicationEvent extends ApplicationEvent &#123;\n\tprivate final String[] args;\n\tpublic SpringApplicationEvent(SpringApplication application, String[] args) &#123;\n\t\tsuper(application);\n\t\tthis.args = args;\n\t&#125;\n\tpublic SpringApplication getSpringApplication() &#123;\n\t\treturn (SpringApplication) getSource();\n\t&#125;\n\tpublic final String[] getArgs() &#123;\n\t\treturn this.args;\n\t&#125;\n&#125;\n\n可以看到SpringApplicationEvent有且仅有一个属性args，该属性就是 SpringBoot 启动时的命令行参数即标注@SpringBootApplication启动类中main函数的参数。\n\n3.4 SpringBoot 具体的生命周期事件类接下来我们再来看一下SpringBoot内置生命周期事件即SpringApplicationEvent的具体子类们。\n\n3.4.1 ApplicationStartingEvent// ApplicationStartingEvent.java\n\npublic class ApplicationStartingEvent extends SpringApplicationEvent &#123;\n\tpublic ApplicationStartingEvent(SpringApplication application, String[] args) &#123;\n\t\tsuper(application, args);\n\t&#125;\n&#125;\n\nSpringBoot 开始启动时便会发布ApplicationStartingEvent事件，其发布时机在环境变量 Environment 或容器 ApplicationContext 创建前但在注册ApplicationListener具体监听器之后，标志标志SpringApplication开始启动。\n\n3.4.2 ApplicationEnvironmentPreparedEvent// ApplicationEnvironmentPreparedEvent.java\n\npublic class ApplicationEnvironmentPreparedEvent extends SpringApplicationEvent &#123;\n\tprivate final ConfigurableEnvironment environment;\n\t/**\n\t * Create a new &#123;@link ApplicationEnvironmentPreparedEvent&#125; instance.\n\t * @param application the current application\n\t * @param args the arguments the application is running with\n\t * @param environment the environment that was just created\n\t */\n\tpublic ApplicationEnvironmentPreparedEvent(SpringApplication application,\n\t\t\tString[] args, ConfigurableEnvironment environment) &#123;\n\t\tsuper(application, args);\n\t\tthis.environment = environment;\n\t&#125;\n\t/**\n\t * Return the environment.\n\t * @return the environment\n\t */\n\tpublic ConfigurableEnvironment getEnvironment() &#123;\n\t\treturn this.environment;\n\t&#125;\n&#125;\n\n可以看到ApplicationEnvironmentPreparedEvent事件多了一个environment属性，我们不妨想一下，多了environment属性的作用是啥？ 答案就是ApplicationEnvironmentPreparedEvent事件的environment属性作用是利用事件发布订阅机制，相应监听器们可以从ApplicationEnvironmentPreparedEvent事件中取出environment变量，然后我们可以为environment属性增加属性值或读出environment变量中的值。\n\n\n\n\n\n\n\n\n\n举个栗子： ConfigFileApplicationListener监听器就是监听了ApplicationEnvironmentPreparedEvent事件，然后取出ApplicationEnvironmentPreparedEvent事件的environment属性，然后再为environment属性增加application.properties配置文件中的环境变量值。\n当 SpringApplication 已经开始启动且环境变量Environment已经创建后，并且为环境变量Environment配置了命令行和Servlet等类型的环境变量后，此时会发布ApplicationEnvironmentPreparedEvent事件。\n监听ApplicationEnvironmentPreparedEvent事件的第一个监听器是ConfigFileApplicationListener，因为是ConfigFileApplicationListener监听器还要为环境变量Environment增加application.properties配置文件中的环境变量；此后还有一些也是监听ApplicationEnvironmentPreparedEvent事件的其他监听器监听到此事件时，此时可以说环境变量Environment几乎已经完全准备好了。\n\n\n\n\n\n\n\n\n\n思考： 监听同一事件的监听器们执行监听逻辑时是有顺序的，我们可以想一下这个排序逻辑是什么时候排序的？还有为什么要这样排序呢？\n\n3.4.3 ApplicationContextInitializedEvent// ApplicationContextInitializedEvent.java\n\npublic class ApplicationContextInitializedEvent extends SpringApplicationEvent &#123;\n\tprivate final ConfigurableApplicationContext context;\n\t/**\n\t * Create a new &#123;@link ApplicationContextInitializedEvent&#125; instance.\n\t * @param application the current application\n\t * @param args the arguments the application is running with\n\t * @param context the context that has been initialized\n\t */\n\tpublic ApplicationContextInitializedEvent(SpringApplication application,\n\t\t\tString[] args, ConfigurableApplicationContext context) &#123;\n\t\tsuper(application, args);\n\t\tthis.context = context;\n\t&#125;\n\t/**\n\t * Return the application context.\n\t * @return the context\n\t */\n\tpublic ConfigurableApplicationContext getApplicationContext() &#123;\n\t\treturn this.context;\n\t&#125;\n&#125;\n\n可以看到ApplicationContextInitializedEvent事件多了个ConfigurableApplicationContext类型的context属性，context属性的作用同样是为了相应监听器可以拿到这个context属性执行一些逻辑，具体作用将在3.4.4详述。\nApplicationContextInitializedEvent事件在ApplicationContext容器创建后，且为ApplicationContext容器设置了environment变量和执行了ApplicationContextInitializers的初始化方法后但在 bean 定义加载前触发，标志 ApplicationContext 已经初始化完毕。\n\n\n\n\n\n\n\n\n\n扩展： 可以看到ApplicationContextInitializedEvent是在为context容器配置environment变量后触发，此时ApplicationContextInitializedEvent等事件只要有context容器的话，那么其他需要environment环境变量的监听器只需要从context中取出environment变量即可，从而ApplicationContextInitializedEvent等事件没必要再配置environment属性。\n\n3.4.4 ApplicationPreparedEvent// ApplicationPreparedEvent.java\n\npublic class ApplicationPreparedEvent extends SpringApplicationEvent &#123;\n\tprivate final ConfigurableApplicationContext context;\n\t/**\n\t * Create a new &#123;@link ApplicationPreparedEvent&#125; instance.\n\t * @param application the current application\n\t * @param args the arguments the application is running with\n\t * @param context the ApplicationContext about to be refreshed\n\t */\n\tpublic ApplicationPreparedEvent(SpringApplication application, String[] args,\n\t\t\tConfigurableApplicationContext context) &#123;\n\t\tsuper(application, args);\n\t\tthis.context = context;\n\t&#125;\n\t/**\n\t * Return the application context.\n\t * @return the context\n\t */\n\tpublic ConfigurableApplicationContext getApplicationContext() &#123;\n\t\treturn this.context;\n\t&#125;\n&#125;\n\n同样可以看到ApplicationPreparedEvent事件多了个ConfigurableApplicationContext类型的context属性，多了context属性的作用是能让监听该事件的监听器们能拿到context属性，监听器拿到context属性一般有如下作用：\n\n从事件中取出context属性，然后可以增加一些后置处理器，比如ConfigFileApplicationListener监听器监听到ApplicationPreparedEvent事件后，然后取出context变量，通过context变量增加了PropertySourceOrderingPostProcessor这个后置处理器；\n通过context属性取出beanFactory容器，然后注册一些bean，比如LoggingApplicationListener监听器通过ApplicationPreparedEvent事件的context属性取出beanFactory容器,然后注册了springBootLoggingSystem这个单例bean；\n通过context属性取出Environment环境变量，然后就可以操作环境变量，比如PropertiesMigrationListener。\n\nApplicationPreparedEvent事件在ApplicationContext容器已经完全准备好时但在容器刷新前触发，在这个阶段bean定义已经加载完毕还有environment已经准备好可以用了。\n\n3.4.5 ApplicationStartedEvent// ApplicationStartedEvent.java\n\npublic class ApplicationStartedEvent extends SpringApplicationEvent &#123;\n\tprivate final ConfigurableApplicationContext context;\n\t/**\n\t * Create a new &#123;@link ApplicationStartedEvent&#125; instance.\n\t * @param application the current application\n\t * @param args the arguments the application is running with\n\t * @param context the context that was being created\n\t */\n\tpublic ApplicationStartedEvent(SpringApplication application, String[] args,\n\t\t\tConfigurableApplicationContext context) &#123;\n\t\tsuper(application, args);\n\t\tthis.context = context;\n\t&#125;\n\t/**\n\t * Return the application context.\n\t * @return the context\n\t */\n\tpublic ConfigurableApplicationContext getApplicationContext() &#123;\n\t\treturn this.context;\n\t&#125;\n&#125;\n\nApplicationStartedEvent事件将在容器刷新后但ApplicationRunner和CommandLineRunner的run方法执行前触发，标志Spring容器已经刷新，此时容器已经准备完毕了。\n\n\n\n\n\n\n\n\n\n扩展： 这里提到了ApplicationRunner和CommandLineRunner接口有啥作用呢？我们一般会在Spring容器刷新完毕后，此时可能有一些系统参数等静态数据需要加载，此时我们就可以实现了ApplicationRunner或CommandLineRunner接口来实现静态数据的加载。\n\n3.4.6 ApplicationReadyEvent// ApplicationReadyEvent.java\n\npublic class ApplicationReadyEvent extends SpringApplicationEvent &#123;\n\tprivate final ConfigurableApplicationContext context;\n\t/**\n\t * Create a new &#123;@link ApplicationReadyEvent&#125; instance.\n\t * @param application the current application\n\t * @param args the arguments the application is running with\n\t * @param context the context that was being created\n\t */\n\tpublic ApplicationReadyEvent(SpringApplication application, String[] args,\n\t\t\tConfigurableApplicationContext context) &#123;\n\t\tsuper(application, args);\n\t\tthis.context = context;\n\t&#125;\n\t/**\n\t * Return the application context.\n\t * @return the context\n\t */\n\tpublic ConfigurableApplicationContext getApplicationContext() &#123;\n\t\treturn this.context;\n\t&#125;\n&#125;\n\nApplicationReadyEvent事件在调用完ApplicationRunner和CommandLineRunner的run方法后触发，此时标志SpringApplication已经正在运行。\n\n3.4.7 ApplicationFailedEvent// ApplicationFailedEvent.java\n\npublic class ApplicationFailedEvent extends SpringApplicationEvent &#123;\n\tprivate final ConfigurableApplicationContext context;\n\tprivate final Throwable exception;\n\t/**\n\t * Create a new &#123;@link ApplicationFailedEvent&#125; instance.\n\t * @param application the current application\n\t * @param args the arguments the application was running with\n\t * @param context the context that was being created (maybe null)\n\t * @param exception the exception that caused the error\n\t */\n\tpublic ApplicationFailedEvent(SpringApplication application, String[] args,\n\t\t\tConfigurableApplicationContext context, Throwable exception) &#123;\n\t\tsuper(application, args);\n\t\tthis.context = context;\n\t\tthis.exception = exception;\n\t&#125;\n\t/**\n\t * Return the application context.\n\t * @return the context\n\t */\n\tpublic ConfigurableApplicationContext getApplicationContext() &#123;\n\t\treturn this.context;\n\t&#125;\n\t/**\n\t * Return the exception that caused the failure.\n\t * @return the exception\n\t */\n\tpublic Throwable getException() &#123;\n\t\treturn this.exception;\n\t&#125;\n&#125;\n复制代码\n\n可以看到ApplicationFailedEvent事件除了多了一个context属性外，还多了一个Throwable类型的exception属性用来记录 SpringBoot 启动失败时的异常。\nApplicationFailedEvent事件在 SpringBoot 启动失败时触发，标志 SpringBoot 启动失败。\n\n4 小结此篇文章相对简单，对 SpringBoot 内置的 7 种生命周期事件进行了详细分析。我们还是引用上篇文章的一张图来回顾一下这些生命周期事件及其用途：\n\n","slug":"SpringBoot源码分析","date":"2022-06-11T09:02:18.830Z","categories_index":"SpringBoot","tags_index":"Spring,SpringBoot,源码分析","author_index":"小李不在_"},{"id":"f63fd983001a548ddde94851f2bab33a","title":"Netty源码分析","content":"本文将介绍 Netty，Java 平台上使用最广泛的 NIO 包，它是对 JDK 中的 NIO 实现的一层封装，让我们能更方便地开发 NIO 程序。其实，Netty 不仅仅是 NIO 吧，但是，基本上大家都冲着 NIO 来的。\n\n本文只介绍 TCP 相关的内容，Netty 对于其他协议的支持，不在本文的讨论范围内。\n和并发包的源码分析不一样，我不可能一行一行源码说，所以有些异常分支是会直接略过，除非我觉得需要介绍。\nNetty 源码一直在更新，各版本之间有些差异，我是按照 4.1.25.Final 版本来进行介绍的。\n\n建议初学者在看完本文以后，可以去翻翻《Netty In Action》，网上也可以找到中文文字版的。\n准备学习源码，一开始肯定是准备环境。\n我喜欢用 maven，也喜欢 Spring Boot，所以我一般先到 https://start.spring.io/ 准备一个最简单的脚手架。\n10 秒搞定脚手架，然后就是导入到 Intellij 中，如果用新版本的 Spring Boot，可能还需要等待下载依赖，期间打开 https://mvnrepository.com/ 搜索马上要用到的 maven 依赖。\nNetty 分为好些模块，有 netty-handler、netty-buffer、netty-transport、netty-common 等等，也有一个 netty-all，它包含了所有的模块。\n既然我们是源码分析，那么自然是用一个最简单的。netty-all 不是最好的选择，netty-example 才是：\n&lt;dependency>\n   &lt;groupId>io.netty&lt;/groupId>\n   &lt;artifactId>netty-example&lt;/artifactId>\n   &lt;version>4.1.25.Final&lt;/version>\n&lt;/dependency>\n\n它不仅可以解决我们的依赖，而且 example 里面的示例非常适合我们学习使用。\n\nEcho 例子Netty 作为 NIO 的库，自然既可以作为服务端接受请求，也可以作为客户端发起请求。使用 Netty 开发客户端或服务端都是非常简单的，Netty 做了很好的封装，我们通常只要开发一个或多个 handler 用来处理我们的自定义逻辑就可以了。\n下面，我们来看一个经常会见到的例子，它叫 Echo，也就是回声，客户端传过去什么值，服务端原样返回什么值。\n\n\n\n\n\n\n\n\n\n打开 netty-example 的源码，把 echo 包下面的代码复制出来玩一玩。\n\n\n\n\n\n\n\n\n\n\n左边是服务端代码，右边是客户端代码。\n上面的代码基本就是模板代码，每次使用都是这一个套路，唯一需要我们开发的部分是 handler(…) 和 childHandler(…) 方法中指定的各个 handler，如 **EchoServerHandler** 和 **EchoClientHandler**，当然 Netty 源码也给我们提供了很多的 handler，比如上面的 LoggingHandler，它就是 Netty 源码中为我们提供的，需要的时候直接拿过来用就好了。\n我们先来看一下上述代码中涉及到的一些内容：\n\nServerBootstrap 类用于创建服务端实例，Bootstrap 用于创建客户端实例。 \n\n两个 EventLoopGroup ：bossGroup 和 workerGroup，它们涉及的是 Netty 的线程模型，可以看到服务端有两个 group，而客户端只有一个，它们就是 Netty 中的线程池。 \n\nNetty 中的 Channel，没有直接使用 Java 原生的 ServerSocketChannel 和 SocketChannel，而是包装了 NioServerSocketChannel 和 NioSocketChannel 与之对应。  \n\n\n\n\n\n\n\n\n\n当然，也有对其他协议的支持，如支持 UDP 协议的 NioDatagramChannel，本文只关心 TCP 相关的。\n\n左边 handler(…) 方法指定了一个 handler（LoggingHandler），这个 handler 是给服务端收到新的请求的时候处理用的。右边 handler(...) 方法指定了客户端处理请求过程中需要使用的 handlers。  \n\n\n\n\n\n\n\n\n\n如果你想在 EchoServer 中也指定多个 handler，也可以像右边的 EchoClient 一样使用 ChannelInitializer\n\n左边 childHandler(…) 指定了 childHandler，这边的 handlers 是给新创建的连接用的，我们知道服务端 ServerSocketChannel 在 accept 一个连接以后，需要创建 SocketChannel 的实例，childHandler(…) 中设置的 handler 就是用于处理新创建的 SocketChannel 的，而不是用来处理 ServerSocketChannel 实例的。 \n\npipeline：handler 可以指定多个（需要上面的 ChannelInitializer 类辅助），它们会组成了一个 pipeline，它们其实就类似拦截器的概念，现在只要记住一点，每个 NioSocketChannel 或 NioServerSocketChannel 实例内部都会有一个 pipeline 实例。pipeline 中还涉及到 handler 的执行顺序。 \n\nChannelFuture：这个涉及到 Netty 中的异步编程，和 JDK 中的 Future 接口类似。\n\n\n对于不了解 Netty 的读者，也不要有什么压力，我会一一介绍它们，本文主要面向新手，我觉得比较难理解或比较重要的部分，会花比较大的篇幅来介绍清楚。\n上面的源码中没有展示消息发送和消息接收的处理，此部分我会在介绍完上面的这些内容以后再进行介绍。\n\n源码分析1.网络操作抽象类： Channel初始化 ChannelChannel 接口是 Netty 对网络操作抽象类。通过 Channel 我们可以进行 I&#x2F;O 操作。\n一旦客户端成功连接服务端，就会新建一个 Channel 同该用户端进行绑定，示例代码如下：\n//  通过 Bootstrap 的 connect 方法连接到服务端\npublic Channel doConnect(InetSocketAddress inetSocketAddress) &#123;\n     CompletableFuture&lt;Channel> completableFuture = new CompletableFuture&lt;>();\n     bootstrap.connect(inetSocketAddress).addListener((ChannelFutureListener) future -> &#123;\n         if (future.isSuccess()) &#123;\n             completableFuture.complete(future.channel());\n         &#125; else &#123;\n             throw new IllegalStateException();\n         &#125;\n     &#125;);\n     return completableFuture.get();\n &#125;\n\n比较常用的Channel接口实现类是 ：\n\nNioServerSocketChannel（服务端）\nNioSocketChannel（客户端）\n\n这两个 Channel 可以和 BIO 编程模型中的ServerSocket以及Socket两个概念对应上。\n这节我们来看看 NioSocketChannel 是怎么和 JDK 底层的 SocketChannel 联系在一起的，它们是一对一的关系。NioServerSocketChannel 和 ServerSocketChannel 同理，也是一对一的关系。\n\n在 Bootstrap（客户端） 和 ServerBootstrap（服务端） 的启动过程中都会调用 channel(…) 方法：\n\n下面，我们来看 channel(…) 方法的源码：\n// AbstractBootstrap\npublic B channel(Class&lt;? extends C> channelClass) &#123;\n    if (channelClass == null) &#123;\n        throw new NullPointerException(\"channelClass\");\n    &#125;\n    return channelFactory(new ReflectiveChannelFactory&lt;C>(channelClass));\n&#125;\n\n我们可以看到，这个方法只是设置了 channelFactory 为 ReflectiveChannelFactory 的一个实例，然后我们看下这里的 ReflectiveChannelFactory 到底是什么：\n\n**newChannel()** 方法是 ChannelFactory 接口中的唯一方法，工厂模式 大家都很熟悉。我们可以看到，ReflectiveChannelFactory#newChannel() 方法中使用了反射调用 Channel 的无参构造方法来创建 Channel，我们只要知道，ChannelFactory 的 newChannel() 方法什么时候会被调用就可以了。\n\n对于 NioSocketChannel，由于它充当客户端的功能，它的创建时机在 connect(…) 的时候；\n对于 NioServerSocketChannel 来说，它充当服务端功能，它的创建时机在绑定端口 bind(…) 的时候。\n\n接下来，我们来简单追踪下充当客户端的 Bootstrap 中 NioSocketChannel 的创建过程，看看 NioSocketChannel 是怎么和 JDK 中的 SocketChannel 关联在一起的：\n// Bootstrap\npublic ChannelFuture connect(String inetHost, int inetPort) &#123;\n    return connect(InetSocketAddress.createUnresolved(inetHost, inetPort));\n&#125;\n\n然后再往里看，到这个方法：\npublic ChannelFuture connect(SocketAddress remoteAddress) &#123;\n    if (remoteAddress == null) &#123;\n        throw new NullPointerException(\"remoteAddress\");\n    // validate 只是校验一下各个参数是不是正确设置了\n    validate();\n    return doResolveAndConnect(remoteAddress, config.localAddress());\n&#125;\n\n继续：\n// 再往里就到这里了\nprivate ChannelFuture doResolveAndConnect(final SocketAddress remoteAddress, final SocketAddress localAddress) &#123;\n    // 我们要说的部分在这里\n    final ChannelFuture regFuture = initAndRegister();\n    final Channel channel = regFuture.channel();\n    ......\n&#125;\n\n然后，我们看 initAndRegister() 方法：\nfinal ChannelFuture initAndRegister() &#123;\n    Channel channel = null;\n    try &#123;\n        // 前面我们说过，这里会进行 Channel 的实例化\n        channel = channelFactory.newChannel();\n        init(channel);\n    &#125; catch (Throwable t) &#123;\n        ...\n    &#125;\n    ...\n    return regFuture;\n&#125;\n\n我们找到了 channel = channelFactory.newChannel() 这行代码，根据前面说的，这里会调用相应 Channel 的无参构造方法。\n然后我们就可以去看 NioSocketChannel 的构造方法了：\npublic NioSocketChannel() &#123;\n    // SelectorProvider 实例用于创建 JDK 的 SocketChannel 实例\n    this(DEFAULT_SELECTOR_PROVIDER);\n&#125;\n\npublic NioSocketChannel(SelectorProvider provider) &#123;\n    // 看这里，newSocket(provider) 方法会创建 JDK 的 SocketChannel\n    this(newSocket(provider));\n&#125;\n\n我们可以看到，在调用 newSocket(provider) 的时候，会创建 JDK NIO 的一个 SocketChannel 实例：\nprivate static SocketChannel newSocket(SelectorProvider provider) &#123;\n    try &#123;\n        // 创建 SocketChannel 实例\n        return provider.openSocketChannel();\n    &#125; catch (IOException e) &#123;\n        throw new ChannelException(\"Failed to open a socket.\", e);\n    &#125;\n&#125;\n\nNioServerSocketChannel 同理，也非常简单，从 ServerBootstrap#bind(...) 方法一路点进去就清楚了。\n所以我们知道了，NioSocketChannel 在实例化过程中，会先实例化 JDK 底层的 SocketChannel，NioServerSocketChannel 也一样，会先实例化 ServerSocketChannel 实例：\n\n说到这里，我们顺便再继续往里看一下 NioSocketChannel 的构造方法：\npublic NioSocketChannel(SelectorProvider provider) &#123;\n    this(newSocket(provider));\n&#125;\n\n刚才我们看到这里，newSocket(provider) 创建了底层的 SocketChannel 实例，我们继续往下看构造方法：\npublic NioSocketChannel(Channel parent, SocketChannel socket) &#123;\n    super(parent, socket);\n    config = new NioSocketChannelConfig(this, socket.socket());\n&#125;\n\n上面有两行代码，第二行代码很简单，实例化了内部的 NioSocketChannelConfig 实例，它用于保存 channel 的配置信息，这里没有我们现在需要关心的内容，直接跳过。\n第一行调用父类构造器，除了设置属性外，还设置了 SocketChannel 的非阻塞模式：\nprotected AbstractNioByteChannel(Channel parent, SelectableChannel ch) &#123;\n    // 毫无疑问，客户端关心的是 OP_READ 事件，等待读取服务端返回数据\n    super(parent, ch, SelectionKey.OP_READ);\n&#125;\n\n// 然后是到这里\nprotected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) &#123;\n    super(parent);\n    this.ch = ch;\n    // 我们看到这里只是保存了 SelectionKey.OP_READ 这个信息，在后面的时候会用到\n    this.readInterestOp = readInterestOp;\n    try &#123;\n        // ******设置 channel 的非阻塞模式******\n        ch.configureBlocking(false);\n    &#125; catch (IOException e) &#123;\n        ......\n    &#125;\n&#125;\n\nNioServerSocketChannel 的构造方法类似，也设置了非阻塞，然后设置服务端关心的 SelectionKey.OP_ACCEPT 事件：\npublic NioServerSocketChannel(ServerSocketChannel channel) &#123;\n    // 对于服务端来说，关心的是 SelectionKey.OP_ACCEPT 事件，等待客户端连接\n    super(null, channel, SelectionKey.OP_ACCEPT);\n    config = new NioServerSocketChannelConfig(this, javaChannel().socket());\n&#125;\n\n这节关于 Channel 的内容我们先介绍这么多，主要就是实例化了 JDK 层的 SocketChannel 或 ServerSocketChannel，然后设置了非阻塞模式，我们后面再继续深入下去。\n\nChannel 的 register 操作经过前面的铺垫，我们已经具备一定的基础了，我们开始来把前面学到的内容揉在一起。这节，我们会介绍 register 操作，这一步其实是非常关键的，对于我们源码分析非常重要。\n我们从 EchoClient 中的 connect() 方法出发，或者 EchoServer 的 bind(port) 方法出发，都会走到 initAndRegister() 这个方法：\nfinal ChannelFuture initAndRegister() &#123;\n    Channel channel = null;\n    try &#123;\n        // 1\n        channel = channelFactory.newChannel();\n        // 2 对于 Bootstrap 和 ServerBootstrap，这里面有些不一样\n        init(channel);\n    &#125; catch (Throwable t) &#123;\n        ...\n    &#125;\n    // 3 我们这里要说的是这行\n    ChannelFuture regFuture = config().group().register(channel);\n    if (regFuture.cause() != null) &#123;\n        if (channel.isRegistered()) &#123;\n            channel.close();\n        &#125; else &#123;\n            channel.unsafe().closeForcibly();\n        &#125;\n    &#125;\n    return regFuture;\n&#125;\n\ninitAndRegister() 这个方法我们已经接触过两次了，前面介绍了:\n\nChannel 的实例化，实例化过程中，会执行 Channel 内部 Unsafe 和 Pipeline 的实例化；\ninit(channel) 方法中，会往 pipeline 中添加 handler（pipeline 此时是 head+channelnitializer+tail）。\n\n\n\n\n\n\n\n\n\n\n我们终于要揭秘 ChannelInitializer 中的 initChannel 方法了~~~\n现在，我们继续往下走，看看第 3 步 **register** ：\nChannelFuture regFuture = config().group().register(channel);\n\n\n\n\n\n\n\n\n\n\n我们说了，register 这一步是非常关键的，它发生在 channel 实例化以后，大家回忆一下当前 channel 中的一些情况：\n实例化了 JDK 底层的 Channel，设置了非阻塞，实例化了 Unsafe，实例化了 Pipeline，同时往 pipeline 中添加了 head、tail 以及一个 ChannelInitializer 实例。\n上面的 config().group() 方法会返回前面实例化的 NioEventLoopGroup 的实例，然后调用其 register(channel) 方法：\nio.netty.channel.MultithreadEventLoopGroup\n@Override\npublic ChannelFuture register(Channel channel) &#123;\n    return next().register(channel);\n&#125;\n\nnext() 方法很简单，就是选择线程池中的一个线程（还记得 chooserFactory 吗?），也就是选择一个 NioEventLoop 实例，这个时候我们就进入到 NioEventLoop 了。\nNioEventLoop 的 register(channel) 方法实现在它的父类 **SingleThreadEventLoop** 中：\n@Override\npublic ChannelFuture register(Channel channel) &#123;\n    return register(new DefaultChannelPromise(channel, this));\n&#125;\n\n上面的代码实例化了一个 Promise，将当前 channel 带了进去：\n@Override\npublic ChannelFuture register(final ChannelPromise promise) &#123;\n    ObjectUtil.checkNotNull(promise, \"promise\");\n    // promise 关联了 channel，channel 持有 Unsafe 实例，register 操作就封装在 Unsafe 中\n    promise.channel().unsafe().register(this, promise);\n    return promise;\n&#125;\n\n\n拿到 channel 中关联的 Unsafe 实例，然后调用它的 register 方法：\n\n\n\n\n\n\n\n\n\n我们说过，Unsafe 专门用来封装底层实现，当然这里也没那么“底层”\nio.netty.channel.AbstractChannel#AbstractUnsafe\n@Override\npublic final void register(EventLoop eventLoop, final ChannelPromise promise) &#123;\n    ...\n    // 将这个 eventLoop 实例设置给这个 channel，从此这个 channel 就是有 eventLoop 的了\n    // 我觉得这一步其实挺关键的，因为后续该 channel 中的所有异步操作，都要提交给这个 eventLoop 来执行\n    AbstractChannel.this.eventLoop = eventLoop;\n\n    // 如果发起 register 动作的线程就是 eventLoop 实例中的线程，那么直接调用 register0(promise)\n    // 对于我们来说，它不会进入到这个分支，\n    //     之所以有这个分支，是因为我们是可以 unregister，然后再 register 的，后面再仔细看\n    if (eventLoop.inEventLoop()) &#123;\n        register0(promise);\n    &#125; else &#123;\n        try &#123;\n            // 否则，提交任务给 eventLoop，eventLoop 中的线程会负责调用 register0(promise)\n            eventLoop.execute(new Runnable() &#123;\n                @Override\n                public void run() &#123;\n                    register0(promise);\n                &#125;\n            &#125;);\n        &#125; catch (Throwable t) &#123;\n            ...\n        &#125;\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\n\n到这里，我们要明白，NioEventLoop 中是还没有实例化 Thread 实例的。\n这几步涉及到了好几个类：NioEventLoop、Promise、Channel、Unsafe 等，大家要仔细理清楚它们的关系。\n对于我们前面过来的 register 操作，其实提交到 eventLoop 以后，就直接返回 promise 实例了，剩下的 register0 是异步操作，它由 NioEventLoop 实例来完成。\n\n\n\n\n\n\n\n\n\nChannel 实例一旦 register 到了 NioEventLoopGroup 实例中的某个 NioEventLoop 实例，那么后续该 Channel 的所有操作，都是由该 NioEventLoop 实例来完成的。\n这个也非常简单，因为 Selector 实例是在 NioEventLoop 实例中的，Channel 实例一旦注册到某个 Selector 实例中，当然也只能在这个实例中处理 NIO 事件。\n我们来看 register0(promise) 方法，我们知道，这个 register 任务进入到了 NioEventLoop 的 taskQueue 中，然后会启动 NioEventLoop 中的线程，该线程会轮询这个 taskQueue，然后执行这个 register 任务。\n注意，此时执行该方法的是 eventLoop 中的线程：\nio.netty.channel.AbstractChannel#register0\nprivate void register0(ChannelPromise promise) &#123;\n    try &#123;\n        ...\n        boolean firstRegistration = neverRegistered;\n        // *** 进行 JDK 底层的操作：Channel 注册到 Selector 上 ***\n        doRegister();\n\n        neverRegistered = false;\n        registered = true;\n        // 到这里，就算是 registered 了\n\n        // 这一步也很关键，因为这涉及到了 ChannelInitializer 的 init(channel)\n        // 我们之前说过，init 方法会将 ChannelInitializer 内部添加的 handlers 添加到 pipeline 中\n        pipeline.invokeHandlerAddedIfNeeded();\n\n        // 设置当前 promise 的状态为 success\n        //   因为当前 register 方法是在 eventLoop 中的线程中执行的，需要通知提交 register 操作的线程\n        safeSetSuccess(promise);\n\n        // 当前的 register 操作已经成功，该事件应该被 pipeline 上\n        //   所有关心 register 事件的 handler 感知到，往 pipeline 中扔一个事件\n        pipeline.fireChannelRegistered();\n\n        // 这里 active 指的是 channel 已经打开\n        if (isActive()) &#123;\n            // 如果该 channel 是第一次执行 register，那么 fire ChannelActive 事件\n            if (firstRegistration) &#123;\n                pipeline.fireChannelActive();\n            &#125; else if (config().isAutoRead()) &#123;\n                // 该 channel 之前已经 register 过了，\n                // 这里让该 channel 立马去监听通道中的 OP_READ 事件\n                beginRead();\n            &#125;\n        &#125;\n    &#125; catch (Throwable t) &#123;\n        ...\n    &#125;\n&#125;\n\n\n我们先说掉上面的 doRegister() 方法，然后再说 pipeline。\n@Override\nprotected void doRegister() throws Exception &#123;\n    boolean selected = false;\n    for (;;) &#123;\n        try &#123;\n            // 附 JDK 中 Channel 的 register 方法：\n            // public final SelectionKey register(Selector sel, int ops, Object att) &#123;...&#125;\n            selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this);\n            return;\n        &#125; catch (CancelledKeyException e) &#123;\n            ...\n        &#125;\n    &#125;\n&#125;\n\n\n我们可以看到，这里做了 JDK 底层的 register 操作，将 SocketChannel(或 ServerSocketChannel) 注册到 Selector 中，并且可以看到，这里的监听集合设置为了 0，也就是什么都不监听。\n\n\n\n\n\n\n\n\n\n当然，也就意味着，后续一定有某个地方会需要修改这个 selectionKey 的监听集合，不然啥都干不了\n我们重点来说说 **pipeline** 操作，我们之前在介绍 NioSocketChannel 的 pipeline 的时候介绍到，我们的 pipeline 现在长这个样子：\n\n\n\n\n\n\n\n\n\n\n现在，我们将看到这里会把 LoggingHandler 和 EchoClientHandler 添加到 pipeline。\n我们继续看代码，register 成功以后，执行了以下操作：\npipeline.invokeHandlerAddedIfNeeded();\n\n\n大家可以跟踪一下，这一步会执行到 pipeline 中 ChannelInitializer 实例的 handlerAdded 方法，在这里会执行它的 init(context) 方法：\n@Override\npublic void handlerAdded(ChannelHandlerContext ctx) throws Exception &#123;\n    if (ctx.channel().isRegistered()) &#123;\n        initChannel(ctx);\n    &#125;\n&#125;\n\n\n然后我们看下 initChannel(ctx)，这里终于来了我们之前介绍过的 init(channel) 方法：\nprivate boolean initChannel(ChannelHandlerContext ctx) throws Exception &#123;\n    if (initMap.putIfAbsent(ctx, Boolean.TRUE) == null) &#123; // Guard against re-entrance.\n        try &#123;\n            // 1. 将把我们自定义的 handlers 添加到 pipeline 中\n            initChannel((C) ctx.channel());\n        &#125; catch (Throwable cause) &#123;\n            ...\n        &#125; finally &#123;\n            // 2. 将 ChannelInitializer 实例从 pipeline 中删除\n            remove(ctx);\n        &#125;\n        return true;\n    &#125;\n    return false;\n&#125;\n\n\n我们前面也说过，ChannelInitializer 的 init(channel) 被执行以后，那么其内部添加的 handlers 会进入到 pipeline 中，然后上面的 finally 块中将 ChannelInitializer 的实例从 pipeline 中删除，那么此时 pipeline 就算建立起来了，如下图：\n\n\n\n\n\n\n\n\n\n\n其实这里还有个问题，如果我们在 ChannelInitializer 中添加的是一个 ChannelInitializer 实例呢？大家可以考虑下这个情况。\npipeline 建立了以后，然后我们继续往下走，会执行到这一句：\npipeline.fireChannelRegistered();\n\n\n我们只要摸清楚了 fireChannelRegistered() 方法，以后碰到其他像 fireChannelActive()、fireXxx() 等就知道怎么回事了，它们都是类似的。我们来看看这句代码会发生什么：\nio.netty.channel.DefaultChannelPipeline#fireChannelRegistered\n@Override\npublic final ChannelPipeline fireChannelRegistered() &#123;\n    // 注意这里的传参是 head\n    AbstractChannelHandlerContext.invokeChannelRegistered(head);\n    return this;\n&#125;\n\n\n也就是说，我们往 pipeline 中扔了一个 **channelRegistered** 事件，这里的 register 属于 Inbound 事件，pipeline 接下来要做的就是执行 pipeline 中的 Inbound 类型的 handlers 中的 channelRegistered() 方法。\n从上面的代码，我们可以看出，往 pipeline 中扔出 channelRegistered 事件以后，第一个处理的 handler 是 **head**。\n接下来，我们还是跟着代码走，此时我们来到了 pipeline 的第一个节点 **head** 的处理中：\nio.netty.channel.AbstractChannelHandlerContext#invokeChannelRegistered\n// next 此时是 head\nstatic void invokeChannelRegistered(final AbstractChannelHandlerContext next) &#123;\n\n    EventExecutor executor = next.executor();\n    // 执行 head 的 invokeChannelRegistered()\n    if (executor.inEventLoop()) &#123;\n        next.invokeChannelRegistered();\n    &#125; else &#123;\n        executor.execute(new Runnable() &#123;\n            @Override\n            public void run() &#123;\n                next.invokeChannelRegistered();\n            &#125;\n        &#125;);\n    &#125;\n&#125;\n\n\n也就是说，这里会先执行 head.invokeChannelRegistered() 方法，而且是放到 NioEventLoop 中的 taskQueue 中执行的：\nio.netty.channel.AbstractChannelHandlerContext#invokeChannelRegistered\nprivate void invokeChannelRegistered() &#123;\n    if (invokeHandler()) &#123;\n        try &#123;\n            // handler() 方法此时会返回 head\n            ((ChannelInboundHandler) handler()).channelRegistered(this);\n        &#125; catch (Throwable t) &#123;\n            notifyHandlerException(t);\n        &#125;\n    &#125; else &#123;\n        fireChannelRegistered();\n    &#125;\n&#125;\n\n\n我们去看 head 的 channelRegistered 方法。\nHeadContext 是 DefaultChannelPipeline 的内部类：\n\nio.netty.channel.DefaultChannelPipeline.HeadContext#channelRegistered\n@Override\npublic void channelRegistered(ChannelHandlerContext ctx) throws Exception &#123;\n    // 1. 这一步是 head 对于 channelRegistered 事件的处理。没有我们要关心的\n    invokeHandlerAddedIfNeeded();\n    // 2. 向后传播 Inbound 事件\n    ctx.fireChannelRegistered();\n&#125;\n\n\n然后 head 会执行 fireChannelRegister() 方法：\nio.netty.channel.AbstractChannelHandlerContext#fireChannelRegistered\n@Override\npublic ChannelHandlerContext fireChannelRegistered() &#123;\n    // 这里很关键\n    // findContextInbound() 方法会沿着 pipeline 找到下一个 Inbound 类型的 handler\n    invokeChannelRegistered(findContextInbound());\n    return this;\n&#125;\n\n\n\n\n\n\n\n\n\n\n\n注意：pipeline.fireChannelRegistered() 是将 channelRegistered 事件抛到 pipeline 中，pipeline 中的 handlers 准备处理该事件。而 context.fireChannelRegistered() 是一个 handler 处理完了以后，向后传播给下一个 handler。\n它们两个的方法名字是一样的，但是来自于不同的类。\nfindContextInbound() 将找到下一个 Inbound 类型的 handler，然后又是重复上面的几个方法。\n\n\n\n\n\n\n\n\n\n我觉得上面这块代码没必要太纠结，总之就是从 head 中开始，依次往下寻找所有 Inbound handler，执行其 channelRegistered(ctx) 操作。\n说了这么多，我们的 register 操作算是真正完成了。\n下面，我们回到 initAndRegister 这个方法：\nfinal ChannelFuture initAndRegister() &#123;\n    Channel channel = null;\n    try &#123;\n        channel = channelFactory.newChannel();\n        init(channel);\n    &#125; catch (Throwable t) &#123;\n        ...\n    &#125;\n\n    // 我们上面说完了这行\n    ChannelFuture regFuture = config().group().register(channel);\n\n    // 如果在 register 的过程中，发生了错误\n    if (regFuture.cause() != null) &#123;\n        if (channel.isRegistered()) &#123;\n            channel.close();\n        &#125; else &#123;\n            channel.unsafe().closeForcibly();\n        &#125;\n    &#125;\n\n    // 源码中说得很清楚，如果到这里，说明后续可以进行 connect() 或 bind() 了，因为两种情况：\n    // 1. 如果 register 动作是在 eventLoop 中发起的，那么到这里的时候，register 一定已经完成\n    // 2. 如果 register 任务已经提交到 eventLoop 中，也就是进到了 eventLoop 中的 taskQueue 中，\n    //    由于后续的 connect 或 bind 也会进入到同一个 eventLoop 的 queue 中，所以一定是会先 register 成功，才会执行 connect 或 bind\n    return regFuture;\n&#125;\n\n\n我们要知道，不管是服务端的 NioServerSocketChannel 还是客户端的 NioSocketChannel，在 bind 或 connect 时，都会先进入 initAndRegister 这个方法，所以我们上面说的那些，对于两者都是通用的。\n大家要记住，register 操作是非常重要的，要知道这一步大概做了哪些事情，register 操作以后，将进入到 bind 或 connect 操作中。\n\nconnect 过程和 bind 过程分析上面我们介绍的 register 操作非常关键，它建立起来了很多的东西，它是 Netty 中 NioSocketChannel 和 NioServerSocketChannel 开始工作的起点。\n这一节，我们来说说 register 之后的 connect 操作和 bind 操作。这节非常简单。\n\nconnect 过程分析对于客户端 NioSocketChannel 来说，前面 register 完成以后，就要开始 connect 了，这一步将连接到服务端。\nprivate ChannelFuture doResolveAndConnect(final SocketAddress remoteAddress, final SocketAddress localAddress) &#123;\n    // 这里完成了 register 操作\n    final ChannelFuture regFuture = initAndRegister();\n    final Channel channel = regFuture.channel();\n\n    // 这里我们不去纠结 register 操作是否 isDone()\n    if (regFuture.isDone()) &#123;\n        if (!regFuture.isSuccess()) &#123;\n            return regFuture;\n        &#125;\n        // 看这里\n        return doResolveAndConnect0(channel, remoteAddress, localAddress, channel.newPromise());\n    &#125; else &#123;\n        ....\n    &#125;\n&#125;\n\n\n这里大家自己一路点进去，我就不浪费篇幅了。最后，我们会来到 AbstractChannel 的 connect 方法：\n@Override\npublic ChannelFuture connect(SocketAddress remoteAddress, ChannelPromise promise) &#123;\n    return pipeline.connect(remoteAddress, promise);\n&#125;\n\n\n我们看到，connect 操作是交给 pipeline 来执行的。进入 pipeline 中，我们会发现，connect 这种 Outbound 类型的操作，是从 pipeline 的 tail 开始的：\n\n\n\n\n\n\n\n\n\n前面我们介绍的 register 操作是 Inbound 的，是从 head 开始的\n@Override\npublic final ChannelFuture connect(SocketAddress remoteAddress, ChannelPromise promise) &#123;\n    return tail.connect(remoteAddress, promise);\n&#125;\n\n\n接下来就是 pipeline 的操作了，从 tail 开始，执行 pipeline 上的 Outbound 类型的 handlers 的 connect(...) 方法，那么真正的底层的 connect 的操作发生在哪里呢？还记得我们的 pipeline 的图吗？\n\n从 tail 开始往前找 out 类型的 handlers，每经过一个 handler，都执行里面的 connect() 方法，最后会到 head 中，因为 head 也是 Outbound 类型的，我们需要的 connect 操作就在 head 中，它会负责调用 unsafe 中提供的 connect 方法：\n// HeadContext\npublic void connect(\n        ChannelHandlerContext ctx,\n        SocketAddress remoteAddress, SocketAddress localAddress,\n        ChannelPromise promise) throws Exception &#123;\n    unsafe.connect(remoteAddress, localAddress, promise);\n&#125;\n\n\n接下来，我们来看一看 connect 在 unsafe 类中所谓的底层操作：\n// AbstractNioChannel.AbstractNioUnsafe\n@Override\npublic final void connect(\n        final SocketAddress remoteAddress, final SocketAddress localAddress, final ChannelPromise promise) &#123;\n        ......\n\n        boolean wasActive = isActive();\n        // 大家自己点进去看 doConnect 方法\n        // 这一步会做 JDK 底层的 SocketChannel connect，然后设置 interestOps 为 SelectionKey.OP_CONNECT\n        // 返回值代表是否已经连接成功\n        if (doConnect(remoteAddress, localAddress)) &#123;\n            // 处理连接成功的情况\n            fulfillConnectPromise(promise, wasActive);\n        &#125; else &#123;\n            connectPromise = promise;\n            requestedRemoteAddress = remoteAddress;\n\n            // 下面这块代码，在处理连接超时的情况，代码很简单\n            // 这里用到了 NioEventLoop 的定时任务的功能，这个我们之前一直都没有介绍过，因为我觉得也不太重要\n            int connectTimeoutMillis = config().getConnectTimeoutMillis();\n            if (connectTimeoutMillis > 0) &#123;\n                connectTimeoutFuture = eventLoop().schedule(new Runnable() &#123;\n                    @Override\n                    public void run() &#123;\n                        ChannelPromise connectPromise = AbstractNioChannel.this.connectPromise;\n                        ConnectTimeoutException cause =\n                                new ConnectTimeoutException(\"connection timed out: \" + remoteAddress);\n                        if (connectPromise != null &amp;&amp; connectPromise.tryFailure(cause)) &#123;\n                            close(voidPromise());\n                        &#125;\n                    &#125;\n                &#125;, connectTimeoutMillis, TimeUnit.MILLISECONDS);\n            &#125;\n\n            promise.addListener(new ChannelFutureListener() &#123;\n                @Override\n                public void operationComplete(ChannelFuture future) throws Exception &#123;\n                    if (future.isCancelled()) &#123;\n                        if (connectTimeoutFuture != null) &#123;\n                            connectTimeoutFuture.cancel(false);\n                        &#125;\n                        connectPromise = null;\n                        close(voidPromise());\n                    &#125;\n                &#125;\n            &#125;);\n        &#125;\n    &#125; catch (Throwable t) &#123;\n        promise.tryFailure(annotateConnectException(t, remoteAddress));\n        closeIfClosed();\n    &#125;\n&#125;\n\n\n如果上面的 doConnect 方法返回 false，那么后续是怎么处理的呢？\n在上一节介绍的 register 操作中，channel 已经 register 到了 selector 上，只不过将 interestOps 设置为了 0，也就是什么都不监听。\n而在上面的 doConnect 方法中，我们看到它在调用底层的 connect 方法后，会设置 interestOps 为 SelectionKey.OP_CONNECT。\n剩下的就是 NioEventLoop 的事情了，还记得 NioEventLoop 的 run() 方法吗？也就是说这里的 connect 成功以后，这个 TCP 连接就建立起来了，后续的操作会在 NioEventLoop.run() 方法中被 processSelectedKeys() 方法处理掉。\n\nbind 过程分析说完 connect 过程，我们再来简单看下 bind 过程：\nprivate ChannelFuture doBind(final SocketAddress localAddress) &#123;\n    // **前面说的 initAndRegister**\n    final ChannelFuture regFuture = initAndRegister();\n\n    final Channel channel = regFuture.channel();\n    if (regFuture.cause() != null) &#123;\n        return regFuture;\n    &#125;\n\n    if (regFuture.isDone()) &#123;\n        // register 动作已经完成，那么执行 bind 操作\n        ChannelPromise promise = channel.newPromise();\n        doBind0(regFuture, channel, localAddress, promise);\n        return promise;\n    &#125; else &#123;\n        ......\n    &#125;\n&#125;\n\n\n然后一直往里看，会看到，bind 操作也是要由 pipeline 来完成的：\nio.netty.channel.AbstractChannel#bind\n@Override\npublic ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) &#123;\n    return pipeline.bind(localAddress, promise);\n&#125;\n\n\nbind 操作和 connect 一样，都是 Outbound 类型的，所以都是 tail 开始：\n@Override\npublic final ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) &#123;\n    return tail.bind(localAddress, promise);\n&#125;\n\n\n最后的 bind 操作又到了 head 中，由 head 来调用 unsafe 提供的 bind 方法：\n@Override\npublic void bind(\n        ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise)\n        throws Exception &#123;\n    unsafe.bind(localAddress, promise);\n&#125;\n\n\n感兴趣的读者自己去看一下 unsafe 中的 bind 方法，非常简单，bind 操作也不是什么异步方法，我们就介绍到这里了。\nChannelHandler 是消息的具体处理器，主要负责处理客户端&#x2F;服务端接收和发送的数据。ChannelPipeline 则是包含了一个或多个 ChannelHandler 的链表。\n\n2.消息处理器链表：ChannelPipelineChannelPipeline：消息处理器链表我想很多读者应该或多或少都有 Netty 中 pipeline 的概念。前面我们说了，使用 Netty 的时候，我们通常就只要写一些自定义的 handler 就可以了，我们定义的这些 handler 会组成一个 pipeline，用于处理 IO 事件，这个和我们平时接触的 Filter 或 Interceptor 表达的差不多是一个意思。\n每个 Channel 内部都有一个 pipeline，pipeline 由多个 handler 组成，handler 之间的顺序是很重要的，因为 IO 事件将按照顺序顺次经过 pipeline 上的 handler，这样每个 handler 可以专注于做一点点小事，由多个 handler 组合来完成一些复杂的逻辑。\n\n从图中，我们知道这是一个双向链表。\n\nIO 事件：Inbound &amp; Outbound首先，我们看两个重要的概念：Inbound 和 Outbound。在 Netty 中，IO 事件被分为 Inbound 事件和 Outbound 事件。\nOutbound 的 out 指的是 出去，有哪些 IO 事件属于此类呢？比如 connect、write、flush 这些 IO 操作是往外部方向进行的，它们就属于 Outbound 事件。\n其他的，诸如 accept、read 这种就属于 Inbound 事件。\n比如客户端在发起请求的时候，需要下面几步：\n\nconnect 到服务器;\nwrite 数据传到服务器\nread 服务器返回的数据\n\nconnect 和 write 就是 out 事件，后面的 read 就是 in 事件。\n比如很多初学者看不懂下面的这段代码，这段代码用于服务端的 childHandler 中：\n1. pipeline.addLast(new StringDecoder());\n2. pipeline.addLast(new StringEncoder());\n3. pipeline.addLast(new BizHandler());\n\n初学者肯定都纳闷，以为这个顺序写错了，应该是先 decode 客户端过来的数据，然后用 BizHandler 处理业务逻辑，最后再 encode 数据然后返回给客户端，所以添加的顺序应该是 1 -&gt; 3 -&gt; 2 才对。\n其实这里的三个 handler 是分组的，分为 Inbound（1 和 3） 和 Outbound（2）：\n1. pipeline.addLast(new StringDecoder());\n2. pipeline.addLast(new StringEncoder());\n3. pipeline.addLast(new BizHandler());\n\n\n客户端连接进来的时候，读取（read）客户端请求数据的操作是 Inbound 的，所以会先使用 1，然后是 3 对处理进行处理；\n处理完数据后，返回给客户端数据的 write 操作是 Outbound 的，此时使用的是 2。\n\n所以虽然添加顺序有点怪，但是执行顺序其实是按照 1 -&gt; 3 -&gt; 2 进行的。\n\n\n\n\n\n\n\n\n\n如果我们在上面的基础上，加上下面的第四行，这是一个 OutboundHandler：\n那么执行顺序是不是就是 1 -&gt; 3 -&gt; 2 -&gt; 4 呢？答案是：不是的。\n**对于 Inbound 操作，按照添加顺序执行每个 Inbound 类型的 ****handler****；而对于 Outbound 操作，是反着来的，从后往前，顺次执行 Outbound 类型的 ****handler**。\n所以，上面的顺序应该是先 1 后 3，它们是 Inbound 的，然后是 4，最后才是 2，它们两个是 Outbound 的。说实话，这种组织方式对新手应该很是头疼。\n那我们在开发的时候怎么写呢？其实也很简单，从最外层开始写，一步步写到业务处理层，把 Inbound 和 Outbound 混写在一起。比如 encode 和 decode 是属于最外层的处理逻辑，先写它们。假设 decode 以后是字符串，那再进来一层应该可以写进来和出去的日志。再进来一层可以写 字符串 &lt;&#x3D;&gt; 对象 的相互转换。然后就应该写业务层了。\n4. pipeline.addLast(new OutboundHandlerA());\n\n到这里，我想大家应该都知道 Inbound 和 Outbound 了吧？下面我们来介绍它们的接口使用。\n\n定义处理 Inbound 事件的 handler 需要实现 ChannelInboundHandler，定义处理 Outbound 事件的 handler 需要实现 ChannelOutboundHandler。最下面的三个类，是 Netty 提供的适配器，特别的，如果我们希望定义一个 handler 能同时处理 Inbound 和 Outbound 事件，可以通过继承中间的 **ChannelDuplexHandler** 的方式，比如 **LoggingHandler** 这种既可以用来处理 Inbound 也可以用来处理 Outbound 事件的 handler。\n下图来源于 Netty ChannelPipeline 。\n\n有了 Inbound 和 Outbound 的概念以后，我们来开始介绍 Pipeline 的源码。\n\nChannelPipeline 源码解读我们说过，一个 Channel 关联一个 pipeline，NioSocketChannel 和 NioServerSocketChannel 在执行构造方法的时候，都会走到它们的父类 AbstractChannel 的构造方法中：\nprotected AbstractChannel(Channel parent) &#123;\n    this.parent = parent;\n    // 给每个 channel 分配一个唯一 id\n    id = newId();\n    // 每个 channel 内部需要一个 Unsafe 的实例\n    unsafe = newUnsafe();\n    // 每个 channel 内部都会创建一个 pipeline\n    pipeline = newChannelPipeline();\n&#125;\n\n上面的三行代码中，id 比较不重要，Netty 中的 Unsafe 实例其实挺重要的，这里简单介绍一下。\n在 JDK 的源码中，sun.misc.Unsafe 类提供了一些底层操作的能力，它设计出来是给 JDK 中的源码使用的，比如 AQS、ConcurrentHashMap 等，我们在之前的并发包的源码分析中也看到了很多它们使用 Unsafe 的场景，这个 Unsafe 类不是给我们的代码使用的，是给 JDK 源码使用的（需要的话，我们也是可以获取它的实例的）。\n\n\n\n\n\n\n\n\n\nUnsafe 类的构造方法是 private 的，但是它提供了 getUnsafe() 这个静态方法：\n大家可以试一下，上面这行代码编译没有问题，但是执行的时候会抛 java.lang.SecurityException 异常，因为它就不是给我们的代码用的。\n但是如果你就是想获取 Unsafe 的实例，可以通过下面这个代码获取到:\nUnsafe unsafe = Unsafe.getUnsafe();\n\nField f = Unsafe.class.getDeclaredField(\"theUnsafe\");\nf.setAccessible(true);\nUnsafe unsafe = (Unsafe) f.get(null);\n\nNetty 中的 Unsafe 也是同样的意思，它封装了 Netty 中会使用到的 JDK 提供的 NIO 接口，比如将 channel 注册到 selector 上，比如 bind 操作，比如 connect 操作等，这些操作都是稍微偏底层一些。Netty 同样也是不希望我们的业务代码使用 Unsafe 的实例，它是提供给 Netty 中的源码使用的。\n\n\n\n\n\n\n\n\n\n不过，对于我们源码分析来说，我们还是会有很多时候需要分析 Unsafe 中的源码的\n关于 Unsafe，我们后面用到了再说，这里只要知道，它封装了大部分需要访问 JDK 的 NIO 接口的操作就好了。这里我们继续将焦点放在实例化 pipeline 上：\nprotected DefaultChannelPipeline newChannelPipeline() &#123;\n    return new DefaultChannelPipeline(this);\n&#125;\n\n这里开始调用 DefaultChannelPipeline 的构造方法，并把当前 channel 的引用传入：\nprotected DefaultChannelPipeline(Channel channel) &#123;\n    this.channel = ObjectUtil.checkNotNull(channel, \"channel\");\n    succeededFuture = new SucceededChannelFuture(channel, null);\n    voidPromise =  new VoidChannelPromise(channel, true);\n\n    tail = new TailContext(this);\n    head = new HeadContext(this);\n\n    head.next = tail;\n    tail.prev = head;\n&#125;\n\n这里实例化了 tail 和 head 这两个 handler。tail 实现了 ChannelInboundHandler 接口，而 head 实现了 ChannelOutboundHandler 和 ChannelInboundHandler 两个接口，并且最后两行代码将 tail 和 head 连接起来:\n\n\n\n\n\n\n\n\n\n\n注意，在不同的版本中，源码也略有差异，head 不一定是 in + out，大家知道这点就好了。\n还有，从上面的 head 和 tail 我们也可以看到，其实 pipeline 中的每个元素是 **ChannelHandlerContext** 的实例，而不是 ChannelHandler 的实例，context 包装了一下 handler，但是，后面我们都会用 handler 来描述一个 pipeline 上的节点，而不是使用 context，希望读者知道这一点。\nChannelHandlerContext 可以说是 ChannelPipeline 的核心，它代表了 ChannelHandler 和 ChannelPipeline 之间的关联，我们首先要知道一个 ChannelPipeline 内部会维护一个双向链表，每当一个 ChannelHandler 被添加到 ChannelPipeline 中时，它都会被包装成为一个 ChannelHandlerContext，组成链表的各个节点。\n\n这里只是构造了 pipeline，并且添加了两个固定的 handler 到其中（head + tail），还不涉及到自定义的 handler 代码执行。我们回过头来看下面这段代码：\n\n\n\n\n\n\n\n\n\n\n我们说过 childHandler 中指定的 handler 不是给 NioServerSocketChannel 使用的，是给 NioSocketChannel 使用的，所以这里我们不看它。\n这里调用 handler(…) 方法指定了一个 LoggingHandler 的实例，然后我们再进去下面的 bind(…) 方法中看看这个 LoggingHandler 实例是怎么进入到我们之前构造的 pipeline 内的。\n顺着 bind() 一直往前走，bind() -&gt; doBind() -&gt; initAndRegister()：\nfinal ChannelFuture initAndRegister() &#123;\n    Channel channel = null;\n    try &#123;\n        // 1. 构造 channel 实例，同时会构造 pipeline 实例，\n        // 现在 pipeline 中有 head 和 tail 两个 handler 了\n        channel = channelFactory.newChannel();\n        // 2. 看这里\n        init(channel);\n    &#125; catch (Throwable t) &#123;\n    ......\n&#125;\n\n上面的两行代码，第一行实现了构造 channel 和 channel 内部的 pipeline，我们来看第二行 init 代码：\nServerBootstrap：\n@Override\nvoid init(Channel channel) throws Exception &#123;\n    ......\n    // 拿到刚刚创建的 channel 内部的 pipeline 实例\n    ChannelPipeline p = channel.pipeline();\n    ...\n    // 开始往 pipeline 中添加一个 handler，这个 handler 是 ChannelInitializer 的实例\n    p.addLast(new ChannelInitializer&lt;Channel>() &#123;\n\n        // 我们以后会看到，下面这个 initChannel 方法何时会被调用\n        @Override\n        public void initChannel(final Channel ch) throws Exception &#123;\n            final ChannelPipeline pipeline = ch.pipeline();\n            // 这个方法返回我们最开始指定的 LoggingHandler 实例\n            ChannelHandler handler = config.handler();\n            if (handler != null) &#123;\n                // 添加 LoggingHandler\n                pipeline.addLast(handler);\n            &#125;\n\n            // 先不用管这里的 eventLoop\n            ch.eventLoop().execute(new Runnable() &#123;\n                @Override\n                public void run() &#123;\n                    // 添加一个 handler 到 pipeline 中：ServerBootstrapAcceptor\n                    // 从名字可以看到，这个 handler 的目的是用于接收客户端请求\n                    pipeline.addLast(new ServerBootstrapAcceptor(\n                            ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs));\n                &#125;\n            &#125;);\n        &#125;\n    &#125;);\n&#125;\n\n这里涉及到 pipeline 中的辅助类 ChannelInitializer，我们看到，它本身是一个 handler（Inbound 类型），但是它的作用和普通 handler 有点不一样，它纯碎是用来辅助将其他的 handler 加入到 pipeline 中的。\n大家可以稍微看一下 ChannelInitializer 的 initChannel 方法，有个简单的认识就好，此时的 pipeline 应该是这样的：\n\nChannelInitializer 的 initChannel(channel) 方法被调用的时候，会往 pipeline 中添加我们最开始指定的 **LoggingHandler** 和添加一个 **ServerBootstrapAcceptor**。但是我们现在还不知道这个 initChannel 方法何时会被调用。\n上面我们说的是作为服务端的 NioServerSocketChannel 的 pipeline，NioSocketChannel 也是差不多的，我们可以看一下 Bootstrap 类的 init(channel) 方法：\nvoid init(Channel channel) throws Exception &#123;\n    ChannelPipeline p = channel.pipeline();\n    p.addLast(config.handler());\n    ...\n&#125;\n\n\n它和服务端 ServerBootstrap 要添加 ServerBootstrapAcceptor 不一样，它只需要将 EchoClient 类中的 ChannelInitializer 实例加进来就可以了，它的 ChannelInitializer 中添加了两个 handler，LoggingHandler 和 EchoClientHandler：\n\n很显然，我们需要的是像 LoggingHandler 和 EchoClientHandler 这样的 handler，但是，它们现在还不在 pipeline 中，那么它们什么时候会真正进入到 pipeline 中呢？以后我们再揭晓。\n还有，为什么 Server 端我们指定的是一个 handler 实例，而 Client 指定的是一个 ChannelInitializer 实例？其实它们是可以随意搭配使用的，你甚至可以在 ChannelInitializer 实例中添加 ChannelInitializer 的实例。\n大家要记住 pipeline 现在的样子，head + channelInitializer + tail。\n本节没有介绍 handler 的向后传播，就是一个 handler 处理完了以后，怎么传递给下一个 handler 来处理？比如我们熟悉的 JavaEE 中的 Filter 是采用在一个 Filter 实例中调用 chain.doFilter(request, response) 来传递给下一个 Filter 这种方式的。\n我们用下面这张图结束本节。下图展示了传播的方法，但我其实是更想让大家看一下，哪些事件是 Inbound 类型的，哪些是 Outbound 类型的：\n\nOutbound 类型的几个事件大家应该比较好认，注意 bind 也是 Outbound 类型的。\n3.异步操作：Future 和 PromiseNetty 中非常多的异步调用，所以在介绍更多 NIO 相关的内容之前，我们来看看它的异步接口是怎么使用的。\n前面我们在介绍 Echo 例子的时候，已经用过了 ChannelFuture 这个接口了：\n\n争取在看完本节后，读者能搞清楚上面的这几行划线部分是怎么走的。\n关于 Future 接口，我想大家应该都很熟悉，用得最多的就是在使用 Java 的线程池 ThreadPoolExecutor 的时候了。在 submit 一个任务到线程池中的时候，返回的就是一个 **Future** 实例，通过它来获取提交的任务的执行状态和最终的执行结果，我们最常用它的 isDone() 和 get() 方法。\n下面是 JDK  中的 Future 接口 java.util.concurrent.Future ：\npublic interface Future&lt;V> &#123;\n    // 取消该任务\n    boolean cancel(boolean mayInterruptIfRunning);\n    // 任务是否已取消\n    boolean isCancelled();\n    // 任务是否已完成\n    boolean isDone();\n    // 阻塞获取任务执行结果\n    V get() throws InterruptedException, ExecutionException;\n    // 带超时参数的获取任务执行结果\n    V get(long timeout, TimeUnit unit)\n        throws InterruptedException, ExecutionException, TimeoutException;\n&#125;\n\nNetty 中的 Future 接口（同名）继承了 JDK 中的 Future 接口，然后添加了一些方法：\nio.netty.util.concurrent.Future\npublic interface Future&lt;V> extends java.util.concurrent.Future&lt;V> &#123;\n\n    // 是否成功\n    boolean isSuccess();\n\n    // 是否可取消\n    boolean isCancellable();\n\n    // 如果任务执行失败，这个方法返回异常信息\n    Throwable cause();\n\n    // 添加 Listener 来进行回调\n    Future&lt;V> addListener(GenericFutureListener&lt;? extends Future&lt;? super V>> listener);\n    Future&lt;V> addListeners(GenericFutureListener&lt;? extends Future&lt;? super V>>... listeners);\n\n    Future&lt;V> removeListener(GenericFutureListener&lt;? extends Future&lt;? super V>> listener);\n    Future&lt;V> removeListeners(GenericFutureListener&lt;? extends Future&lt;? super V>>... listeners);\n\n    // 阻塞等待任务结束，如果任务失败，将“导致失败的异常”重新抛出来\n    Future&lt;V> sync() throws InterruptedException;\n    // 不响应中断的 sync()，这个大家应该都很熟了\n    Future&lt;V> syncUninterruptibly();\n\n    // 阻塞等待任务结束，和 sync() 功能是一样的，不过如果任务失败，它不会抛出执行过程中的异常\n    Future&lt;V> await() throws InterruptedException;\n    Future&lt;V> awaitUninterruptibly();\n    boolean await(long timeout, TimeUnit unit) throws InterruptedException;\n    boolean await(long timeoutMillis) throws InterruptedException;\n    boolean awaitUninterruptibly(long timeout, TimeUnit unit);\n    boolean awaitUninterruptibly(long timeoutMillis);\n\n    // 获取执行结果，不阻塞。我们都知道 java.util.concurrent.Future 中的 get() 是阻塞的\n    V getNow();\n\n    // 取消任务执行，如果取消成功，任务会因为 CancellationException 异常而导致失败\n    //      也就是 isSuccess()==false，同时上面的 cause() 方法返回 CancellationException 的实例。\n    // mayInterruptIfRunning 说的是：是否对正在执行该任务的线程进行中断(这样才能停止该任务的执行)，\n    //       似乎 Netty 中 Future 接口的各个实现类，都没有使用这个参数\n    @Override\n    boolean cancel(boolean mayInterruptIfRunning);\n&#125;\n\n看完上面的 Netty 的 Future 接口，我们可以发现，它加了 sync() 和 await() 用于阻塞等待，还加了 Listeners，只要任务结束去回调 Listener 们就可以了，那么我们就不一定要主动调用 isDone() 来获取状态，或通过 get() 阻塞方法来获取值。\n\n\n\n\n\n\n\n\n\n所以它其实有两种使用范式\n顺便说下 sync() 和 await() 的区别：sync() 内部会先调用 await() 方法，等 await() 方法返回后，会检查下这个任务是否失败，如果失败，重新将导致失败的异常抛出来。也就是说，如果使用 await()，任务抛出异常后，await() 方法会返回，但是不会抛出异常，而 sync() 方法返回的同时会抛出异常。\n\n\n\n\n\n\n\n\n\n我们也可以看到，Future 接口没有和 IO 操作关联在一起，还是比较_纯净_的接口。\n接下来，我们来看 Future 接口的子接口 ChannelFuture，这个接口用得最多，它将和 IO 操作中的 Channel 关联在一起了，用于异步处理 Channel 中的事件。\npublic interface ChannelFuture extends Future&lt;Void> &#123;\n\n    // ChannelFuture 关联的 Channel\n    Channel channel();\n\n    // 覆写以下几个方法，使得它们返回值为 ChannelFuture 类型 \n    @Override\n    ChannelFuture addListener(GenericFutureListener&lt;? extends Future&lt;? super Void>> listener);\n    @Override\n    ChannelFuture addListeners(GenericFutureListener&lt;? extends Future&lt;? super Void>>... listeners);\n    @Override\n    ChannelFuture removeListener(GenericFutureListener&lt;? extends Future&lt;? super Void>> listener);\n    @Override\n    ChannelFuture removeListeners(GenericFutureListener&lt;? extends Future&lt;? super Void>>... listeners);\n\n    @Override\n    ChannelFuture sync() throws InterruptedException;\n    @Override\n    ChannelFuture syncUninterruptibly();\n\n    @Override\n    ChannelFuture await() throws InterruptedException;\n    @Override\n    ChannelFuture awaitUninterruptibly();\n\n    // 用来标记该 future 是 void 的，\n    // 这样就不允许使用 addListener(...), sync(), await() 以及它们的几个重载方法\n    boolean isVoid();\n&#125;\n\n我们看到，ChannelFuture 接口相对于 Future 接口，除了将 channel 关联进来，没有增加什么东西。还有个 isVoid() 方法算是不那么重要的存在吧。其他几个都是方法覆写，为了让返回值类型变为 ChannelFuture，而不是原来的 Future。\n这里有点跳，我们来介绍下 Promise 接口，它和 ChannelFuture 接口无关，而是和前面的 Future 接口相关，Promise 这个接口非常重要。\nPromise 接口和 ChannelFuture 一样，也继承了 Netty 的 Future 接口，然后加了一些 Promise 的内容：\npublic interface Promise&lt;V> extends Future&lt;V> &#123;\n\n    // 标记该 future 成功及设置其执行结果，并且会通知所有的 listeners。\n    // 如果该操作失败，将抛出异常(失败指的是该 future 已经有了结果了，成功的结果，或者失败的结果)\n    Promise&lt;V> setSuccess(V result);\n\n    // 和 setSuccess 方法一样，只不过如果失败，它不抛异常，返回 false\n    boolean trySuccess(V result);\n\n    // 标记该 future 失败，及其失败原因。\n    // 如果失败，将抛出异常(失败指的是已经有了结果了)\n    Promise&lt;V> setFailure(Throwable cause);\n\n    // 标记该 future 失败，及其失败原因。\n    // 如果已经有结果，返回 false，不抛出异常\n    boolean tryFailure(Throwable cause);\n\n    // 标记该 future 不可以被取消\n    boolean setUncancellable();\n\n    // 这里和 ChannelFuture 一样，对这几个方法进行覆写，目的是为了返回 Promise 类型的实例\n    @Override\n    Promise&lt;V> addListener(GenericFutureListener&lt;? extends Future&lt;? super V>> listener);\n    @Override\n    Promise&lt;V> addListeners(GenericFutureListener&lt;? extends Future&lt;? super V>>... listeners);\n\n    @Override\n    Promise&lt;V> removeListener(GenericFutureListener&lt;? extends Future&lt;? super V>> listener);\n    @Override\n    Promise&lt;V> removeListeners(GenericFutureListener&lt;? extends Future&lt;? super V>>... listeners);\n\n    @Override\n    Promise&lt;V> await() throws InterruptedException;\n    @Override\n    Promise&lt;V> awaitUninterruptibly();\n\n    @Override\n    Promise&lt;V> sync() throws InterruptedException;\n    @Override\n    Promise&lt;V> syncUninterruptibly();\n&#125;\n\n可能有些读者对 Promise 的概念不是很熟悉，这里简单说两句。\n我觉得只要明白一点，Promise 实例内部是一个任务，任务的执行往往是异步的，通常是一个线程池来处理任务。Promise 提供的 setSuccess(V result) 或 setFailure(Throwable t)将来会被某个执行任务的线程在执行完成以后调用，同时那个线程在调用 setSuccess(result) 或 setFailure(t) 后会回调 listeners 的回调函数（当然，回调的具体内容不一定要由执行任务的线程自己来执行，它可以创建新的线程来执行，也可以将回调任务提交到某个线程池来执行）。而且，一旦 setSuccess(...) 或 setFailure(...) 后，那些 await() 或 sync() 的线程就会从等待中返回。\n**所以这里就有两种编程方式，一种是用 ****await()**，等 **await()** 方法返回后，得到 **promise** 的执行结果，然后处理它；另一种就是提供 **Listener** 实例，我们不太关心任务什么时候会执行完，只要它执行完了以后会去执行 listener 中的处理方法就行。\n接下来，我们再来看下 **ChannelPromise**，它继承了前面介绍的 ChannelFuture 和 Promise 接口。\n\nChannelPromise 接口在 Netty 中使用得比较多，因为它综合了 ChannelFuture 和 Promise 两个接口：\n/**\n * Special &#123;@link ChannelFuture&#125; which is writable.\n */\npublic interface ChannelPromise extends ChannelFuture, Promise&lt;Void> &#123;\n\n    // 覆写 ChannelFuture 中的 channel() 方法，其实这个方法一点没变\n    @Override\n    Channel channel();\n\n    // 下面几个方法是覆写 Promise 中的接口，为了返回值类型是 ChannelPromise\n    @Override\n    ChannelPromise setSuccess(Void result);\n    ChannelPromise setSuccess();\n    boolean trySuccess();\n    @Override\n    ChannelPromise setFailure(Throwable cause);\n\n    // 到这里大家应该都熟悉了，下面几个方法的覆写也是为了得到 ChannelPromise 类型的实例\n    @Override\n    ChannelPromise addListener(GenericFutureListener&lt;? extends Future&lt;? super Void>> listener);\n    @Override\n    ChannelPromise addListeners(GenericFutureListener&lt;? extends Future&lt;? super Void>>... listeners);\n    @Override\n    ChannelPromise removeListener(GenericFutureListener&lt;? extends Future&lt;? super Void>> listener);\n    @Override\n    ChannelPromise removeListeners(GenericFutureListener&lt;? extends Future&lt;? super Void>>... listeners);\n\n    @Override\n    ChannelPromise sync() throws InterruptedException;\n    @Override\n    ChannelPromise syncUninterruptibly();\n    @Override\n    ChannelPromise await() throws InterruptedException;\n    @Override\n    ChannelPromise awaitUninterruptibly();\n\n    /**\n     * Returns a new &#123;@link ChannelPromise&#125; if &#123;@link #isVoid()&#125; returns &#123;@code true&#125; otherwise itself.\n     */\n    // 我们忽略这个方法吧。\n    ChannelPromise unvoid();\n&#125;\n\n我们可以看到，它综合了 ChannelFuture 和 Promise 中的方法，只不过通过覆写将返回值都变为 ChannelPromise 了而已，没有增加什么新的功能。\n小结一下，我们上面介绍了几个接口，Future 以及它的子接口 ChannelFuture 和 Promise，然后是 ChannelPromise 接口同时继承了 ChannelFuture 和 Promise。\n我把这几个接口的主要方法列在一起，这样大家看得清晰些：\n\n接下来，我们需要来一个实现类，这样才能比较直观地看出它们是怎么使用的，因为上面的这些都是接口定义，具体还得看实现类是怎么工作的。\n下面，我们来介绍下 DefaultPromise 这个实现类，这个类很常用，它的源码也不短，我们先介绍几个关键的内容，然后介绍一个示例使用。\n首先，我们看下它有哪些属性：\npublic class DefaultPromise&lt;V> extends AbstractFuture&lt;V> implements Promise&lt;V> &#123;\n      // 保存执行结果\n    private volatile Object result;\n    // 执行任务的线程池，promise 持有 executor 的引用，这个其实有点奇怪了\n    // 因为“任务”其实没必要知道自己在哪里被执行的\n    private final EventExecutor executor;\n      // 监听者，回调函数，任务结束后（正常或异常结束）执行\n    private Object listeners;\n\n    // 等待这个 promise 的线程数(调用sync()/await()进行等待的线程数量)\n    private short waiters;\n\n    // 是否正在唤醒等待线程，用于防止重复执行唤醒，不然会重复执行 listeners 的回调方法\n    private boolean notifyingListeners;\n    ......\n&#125;\n\n\n\n\n\n\n\n\n\n\n可以看出，此类实现了 Promise，但是没有实现 ChannelFuture，所以它和 Channel 联系不起来。\n别急，我们后面会碰到另一个类 DefaultChannelPromise 的使用，这个类是综合了 ChannelFuture 和 Promise 的，但是它的实现其实大部分都是继承自这里的 DefaultPromise 类的。\n说完上面的属性以后，大家可以看下 setSuccess(V result) 、trySuccess(V result) 和 setFailure(Throwable cause) 、 tryFailure(Throwable cause) 这几个方法：\n\n\n\n\n\n\n\n\n\n\n看出 setSuccess(result) 和 trySuccess(result) 的区别了吗？\n上面几个方法都非常简单，先设置好值，然后执行监听者们的回调方法。notifyListeners() 方法感兴趣的读者也可以看一看，不过它还涉及到 Netty 线程池的一些内容，我们还没有介绍到线程池，这里就不展开了。上面的代码，在 setSuccess0 或 setFailure0 方法中都会唤醒阻塞在 sync() 或 await() 的线程\n另外，就是可以看下 sync() 和 await() 的区别，其他的我觉得随便看看就好了。\n@Override\npublic Promise&lt;V> sync() throws InterruptedException &#123;\n    await();\n    // 如果任务是失败的，重新抛出相应的异常\n    rethrowIfFailed();\n    return this;\n&#125;\n\n接下来，我们来写个实例代码吧：\npublic static void main(String[] args) &#123;\n\n    // 构造线程池\n    EventExecutor executor = new DefaultEventExecutor();\n\n    // 创建 DefaultPromise 实例\n    Promise promise = new DefaultPromise(executor);\n\n    // 下面给这个 promise 添加两个 listener\n    promise.addListener(new GenericFutureListener&lt;Future&lt;Integer>>() &#123;\n        @Override\n        public void operationComplete(Future future) throws Exception &#123;\n            if (future.isSuccess()) &#123;\n                System.out.println(\"任务结束，结果：\" + future.get());\n            &#125; else &#123;\n                System.out.println(\"任务失败，异常：\" + future.cause());\n            &#125;\n        &#125;\n    &#125;).addListener(new GenericFutureListener&lt;Future&lt;Integer>>() &#123;\n        @Override\n        public void operationComplete(Future future) throws Exception &#123;\n            System.out.println(\"任务结束，balabala...\");\n        &#125;\n    &#125;);\n\n    // 提交任务到线程池，五秒后执行结束，设置执行 promise 的结果\n    executor.submit(new Runnable() &#123;\n        @Override\n        public void run() &#123;\n            try &#123;\n                Thread.sleep(5000);\n            &#125; catch (InterruptedException e) &#123;\n            &#125;\n            // 设置 promise 的结果\n            // promise.setFailure(new RuntimeException());\n            promise.setSuccess(123456);\n        &#125;\n    &#125;);\n\n    // main 线程阻塞等待执行结果\n    try &#123;\n        promise.sync();\n    &#125; catch (InterruptedException e) &#123;\n    &#125;\n&#125;\n\n运行代码，两个 listener 将在 5 秒后将输出：\n任务结束，结果：123456\n任务结束，balabala...\n\n\n\n\n\n\n\n\n\n\n读者这里可以试一下 sync() 和 await() 的区别，在任务中调用 promise.setFailure(new RuntimeException()) 试试看。\n上面的代码中，大家可能会对线程池 executor 和 promise 之间的关系感到有点迷惑。读者应该也要清楚，具体的任务不一定就要在这个 executor 中被执行。任务结束以后，需要调用 promise.setSuccess(result) 作为通知。\n通常来说，promise 代表的 future 是不需要和线程池搅在一起的，future 只关心任务是否结束以及任务的执行结果，至于是哪个线程或哪个线程池执行的任务，future 其实是不关心的。\n不过 Netty 毕竟不是要创建一个通用的线程池实现，而是和它要处理的 IO 息息相关的，所以我们只不过要理解它就好了。\n这节就说这么多吧，我们回过头来再看一下这张图，看看大家是不是看懂了这节内容：\n\n我们就说说上图左边的部分吧，虽然我们还不知道 bind() 操作中具体会做什么工作，但是我们应该可以猜出一二。\n显然，main 线程调用 b.bind(port) 这个方法会返回一个 ChannelFuture，bind() 是一个异步方法，当某个执行线程执行了真正的绑定操作后，那个执行线程一定会标记这个 future 为成功（我们假定 bind 会成功），然后这里的 sync() 方法（main 线程）就会返回了。\n\n\n\n\n\n\n\n\n\n如果 bind(port) 失败，我们知道，sync() 方法会将异常抛出来，然后就会执行到 finally 块了。\n一旦绑定端口 bind 成功，进入下面一行，f.channel() 方法会返回该 future 关联的 channel。\nchannel.closeFuture() 也会返回一个 ChannelFuture，然后调用了 sync() 方法，这个 sync() 方法返回的条件是：**有其他的线程关闭了 ****NioServerSocketChannel**，往往是因为需要停掉服务了，然后那个线程会设置 future 的状态（ setSuccess(result) 或 setFailure(cause) ），这个 sync() 方法才会返回。\n4.线程池：EventLoopGroup接下来，我们来分析 Netty 中的线程池。Netty 中的线程池比较不好理解，因为它的类比较多，而且它们之间的关系错综复杂。看下图，感受下 NioEventLoop 类和 NioEventLoopGroup 类的继承结构：\n\n这张图我按照继承关系整理而来，大家仔细看一下就会发现，涉及到的类确实挺多的。本节来给大家理理清楚这部分内容。\n首先，我们说的 Netty 的线程池，指的就是 **NioEventLoopGroup** 的实例；线程池中的单个线程，指的是右边 **NioEventLoop** 的实例。\n回顾下我们第一节介绍的 Echo 例子，客户端和服务端的启动代码中，最开始我们总是先实例化 NioEventLoopGroup：\n// EchoClient 代码最开始：\nEventLoopGroup group = new NioEventLoopGroup();\n\n// EchoServer 代码最开始：\nEventLoopGroup bossGroup = new NioEventLoopGroup(1);\nEventLoopGroup workerGroup = new NioEventLoopGroup();\n\n下面，我们就从 NioEventLoopGroup 的源码开始进行分析。\n\nNioEventLoopGroup 的创建我们打开 NioEventLoopGroup 的源码，可以看到，NioEventLoopGroup 有多个构造方法用于参数设置，最简单地，我们采用无参构造函数，或仅仅设置线程数量就可以了，其他的参数采用默认值。\n\n\n\n\n\n\n\n\n\n比如上面的代码中，我们只在实例化 bossGroup 的时候指定了参数，代表该线程池需要一个线程。\npublic NioEventLoopGroup() &#123;\n    this(0);\n&#125;\npublic NioEventLoopGroup(int nThreads) &#123;\n    this(nThreads, (Executor) null);\n&#125;\n\n...\n\n// 参数最全的构造方法\npublic NioEventLoopGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory,\n                         final SelectorProvider selectorProvider,\n                         final SelectStrategyFactory selectStrategyFactory,\n                         final RejectedExecutionHandler rejectedExecutionHandler) &#123;\n    // 调用父类的构造方法\n    super(nThreads, executor, chooserFactory, selectorProvider, selectStrategyFactory, rejectedExecutionHandler);\n&#125;\n\n我们来稍微看一下构造方法中的各个参数：\n\nnThreads：这个最简单，就是线程池中的线程数，也就是 NioEventLoop 的实例数量。\nexecutor：我们知道，我们本身就是要构造一个线程池（Executor），为什么这里传一个 executor 实例呢？它其实不是给线程池用的，而是给 NioEventLoop 用的，以后再说。\nchooserFactory：当我们提交一个任务到线程池的时候，线程池需要选择（choose）其中的一个线程来执行这个任务，这个就是用来实现选择策略的。\nselectorProvider：这个简单，我们需要通过它来实例化 JDK 的 Selector，可以看到每个线程池都持有一个 selectorProvider 实例。\nselectStrategyFactory：这个涉及到的是线程池中线程的工作流程，在介绍 NioEventLoop 的时候会说。\nrejectedExecutionHandler：这个也是线程池的好朋友了，用于处理线程池中没有可用的线程来执行任务的情况。在 Netty 中稍微有一点点不一样，这个是给 NioEventLoop 实例用的，以后我们再详细介绍。\n\n这里介绍这些参数是希望大家有个印象而已，大家发现没有，在构造 NioEventLoopGroup 实例时的好几个参数，都是用来构造 NioEventLoop 用的。\n下面，我们从 NioEventLoopGroup 的无参构造方法开始，跟着源码走：\npublic NioEventLoopGroup() &#123;\n    this(0);\n&#125;\n\n然后一步步走下去，到这个构造方法：\npublic NioEventLoopGroup(int nThreads, ThreadFactory threadFactory, final SelectorProvider selectorProvider, final SelectStrategyFactory selectStrategyFactory) &#123;\n\n    super(nThreads, threadFactory, selectorProvider, selectStrategyFactory, RejectedExecutionHandlers.reject());\n&#125;\n\n大家自己要去跟一下源码，这样才知道中间设置了哪些默认值，下面这几个参数都被设置了默认值：\n\nselectorProvider = SelectorProvider.provider()\n\n\n\n\n\n\n\n\n\n\n这个没什么好说的，调用了 JDK 提供的方法\n\nselectStrategyFactory = DefaultSelectStrategyFactory.INSTANCE\n\n\n\n\n\n\n\n\n\n\n这个涉及到的是线程在做 select 操作和执行任务过程中的策略选择问题，在介绍 NioEventLoop 的时候会用到。\n\nrejectedExecutionHandler = RejectedExecutionHandlers.reject()\n\n\n\n\n\n\n\n\n\n\n大家进去看一下 reject() 方法，也就是说，Netty 选择的默认拒绝策略是：抛出异常\n跟着源码走，我们会来到父类 MultithreadEventLoopGroup 的构造方法中：\nprotected MultithreadEventLoopGroup(int nThreads, ThreadFactory threadFactory, Object... args) &#123;\n    super(nThreads == 0 ? DEFAULT_EVENT_LOOP_THREADS : nThreads, threadFactory, args);\n&#125;\n\n这里我们发现，如果采用无参构造函数，那么到这里的时候，默认地 nThreads 会被设置为 **CPU 核心数 *2**。大家可以看下 DEFAULT_EVENT_LOOP_THREADS 的默认值，以及 static 代码块的设值逻辑。\n我们继续往下走：\nprotected MultithreadEventExecutorGroup(int nThreads, ThreadFactory threadFactory, Object...args) &#123;\n    this(nThreads, threadFactory == null ? null : new ThreadPerTaskExecutor(threadFactory), args);\n&#125;\n\n到这一步的时候，new ThreadPerTaskExecutor(threadFactory) 会构造一个 executor。\n\n\n\n\n\n\n\n\n\n我们现在还不知道这个 executor 怎么用。这里我们先看下它的源码：\nExecutor 作为线程池的最顶层接口， 我们知道，它只有一个 execute(runnable) 方法，从上面我们可以看到，实现类 ThreadPerTaskExecutor 的逻辑就是每来一个任务，新建一个线程。\n我们先记住这个，前面也说了，它是给 NioEventLoop 用的，不是给 NioEventLoopGroup 用的。\npublic final class ThreadPerTaskExecutor implements Executor &#123;\n     private final ThreadFactory threadFactory;\n\n     public ThreadPerTaskExecutor(ThreadFactory threadFactory) &#123;\n           if (threadFactory == null) &#123;\n               throw new NullPointerException(\"threadFactory\");\n           &#125;\n           this.threadFactory = threadFactory;\n     &#125;\n\n     @Override\n     public void execute(Runnable command) &#123;\n           // 为每个任务新建一个线程\n           threadFactory.newThread(command).start();\n     &#125;\n&#125;\n\n上一步设置完了 executor，我们继续往下看：\nprotected MultithreadEventExecutorGroup(int nThreads, Executor executor, Object...args) &#123;\n    this(nThreads, executor, DefaultEventExecutorChooserFactory.INSTANCE, args);\n&#125;\n\n这一步设置了 chooserFactory，用来实现从线程池中选择一个线程的选择策略。\n\n\n\n\n\n\n\n\n\nChooserFactory 的逻辑比较简单，我们看下 DefaultEventExecutorChooserFactory 的实现：\n这里设置的策略也很简单：\n1、如果线程池的线程数量是 2^n，采用下面的方式会高效一些：\n2、如果不是，用取模的方式：\n@Override\npublic EventExecutorChooser newChooser(EventExecutor[] executors) &#123;\n     if (isPowerOfTwo(executors.length)) &#123;\n           return new PowerOfTwoEventExecutorChooser(executors);\n     &#125; else &#123;\n           return new GenericEventExecutorChooser(executors);\n     &#125;\n&#125;\n\n@Override\npublic EventExecutor next() &#123;\n     return executors[idx.getAndIncrement() &amp; executors.length - 1];\n&#125;\n\n@Override\npublic EventExecutor next() &#123;\n     return executors[Math.abs(idx.getAndIncrement() % executors.length)];\n&#125;\n\n走了这么久，我们终于到了一个干实事的构造方法中了。\nio.netty.util.concurrent.MultithreadEventExecutorGroup\nprotected MultithreadEventExecutorGroup(int nThreads, Executor executor,\n                                        EventExecutorChooserFactory chooserFactory, Object... args) &#123;\n    if (nThreads &lt;= 0) &#123;\n        throw new IllegalArgumentException(String.format(\"nThreads: %d (expected: > 0)\", nThreads));\n    &#125;\n\n    // executor 如果是 null，做一次和前面一样的默认设置。\n    if (executor == null) &#123;\n        executor = new ThreadPerTaskExecutor(newDefaultThreadFactory());\n    &#125;\n\n    // 这里的 children 数组非常重要，它就是线程池中的线程数组，这么说不太严谨，但是就大概这个意思\n    children = new EventExecutor[nThreads];\n\n    // 下面这个 for 循环将实例化 children 数组中的每一个元素\n    for (int i = 0; i &lt; nThreads; i ++) &#123;\n        boolean success = false;\n        try &#123;\n            // 实例化！！！！！！\n            children[i] = newChild(executor, args);\n            success = true;\n        &#125; catch (Exception e) &#123;\n            // TODO: Think about if this is a good exception type\n            throw new IllegalStateException(\"failed to create a child event loop\", e);\n        &#125; finally &#123;\n            // 如果有一个 child 实例化失败，那么 success 就会为 false，然后进入下面的失败处理逻辑\n            if (!success) &#123;\n                // 把已经成功实例化的“线程” shutdown，shutdown 是异步操作\n                for (int j = 0; j &lt; i; j ++) &#123;\n                    children[j].shutdownGracefully();\n                &#125;\n\n                // 等待这些线程成功 shutdown\n                for (int j = 0; j &lt; i; j ++) &#123;\n                    EventExecutor e = children[j];\n                    try &#123;\n                        while (!e.isTerminated()) &#123;\n                            e.awaitTermination(Integer.MAX_VALUE, TimeUnit.SECONDS);\n                        &#125;\n                    &#125; catch (InterruptedException interrupted) &#123;\n                        // 把中断状态设置回去，交给关心的线程来处理.\n                        Thread.currentThread().interrupt();\n                        break;\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n    // ================================================\n    // === 到这里，就是代表上面的实例化所有线程已经成功结束 ===\n    // ================================================\n\n    // 通过之前设置的 chooserFactory 来实例化 Chooser，把线程池数组传进去，\n    //     这就不必再说了吧，实现线程选择策略\n    chooser = chooserFactory.newChooser(children);\n\n    // 设置一个 Listener 用来监听该线程池的 termination 事件\n    // 下面的代码逻辑是：给池中每一个线程都设置这个 listener，当监听到所有线程都 terminate 以后，这个线程池就算真正的 terminate 了。\n    final FutureListener&lt;Object> terminationListener = new FutureListener&lt;Object>() &#123;\n        @Override\n        public void operationComplete(Future&lt;Object> future) throws Exception &#123;\n            if (terminatedChildren.incrementAndGet() == children.length) &#123;\n                terminationFuture.setSuccess(null);\n            &#125;\n        &#125;\n    &#125;;\n    for (EventExecutor e: children) &#123;\n        e.terminationFuture().addListener(terminationListener);\n    &#125;\n\n    // 设置 readonlyChildren，它是只读集合，以后用到再说\n    Set&lt;EventExecutor> childrenSet = new LinkedHashSet&lt;EventExecutor>(children.length);\n    Collections.addAll(childrenSet, children);\n    readonlyChildren = Collections.unmodifiableSet(childrenSet);\n&#125;\n\n上面的代码非常简单吧，没有什么需要特别说的，接下来，我们来看看 newChild() 这个方法，这个方法非常重要，它将创建线程池中的线程。\n\n\n\n\n\n\n\n\n\n我上面已经用过很多次”线程”这个词了，它可不是 Thread 的意思，而是指池中的个体，后面我们会看到每个”线程”在什么时候会真正创建 Thread 实例。反正每个 NioEventLoop 实例内部都会有一个自己的 Thread 实例，所以把这两个概念混在一起也无所谓吧。\nnewChild(…) 方法在 NioEventLoopGroup 中覆写了，上面说的”线程”其实就是 NioEventLoop：\n@Override\nprotected EventLoop newChild(Executor executor, Object... args) throws Exception &#123;\n    return new NioEventLoop(this, executor, (SelectorProvider) args[0],\n        ((SelectStrategyFactory) args[1]).newSelectStrategy(), (RejectedExecutionHandler) args[2]);\n&#125;\n\n它调用了 NioEventLoop 的构造方法：\nNioEventLoop(NioEventLoopGroup parent, Executor executor, SelectorProvider selectorProvider,\n             SelectStrategy strategy, RejectedExecutionHandler rejectedExecutionHandler) &#123;\n    // 调用父类构造器\n    super(parent, executor, false, DEFAULT_MAX_PENDING_TASKS, rejectedExecutionHandler);\n    if (selectorProvider == null) &#123;\n        throw new NullPointerException(\"selectorProvider\");\n    &#125;\n    if (strategy == null) &#123;\n        throw new NullPointerException(\"selectStrategy\");\n    &#125;\n    provider = selectorProvider;\n    // 开启 NIO 中最重要的组件：Selector\n    final SelectorTuple selectorTuple = openSelector();\n    selector = selectorTuple.selector;\n    unwrappedSelector = selectorTuple.unwrappedSelector;\n    selectStrategy = strategy;\n&#125;\n\n我们先粗略观察一下，然后再往下看：\n\n在 Netty 中，NioEventLoopGroup 代表线程池，NioEventLoop 就是其中的线程。\n线程池 NioEventLoopGroup 是池中的线程 NioEventLoop 的 parent，从上面的代码中的取名可以看出。\n每个 NioEventLoop 都有自己的 Selector，上面的代码也反应了这一点，这和 Tomcat 中的 NIO 模型有点区别。\nexecutor、selectStrategy 和 rejectedExecutionHandler 从 NioEventLoopGroup 中一路传到了 NioEventLoop 中。\n\n这个时候，我们来看一下 NioEventLoop 类的属性都有哪些，我们先忽略它继承自父类的属性，单单看它自己的：\nprivate Selector selector;\nprivate Selector unwrappedSelector;\nprivate SelectedSelectionKeySet selectedKeys;\n\nprivate final SelectorProvider provider;\n\nprivate final AtomicBoolean wakenUp = new AtomicBoolean();\n\nprivate final SelectStrategy selectStrategy;\n\nprivate volatile int ioRatio = 50;\nprivate int cancelledKeys;\nprivate boolean needsToSelectAgain;\n\n结合它的构造方法我们来总结一下：\n\nprovider：它由 NioEventLoopGroup 传进来，前面我们说了一个线程池有一个 selectorProvider，用于创建 Selector 实例 \nselector：虽然我们还没看创建 selector 的代码，但我们已经知道，在 Netty 中 Selector 是跟着线程池中的线程走的。也就是说，并非一个线程池一个 Selector 实例，而是线程池中每一个线程都有一个 Selector 实例。\n\n\n\n\n\n\n\n\n\n\n在无参构造过程中，我们发现，Netty 设置线程个数是 CPU 核心数的两倍，假设我们的机器 CPU 是 4 核，那么对应的就会有 8 个 Selector 实例。\n\nselectStrategy：select 操作的策略，这个不急。 \nioRatio：这是 IO 任务的执行时间比例，因为每个线程既有 IO 任务执行，也有非 IO 任务需要执行，所以该参数为了保证有足够时间是给 IO 的。这里也不需要急着去理解什么 IO 任务、什么非 IO 任务。\n\n然后我们继续走它的构造方法，我们看到上面的构造方法调用了父类的构造器，它的父类是 SingleThreadEventLoop。\nio.netty.channel.SingleThreadEventLoop :\nprotected static final int DEFAULT_MAX_PENDING_TASKS = Math.max(16,\n        SystemPropertyUtil.getInt(\"io.netty.eventLoop.maxPendingTasks\", Integer.MAX_VALUE));\n\nprotected SingleThreadEventLoop(EventLoopGroup parent, ThreadFactory threadFactory,\n                                boolean addTaskWakesUp, int maxPendingTasks,\n                                RejectedExecutionHandler rejectedExecutionHandler) &#123;\n    super(parent, threadFactory, addTaskWakesUp, maxPendingTasks, rejectedExecutionHandler);\n    tailTasks = newTaskQueue(maxPendingTasks);\n&#125;\n\nSingleThreadEventLoop 这个名字很诡异有没有？然后它的构造方法又调用了父类 SingleThreadEventExecutor 的构造方法。\nio.netty.util.concurrent.SingleThreadEventExecutor ：\nprotected SingleThreadEventExecutor(EventExecutorGroup parent, Executor executor,\n                                    boolean addTaskWakesUp, int maxPendingTasks,\n                                    RejectedExecutionHandler rejectedHandler) &#123;\n    super(parent);\n    this.addTaskWakesUp = addTaskWakesUp;\n    this.maxPendingTasks = Math.max(16, maxPendingTasks);\n    this.executor = ObjectUtil.checkNotNull(executor, \"executor\");\n    // taskQueue，这个东西很重要，提交给 NioEventLoop 的任务都会进入到这个 taskQueue 中等待被执行\n    // 这个 queue 的默认容量是 16\n    taskQueue = newTaskQueue(this.maxPendingTasks);\n    rejectedExecutionHandler = ObjectUtil.checkNotNull(rejectedHandler, \"rejectedHandler\");\n&#125;\n\nprotected Queue&lt;Runnable> newTaskQueue(int maxPendingTasks) &#123;\n  \treturn new LinkedBlockingQueue&lt;Runnable>(maxPendingTasks);\n&#125;\n\n\n到这里就更加诡异了，NioEventLoop 的父类是 SingleThreadEventLoop，而 SingleThreadEventLoop 的父类是 **SingleThreadEventExecutor**，它的名字告诉我们，它是一个 Executor，是一个线程池，而且是 Single Thread 单线程的。\n也就是说，线程池 NioEventLoopGroup 中的每一个线程 NioEventLoop 也可以当做一个线程池来用，只不过它只有一个线程。这种设计虽然看上去很巧妙，不过有点反人类的样子。\n上面这个构造函数比较简单：\n\n设置了 parent，也就是之前创建的线程池 NioEventLoopGroup 实例 \nexecutor：它是我们之前实例化的 ThreadPerTaskExecutor，我们说过，这个东西在线程池中没有用，它是给 NioEventLoop 用的，马上我们就要看到它了。提前透露一下，它用来开启 NioEventLoop 中的线程（Thread 实例）。 \ntaskQueue：这算是该构造方法中新的东西，它是任务队列。我们前面说过，NioEventLoop 需要负责 IO 事件和非 IO 事件，通常它都在执行 selector 的 select 方法或者正在处理 selectedKeys，如果我们要 submit 一个任务给它，任务就会被放到 taskQueue 中，等它来轮询。 \nrejectedExecutionHandler：taskQueue 的默认容量是 16，所以，如果 submit 的任务堆积了到了 16，再往里面提交任务会触发 rejectedExecutionHandler 的执行策略。\n\n\n\n\n\n\n\n\n\n\n还记得默认策略吗：抛出 RejectedExecutionException 异常。\n在 NioEventLoopGroup 的默认构造中，它的实现是这样的：\nprivate static final RejectedExecutionHandler REJECT = new RejectedExecutionHandler() &#123;\n    @Override\n    public void rejected(Runnable task, SingleThreadEventExecutor executor) &#123;\n        throw new RejectedExecutionException();\n    &#125;\n&#125;;\n\n\n然后，我们再回到 NioEventLoop 的构造方法：\nNioEventLoop(NioEventLoopGroup parent, Executor executor, SelectorProvider selectorProvider,\n             SelectStrategy strategy, RejectedExecutionHandler rejectedExecutionHandler) &#123;\n    // 我们刚刚说完了这个\n    super(parent, executor, false, DEFAULT_MAX_PENDING_TASKS, rejectedExecutionHandler);\n    if (selectorProvider == null) &#123;\n        throw new NullPointerException(\"selectorProvider\");\n    &#125;\n    if (strategy == null) &#123;\n        throw new NullPointerException(\"selectStrategy\");\n    &#125;\n    provider = selectorProvider;\n    // 创建 selector 实例\n    final SelectorTuple selectorTuple = openSelector();\n    selector = selectorTuple.selector;\n    unwrappedSelector = selectorTuple.unwrappedSelector;\n\n    selectStrategy = strategy;\n&#125;\n\n\n可以看到，最重要的方法其实就是 openSelector() 方法，它将创建 NIO 中最重要的一个组件 **Selector**。在这个方法中，Netty 也做了一些优化，这部分我们就不去分析它了。\n到这里，我们的线程池 NioEventLoopGroup 创建完成了，并且实例化了池中的所有 NioEventLoop 实例。\n同时，大家应该已经看到，上面并没有真正创建 NioEventLoop 中的线程（没有创建 Thread 实例）。\n提前透露一下，创建线程的时机在第一个任务提交过来的时候，那么第一个任务是什么呢？就是我们前面说的 channel 的 **register** 操作。\n\nNioEventLoop 的工作流程前面，我们在分析线程池的实例化的时候说过，NioEventLoop 中并没有启动 Java 线程。这里我们来仔细分析下在 register 过程中调用的 **eventLoop.execute(runnable)** 这个方法，这个代码在父类 SingleThreadEventExecutor 中。\nio.netty.util.concurrent.SingleThreadEventExecutor#execute\n@Override\npublic void execute(Runnable task) &#123;\n    if (task == null) &#123;\n        throw new NullPointerException(\"task\");\n    &#125;\n    // 判断添加任务的线程是否就是当前 EventLoop 中的线程\n    boolean inEventLoop = inEventLoop();\n\n    // 添加任务到之前介绍的 taskQueue 中，\n    //     如果 taskQueue 满了(默认大小 16)，根据我们之前说的，默认的策略是抛出异常\n    addTask(task);\n\n    if (!inEventLoop) &#123;\n        // 如果不是 NioEventLoop 内部线程提交的 task，那么判断下线程是否已经启动，没有的话，就启动线程\n        startThread();\n        if (isShutdown() &amp;&amp; removeTask(task)) &#123;\n            reject();\n        &#125;\n    &#125;\n\n    if (!addTaskWakesUp &amp;&amp; wakesUpForTask(task)) &#123;\n        wakeup(inEventLoop);\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\n\n原来启动 NioEventLoop 中的线程的方法在这里。\n另外，上节我们说的 register 操作进到了 taskQueue 中，所以它其实是被归类到了非 IO 操作的范畴。\n下面是 startThread 的源码，判断线程是否已经启动来决定是否要进行启动操作。\nio.netty.util.concurrent.SingleThreadEventExecutor#startThread\nprivate void startThread() &#123;\n    if (state == ST_NOT_STARTED) &#123;\n        if (STATE_UPDATER.compareAndSet(this, ST_NOT_STARTED, ST_STARTED)) &#123;\n            try &#123;\n                doStartThread();\n            &#125; catch (Throwable cause) &#123;\n                STATE_UPDATER.set(this, ST_NOT_STARTED);\n                PlatformDependent.throwException(cause);\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n\n我们按照前面的思路，根据线程没有启动的情况，来看看 doStartThread() 方法：\nio.netty.util.concurrent.SingleThreadEventExecutor#doStartThread\nprivate void doStartThread() &#123;\n    assert thread == null;\n    // 这里的 executor 大家是不是有点熟悉的感觉，它就是一开始我们实例化 NioEventLoop 的时候传进来的 ThreadPerTaskExecutor 的实例。它是每次来一个任务，创建一个线程的那种 executor。\n    // 一旦我们调用它的 execute 方法，它就会创建一个新的线程，所以这里终于会创建 Thread 实例\n    executor.execute(new Runnable() &#123;\n        @Override\n        public void run() &#123;\n            // 看这里，将 “executor” 中创建的这个线程设置为 NioEventLoop 的线程！！！\n            thread = Thread.currentThread();\n\n            if (interrupted) &#123;\n                thread.interrupt();\n            &#125;\n\n            boolean success = false;\n            updateLastExecutionTime();\n            try &#123;\n                // 执行 SingleThreadEventExecutor 的 run() 方法，它在 NioEventLoop 中实现了\n                SingleThreadEventExecutor.this.run();\n                success = true;\n            &#125; catch (Throwable t) &#123;\n                logger.warn(\"Unexpected exception from an event executor: \", t);\n            &#125; finally &#123;\n                // ... 我们直接忽略掉这里的代码\n            &#125;\n        &#125;\n    &#125;);\n&#125;\n\n\n上面线程启动以后，会执行 NioEventLoop 中的 run() 方法，这是一个非常重要的方法，这个方法肯定是没那么容易结束的，必然是像 JDK 线程池的 Worker 那样，不断地循环获取新的任务的。它需要不断地做 select 操作和轮询 taskQueue 这个队列。\n我们先来简单地看一下它的源码，这里先不做深入地介绍。\nio.netty.channel.nio.NioEventLoop#run\n@Override\nprotected void run() &#123;\n    // 代码嵌套在 for 循环中\n    for (;;) &#123;\n        try &#123;\n            // selectStrategy 终于要派上用场了\n            // 它有两个值，一个是 CONTINUE 一个是 SELECT\n            // 针对这块代码，我们分析一下。\n            // 1. 如果 taskQueue 不为空，也就是 hasTasks() 返回 true，\n            //         那么执行一次 selectNow()，该方法不会阻塞\n            // 2. 如果 hasTasks() 返回 false，那么执行 SelectStrategy.SELECT 分支，\n            //    进行 select(...)，这块是带阻塞的\n            // 这个很好理解，就是按照是否有任务在排队来决定是否可以进行阻塞\n            switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) &#123;\n                case SelectStrategy.CONTINUE:\n                    continue;\n                case SelectStrategy.SELECT:\n                    // 如果 !hasTasks()，那么进到这个 select 分支，这里 select 带阻塞的\n                    select(wakenUp.getAndSet(false));\n                    if (wakenUp.get()) &#123;\n                        selector.wakeup();\n                    &#125;\n                default:\n            &#125;\n\n\n            cancelledKeys = 0;\n            needsToSelectAgain = false;\n            // 默认地，ioRatio 的值是 50\n            final int ioRatio = this.ioRatio;\n\n            if (ioRatio == 100) &#123;\n                // 如果 ioRatio 设置为 100，那么先执行 IO 操作，然后在 finally 块中执行 taskQueue 中的任务\n                try &#123;\n                    // 1. 执行 IO 操作。因为前面 select 以后，可能有些 channel 是需要处理的。\n                    processSelectedKeys();\n                &#125; finally &#123;\n                    // 2. 执行非 IO 任务，也就是 taskQueue 中的任务\n                    runAllTasks();\n                &#125;\n            &#125; else &#123;\n                // 如果 ioRatio 不是 100，那么根据 IO 操作耗时，限制非 IO 操作耗时\n                final long ioStartTime = System.nanoTime();\n                try &#123;\n                    // 执行 IO 操作\n                    processSelectedKeys();\n                &#125; finally &#123;\n                    // 根据 IO 操作消耗的时间，计算执行非 IO 操作（runAllTasks）可以用多少时间.\n                    final long ioTime = System.nanoTime() - ioStartTime;\n                    runAllTasks(ioTime * (100 - ioRatio) / ioRatio);\n                &#125;\n            &#125;\n        &#125; catch (Throwable t) &#123;\n            handleLoopException(t);\n        &#125;\n        // Always handle shutdown even if the loop processing threw an exception.\n        try &#123;\n            if (isShuttingDown()) &#123;\n                closeAll();\n                if (confirmShutdown()) &#123;\n                    return;\n                &#125;\n            &#125;\n        &#125; catch (Throwable t) &#123;\n            handleLoopException(t);\n        &#125;\n    &#125;\n&#125;\n\n\n上面这段代码是 NioEventLoop 的核心，这里介绍两点：\n\n首先，会根据 hasTasks() 的结果来决定是执行 selectNow() 还是 select(oldWakenUp)，这个应该好理解。如果有任务正在等待，那么应该使用无阻塞的 selectNow()，如果没有任务在等待，那么就可以使用带阻塞的 select 操作。\nioRatio 控制 IO 操作所占的时间比重： \n如果设置为 100%，那么先执行 IO 操作，然后再执行任务队列中的任务。\n如果不是 100%，那么先执行 IO 操作，然后执行 taskQueue 中的任务，但是需要控制执行任务的总时间。也就是说，非 IO 操作可以占用的时间，通过 ioRatio 以及这次 IO 操作耗时计算得出。\n\n\n\n我们这里先不要去关心 select(oldWakenUp) 、processSelectedKeys() 方法和 runAllTasks(…) 方法的细节，只要先理解它们分别做什么事情就可以了。\n回过神来，我们前面在 register 的时候提交了 register 任务给 NioEventLoop，这是 NioEventLoop 接收到的第一个任务，所以这里会实例化 Thread 并且启动，然后进入到 NioEventLoop 中的 run 方法。\n\n\n\n\n\n\n\n\n\n当然了，实际情况可能是，Channel 实例被 register 到一个已经启动线程的 NioEventLoop 实例中。\n","slug":"Netty源码分析","date":"2022-06-11T08:38:37.855Z","categories_index":"源码","tags_index":"java,源码,Netty","author_index":"小李不在_"},{"id":"fceed54d2b78e915f81cbddb878dcc7f","title":"SpringSecurity","content":"\n\n\n0. 简介Spring Security 是 Spring 家族中的一个安全管理框架。相比与另外一个安全框架Shiro，它提供了更丰富的功能，社区资源也比Shiro丰富。\n\n一般来说中大型的项目都是使用SpringSecurity 来做安全框架。小项目有Shiro的比较多，因为相比与SpringSecurity，Shiro的上手更加的简单。\n\n 一般Web应用的需要进行认证和授权。\n\n    认证：验证当前访问系统的是不是本系统的用户，并且要确认具体是哪个用户\n\n    授权：经过认证后判断当前用户是否有权限进行某个操作\n\n而认证和授权也是SpringSecurity作为安全框架的核心功能。\n\n\n1. 快速入门\n1.1 准备工作我们先要搭建一个简单的SpringBoot工程\n\n① 设置父工程 添加依赖\n&lt;parent>\n    &lt;groupId>org.springframework.boot&lt;/groupId>\n    &lt;artifactId>spring-boot-starter-parent&lt;/artifactId>\n    &lt;version>2.5.0&lt;/version>\n&lt;/parent>\n&lt;dependencies>\n    &lt;dependency>\n        &lt;groupId>org.springframework.boot&lt;/groupId>\n        &lt;artifactId>spring-boot-starter-web&lt;/artifactId>\n    &lt;/dependency>\n    &lt;dependency>\n        &lt;groupId>org.projectlombok&lt;/groupId>\n        &lt;artifactId>lombok&lt;/artifactId>\n        &lt;optional>true&lt;/optional>\n    &lt;/dependency>\n&lt;/dependencies>\n\n② 创建启动类\n@SpringBootApplication\npublic class SecurityApplication &#123;\n\n    public static void main(String[] args) &#123;\n        SpringApplication.run(SecurityApplication.class,args);\n    &#125;\n&#125;\n\n③ 创建Controller\n\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class HelloController &#123;\n\n    @RequestMapping(\"/hello\")\n    public String hello()&#123;\n        return \"hello\";\n    &#125;\n&#125;\n\n\n1.2 引入SpringSecurity在SpringBoot项目中使用SpringSecurity我们只需要引入依赖即可实现入门案例。\n\n&lt;dependency>\n    &lt;groupId>org.springframework.boot&lt;/groupId>\n    &lt;artifactId>spring-boot-starter-security&lt;/artifactId>\n&lt;/dependency>\n\n引入依赖后我们在尝试去访问之前的接口就会自动跳转到一个SpringSecurity的默认登陆页面，默认用户名是user,密码会输出在控制台。\n\n必须登陆之后才能对接口进行访问。\n\n\n2. 认证\n2.1 登陆校验流程\n\n2.2 原理初探想要知道如何实现自己的登陆流程就必须要先知道入门案例中SpringSecurity的流程。\n\n\n2.2.1 SpringSecurity完整流程SpringSecurity的原理其实就是一个过滤器链，内部包含了提供各种功能的过滤器。这里我们可以看看入门案例中的过滤器。\n\n\n图中只展示了核心过滤器，其它的非核心过滤器并没有在图中展示。\n\nUsernamePasswordAuthenticationFilter:负责处理我们在登陆页面填写了用户名密码后的登陆请求。入门案例的认证工作主要有它负责。\nExceptionTranslationFilter：处理过滤器链中抛出的任何AccessDeniedException和AuthenticationException 。\nFilterSecurityInterceptor：负责权限校验的过滤器。\n我们可以通过Debug查看当前系统中SpringSecurity过滤器链中有哪些过滤器及它们的顺序。\n\n\n\n2.2.2 认证流程详解\n概念速查:\nAuthentication接口: 它的实现类，表示当前访问系统的用户，封装了用户相关信息。\nAuthenticationManager接口：定义了认证Authentication的方法\nUserDetailsService接口：加载用户特定数据的核心接口。里面定义了一个根据用户名查询用户信息的方法。\nUserDetails接口：提供核心用户信息。通过UserDetailsService根据用户名获取处理的用户信息要封装成UserDetails对象返回。然后将这些信息封装到Authentication对象中。\n\n2.3 解决问题\n2.3.1 思路分析登录\n①自定义登录接口\n\n            调用ProviderManager的方法进行认证 如果认证通过生成jwt\n\n            把用户信息存入redis中\n\n②自定义UserDetailsService\n\n            在这个实现类中去查询数据库\n\n校验：\n①定义Jwt认证过滤器\n\n            获取token\n\n            解析token获取其中的userid\n\n            从redis中获取用户信息\n\n            存入SecurityContextHolder\n\n\n2.3.2 准备工作①添加依赖\n&lt;!--redis依赖-->\n&lt;dependency>\n    &lt;groupId>org.springframework.boot&lt;/groupId>\n    &lt;artifactId>spring-boot-starter-data-redis&lt;/artifactId>\n&lt;/dependency>\n&lt;!--fastjson依赖-->\n&lt;dependency>\n    &lt;groupId>com.alibaba&lt;/groupId>\n    &lt;artifactId>fastjson&lt;/artifactId>\n    &lt;version>1.2.33&lt;/version>\n&lt;/dependency>\n&lt;!--jwt依赖-->\n&lt;dependency>\n    &lt;groupId>io.jsonwebtoken&lt;/groupId>\n    &lt;artifactId>jjwt&lt;/artifactId>\n    &lt;version>0.9.0&lt;/version>\n&lt;/dependency>\n\n② 添加Redis相关配置\n\nimport com.alibaba.fastjson.JSON;\nimport com.alibaba.fastjson.serializer.SerializerFeature;\nimport com.fasterxml.jackson.databind.JavaType;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.type.TypeFactory;\nimport org.springframework.data.redis.serializer.RedisSerializer;\nimport org.springframework.data.redis.serializer.SerializationException;\nimport com.alibaba.fastjson.parser.ParserConfig;\nimport org.springframework.util.Assert;\nimport java.nio.charset.Charset;\n\n/**\n * Redis使用FastJson序列化\n * \n * @author sg\n */\npublic class FastJsonRedisSerializer&lt;T> implements RedisSerializer&lt;T>\n&#123;\n\n    public static final Charset DEFAULT_CHARSET = Charset.forName(\"UTF-8\");\n\n    private Class&lt;T> clazz;\n\n    static\n    &#123;\n        ParserConfig.getGlobalInstance().setAutoTypeSupport(true);\n    &#125;\n\n    public FastJsonRedisSerializer(Class&lt;T> clazz)\n    &#123;\n        super();\n        this.clazz = clazz;\n    &#125;\n\n    @Override\n    public byte[] serialize(T t) throws SerializationException\n    &#123;\n        if (t == null)\n        &#123;\n            return new byte[0];\n        &#125;\n        return JSON.toJSONString(t, SerializerFeature.WriteClassName).getBytes(DEFAULT_CHARSET);\n    &#125;\n\n    @Override\n    public T deserialize(byte[] bytes) throws SerializationException\n    &#123;\n        if (bytes == null || bytes.length &lt;= 0)\n        &#123;\n            return null;\n        &#125;\n        String str = new String(bytes, DEFAULT_CHARSET);\n\n        return JSON.parseObject(str, clazz);\n    &#125;\n\n\n    protected JavaType getJavaType(Class&lt;?> clazz)\n    &#123;\n        return TypeFactory.defaultInstance().constructType(clazz);\n    &#125;\n&#125;\n\n\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.data.redis.connection.RedisConnectionFactory;\nimport org.springframework.data.redis.core.RedisTemplate;\nimport org.springframework.data.redis.serializer.StringRedisSerializer;\n\n@Configuration\npublic class RedisConfig &#123;\n\n    @Bean\n    @SuppressWarnings(value = &#123; \"unchecked\", \"rawtypes\" &#125;)\n    public RedisTemplate&lt;Object, Object> redisTemplate(RedisConnectionFactory connectionFactory)\n    &#123;\n        RedisTemplate&lt;Object, Object> template = new RedisTemplate&lt;>();\n        template.setConnectionFactory(connectionFactory);\n\n        FastJsonRedisSerializer serializer = new FastJsonRedisSerializer(Object.class);\n\n        // 使用StringRedisSerializer来序列化和反序列化redis的key值\n        template.setKeySerializer(new StringRedisSerializer());\n        template.setValueSerializer(serializer);\n\n        // Hash的key也采用StringRedisSerializer的序列化方式\n        template.setHashKeySerializer(new StringRedisSerializer());\n        template.setHashValueSerializer(serializer);\n\n        template.afterPropertiesSet();\n        return template;\n    &#125;\n&#125;\n\n③ 响应类\n\nimport com.fasterxml.jackson.annotation.JsonInclude;\n\n/**\n * @Author 三更  B站： https://space.bilibili.com/663528522\n */\n@JsonInclude(JsonInclude.Include.NON_NULL)\npublic class ResponseResult&lt;T> &#123;\n    /**\n     * 状态码\n     */\n    private Integer code;\n    /**\n     * 提示信息，如果有错误时，前端可以获取该字段进行提示\n     */\n    private String msg;\n    /**\n     * 查询到的结果数据，\n     */\n    private T data;\n\n    public ResponseResult(Integer code, String msg) &#123;\n        this.code = code;\n        this.msg = msg;\n    &#125;\n\n    public ResponseResult(Integer code, T data) &#123;\n        this.code = code;\n        this.data = data;\n    &#125;\n\n    public Integer getCode() &#123;\n        return code;\n    &#125;\n\n    public void setCode(Integer code) &#123;\n        this.code = code;\n    &#125;\n\n    public String getMsg() &#123;\n        return msg;\n    &#125;\n\n    public void setMsg(String msg) &#123;\n        this.msg = msg;\n    &#125;\n\n    public T getData() &#123;\n        return data;\n    &#125;\n\n    public void setData(T data) &#123;\n        this.data = data;\n    &#125;\n\n    public ResponseResult(Integer code, String msg, T data) &#123;\n        this.code = code;\n        this.msg = msg;\n        this.data = data;\n    &#125;\n&#125;\n\n④工具类\n\nimport io.jsonwebtoken.Claims;\nimport io.jsonwebtoken.JwtBuilder;\nimport io.jsonwebtoken.Jwts;\nimport io.jsonwebtoken.SignatureAlgorithm;\n\nimport javax.crypto.SecretKey;\nimport javax.crypto.spec.SecretKeySpec;\nimport java.util.Base64;\nimport java.util.Date;\nimport java.util.UUID;\n\n/**\n * JWT工具类\n */\npublic class JwtUtil &#123;\n\n    //有效期为\n    public static final Long JWT_TTL = 60 * 60 *1000L;// 60 * 60 *1000  一个小时\n    //设置秘钥明文\n    public static final String JWT_KEY = \"sangeng\";\n\n    public static String getUUID()&#123;\n        String token = UUID.randomUUID().toString().replaceAll(\"-\", \"\");\n        return token;\n    &#125;\n    \n    /**\n     * 生成jtw\n     * @param subject token中要存放的数据（json格式）\n     * @return\n     */\n    public static String createJWT(String subject) &#123;\n        JwtBuilder builder = getJwtBuilder(subject, null, getUUID());// 设置过期时间\n        return builder.compact();\n    &#125;\n\n    /**\n     * 生成jtw\n     * @param subject token中要存放的数据（json格式）\n     * @param ttlMillis token超时时间\n     * @return\n     */\n    public static String createJWT(String subject, Long ttlMillis) &#123;\n        JwtBuilder builder = getJwtBuilder(subject, ttlMillis, getUUID());// 设置过期时间\n        return builder.compact();\n    &#125;\n\n    private static JwtBuilder getJwtBuilder(String subject, Long ttlMillis, String uuid) &#123;\n        SignatureAlgorithm signatureAlgorithm = SignatureAlgorithm.HS256;\n        SecretKey secretKey = generalKey();\n        long nowMillis = System.currentTimeMillis();\n        Date now = new Date(nowMillis);\n        if(ttlMillis==null)&#123;\n            ttlMillis=JwtUtil.JWT_TTL;\n        &#125;\n        long expMillis = nowMillis + ttlMillis;\n        Date expDate = new Date(expMillis);\n        return Jwts.builder()\n                .setId(uuid)              //唯一的ID\n                .setSubject(subject)   // 主题  可以是JSON数据\n                .setIssuer(\"sg\")     // 签发者\n                .setIssuedAt(now)      // 签发时间\n                .signWith(signatureAlgorithm, secretKey) //使用HS256对称加密算法签名, 第二个参数为秘钥\n                .setExpiration(expDate);\n    &#125;\n\n    /**\n     * 创建token\n     * @param id\n     * @param subject\n     * @param ttlMillis\n     * @return\n     */\n    public static String createJWT(String id, String subject, Long ttlMillis) &#123;\n        JwtBuilder builder = getJwtBuilder(subject, ttlMillis, id);// 设置过期时间\n        return builder.compact();\n    &#125;\n\n    public static void main(String[] args) throws Exception &#123;\n        String token = \"eyJhbGciOiJIUzI1NiJ9.eyJqdGkiOiJjYWM2ZDVhZi1mNjVlLTQ0MDAtYjcxMi0zYWEwOGIyOTIwYjQiLCJzdWIiOiJzZyIsImlzcyI6InNnIiwiaWF0IjoxNjM4MTA2NzEyLCJleHAiOjE2MzgxMTAzMTJ9.JVsSbkP94wuczb4QryQbAke3ysBDIL5ou8fWsbt_ebg\";\n        Claims claims = parseJWT(token);\n        System.out.println(claims);\n    &#125;\n\n    /**\n     * 生成加密后的秘钥 secretKey\n     * @return\n     */\n    public static SecretKey generalKey() &#123;\n        byte[] encodedKey = Base64.getDecoder().decode(JwtUtil.JWT_KEY);\n        SecretKey key = new SecretKeySpec(encodedKey, 0, encodedKey.length, \"AES\");\n        return key;\n    &#125;\n    \n    /**\n     * 解析\n     *\n     * @param jwt\n     * @return\n     * @throws Exception\n     */\n    public static Claims parseJWT(String jwt) throws Exception &#123;\n        SecretKey secretKey = generalKey();\n        return Jwts.parser()\n                .setSigningKey(secretKey)\n                .parseClaimsJws(jwt)\n                .getBody();\n    &#125;\n\n\n&#125;\n\n\nimport java.util.*;\nimport java.util.concurrent.TimeUnit;\n\n@SuppressWarnings(value = &#123; \"unchecked\", \"rawtypes\" &#125;)\n@Component\npublic class RedisCache\n&#123;\n    @Autowired\n    public RedisTemplate redisTemplate;\n\n    /**\n     * 缓存基本的对象，Integer、String、实体类等\n     *\n     * @param key 缓存的键值\n     * @param value 缓存的值\n     */\n    public &lt;T> void setCacheObject(final String key, final T value)\n    &#123;\n        redisTemplate.opsForValue().set(key, value);\n    &#125;\n\n    /**\n     * 缓存基本的对象，Integer、String、实体类等\n     *\n     * @param key 缓存的键值\n     * @param value 缓存的值\n     * @param timeout 时间\n     * @param timeUnit 时间颗粒度\n     */\n    public &lt;T> void setCacheObject(final String key, final T value, final Integer timeout, final TimeUnit timeUnit)\n    &#123;\n        redisTemplate.opsForValue().set(key, value, timeout, timeUnit);\n    &#125;\n\n    /**\n     * 设置有效时间\n     *\n     * @param key Redis键\n     * @param timeout 超时时间\n     * @return true=设置成功；false=设置失败\n     */\n    public boolean expire(final String key, final long timeout)\n    &#123;\n        return expire(key, timeout, TimeUnit.SECONDS);\n    &#125;\n\n    /**\n     * 设置有效时间\n     *\n     * @param key Redis键\n     * @param timeout 超时时间\n     * @param unit 时间单位\n     * @return true=设置成功；false=设置失败\n     */\n    public boolean expire(final String key, final long timeout, final TimeUnit unit)\n    &#123;\n        return redisTemplate.expire(key, timeout, unit);\n    &#125;\n\n    /**\n     * 获得缓存的基本对象。\n     *\n     * @param key 缓存键值\n     * @return 缓存键值对应的数据\n     */\n    public &lt;T> T getCacheObject(final String key)\n    &#123;\n        ValueOperations&lt;String, T> operation = redisTemplate.opsForValue();\n        return operation.get(key);\n    &#125;\n\n    /**\n     * 删除单个对象\n     *\n     * @param key\n     */\n    public boolean deleteObject(final String key)\n    &#123;\n        return redisTemplate.delete(key);\n    &#125;\n\n    /**\n     * 删除集合对象\n     *\n     * @param collection 多个对象\n     * @return\n     */\n    public long deleteObject(final Collection collection)\n    &#123;\n        return redisTemplate.delete(collection);\n    &#125;\n\n    /**\n     * 缓存List数据\n     *\n     * @param key 缓存的键值\n     * @param dataList 待缓存的List数据\n     * @return 缓存的对象\n     */\n    public &lt;T> long setCacheList(final String key, final List&lt;T> dataList)\n    &#123;\n        Long count = redisTemplate.opsForList().rightPushAll(key, dataList);\n        return count == null ? 0 : count;\n    &#125;\n\n    /**\n     * 获得缓存的list对象\n     *\n     * @param key 缓存的键值\n     * @return 缓存键值对应的数据\n     */\n    public &lt;T> List&lt;T> getCacheList(final String key)\n    &#123;\n        return redisTemplate.opsForList().range(key, 0, -1);\n    &#125;\n\n    /**\n     * 缓存Set\n     *\n     * @param key 缓存键值\n     * @param dataSet 缓存的数据\n     * @return 缓存数据的对象\n     */\n    public &lt;T> BoundSetOperations&lt;String, T> setCacheSet(final String key, final Set&lt;T> dataSet)\n    &#123;\n        BoundSetOperations&lt;String, T> setOperation = redisTemplate.boundSetOps(key);\n        Iterator&lt;T> it = dataSet.iterator();\n        while (it.hasNext())\n        &#123;\n            setOperation.add(it.next());\n        &#125;\n        return setOperation;\n    &#125;\n\n    /**\n     * 获得缓存的set\n     *\n     * @param key\n     * @return\n     */\n    public &lt;T> Set&lt;T> getCacheSet(final String key)\n    &#123;\n        return redisTemplate.opsForSet().members(key);\n    &#125;\n\n    /**\n     * 缓存Map\n     *\n     * @param key\n     * @param dataMap\n     */\n    public &lt;T> void setCacheMap(final String key, final Map&lt;String, T> dataMap)\n    &#123;\n        if (dataMap != null) &#123;\n            redisTemplate.opsForHash().putAll(key, dataMap);\n        &#125;\n    &#125;\n\n    /**\n     * 获得缓存的Map\n     *\n     * @param key\n     * @return\n     */\n    public &lt;T> Map&lt;String, T> getCacheMap(final String key)\n    &#123;\n        return redisTemplate.opsForHash().entries(key);\n    &#125;\n\n    /**\n     * 往Hash中存入数据\n     *\n     * @param key Redis键\n     * @param hKey Hash键\n     * @param value 值\n     */\n    public &lt;T> void setCacheMapValue(final String key, final String hKey, final T value)\n    &#123;\n        redisTemplate.opsForHash().put(key, hKey, value);\n    &#125;\n\n    /**\n     * 获取Hash中的数据\n     *\n     * @param key Redis键\n     * @param hKey Hash键\n     * @return Hash中的对象\n     */\n    public &lt;T> T getCacheMapValue(final String key, final String hKey)\n    &#123;\n        HashOperations&lt;String, String, T> opsForHash = redisTemplate.opsForHash();\n        return opsForHash.get(key, hKey);\n    &#125;\n\n    /**\n     * 删除Hash中的数据\n     * \n     * @param key\n     * @param hkey\n     */\n    public void delCacheMapValue(final String key, final String hkey)\n    &#123;\n        HashOperations hashOperations = redisTemplate.opsForHash();\n        hashOperations.delete(key, hkey);\n    &#125;\n\n    /**\n     * 获取多个Hash中的数据\n     *\n     * @param key Redis键\n     * @param hKeys Hash键集合\n     * @return Hash对象集合\n     */\n    public &lt;T> List&lt;T> getMultiCacheMapValue(final String key, final Collection&lt;Object> hKeys)\n    &#123;\n        return redisTemplate.opsForHash().multiGet(key, hKeys);\n    &#125;\n\n    /**\n     * 获得缓存的基本对象列表\n     *\n     * @param pattern 字符串前缀\n     * @return 对象列表\n     */\n    public Collection&lt;String> keys(final String pattern)\n    &#123;\n        return redisTemplate.keys(pattern);\n    &#125;\n&#125;\n\n\nimport javax.servlet.http.HttpServletResponse;\nimport java.io.IOException;\n\npublic class WebUtils\n&#123;\n    /**\n     * 将字符串渲染到客户端\n     * \n     * @param response 渲染对象\n     * @param string 待渲染的字符串\n     * @return null\n     */\n    public static String renderString(HttpServletResponse response, String string) &#123;\n        try\n        &#123;\n            response.setStatus(200);\n            response.setContentType(\"application/json\");\n            response.setCharacterEncoding(\"utf-8\");\n            response.getWriter().print(string);\n        &#125;\n        catch (IOException e)\n        &#123;\n            e.printStackTrace();\n        &#125;\n        return null;\n    &#125;\n&#125;\n\n⑤实体类\nimport java.io.Serializable;\nimport java.util.Date;\n\n\n/**\n * 用户表(User)实体类\n *\n * @author 三更\n */\n@Data\n@AllArgsConstructor\n@NoArgsConstructor\npublic class User implements Serializable &#123;\n    private static final long serialVersionUID = -40356785423868312L;\n    \n    /**\n    * 主键\n    */\n    private Long id;\n    /**\n    * 用户名\n    */\n    private String userName;\n    /**\n    * 昵称\n    */\n    private String nickName;\n    /**\n    * 密码\n    */\n    private String password;\n    /**\n    * 账号状态（0正常 1停用）\n    */\n    private String status;\n    /**\n    * 邮箱\n    */\n    private String email;\n    /**\n    * 手机号\n    */\n    private String phonenumber;\n    /**\n    * 用户性别（0男，1女，2未知）\n    */\n    private String sex;\n    /**\n    * 头像\n    */\n    private String avatar;\n    /**\n    * 用户类型（0管理员，1普通用户）\n    */\n    private String userType;\n    /**\n    * 创建人的用户id\n    */\n    private Long createBy;\n    /**\n    * 创建时间\n    */\n    private Date createTime;\n    /**\n    * 更新人\n    */\n    private Long updateBy;\n    /**\n    * 更新时间\n    */\n    private Date updateTime;\n    /**\n    * 删除标志（0代表未删除，1代表已删除）\n    */\n    private Integer delFlag;\n&#125;\n\n\n2.3.3 实现\n2.3.3.1 数据库校验用户从之前的分析我们可以知道，我们可以自定义一个UserDetailsService,让SpringSecurity使用我们的UserDetailsService。我们自己的UserDetailsService可以从数据库中查询用户名和密码。\n\n\n准备工作我们先创建一个用户表， 建表语句如下：\n\nCREATE TABLE &#96;sys_user&#96; (\n  &#96;id&#96; BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT &#39;主键&#39;,\n  &#96;user_name&#96; VARCHAR(64) NOT NULL DEFAULT &#39;NULL&#39; COMMENT &#39;用户名&#39;,\n  &#96;nick_name&#96; VARCHAR(64) NOT NULL DEFAULT &#39;NULL&#39; COMMENT &#39;昵称&#39;,\n  &#96;password&#96; VARCHAR(64) NOT NULL DEFAULT &#39;NULL&#39; COMMENT &#39;密码&#39;,\n  &#96;status&#96; CHAR(1) DEFAULT &#39;0&#39; COMMENT &#39;账号状态（0正常 1停用）&#39;,\n  &#96;email&#96; VARCHAR(64) DEFAULT NULL COMMENT &#39;邮箱&#39;,\n  &#96;phonenumber&#96; VARCHAR(32) DEFAULT NULL COMMENT &#39;手机号&#39;,\n  &#96;sex&#96; CHAR(1) DEFAULT NULL COMMENT &#39;用户性别（0男，1女，2未知）&#39;,\n  &#96;avatar&#96; VARCHAR(128) DEFAULT NULL COMMENT &#39;头像&#39;,\n  &#96;user_type&#96; CHAR(1) NOT NULL DEFAULT &#39;1&#39; COMMENT &#39;用户类型（0管理员，1普通用户）&#39;,\n  &#96;create_by&#96; BIGINT(20) DEFAULT NULL COMMENT &#39;创建人的用户id&#39;,\n  &#96;create_time&#96; DATETIME DEFAULT NULL COMMENT &#39;创建时间&#39;,\n  &#96;update_by&#96; BIGINT(20) DEFAULT NULL COMMENT &#39;更新人&#39;,\n  &#96;update_time&#96; DATETIME DEFAULT NULL COMMENT &#39;更新时间&#39;,\n  &#96;del_flag&#96; INT(11) DEFAULT &#39;0&#39; COMMENT &#39;删除标志（0代表未删除，1代表已删除）&#39;,\n  PRIMARY KEY (&#96;id&#96;)\n) ENGINE&#x3D;INNODB AUTO_INCREMENT&#x3D;2 DEFAULT CHARSET&#x3D;utf8mb4 COMMENT&#x3D;&#39;用户表&#39;\n\n    引入MybatisPuls和mysql驱动的依赖\n\n&lt;dependency>\n    &lt;groupId>com.baomidou&lt;/groupId>\n    &lt;artifactId>mybatis-plus-boot-starter&lt;/artifactId>\n    &lt;version>3.4.3&lt;/version>\n&lt;/dependency>\n&lt;dependency>\n    &lt;groupId>mysql&lt;/groupId>\n    &lt;artifactId>mysql-connector-java&lt;/artifactId>\n&lt;/dependency>\n\n    配置数据库信息\n\nspring:\n  datasource:\n    url: jdbc:mysql://localhost:3306/sg_security?characterEncoding=utf-8&amp;serverTimezone=UTC\n    username: root\n    password: root\n    driver-class-name: com.mysql.cj.jdbc.Driver\n\n    定义Mapper接口\n\npublic interface UserMapper extends BaseMapper&lt;User> &#123;\n&#125;\n\n    修改User实体类\n\n类名上加@TableName(value = \"sys_user\") ,id字段上加 @TableId\n\n    配置Mapper扫描\n\n@SpringBootApplication\n@MapperScan(\"com.sangeng.mapper\")\npublic class SimpleSecurityApplication &#123;\n    public static void main(String[] args) &#123;\n        ConfigurableApplicationContext run = SpringApplication.run(SimpleSecurityApplication.class);\n        System.out.println(run);\n    &#125;\n&#125;\n\n    添加junit依赖\n\n&lt;dependency>\n    &lt;groupId>org.springframework.boot&lt;/groupId>\n    &lt;artifactId>spring-boot-starter-test&lt;/artifactId>\n&lt;/dependency>\n\n   测试MP是否能正常使用\n\n/**\n * @Author 三更  B站： https://space.bilibili.com/663528522\n */\n@SpringBootTest\npublic class MapperTest &#123;\n\n    @Autowired\n    private UserMapper userMapper;\n\n    @Test\n    public void testUserMapper()&#123;\n        List&lt;User> users = userMapper.selectList(null);\n        System.out.println(users);\n    &#125;\n&#125;\n\n\n核心代码实现创建一个类实现UserDetailsService接口，重写其中的方法。更加用户名从数据库中查询用户信息\n/**\n * @Author 三更  B站： https://space.bilibili.com/663528522\n */\n@Service\npublic class UserDetailsServiceImpl implements UserDetailsService &#123;\n\n    @Autowired\n    private UserMapper userMapper;\n\n    @Override\n    public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123;\n        //根据用户名查询用户信息\n        LambdaQueryWrapper&lt;User> wrapper = new LambdaQueryWrapper&lt;>();\n        wrapper.eq(User::getUserName,username);\n        User user = userMapper.selectOne(wrapper);\n        //如果查询不到数据就通过抛出异常来给出提示\n        if(Objects.isNull(user))&#123;\n            throw new RuntimeException(\"用户名或密码错误\");\n        &#125;\n        //TODO 根据用户查询权限信息 添加到LoginUser中\n        \n        //封装成UserDetails对象返回 \n        return new LoginUser(user);\n    &#125;\n&#125;\n\n因为UserDetailsService方法的返回值是UserDetails类型，所以需要定义一个类，实现该接口，把用户信息封装在其中。\n/**\n * @Author 三更  B站： https://space.bilibili.com/663528522\n */\n@Data\n@NoArgsConstructor\n@AllArgsConstructor\npublic class LoginUser implements UserDetails &#123;\n\n    private User user;\n\n\n    @Override\n    public Collection&lt;? extends GrantedAuthority> getAuthorities() &#123;\n        return null;\n    &#125;\n\n    @Override\n    public String getPassword() &#123;\n        return user.getPassword();\n    &#125;\n\n    @Override\n    public String getUsername() &#123;\n        return user.getUserName();\n    &#125;\n\n    @Override\n    public boolean isAccountNonExpired() &#123;\n        return true;\n    &#125;\n\n    @Override\n    public boolean isAccountNonLocked() &#123;\n        return true;\n    &#125;\n\n    @Override\n    public boolean isCredentialsNonExpired() &#123;\n        return true;\n    &#125;\n\n    @Override\n    public boolean isEnabled() &#123;\n        return true;\n    &#125;\n&#125;\n\n注意：如果要测试，需要往用户表中写入用户数据，并且如果你想让用户的密码是明文存储，需要在密码前加{noop}。例如\n\n这样登陆的时候就可以用sg作为用户名，1234作为密码来登陆了。\n\n2.3.3.2 密码加密存储实际项目中我们不会把密码明文存储在数据库中。\n\n默认使用的PasswordEncoder要求数据库中的密码格式为：&#123;id&#125;password 。它会根据id去判断密码的加密方式。但是我们一般不会采用这种方式。所以就需要替换PasswordEncoder。\n\n我们一般使用SpringSecurity为我们提供的BCryptPasswordEncoder。\n\n我们只需要使用把BCryptPasswordEncoder对象注入Spring容器中，SpringSecurity就会使用该PasswordEncoder来进行密码校验。\n\n我们可以定义一个SpringSecurity的配置类，SpringSecurity要求这个配置类要继承WebSecurityConfigurerAdapter。\n\n/**\n * @Author 三更  B站： https://space.bilibili.com/663528522\n */\n@Configuration\npublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123;\n\n\n    @Bean\n    public PasswordEncoder passwordEncoder()&#123;\n        return new BCryptPasswordEncoder();\n    &#125;\n\n&#125;\n\n\n2.3.3.3 登陆接口接下我们需要自定义登陆接口，然后让SpringSecurity对这个接口放行,让用户访问这个接口的时候不用登录也能访问。\n\n在接口中我们通过AuthenticationManager的authenticate方法来进行用户认证,所以需要在SecurityConfig中配置把AuthenticationManager注入容器。\n\n认证成功的话要生成一个jwt，放入响应中返回。并且为了让用户下回请求时能通过jwt识别出具体的是哪个用户，我们需要把用户信息存入redis，可以把用户id作为key。\n\n@RestController\npublic class LoginController &#123;\n\n    @Autowired\n    private LoginServcie loginServcie;\n\n    @PostMapping(\"/user/login\")\n    public ResponseResult login(@RequestBody User user)&#123;\n        return loginServcie.login(user);\n    &#125;\n&#125;\n\n/**\n * @Author 三更  B站： https://space.bilibili.com/663528522\n */\n@Configuration\npublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123;\n\n\n    @Bean\n    public PasswordEncoder passwordEncoder()&#123;\n        return new BCryptPasswordEncoder();\n    &#125;\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception &#123;\n        http\n                //关闭csrf\n                .csrf().disable()\n                //不通过Session获取SecurityContext\n                .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS)\n                .and()\n                .authorizeRequests()\n                // 对于登录接口 允许匿名访问\n                .antMatchers(\"/user/login\").anonymous()\n                // 除上面外的所有请求全部需要鉴权认证\n                .anyRequest().authenticated();\n    &#125;\n\n    @Bean\n    @Override\n    public AuthenticationManager authenticationManagerBean() throws Exception &#123;\n        return super.authenticationManagerBean();\n    &#125;\n&#125;\n\n\n\n@Service\npublic class LoginServiceImpl implements LoginServcie &#123;\n\n    @Autowired\n    private AuthenticationManager authenticationManager;\n    @Autowired\n    private RedisCache redisCache;\n\n    @Override\n    public ResponseResult login(User user) &#123;\n        UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(user.getUserName(),user.getPassword());\n        Authentication authenticate = authenticationManager.authenticate(authenticationToken);\n        if(Objects.isNull(authenticate))&#123;\n            throw new RuntimeException(\"用户名或密码错误\");\n        &#125;\n        //使用userid生成token\n        LoginUser loginUser = (LoginUser) authenticate.getPrincipal();\n        String userId = loginUser.getUser().getId().toString();\n        String jwt = JwtUtil.createJWT(userId);\n        //authenticate存入redis\n        redisCache.setCacheObject(\"login:\"+userId,loginUser);\n        //把token响应给前端\n        HashMap&lt;String,String> map = new HashMap&lt;>();\n        map.put(\"token\",jwt);\n        return new ResponseResult(200,\"登陆成功\",map);\n    &#125;\n&#125;\n\n\n2.3.3.4 认证过滤器我们需要自定义一个过滤器，这个过滤器会去获取请求头中的token，对token进行解析取出其中的userid。\n\n使用userid去redis中获取对应的LoginUser对象。\n\n然后封装Authentication对象存入SecurityContextHolder\n\n@Component\npublic class JwtAuthenticationTokenFilter extends OncePerRequestFilter &#123;\n\n    @Autowired\n    private RedisCache redisCache;\n\n    @Override\n    protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123;\n        //获取token\n        String token = request.getHeader(\"token\");\n        if (!StringUtils.hasText(token)) &#123;\n            //放行\n            filterChain.doFilter(request, response);\n            return;\n        &#125;\n        //解析token\n        String userid;\n        try &#123;\n            Claims claims = JwtUtil.parseJWT(token);\n            userid = claims.getSubject();\n        &#125; catch (Exception e) &#123;\n            e.printStackTrace();\n            throw new RuntimeException(\"token非法\");\n        &#125;\n        //从redis中获取用户信息\n        String redisKey = \"login:\" + userid;\n        LoginUser loginUser = redisCache.getCacheObject(redisKey);\n        if(Objects.isNull(loginUser))&#123;\n            throw new RuntimeException(\"用户未登录\");\n        &#125;\n        //存入SecurityContextHolder\n        //TODO 获取权限信息封装到Authentication中\n        UsernamePasswordAuthenticationToken authenticationToken =\n                new UsernamePasswordAuthenticationToken(loginUser,null,null);\n        SecurityContextHolder.getContext().setAuthentication(authenticationToken);\n        //放行\n        filterChain.doFilter(request, response);\n    &#125;\n&#125;\n\n/**\n * @Author 三更  B站： https://space.bilibili.com/663528522\n */\n@Configuration\npublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123;\n\n\n    @Bean\n    public PasswordEncoder passwordEncoder()&#123;\n        return new BCryptPasswordEncoder();\n    &#125;\n\n\n    @Autowired\n    JwtAuthenticationTokenFilter jwtAuthenticationTokenFilter;\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception &#123;\n        http\n                //关闭csrf\n                .csrf().disable()\n                //不通过Session获取SecurityContext\n                .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS)\n                .and()\n                .authorizeRequests()\n                // 对于登录接口 允许匿名访问\n                .antMatchers(\"/user/login\").anonymous()\n                // 除上面外的所有请求全部需要鉴权认证\n                .anyRequest().authenticated();\n\n        //把token校验过滤器添加到过滤器链中\n        http.addFilterBefore(jwtAuthenticationTokenFilter, UsernamePasswordAuthenticationFilter.class);\n    &#125;\n\n    @Bean\n    @Override\n    public AuthenticationManager authenticationManagerBean() throws Exception &#123;\n        return super.authenticationManagerBean();\n    &#125;\n&#125;\n\n\n2.3.3.5 退出登陆我们只需要定义一个登陆接口，然后获取SecurityContextHolder中的认证信息，删除redis中对应的数据即可。\n\n/**\n * @Author 三更  B站： https://space.bilibili.com/663528522\n */\n@Service\npublic class LoginServiceImpl implements LoginServcie &#123;\n\n    @Autowired\n    private AuthenticationManager authenticationManager;\n    @Autowired\n    private RedisCache redisCache;\n\n    @Override\n    public ResponseResult login(User user) &#123;\n        UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(user.getUserName(),user.getPassword());\n        Authentication authenticate = authenticationManager.authenticate(authenticationToken);\n        if(Objects.isNull(authenticate))&#123;\n            throw new RuntimeException(\"用户名或密码错误\");\n        &#125;\n        //使用userid生成token\n        LoginUser loginUser = (LoginUser) authenticate.getPrincipal();\n        String userId = loginUser.getUser().getId().toString();\n        String jwt = JwtUtil.createJWT(userId);\n        //authenticate存入redis\n        redisCache.setCacheObject(\"login:\"+userId,loginUser);\n        //把token响应给前端\n        HashMap&lt;String,String> map = new HashMap&lt;>();\n        map.put(\"token\",jwt);\n        return new ResponseResult(200,\"登陆成功\",map);\n    &#125;\n\n    @Override\n    public ResponseResult logout() &#123;\n        Authentication authentication = SecurityContextHolder.getContext().getAuthentication();\n        LoginUser loginUser = (LoginUser) authentication.getPrincipal();\n        Long userid = loginUser.getUser().getId();\n        redisCache.deleteObject(\"login:\"+userid);\n        return new ResponseResult(200,\"退出成功\");\n    &#125;\n&#125;\n\n\n3. 授权\n3.0 权限系统的作用例如一个学校图书馆的管理系统，如果是普通学生登录就能看到借书还书相关的功能，不可能让他看到并且去使用添加书籍信息，删除书籍信息等功能。但是如果是一个图书馆管理员的账号登录了，应该就能看到并使用添加书籍信息，删除书籍信息等功能。\n\n总结起来就是**不同的用户可以使用不同的功能**。这就是权限系统要去实现的效果。\n\n我们不能只依赖前端去判断用户的权限来选择显示哪些菜单哪些按钮。因为如果只是这样，如果有人知道了对应功能的接口地址就可以不通过前端，直接去发送请求来实现相关功能操作。\n\n所以我们还需要在后台进行用户权限的判断，判断当前用户是否有相应的权限，必须具有所需权限才能进行相应的操作。\n\n\n3.1 授权基本流程在SpringSecurity中，会使用默认的FilterSecurityInterceptor来进行权限校验。在FilterSecurityInterceptor中会从SecurityContextHolder获取其中的Authentication，然后获取其中的权限信息。当前用户是否拥有访问当前资源所需的权限。\n\n所以我们在项目中只需要把当前登录用户的权限信息也存入Authentication。\n\n然后设置我们的资源所需要的权限即可。\n\n\n3.2 授权实现\n3.2.1 限制访问资源所需权限SpringSecurity为我们提供了基于注解的权限控制方案，这也是我们项目中主要采用的方式。我们可以使用注解去指定访问对应的资源所需的权限。\n\n但是要使用它我们需要先开启相关配置。\n\n@EnableGlobalMethodSecurity(prePostEnabled = true)\n\n然后就可以使用对应的注解。[@PreAuthorize ](/PreAuthorize ) \n\n@RestController\npublic class HelloController &#123;\n\n    @RequestMapping(\"/hello\")\n    @PreAuthorize(\"hasAuthority('test')\")\n    public String hello()&#123;\n        return \"hello\";\n    &#125;\n&#125;\n\n\n3.2.2 封装权限信息我们前面在写UserDetailsServiceImpl的时候说过，在查询出用户后还要获取对应的权限信息，封装到UserDetails中返回。\n\n我们先直接把权限信息写死封装到UserDetails中进行测试。\n\n我们之前定义了UserDetails的实现类LoginUser，想要让其能封装权限信息就要对其进行修改。\n\npackage com.sangeng.domain;\n\nimport com.alibaba.fastjson.annotation.JSONField;\nimport lombok.AllArgsConstructor;\nimport lombok.Data;\nimport lombok.NoArgsConstructor;\nimport org.springframework.security.core.GrantedAuthority;\nimport org.springframework.security.core.authority.SimpleGrantedAuthority;\nimport org.springframework.security.core.userdetails.UserDetails;\n\nimport java.util.Collection;\nimport java.util.List;\nimport java.util.stream.Collectors;\n\n/**\n * @Author 三更  B站： https://space.bilibili.com/663528522\n */\n@Data\n@NoArgsConstructor\npublic class LoginUser implements UserDetails &#123;\n\n    private User user;\n        \n    //存储权限信息\n    private List&lt;String> permissions;\n    \n    \n    public LoginUser(User user,List&lt;String> permissions) &#123;\n        this.user = user;\n        this.permissions = permissions;\n    &#125;\n\n\n    //存储SpringSecurity所需要的权限信息的集合\n    @JSONField(serialize = false)\n    private List&lt;GrantedAuthority> authorities;\n\n    @Override\n    public  Collection&lt;? extends GrantedAuthority> getAuthorities() &#123;\n        if(authorities!=null)&#123;\n            return authorities;\n        &#125;\n        //把permissions中字符串类型的权限信息转换成GrantedAuthority对象存入authorities中\n        authorities = permissions.stream().\n                map(SimpleGrantedAuthority::new)\n                .collect(Collectors.toList());\n        return authorities;\n    &#125;\n\n    @Override\n    public String getPassword() &#123;\n        return user.getPassword();\n    &#125;\n\n    @Override\n    public String getUsername() &#123;\n        return user.getUserName();\n    &#125;\n\n    @Override\n    public boolean isAccountNonExpired() &#123;\n        return true;\n    &#125;\n\n    @Override\n    public boolean isAccountNonLocked() &#123;\n        return true;\n    &#125;\n\n    @Override\n    public boolean isCredentialsNonExpired() &#123;\n        return true;\n    &#125;\n\n    @Override\n    public boolean isEnabled() &#123;\n        return true;\n    &#125;\n&#125;\n\n    LoginUser修改完后我们就可以在UserDetailsServiceImpl中去把权限信息封装到LoginUser中了。我们写死权限进行测试，后面我们再从数据库中查询权限信息。\n\npackage com.sangeng.service.impl;\n\nimport com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;\nimport com.baomidou.mybatisplus.core.conditions.query.QueryWrapper;\nimport com.baomidou.mybatisplus.extension.conditions.query.LambdaQueryChainWrapper;\nimport com.sangeng.domain.LoginUser;\nimport com.sangeng.domain.User;\nimport com.sangeng.mapper.UserMapper;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.security.core.userdetails.UserDetails;\nimport org.springframework.security.core.userdetails.UserDetailsService;\nimport org.springframework.security.core.userdetails.UsernameNotFoundException;\nimport org.springframework.stereotype.Service;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.Objects;\n\n/**\n * @Author 三更  B站： https://space.bilibili.com/663528522\n */\n@Service\npublic class UserDetailsServiceImpl implements UserDetailsService &#123;\n\n    @Autowired\n    private UserMapper userMapper;\n\n    @Override\n    public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123;\n        LambdaQueryWrapper&lt;User> wrapper = new LambdaQueryWrapper&lt;>();\n        wrapper.eq(User::getUserName,username);\n        User user = userMapper.selectOne(wrapper);\n        if(Objects.isNull(user))&#123;\n            throw new RuntimeException(\"用户名或密码错误\");\n        &#125;\n        //TODO 根据用户查询权限信息 添加到LoginUser中\n        List&lt;String> list = new ArrayList&lt;>(Arrays.asList(\"test\"));\n        return new LoginUser(user,list);\n    &#125;\n&#125;\n\n\n3.2.3 从数据库查询权限信息\n3.2.3.1 RBAC权限模型RBAC权限模型（Role-Based Access Control）即：基于角色的权限控制。这是目前最常被开发者使用也是相对易用、通用权限模型。\n\n![image-20211222110249727.png](https://cdn.nlark.com/yuque/0/2022/png/26737039/1654678998174-ddf9e502-0eb7-46de-8f1e-b21c87914758.png#clientId=u30b1fcc0-d450-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=drop&amp;id=u8ac9a782&amp;name=image-20211222110249727.png&amp;originHeight=716&amp;originWidth=1187&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=59299&amp;status=done&amp;style=none&amp;taskId=ucc024657-450e-4d8f-936a-42ecaee0d1f&amp;title=)\n\n\n3.2.3.2 准备工作\nCREATE DATABASE /*!32312 IF NOT EXISTS*/`sg_security` /*!40100 DEFAULT CHARACTER SET utf8mb4 */;\n\nUSE `sg_security`;\n\n/*Table structure for table `sys_menu` */\n\nDROP TABLE IF EXISTS `sys_menu`;\n\nCREATE TABLE `sys_menu` (\n  `id` bigint(20) NOT NULL AUTO_INCREMENT,\n  `menu_name` varchar(64) NOT NULL DEFAULT 'NULL' COMMENT '菜单名',\n  `path` varchar(200) DEFAULT NULL COMMENT '路由地址',\n  `component` varchar(255) DEFAULT NULL COMMENT '组件路径',\n  `visible` char(1) DEFAULT '0' COMMENT '菜单状态（0显示 1隐藏）',\n  `status` char(1) DEFAULT '0' COMMENT '菜单状态（0正常 1停用）',\n  `perms` varchar(100) DEFAULT NULL COMMENT '权限标识',\n  `icon` varchar(100) DEFAULT '#' COMMENT '菜单图标',\n  `create_by` bigint(20) DEFAULT NULL,\n  `create_time` datetime DEFAULT NULL,\n  `update_by` bigint(20) DEFAULT NULL,\n  `update_time` datetime DEFAULT NULL,\n  `del_flag` int(11) DEFAULT '0' COMMENT '是否删除（0未删除 1已删除）',\n  `remark` varchar(500) DEFAULT NULL COMMENT '备注',\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4 COMMENT='菜单表';\n\n/*Table structure for table `sys_role` */\n\nDROP TABLE IF EXISTS `sys_role`;\n\nCREATE TABLE `sys_role` (\n  `id` bigint(20) NOT NULL AUTO_INCREMENT,\n  `name` varchar(128) DEFAULT NULL,\n  `role_key` varchar(100) DEFAULT NULL COMMENT '角色权限字符串',\n  `status` char(1) DEFAULT '0' COMMENT '角色状态（0正常 1停用）',\n  `del_flag` int(1) DEFAULT '0' COMMENT 'del_flag',\n  `create_by` bigint(200) DEFAULT NULL,\n  `create_time` datetime DEFAULT NULL,\n  `update_by` bigint(200) DEFAULT NULL,\n  `update_time` datetime DEFAULT NULL,\n  `remark` varchar(500) DEFAULT NULL COMMENT '备注',\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8mb4 COMMENT='角色表';\n\n/*Table structure for table `sys_role_menu` */\n\nDROP TABLE IF EXISTS `sys_role_menu`;\n\nCREATE TABLE `sys_role_menu` (\n  `role_id` bigint(200) NOT NULL AUTO_INCREMENT COMMENT '角色ID',\n  `menu_id` bigint(200) NOT NULL DEFAULT '0' COMMENT '菜单id',\n  PRIMARY KEY (`role_id`,`menu_id`)\n) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4;\n\n/*Table structure for table `sys_user` */\n\nDROP TABLE IF EXISTS `sys_user`;\n\nCREATE TABLE `sys_user` (\n  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '主键',\n  `user_name` varchar(64) NOT NULL DEFAULT 'NULL' COMMENT '用户名',\n  `nick_name` varchar(64) NOT NULL DEFAULT 'NULL' COMMENT '昵称',\n  `password` varchar(64) NOT NULL DEFAULT 'NULL' COMMENT '密码',\n  `status` char(1) DEFAULT '0' COMMENT '账号状态（0正常 1停用）',\n  `email` varchar(64) DEFAULT NULL COMMENT '邮箱',\n  `phonenumber` varchar(32) DEFAULT NULL COMMENT '手机号',\n  `sex` char(1) DEFAULT NULL COMMENT '用户性别（0男，1女，2未知）',\n  `avatar` varchar(128) DEFAULT NULL COMMENT '头像',\n  `user_type` char(1) NOT NULL DEFAULT '1' COMMENT '用户类型（0管理员，1普通用户）',\n  `create_by` bigint(20) DEFAULT NULL COMMENT '创建人的用户id',\n  `create_time` datetime DEFAULT NULL COMMENT '创建时间',\n  `update_by` bigint(20) DEFAULT NULL COMMENT '更新人',\n  `update_time` datetime DEFAULT NULL COMMENT '更新时间',\n  `del_flag` int(11) DEFAULT '0' COMMENT '删除标志（0代表未删除，1代表已删除）',\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8mb4 COMMENT='用户表';\n\n/*Table structure for table `sys_user_role` */\n\nDROP TABLE IF EXISTS `sys_user_role`;\n\nCREATE TABLE `sys_user_role` (\n  `user_id` bigint(200) NOT NULL AUTO_INCREMENT COMMENT '用户id',\n  `role_id` bigint(200) NOT NULL DEFAULT '0' COMMENT '角色id',\n  PRIMARY KEY (`user_id`,`role_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n\nSELECT \n\tDISTINCT m.&#96;perms&#96;\nFROM\n\tsys_user_role ur\n\tLEFT JOIN &#96;sys_role&#96; r ON ur.&#96;role_id&#96; &#x3D; r.&#96;id&#96;\n\tLEFT JOIN &#96;sys_role_menu&#96; rm ON ur.&#96;role_id&#96; &#x3D; rm.&#96;role_id&#96;\n\tLEFT JOIN &#96;sys_menu&#96; m ON m.&#96;id&#96; &#x3D; rm.&#96;menu_id&#96;\nWHERE\n\tuser_id &#x3D; 2\n\tAND r.&#96;status&#96; &#x3D; 0\n\tAND m.&#96;status&#96; &#x3D; 0\n\npackage com.sangeng.domain;\n\nimport com.baomidou.mybatisplus.annotation.TableId;\nimport com.baomidou.mybatisplus.annotation.TableName;\nimport com.fasterxml.jackson.annotation.JsonInclude;\nimport lombok.AllArgsConstructor;\nimport lombok.Data;\nimport lombok.NoArgsConstructor;\n\nimport java.io.Serializable;\nimport java.util.Date;\n\n/**\n * 菜单表(Menu)实体类\n *\n * @author makejava\n * @since 2021-11-24 15:30:08\n */\n@TableName(value=\"sys_menu\")\n@Data\n@AllArgsConstructor\n@NoArgsConstructor\n@JsonInclude(JsonInclude.Include.NON_NULL)\npublic class Menu implements Serializable &#123;\n    private static final long serialVersionUID = -54979041104113736L;\n    \n        @TableId\n    private Long id;\n    /**\n    * 菜单名\n    */\n    private String menuName;\n    /**\n    * 路由地址\n    */\n    private String path;\n    /**\n    * 组件路径\n    */\n    private String component;\n    /**\n    * 菜单状态（0显示 1隐藏）\n    */\n    private String visible;\n    /**\n    * 菜单状态（0正常 1停用）\n    */\n    private String status;\n    /**\n    * 权限标识\n    */\n    private String perms;\n    /**\n    * 菜单图标\n    */\n    private String icon;\n    \n    private Long createBy;\n    \n    private Date createTime;\n    \n    private Long updateBy;\n    \n    private Date updateTime;\n    /**\n    * 是否删除（0未删除 1已删除）\n    */\n    private Integer delFlag;\n    /**\n    * 备注\n    */\n    private String remark;\n&#125;\n\n\n3.2.3.3 代码实现我们只需要根据用户id去查询到其所对应的权限信息即可。\n\n所以我们可以先定义个mapper，其中提供一个方法可以根据userid查询权限信息。\n\nimport com.baomidou.mybatisplus.core.mapper.BaseMapper;\nimport com.sangeng.domain.Menu;\n\nimport java.util.List;\n\n/**\n * @Author 三更  B站： https://space.bilibili.com/663528522\n */\npublic interface MenuMapper extends BaseMapper&lt;Menu> &#123;\n    List&lt;String> selectPermsByUserId(Long id);\n&#125;\n\n尤其是自定义方法，所以需要创建对应的mapper文件，定义对应的sql语句\n\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n&lt;mapper namespace=\"com.sangeng.mapper.MenuMapper\">\n\n\n    &lt;select id=\"selectPermsByUserId\" resultType=\"java.lang.String\">\n        SELECT\n            DISTINCT m.`perms`\n        FROM\n            sys_user_role ur\n            LEFT JOIN `sys_role` r ON ur.`role_id` = r.`id`\n            LEFT JOIN `sys_role_menu` rm ON ur.`role_id` = rm.`role_id`\n            LEFT JOIN `sys_menu` m ON m.`id` = rm.`menu_id`\n        WHERE\n            user_id = #&#123;userid&#125;\n            AND r.`status` = 0\n            AND m.`status` = 0\n    &lt;/select>\n&lt;/mapper>\n\n在application.yml中配置mapperXML文件的位置\n\nspring:\n  datasource:\n    url: jdbc:mysql://localhost:3306/sg_security?characterEncoding=utf-8&amp;serverTimezone=UTC\n    username: root\n    password: root\n    driver-class-name: com.mysql.cj.jdbc.Driver\n  redis:\n    host: localhost\n    port: 6379\nmybatis-plus:\n  mapper-locations: classpath*:/mapper/**/*.xml\n\n然后我们可以在UserDetailsServiceImpl中去调用该mapper的方法查询权限信息封装到LoginUser对象中即可。\n\n/**\n * @Author 三更  B站： https://space.bilibili.com/663528522\n */\n@Service\npublic class UserDetailsServiceImpl implements UserDetailsService &#123;\n\n    @Autowired\n    private UserMapper userMapper;\n\n    @Autowired\n    private MenuMapper menuMapper;\n\n    @Override\n    public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123;\n        LambdaQueryWrapper&lt;User> wrapper = new LambdaQueryWrapper&lt;>();\n        wrapper.eq(User::getUserName,username);\n        User user = userMapper.selectOne(wrapper);\n        if(Objects.isNull(user))&#123;\n            throw new RuntimeException(\"用户名或密码错误\");\n        &#125;\n        List&lt;String> permissionKeyList =  menuMapper.selectPermsByUserId(user.getId());\n//        //测试写法\n//        List&lt;String> list = new ArrayList&lt;>(Arrays.asList(\"test\"));\n        return new LoginUser(user,permissionKeyList);\n    &#125;\n&#125;\n\n\n4. 自定义失败处理我们还希望在认证失败或者是授权失败的情况下也能和我们的接口一样返回相同结构的json，这样可以让前端能对响应进行统一的处理。要实现这个功能我们需要知道SpringSecurity的异常处理机制。\n\n在SpringSecurity中，如果我们在认证或者授权的过程中出现了异常会被ExceptionTranslationFilter捕获到。在ExceptionTranslationFilter中会去判断是认证失败还是授权失败出现的异常。\n\n如果是认证过程中出现的异常会被封装成AuthenticationException然后调用**AuthenticationEntryPoint**对象的方法去进行异常处理。\n\n如果是授权过程中出现的异常会被封装成AccessDeniedException然后调用**AccessDeniedHandler**对象的方法去进行异常处理。\n\n所以如果我们需要自定义异常处理，我们只需要自定义AuthenticationEntryPoint和AccessDeniedHandler然后配置给SpringSecurity即可。\n\n①自定义实现类\n@Component\npublic class AccessDeniedHandlerImpl implements AccessDeniedHandler &#123;\n    @Override\n    public void handle(HttpServletRequest request, HttpServletResponse response, AccessDeniedException accessDeniedException) throws IOException, ServletException &#123;\n        ResponseResult result = new ResponseResult(HttpStatus.FORBIDDEN.value(), \"权限不足\");\n        String json = JSON.toJSONString(result);\n        WebUtils.renderString(response,json);\n\n    &#125;\n&#125;\n\n/**\n * @Author 三更  B站： https://space.bilibili.com/663528522\n */\n@Component\npublic class AuthenticationEntryPointImpl implements AuthenticationEntryPoint &#123;\n    @Override\n    public void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException authException) throws IOException, ServletException &#123;\n        ResponseResult result = new ResponseResult(HttpStatus.UNAUTHORIZED.value(), \"认证失败请重新登录\");\n        String json = JSON.toJSONString(result);\n        WebUtils.renderString(response,json);\n    &#125;\n&#125;\n\n②配置给SpringSecurity\n先注入对应的处理器\n\n@Autowired\nprivate AuthenticationEntryPoint authenticationEntryPoint;\n\n@Autowired\nprivate AccessDeniedHandler accessDeniedHandler;\n\n然后我们可以使用HttpSecurity对象的方法去配置。\n\nhttp.exceptionHandling().authenticationEntryPoint(authenticationEntryPoint).\n        accessDeniedHandler(accessDeniedHandler);\n\n\n5. 跨域浏览器出于安全的考虑，使用 XMLHttpRequest对象发起 HTTP请求时必须遵守同源策略，否则就是跨域的HTTP请求，默认情况下是被禁止的。 同源策略要求源相同才能正常进行通信，即协议、域名、端口号都完全一致。\n\n前后端分离项目，前端项目和后端项目一般都不是同源的，所以肯定会存在跨域请求的问题。\n\n所以我们就要处理一下，让前端能进行跨域请求。\n\n①先对SpringBoot配置，运行跨域请求\n@Configuration\npublic class CorsConfig implements WebMvcConfigurer &#123;\n\n    @Override\n    public void addCorsMappings(CorsRegistry registry) &#123;\n      // 设置允许跨域的路径\n        registry.addMapping(\"/**\")\n                // 设置允许跨域请求的域名\n                .allowedOriginPatterns(\"*\")\n                // 是否允许cookie\n                .allowCredentials(true)\n                // 设置允许的请求方式\n                .allowedMethods(\"GET\", \"POST\", \"DELETE\", \"PUT\")\n                // 设置允许的header属性\n                .allowedHeaders(\"*\")\n                // 跨域允许时间\n                .maxAge(3600);\n    &#125;\n&#125;\n\n②开启SpringSecurity的跨域访问\n由于我们的资源都会收到SpringSecurity的保护，所以想要跨域访问还要让SpringSecurity运行跨域访问。\n@Override\nprotected void configure(HttpSecurity http) throws Exception &#123;\n    http\n            //关闭csrf\n            .csrf().disable()\n            //不通过Session获取SecurityContext\n            .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS)\n            .and()\n            .authorizeRequests()\n            // 对于登录接口 允许匿名访问\n            .antMatchers(\"/user/login\").anonymous()\n            // 除上面外的所有请求全部需要鉴权认证\n            .anyRequest().authenticated();\n\n    //添加过滤器\n    http.addFilterBefore(jwtAuthenticationTokenFilter, UsernamePasswordAuthenticationFilter.class);\n\n    //配置异常处理器\n    http.exceptionHandling()\n            //配置认证失败处理器\n            .authenticationEntryPoint(authenticationEntryPoint)\n            .accessDeniedHandler(accessDeniedHandler);\n\n    //允许跨域\n    http.cors();\n&#125;\n\n\n6. 遗留小问题\n其它权限校验方法我们前面都是使用@PreAuthorize注解，然后在在其中使用的是hasAuthority方法进行校验。SpringSecurity还为我们提供了其它方法例如：hasAnyAuthority，hasRole，hasAnyRole等。\n\n\n\n这里我们先不急着去介绍这些方法，我们先去理解hasAuthority的原理，然后再去学习其他方法你就更容易理解，而不是死记硬背区别。并且我们也可以选择定义校验方法，实现我们自己的校验逻辑。\n\nhasAuthority方法实际是执行到了SecurityExpressionRoot的hasAuthority，大家只要断点调试既可知道它内部的校验原理。\n\n它内部其实是调用authentication的getAuthorities方法获取用户的权限列表。然后判断我们存入的方法参数数据在权限列表中。\n\nhasAnyAuthority方法可以传入多个权限，只有用户有其中任意一个权限都可以访问对应资源。\n\n@PreAuthorize(\"hasAnyAuthority('admin','test','system:dept:list')\")\npublic String hello()&#123;\n    return \"hello\";\n&#125;\n\nhasRole要求有对应的角色才可以访问，但是它内部会把我们传入的参数拼接上 **ROLE_** 后再去比较。所以这种情况下要用用户对应的权限也要有 **ROLE_** 这个前缀才可以。\n\n@PreAuthorize(\"hasRole('system:dept:list')\")\npublic String hello()&#123;\n    return \"hello\";\n&#125;\n\nhasAnyRole 有任意的角色就可以访问。它内部也会把我们传入的参数拼接上 **ROLE_** 后再去比较。所以这种情况下要用用户对应的权限也要有 **ROLE_** 这个前缀才可以。\n\n@PreAuthorize(\"hasAnyRole('admin','system:dept:list')\")\npublic String hello()&#123;\n    return \"hello\";\n&#125;\n\n\n自定义权限校验方法我们也可以定义自己的权限校验方法，在@PreAuthorize注解中使用我们的方法。\n\n@Component(\"ex\")\npublic class SGExpressionRoot &#123;\n\n    public boolean hasAuthority(String authority)&#123;\n        //获取当前用户的权限\n        Authentication authentication = SecurityContextHolder.getContext().getAuthentication();\n        LoginUser loginUser = (LoginUser) authentication.getPrincipal();\n        List&lt;String> permissions = loginUser.getPermissions();\n        //判断用户权限集合中是否存在authority\n        return permissions.contains(authority);\n    &#125;\n&#125;\n\n 在SPEL表达式中使用 @ex相当于获取容器中bean的名字未ex的对象。然后再调用这个对象的hasAuthority方法\n\n@RequestMapping(\"/hello\")\n@PreAuthorize(\"@ex.hasAuthority('system:dept:list')\")\npublic String hello()&#123;\n    return \"hello\";\n&#125;\n\n\n基于配置的权限控制我们也可以在配置类中使用使用配置的方式对资源进行权限控制。\n\n@Override\nprotected void configure(HttpSecurity http) throws Exception &#123;\n    http\n            //关闭csrf\n            .csrf().disable()\n            //不通过Session获取SecurityContext\n            .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS)\n            .and()\n            .authorizeRequests()\n            // 对于登录接口 允许匿名访问\n            .antMatchers(\"/user/login\").anonymous()\n            .antMatchers(\"/testCors\").hasAuthority(\"system:dept:list222\")\n            // 除上面外的所有请求全部需要鉴权认证\n            .anyRequest().authenticated();\n\n    //添加过滤器\n    http.addFilterBefore(jwtAuthenticationTokenFilter, UsernamePasswordAuthenticationFilter.class);\n\n    //配置异常处理器\n    http.exceptionHandling()\n            //配置认证失败处理器\n            .authenticationEntryPoint(authenticationEntryPoint)\n            .accessDeniedHandler(accessDeniedHandler);\n\n    //允许跨域\n    http.cors();\n&#125;\n\n\nCSRFCSRF是指跨站请求伪造（Cross-site request forgery），是web常见的攻击之一。\n\n[https://blog.csdn.net/freeking101/article/details/86537087](https://blog.csdn.net/freeking101/article/details/86537087)\n\nSpringSecurity去防止CSRF攻击的方式就是通过csrf_token。后端会生成一个csrf_token，前端发起请求的时候需要携带这个csrf_token,后端会有过滤器进行校验，如果没有携带或者是伪造的就不允许访问。\n\n我们可以发现CSRF攻击依靠的是cookie中所携带的认证信息。但是在前后端分离的项目中我们的认证信息其实是token，而token并不是存储中cookie中，并且需要前端代码去把token设置到请求头中才可以，所以CSRF攻击也就不用担心了。\n\n\n认证成功处理器实际上在UsernamePasswordAuthenticationFilter进行登录认证的时候，如果登录成功了是会调用AuthenticationSuccessHandler的方法进行认证成功后的处理的。AuthenticationSuccessHandler就是登录成功处理器。\n\n我们也可以自己去自定义成功处理器进行成功后的相应处理。\n\n@Component\npublic class SGSuccessHandler implements AuthenticationSuccessHandler &#123;\n\n    @Override\n    public void onAuthenticationSuccess(HttpServletRequest request, HttpServletResponse response, Authentication authentication) throws IOException, ServletException &#123;\n        System.out.println(\"认证成功了\");\n    &#125;\n&#125;\n\n@Configuration\npublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123;\n\n    @Autowired\n    private AuthenticationSuccessHandler successHandler;\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception &#123;\n        http.formLogin().successHandler(successHandler);\n\n        http.authorizeRequests().anyRequest().authenticated();\n    &#125;\n&#125;\n\n\n认证失败处理器实际上在UsernamePasswordAuthenticationFilter进行登录认证的时候，如果认证失败了是会调用AuthenticationFailureHandler的方法进行认证失败后的处理的。AuthenticationFailureHandler就是登录失败处理器。\n\n我们也可以自己去自定义失败处理器进行失败后的相应处理。\n\n@Component\npublic class SGFailureHandler implements AuthenticationFailureHandler &#123;\n    @Override\n    public void onAuthenticationFailure(HttpServletRequest request, HttpServletResponse response, AuthenticationException exception) throws IOException, ServletException &#123;\n        System.out.println(\"认证失败了\");\n    &#125;\n&#125;\n\n@Configuration\npublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123;\n\n    @Autowired\n    private AuthenticationSuccessHandler successHandler;\n\n    @Autowired\n    private AuthenticationFailureHandler failureHandler;\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception &#123;\n        http.formLogin()\n//                配置认证成功处理器\n                .successHandler(successHandler)\n//                配置认证失败处理器\n                .failureHandler(failureHandler);\n\n        http.authorizeRequests().anyRequest().authenticated();\n    &#125;\n&#125;\n\n\n登出成功处理器@Component\npublic class SGLogoutSuccessHandler implements LogoutSuccessHandler &#123;\n    @Override\n    public void onLogoutSuccess(HttpServletRequest request, HttpServletResponse response, Authentication authentication) throws IOException, ServletException &#123;\n        System.out.println(\"注销成功\");\n    &#125;\n&#125;\n\n@Configuration\npublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123;\n\n    @Autowired\n    private AuthenticationSuccessHandler successHandler;\n\n    @Autowired\n    private AuthenticationFailureHandler failureHandler;\n\n    @Autowired\n    private LogoutSuccessHandler logoutSuccessHandler;\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception &#123;\n        http.formLogin()\n//                配置认证成功处理器\n                .successHandler(successHandler)\n//                配置认证失败处理器\n                .failureHandler(failureHandler);\n\n        http.logout()\n                //配置注销成功处理器\n                .logoutSuccessHandler(logoutSuccessHandler);\n\n        http.authorizeRequests().anyRequest().authenticated();\n    &#125;\n&#125;\n\n","slug":"SpringSecurity","date":"2022-06-09T08:30:49.418Z","categories_index":"SpringSecurity","tags_index":"java,SpringSecurity,Spring","author_index":"小李不在_"},{"id":"e1579ed1c931165c644c9ec68da7a87a","title":"Kafka","content":"一、为什么使用消息队列1.使用同步的通信方式来解决多个服务之间的通信同步的通信方式会存在性能和稳定性的问题。\n2.使用异步的通信方式\n针对于同步的通信方式来说，异步的方式，可以让上游快速成功，极大提高了系统的吞吐量。而且在分布式系统中，通过下游多个服务的分布式事务的保障，也能保障业务执行之后的最终一致性。\n消息队列解决具体的是什么问题——通信问题。\n二、消息队列的流派目前消息队列的中间件选型有很多种：\n\nrabbitMQ：内部的可玩性（功能性）是非常强的\n\nrocketMQ： 阿里内部一个大神，根据kafka的内部执行原理，手写的一个消息队列中间件。性能是与Kafka相比肩，除此之外，在功能上封装了更多的功能。\n\nkafka：全球消息处理性能最快的一款MQ\n\nzeroMQ\n\n\n这些消息队列中间件有什么区别？\n1. 有broker\n重topic：Kafka、RocketMQ、ActiveMQ\n整个broker，依据topic来进行消息的中转。在重topic的消息队列里必然需要topic的存在\n\n轻topic：RabbitMQ\ntopic只是一种中转模式。\n\n\n2.无broker在生产者和消费者之间没有使用broker，例如zeroMQ，直接使用socket进行通信。\n三、Kafka的基本知识1.Kafka的安装\n部署一台zookeeper服务器\n安装jdk\n下载kafka的安装包：http://kafka.apache.org/downloads\n上传到kafka服务器上：/usr/local/kafka\n解压缩压缩包\n进入到config目录内，修改server.properties\n\n#broker.id属性在kafka集群中必须要是唯一\nbroker.id=0\n#kafka部署的机器ip和提供服务的端口号\nlisteners=PLAINTEXT://192.168.65.60:9092   \n#kafka的消息存储文件\nlog.dir=/usr/local/data/kafka-logs\n#kafka连接zookeeper的地址\nzookeeper.connect=192.168.65.60:2181\n\n\n进入到bin目录内，执行以下命令来启动kafka服务器（带着配置文件）\n\n./kafka-server-start.sh -daemon ../config/server.properties \n\n\n校验kafka是否启动成功：\n\n进入到zk内查看是否有kafka的节点：/brokers/ids/0\nserver.properties核心配置详解\n\n\nProperty\nDefault\nDescription\n\n\n\nbroker.id\n0\n每个broker都可以用一个唯一的非负整数id进行标识；这个id可以作为broker的“名字”，你可以选择任意你喜欢的数字作为id，只要id是唯一的即可。\n\n\nlog.dirs\n&#x2F;tmp&#x2F;kafka-logs\nkafka存放数据的路径。这个路径并不是唯一的，可以是多个，路径之间只需要使用逗号分隔即可；每当创建新partition时，都会选择在包含最少partitions的路径下进行。\n\n\nlisteners\nPLAINTEXT:&#x2F;&#x2F;192.168.65.60:9092\nserver接受客户端连接的端口，ip配置kafka本机ip即可\n\n\nzookeeper.connect\nlocalhost:2181\nzooKeeper连接字符串的格式为：hostname:port，此处hostname和port分别是ZooKeeper集群中某个节点的host和port；zookeeper如果是集群，连接方式为 hostname1:port1, hostname2:port2, hostname3:port3\n\n\nlog.retention.hours\n168\n每个日志文件删除之前保存的时间。默认数据保存时间对所有topic都一样。\n\n\nnum.partitions\n1\n创建topic的默认分区数\n\n\ndefault.replication.factor\n1\n自动创建topic的默认副本数量，建议设置为大于等于2\n\n\nmin.insync.replicas\n1\n当producer设置acks为-1时，min.insync.replicas指定replicas的最小数目（必须确认每一个repica的写数据都是成功的），如果这个数目没有达到，producer发送消息会产生异常\n\n\ndelete.topic.enable\nfalse\n是否允许删除主题\n\n\n2.kafka中的一些基本概念\n\n\n名称\n解释\n\n\n\nBroker\n消息中间件处理节点，一个Kafka节点就是一个broker，一个或者多个Broker可以组成一个Kafka集群\n\n\nTopic\nKafka根据topic对消息进行归类，发布到Kafka集群的每条消息都需要指定一个topic\n\n\nProducer\n消息生产者，向Broker发送消息的客户端\n\n\nConsumer\n消息消费者，从Broker读取消息的客户端\n\n\n\n\n\n\n\n\n\n\n3.创建topic\n通过kafka命令向zk中创建一个主题\n\n./kafka-topics.sh --create --zookeeper 172.16.253.35:2181 --replication-factor 1 --partitions 1 --topic test\n\n\n查看当前zk中所有的主题\n\n./kafka-topics.sh --list --zookeeper 172.16.253.35:2181 test\n\n\n\n4.发送消息把消息发送给broker中的某个topic，打开一个kafka发送消息的客户端，然后开始用客户端向kafka服务器发送消息\n./kafka-console-consumer.sh --bootstrap-server 172.16.253.38:9092 --topic test\n\n\n\n5.消费消息打开一个消费消息的客户端，向kafka服务器的某个主题消费消息\n\n方式一：从当前主题中的最后一条消息的offset（偏移量位置）+1开始消费\n\n./kafka-console-consumer.sh --bootstrap-server 172.16.253.38:9092 --topic test\n\n\n方式二：从当前主题中的第一条消息开始消费\n\n./kafka-console-consumer.sh --bootstrap-server 172.16.253.38:9092 --from-beginning --topic test\n\n\n\n6.关于消息的细节\n\n生产者将消息发送给broker，broker会将消息保存在本地的日志文件中\n\n/usr/local/kafka/data/kafka-logs/主题-分区/00000000.log\n\n\n消息的保存是有序的，通过offset偏移量来描述消息的有序性\n消费者消费消息时也是通过offset来描述当前要消费的那条消息的位置\n\n7.单播消息在一个kafka的topic中，启动两个消费者，一个生产者，问：生产者发送消息，这条消息是否同时会被两个消费者消费？\n如果多个消费者在同一个消费组，那么只有一个消费者可以收到订阅的topic中的消息。换言之，同一个消费组中只能有一个消费者收到一个topic中的消息。\n.&#x2F;kafka-console-consumer.sh --bootstrap-server 172.16.253.38:9092  --consumer-property group.id&#x3D;testGroup --topic test\n\n\n\n8.多播消息不同的消费组订阅同一个topic，那么不同的消费组中只有一个消费者能收到消息。实际上也是多个消费组中的多个消费者收到了同一个消息。\n./kafka-console-consumer.sh --bootstrap-server 172.16.253.38:9092  --consumer-property group.id=testGroup1 --topic test\n./kafka-console-consumer.sh --bootstrap-server 172.16.253.38:9092  --consumer-property group.id=testGroup2 --topic test\n\n\n\n下图就是描述多播和单播消息的区别\n\n9. 查看消费组的详细信息通过以下命令可以查看到消费组的相信信息：\n./kafka-consumer-groups.sh --bootstrap-server 172.16.253.38:9092 --describe --group testGroup\n\n\n重点关注以下几个信息：\n\ncurrent-offset: 最后被消费的消息的偏移量\nLog-end-offset: 消息总量（最后一条消息的偏移量）\nLag：积压了多少条消息\n\n四、Kafka中主题和分区的概念1.主题Topic主题-topic在kafka中是一个逻辑的概念，kafka通过topic将消息进行分类。不同的topic会被订阅该topic的消费者消费。\n但是有一个问题，如果说这个topic中的消息非常非常多，多到需要几T来存，因为消息是会被保存到log日志文件中的。为了解决这个文件过大的问题，kafka提出了Partition分区的概念\n2.分区Partition1）分区的概念通过partition将一个topic中的消息分区来存储。这样的好处有多个：\n\n分区存储，可以解决统一存储文件过大的问题\n提供了读写的吞吐量：读和写可以同时在多个分区中进行\n\n\n\n\n\n2）创建多分区的主题./kafka-topics.sh --create --zookeeper 172.16.253.35:2181 --replication-factor 1 --partitions 2 --topic test1\n\n\n\n3.kafka中消息日志文件中保存的内容\n00000.log： 这个文件中保存的就是消息\n\n__consumer_offsets-49:\nkafka内部自己创建了__consumer_offsets主题包含了50个分区。这个主题用来存放消费者消费某个主题的偏移量。因为每个消费者都会自己维护着消费的主题的偏移量，也就是说每个消费者会把消费的主题的偏移量自主上报给kafka中的默认主题：consumer_offsets。因此kafka为了提升这个主题的并发性，默认设置了50个分区。\n\n提交到哪个分区：通过hash函数：hash(consumerGroupId) % __consumer_offsets主题的分区数\n\n提交到该主题中的内容是：key是consumerGroupId+topic+分区号，value就是当前offset的值\n\n\n\n文件中保存的消息，默认保存7天。七天到后消息会被删除。\n\n\n五、Kafka集群操作1.搭建kafka集群（三个broker）\n创建三个server.properties文件\n\n# 0 1 2\nbroker.id=2\n// 9092 9093 9094\nlisteners=PLAINTEXT://192.168.65.60:9094\n//kafka-logs kafka-logs-1 kafka-logs-2\nlog.dir=/usr/local/data/kafka-logs-2\n\n\n通过命令来启动三台broker\n\n./kafka-server-start.sh -daemon ../config/server.properties\n./kafka-server-start.sh -daemon ../config/server1.properties\n./kafka-server-start.sh -daemon ../config/server2.properties\n\n\n校验是否启动成功\n\n进入到zk中查看&#x2F;brokers&#x2F;ids中过是否有三个znode（0，1，2）\n2.副本的概念在创建主题时，除了指明了主题的分区数以外，还指明了副本数，那么副本是一个什么概念呢？\n./kafka-topics.sh --create --zookeeper 172.16.253.35:2181 --replication-factor 3 --partitions 2 --topic my-replicated-topic\n\n\n\n副本是为了为主题中的分区创建多个备份，多个副本在kafka集群的多个broker中，会有一个副本作为leader，其他是follower。\n查看topic情况：\n# 查看topic情况\n./kafka-topics.sh --describe --zookeeper 172.16.253.35:2181 --topic my-replicated-topic\n\n\n\n\n\nleader：\n\nkafka的写和读的操作，都发生在leader上。leader负责把数据同步给follower。当leader挂了，经过主从选举，从多个follower中选举产生一个新的leader\n\nfollower\n\n接收leader的同步的数据\n\nisr：\n可以同步和已同步的节点会被存入到isr集合中。这里有一个细节：如果isr中的节点性能较差，会被踢出isr集合。\n\n\n（重点～！）此时，broker、主题、分区、副本 这些概念就全部展现了，大家需要把这些概念梳理清楚：\n集群中有多个broker，创建主题时可以指明主题有多个分区（把消息拆分到不同的分区中存储），可以为分区创建多个副本，不同的副本存放在不同的broker里。\n3.关于集群消费1）向集群发送消息：./kafka-console-consumer.sh --bootstrap-server 172.16.253.38:9092,172.16.253.38:9093,172.16.253.38:9094 --from-beginning --consumer-property group.id=testGroup1 --topic my-replicated-topic\n\n2）从集群中消费消息./kafka-console-producer.sh --broker-list 172.16.253.38:9092,172.16.253.38:9093,172.16.253.38:9094 --topic my-replicated-topic\n\n3）指定消费组来消费消息./kafka-console-consumer.sh --bootstrap-server 172.16.253.38:9092,172.16.253.38:9093,172.16.253.38:9094 --from-beginning --consumer-property group.id=testGroup1 --topic my-replicated-topic\n\n4）分区分消费组的集群消费中的细节\n\n\n一个partition只能被一个消费组中的一个消费者消费，目的是为了保证消费的顺序性，但是多个partion的多个消费者消费的总的顺序性是得不到保证的，那怎么做到消费的总顺序性呢？\n\npartition的数量决定了消费组中消费者的数量，建议同一个消费组中消费者的数量不要超过partition的数量，否则多的消费者消费不到消息\n\n如果消费者挂了，那么会触发rebalance机制（后面介绍），会让其他消费者来消费该分区\n\n\n六、kafka的java客户端-生产者的实现1.生产者的基本实现\n引入依赖\n\n&lt;dependency>\n    &lt;groupId>org.apache.kafka&lt;/groupId>\n    &lt;artifactId>kafka-clients&lt;/artifactId>\n    &lt;version>2.4.1&lt;/version>\n&lt;/dependency>\n\n\n具体实现\n\npackage com.qf.kafka;\n\nimport org.apache.kafka.clients.producer.*;\nimport org.apache.kafka.common.serialization.StringSerializer;\n\nimport java.util.Properties;\nimport java.util.concurrent.ExecutionException;\n\npublic class MySimpleProducer &#123;\n\n  private final static String TOPIC_NAME = \"my-replicated-topic\";\n\n  public static void main(String[] args) throws ExecutionException, InterruptedException &#123;\n\n    //1.设置参数\n    Properties props = new Properties();\n    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"172.16.253.38:9092,172.16.253.38:9093,172.16.253.38:9094\");\n\n    //把发送的key从字符串序列化为字节数组\n    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\n    //把发送消息value从字符串序列化为字节数组\n    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\n\n    //2.创建生产消息的客户端，传入参数\n    Producer&lt;String,String> producer = new KafkaProducer&lt;String, String>(props);\n\n    //3.创建消息\n    //key：作用是决定了往哪个分区上发，value：具体要发送的消息内容\n    ProducerRecord&lt;String,String> producerRecord = new ProducerRecord&lt;>(TOPIC_NAME,\"mykeyvalue\",\"hellokafka\");\n\n    //4.发送消息,得到消息发送的元数据并输出\n    RecordMetadata metadata = producer.send(producerRecord).get();\n    System.out.println(\"同步方式发送消息结果：\" + \"topic-\" + metadata.topic() + \"|partition-\"\n      + metadata.partition() + \"|offset-\" + metadata.offset());\n  &#125;\n&#125;\n\n\n\n\n2.生产者的同步发送消息\n\n如果生产者发送消息没有收到ack，生产者会阻塞，阻塞到3s的时间，如果还没有收到消息，会进行重试。重试的次数3次。\nRecordMetadata metadata = producer.send(producerRecord).get();\nSystem.out.println(\"同步方式发送消息结果：\" + \"topic-\" + metadata.topic() + \"|partition-\"\n  + metadata.partition() + \"|offset-\" + metadata.offset());\n\n\n\n3.生产者的异步发送消息\n\n异步发送，生产者发送完消息后就可以执行之后的业务，broker在收到消息后异步调用生产者提供的callback回调方法。\n//5.异步发送消息\n    producer.send(producerRecord, new Callback() &#123;\n      public void onCompletion(RecordMetadata metadata, Exception exception) &#123;\n        if (exception != null) &#123;\n          System.err.println(\"发送消息失败：\" + exception.getStackTrace());\n\n        &#125;\n        if (metadata != null) &#123;\n          System.out.println(\"异步方式发送消息结果：\" + \"topic-\" + metadata.topic() + \"|partition-\"\n            + metadata.partition() + \"|offset-\" + metadata.offset());\n        &#125;\n      &#125;\n    &#125;);\n\n\n\n4.生产者中的ack的配置在同步发送的前提下，生产者在获得集群返回的ack之前会一直阻塞。那么集群什么时候返回ack呢？此时ack有3个配置：\n\nack &#x3D; 0   kafka-cluster不需要任何的broker收到消息，就立即返回ack给生产者，最容易丢消息的，效率是最高的\n\nack&#x3D;1（默认）： 多副本之间的leader已经收到消息，并把消息写入到本地的log中，才会返回ack给生产者，性能和安全性是最均衡的\n\nack&#x3D;-1&#x2F;all。里面有默认的配置min.insync.replicas&#x3D;2(默认为1，推荐配置大于等于2)，此时就需要leader和一个follower同步完后，才会返回ack给生产者（此时集群中有2个broker已完成数据的接收），这种方式最安全，但性能最差。\n\n\n\n\n下面是关于ack和重试（如果没有收到ack，就开启重试）的配置\nprops.put(ProducerConfig.ACKS_CONFIG, \"1\");\n   \t/*\n      发送失败会重试，默认重试间隔100ms，重试能保证消息发送的可靠性，但是也可能造成消息重复发送，比如网络抖动，所以需要在\n      接收者那边做好消息接收的幂等性处理\n      */\n      props.put(ProducerConfig.RETRIES_CONFIG, 3);\n      //重试间隔设置\n      props.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, 300);\n\n\n\n5.关于消息发送的缓冲区\n\n\nkafka默认会创建一个消息缓冲区，用来存放要发送的消息，缓冲区是32m\n\nprops.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432);\n\n\nkafka本地线程会去缓冲区中一次拉16k的数据，发送到broker\n\nprops.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);\n\n\n如果线程拉不到16k的数据，间隔10ms也会将已拉到的数据发到broker\n\nprops.put(ProducerConfig.LINGER_MS_CONFIG, 10);\n\n七、Java客户端消费者的实现细节1.消费者的基本实现package com.qf.kafka;\n\nimport org.apache.kafka.clients.consumer.ConsumerConfig;\nimport org.apache.kafka.clients.consumer.ConsumerRecord;\nimport org.apache.kafka.clients.consumer.ConsumerRecords;\nimport org.apache.kafka.clients.consumer.KafkaConsumer;\nimport org.apache.kafka.common.serialization.StringDeserializer;\n\nimport java.time.Duration;\nimport java.util.Arrays;\nimport java.util.Properties;\n\npublic class MySimpleConsumer &#123;\n\n\n  private final static String TOPIC_NAME = \"my-replicated-topic\";\n  private final static String CONSUMER_GROUP_NAME = \"testGroup\";\n\n  public static void main(String[] args) &#123;\n    Properties props = new Properties();\n    props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, \"172.16.253.38:9092,172.16.253.38:9093,172.16.253.38:9094\");\n    // 消费分组名\n    props.put(ConsumerConfig.GROUP_ID_CONFIG, CONSUMER_GROUP_NAME);\n    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n    //1.创建一个消费者的客户端\n    KafkaConsumer&lt;String, String> consumer = new KafkaConsumer&lt;String, String>(props);\n    //2. 消费者订阅主题列表\n    consumer.subscribe(Arrays.asList(TOPIC_NAME));\n\n    while (true) &#123;\n      /*\n       * 3.poll() API 是拉取消息的长轮询\n       */\n      ConsumerRecords&lt;String, String> records = consumer.poll(Duration.ofMillis(1000));\n      for (ConsumerRecord&lt;String, String> record : records) &#123;\n        //4.打印消息\n        System.out.printf(\"收到消息：partition = %d,offset = %d, key = %s, value = %s%n\", record.partition(),\n          record.offset(), record.key(), record.value());\n      &#125;\n    &#125;\n  &#125;\n\n&#125;\n\n\n2.关于消费者自动提交和手动提交offset1）提交的内容消费者无论是自动提交还是手动提交，都需要把所属的消费组+消费的某个主题+消费的某个分区及消费的偏移量，这样的信息提交到集群的_consumer_offsets主题里面。\n2）自动提交消费者poll消息下来以后就会自动提交offset\n// 是否自动提交offset，默认就是true\nprops.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"true\");\n// 自动提交offset的间隔时间\nprops.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, \"1000\");\n\n注意：自动提交会丢消息。因为消费者在消费前提交offset，有可能提交完后还没消费时消费者挂了。\n3）手动提交需要把自动提交的配置改成false\nprops.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"false\");\n\n手动提交又分成了两种：\n\n手动同步提交\n在消费完消息后调用同步提交的方法，当集群返回ack前一直阻塞，返回ack后表示提交成功，执行之后的逻辑\nwhile (true) &#123;\n     /*\n      * poll() API 是拉取消息的长轮询\n      */\n     ConsumerRecords&lt;String, String> records = consumer.poll(Duration.ofMillis(1000));\n     for (ConsumerRecord&lt;String, String> record : records) &#123;\n       System.out.printf(\"收到消息：partition = %d,offset = %d, key = %s, value = %s%n\", record.partition(),\n         record.offset(), record.key(), record.value());\n     &#125;\n     //所有的消息已消费完\n     if (records.count() > 0) &#123;//有消息\n       // 手动同步提交offset，当前线程会阻塞直到offset提交成功\n       // 一般使用同步提交，因为提交之后一般也没有什么逻辑代码了\n       consumer.commitSync();//=======阻塞=== 提交成功\n     &#125;\n   &#125;\n &#125;\n\n\n\n手动异步提交\n在消息消费完后提交，不需要等到集群ack，直接执行之后的逻辑，可以设置一个回调方法，供集群调用\nwhile (true) &#123;\n     /*\n      * poll() API 是拉取消息的长轮询\n      */\n     ConsumerRecords&lt;String, String> records = consumer.poll(Duration.ofMillis(1000));\n     for (ConsumerRecord&lt;String, String> record : records) &#123;\n       System.out.printf(\"收到消息：partition = %d,offset = %d, key = %s, value = %s%n\", record.partition(),\n         record.offset(), record.key(), record.value());\n     &#125;\n     //所有的消息已消费完\n     if (records.count() > 0) &#123;\n  \n       // 手动异步提交offset，当前线程提交offset不会阻塞，可以继续处理后面的程序逻辑\n       consumer.commitAsync(new OffsetCommitCallback() &#123;\n         @Override\n         public void onComplete(Map&lt;TopicPartition, OffsetAndMetadata> offsets, Exception exception) &#123;\n           if (exception != null) &#123;\n             System.err.println(\"Commit failed for \" + offsets);\n             System.err.println(\"Commit failed exception: \" + exception.getStackTrace());\n           &#125;\n         &#125;\n       &#125;);\n  \n     &#125;\n   &#125;\n &#125;\n\n3.长轮询poll消息\n默认情况下，消费者一次会poll500条消息。\n\n//一次poll最大拉取消息的条数，可以根据消费速度的快慢来设置\nprops.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);\n\n\n代码中设置了长轮询的时间是1000毫秒\n\nwhile (true) &#123;\n     /*\n      * poll() API 是拉取消息的长轮询\n      */\n     ConsumerRecords&lt;String, String> records = consumer.poll(Duration.ofMillis(1000));\n     for (ConsumerRecord&lt;String, String> record : records) &#123;\n       System.out.printf(\"收到消息：partition = %d,offset = %d, key = %s, value = %s%n\", record.partition(),\n         record.offset(), record.key(), record.value());\n     &#125;\n\n意味着：\n\n\n如果一次poll到500条，就直接执行for循环\n如果这一次没有poll到500条。且时间在1秒内，那么长轮询继续poll，要么到500条，要么到1s\n如果多次poll都没达到500条，且1秒时间到了，那么直接执行for循环\n\n\n如果两次poll的间隔超过30s，集群会认为该消费者的消费能力过弱，该消费者被踢出消费组，触发rebalance机制，rebalance机制会造成性能开销。可以通过设置这个参数，让一次poll的消息条数少一点\n\n//一次poll最大拉取消息的条数，可以根据消费速度的快慢来设置\n  props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);\n  //如果两次poll的时间如果超出了30s的时间间隔，kafka会认为其消费能力过弱，将其踢出消费组。将分区分配给其他消费者。-rebalance\n  props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 30 * 1000);\n\n\n\n4.消费者的健康状态检查消费者每隔1s向kafka集群发送心跳，集群发现如果有超过10s没有续约的消费者，将被踢出消费组，触发该消费组的rebalance机制，将该分区交给消费组里的其他消费者进行消费。\n//consumer给broker发送心跳的间隔时间\n    props.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 1000);\n    //kafka如果超过10秒没有收到消费者的心跳，则会把消费者踢出消费组，进行rebalance，把分区分配给其他消费者。\n    props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10 * 1000);\n\n\n\n5.指定分区和偏移量、时间消费\n指定分区消费\n\nconsumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));\n\n\n从头消费\n\nconsumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));\nconsumer.seekToBeginning(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));\n\n\n指定offset消费\n\nconsumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));\nconsumer.seek(new TopicPartition(TOPIC_NAME, 0), 10);\n\n\n指定时间消费\n\n根据时间，去所有的partition中确定该时间对应的offset，然后去所有的partition中找到该offset之后的消息开始消费。\nList&lt;PartitionInfo> topicPartitions = consumer.partitionsFor(TOPIC_NAME);\n        //从1小时前开始消费\n        long fetchDataTime = new Date().getTime() - 1000 * 60 * 60;\n        Map&lt;TopicPartition, Long> map = new HashMap&lt;>();\n        for (PartitionInfo par : topicPartitions) &#123;\n            map.put(new TopicPartition(TOPIC_NAME, par.partition()), fetchDataTime);\n        &#125;\n        Map&lt;TopicPartition, OffsetAndTimestamp> parMap = consumer.offsetsForTimes(map);\n        for (Map.Entry&lt;TopicPartition, OffsetAndTimestamp> entry : parMap.entrySet()) &#123;\n            TopicPartition key = entry.getKey();\n            OffsetAndTimestamp value = entry.getValue();\n            if (key == null || value == null) continue;\n            Long offset = value.offset();\n            System.out.println(\"partition-\" + key.partition() + \"|offset-\" + offset);\n            System.out.println();\n            //根据消费里的timestamp确定offset\n            if (value != null) &#123;\n                consumer.assign(Arrays.asList(key));\n                consumer.seek(key, offset);\n            &#125;\n        &#125;\n\n\n6.新消费组的消费offset规则新消费组中的消费者在启动以后，默认会从当前分区的最后一条消息的offset+1开始消费（消费新消息）。可以通过以下的设置，让新的消费者第一次从头开始消费。之后开始消费新消息（最后消费的位置的偏移量+1）\n\nLatest:默认的，消费新消息\nearliest：第一次从头开始消费。之后开始消费新消息（最后消费的位置的偏移量+1）\n\nprops.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n\n\n\n八、Springboot中使用Kafka1.引入依赖&lt;dependency>\n    &lt;groupId>org.springframework.kafka&lt;/groupId>\n    &lt;artifactId>spring-kafka&lt;/artifactId>\n&lt;/dependency>\n\n2.编写配置文件server:\n  port: 9999\n\nspring:\n  kafka:\n    bootstrap-servers: 192.168.111.129:9092  #,172.16.253.38:9093,172.16.253.38:9094  集群\n    producer: #生产者配置\n      retries: 3 # 设置大于0的值，没有收到ack会重复发送三次\n      batch-size: 16384  #16kb 每次拉取16kb(缓冲区中数据大于16kb)\n      buffer-memory: 33554432 #32mb 消息缓冲区\n      acks: 1 #一个leader拿到消息才返回ack  （0，1，-1三种）\n      # 指定消息key和消息体的编解码方式\n      key-serializer: org.apache.kafka.common.serialization.StringSerializer\n      value-serializer: org.apache.kafka.common.serialization.StringSerializer\n    consumer: #消费者配置\n      group-id: default-group #消费组\n      enable-auto-commit: false  #手动提交\n      auto-offset-reset: earliest #一个新消费组默认从头开始消费\n      # 指定消息key和消息体的编解码方式\n      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer\n      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer\n      max-poll-records: 500 #一次最多拉去500条消息\n    listener:\n      # 当每一条记录被消费者监听器（ListenerConsumer）处理之后提交\n      # RECORD\n      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后提交\n      # BATCH\n      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，距离上次提交时间大于TIME时提交\n      # TIME\n      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，被处理record数量大于等于COUNT时提交\n      # COUNT\n      # TIME |　COUNT　有一个条件满足时提交\n      # COUNT_TIME\n      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后, 手动调用Acknowledgment.acknowledge()后提交\n      # MANUAL\n      # 手动调用Acknowledgment.acknowledge()后立即提交，一般使用这种\n      # MANUAL_IMMEDIATE\n      ack-mode: MANUAL_IMMEDIATE\n#  redis:\n#    host: 172.16.253.21\n\n\n\n3.编写消息生产者package com.qf.kafka.spring.boot.demo.controller;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.kafka.core.KafkaTemplate;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\n@RequestMapping(\"/msg\")\npublic class MyKafkaController &#123;\n\n  private final static String TOPIC_NAME = \"my-replicated-topic\";\n\n  @Autowired\n  private KafkaTemplate&lt;String,String> kafkaTemplate;\n\n  @RequestMapping(\"/send\")\n  public String sendMessage()&#123;\n\n    kafkaTemplate.send(TOPIC_NAME,0,\"key\",\"this is a message!\");\n\n    return \"send success!\";\n\n  &#125;\n\n\n\n\n&#125;\n\n\n\n\n4.编写消费者package com.qf.kafka.spring.boot.demo.consumer;\n\nimport org.apache.kafka.clients.consumer.ConsumerRecord;\nimport org.apache.kafka.clients.consumer.ConsumerRecords;\nimport org.springframework.kafka.annotation.KafkaListener;\nimport org.springframework.kafka.support.Acknowledgment;\nimport org.springframework.stereotype.Component;\n\n@Component\npublic class MyConsumer &#123;\n\n\t@KafkaListener(topics = \"my-replicated-topic\", groupId = \"MyGroup1\")\n    public void listenGroup(ConsumerRecord&lt;String, String> record, Acknowledgment ack) &#123;\n        String value = record.value();\n        System.out.println(value);\n        System.out.println(record);\n        //手动提交offset\n        ack.acknowledge();\n    &#125;\n\n&#125;\n\n\n5.消费者中配置消费主题、分区和偏移量@KafkaListener(groupId = \"testGroup\", topicPartitions = &#123;\n        //主题，分区\n        //可以消费多个主题，分区\n        @TopicPartition(topic = \"topic1\", partitions = &#123;\"0\", \"1\"&#125;),\n        //可以设置偏移量,0号分区正常消费，1号分区从偏移量100开始消费\n        @TopicPartition(topic = \"topic2\", partitions = \"0\", partitionOffsets = @PartitionOffset(partition = \"1\", initialOffset = \"100\"))\n    &#125;, concurrency = \"3\") //concurrency就是同消费组下的消费者个数，就是并发消费数，建议小于等于分区总数\npublic void listenGroupPro(ConsumerRecord&lt;String, String> record, Acknowledgment ack) &#123;\n    String value = record.value();\n    System.out.println(value);\n    System.out.println(record);\n    //手动提交offset\n    ack.acknowledge();\n&#125;\n\n\n\n\n九、kafka集群中的controller、rebalance、HW1.controller\n集群中谁来充当controller\n\n每个broker启动时会向zk创建一个临时序号节点，获得的序号最小的那个broker将会作为集群中的controller，负责这么几件事：\n\n当集群中有一个副本的leader挂掉，需要在集群中选举出一个新的leader，选举的规则是从isr集合中最左边获得。\n当集群中有broker新增或减少，controller会同步信息给其他broker\n当集群中有分区新增或减少，controller会同步信息给其他broker\n\n2.rebalance机制\n前提：消费组中的消费者没有指明分区来消费\n\n触发的条件：当消费组中的消费者和分区的关系发生变化的时候\n\n分区分配的策略：在rebalance之前，分区怎么分配会有这么三种策略\n\nrange：根据公示计算得到每个消费消费哪几个分区：前面的消费者是分区总数&#x2F;消费者数量+1,之后的消费者是分区总数&#x2F;消费者数量\n轮询：大家轮着来\nsticky：粘合策略，如果需要rebalance，会在之前已分配的基础上调整，不会改变之前的分配情况。如果这个策略没有开，那么就要进行全部的重新分配。建议开启。\n\n\n\n3.HW和LEOLEO是某个副本最后消息的消息位置（log-end-offset）\nHW是已完成同步的位置。消息在写入broker时，且每个broker完成这条消息的同步后，hw才会变化。在这之前消费者是消费不到这条消息的。在同步完成之后，HW更新之后，消费者才能消费到这条消息，这样的目的是防止消息的丢失。\n\n十、Kafka中的优化问题1.如何防止消息丢失\n生产者：1）使用同步发送 2）把ack设成1或者all，并且设置同步的分区数&gt;&#x3D;2\n消费者：把自动提交改成手动提交\n\n2.如何防止重复消费在防止消息丢失的方案中，如果生产者发送完消息后，因为网络抖动，没有收到ack，但实际上broker已经收到了。\n此时生产者会进行重试，于是broker就会收到多条相同的消息，而造成消费者的重复消费。\n怎么解决：\n\n生产者关闭重试：会造成丢消息（不建议）\n\n消费者解决非幂等性消费问题：\n所谓的幂等性：多次访问的结果是一样的。对于rest的请求（get（幂等）、post（非幂等）、put（幂等）、delete（幂等））\n解决方案：\n\n在数据库中创建联合主键，防止相同的主键 创建出多条记录\n使用分布式锁，以业务id为锁。保证只有一条记录能够创建成功\n\n\n\n\n3.如何做到消息的顺序消费\n生产者：保证消息按顺序消费，且消息不丢失——使用同步的发送，ack设置成非0的值。\n消费者：主题只能设置一个分区，消费组中只能有一个消费者\n\nkafka的顺序消费使用场景不多，因为牺牲掉了性能，但是比如rocketmq在这一块有专门的功能已设计好。\n4.如何解决消息积压问题\n1）消息积压问题的出现消息的消费者的消费速度远赶不上生产者的生产消息的速度，导致kafka中有大量的数据没有被消费。随着没有被消费的数据堆积越多，消费者寻址的性能会越来越差，最后导致整个kafka对外提供的服务的性能很差，从而造成其他服务也访问速度变慢，造成服务雪崩。\n2）消息积压的解决方案\n在这个消费者中，使用多线程，充分利用机器的性能进行消费消息。\n通过业务的架构设计，提升业务层面消费的性能。\n创建多个消费组，多个消费者，部署到其他机器上，一起消费，提高消费者的消费速度\n创建一个消费者，该消费者在kafka另建一个主题，配上多个分区，多个分区再配上多个消费者。该消费者将poll下来的消息，不进行消费，直接转发到新建的主题上。此时，新的主题的多个分区的多个消费者就开始一起消费了。——不常用\n\n\n5.实现延时队列的效果1）应用场景订单创建后，超过30分钟没有支付，则需要取消订单，这种场景可以通过延时队列来实现\n2）具体方案\n\nkafka中创建创建相应的主题\n消费者消费该主题的消息（轮询）\n消费者消费消息时判断消息的创建时间和当前时间是否超过30分钟（前提是订单没支付）\n如果是：去数据库中修改订单状态为已取消\n如果否：记录当前消息的offset，并不再继续消费之后的消息。等待1分钟后，再次向kafka拉取该offset及之后的消息，继续进行判断，以此反复。\n\n\n\n\n十一、Kafka-eagle监控平台1.搭建\n去kafka-eagle官网下载压缩包\n\nhttp://download.kafka-eagle.org/\n\n分配一台虚拟机\n虚拟机中安装jdk\n解压缩kafka-eagle的压缩包\n给kafka-eagle配置环境变量\n\nexport KE_HOME=/usr/local/kafka-eagle\nexport PATH=$PATH:$KE_HOME/bin\n\n\n需要修改kafka-eagle内部的配置文件：vim system-config.properties \n修改里面的zk的地址和mysql的地址\n\n进入到bin中，通过命令来启动\n\n\n./ke.sh start\n\n2.平台的使用\n","slug":"kafka","date":"2022-07-13T08:31:01.630Z","categories_index":"Kafka","tags_index":"Kafka,消息中间件","author_index":"小李不在_"},{"id":"090d1240eb81aec2da7fdd1a11b68406","title":"Stream流","content":"JDK8 Stream概念\n\n\n\n\n\n\n\n\nStream是Java8 API的新成员，它允许以声明性方式处理数据集合 。\n特点\n\n\n\n\n\n\n\n\n（1）代码简洁：函数式编程写出的代码简洁且意图明确，使用stream接口让你从此告别for循环。 \n（2）多核友好：Java函数式编程使得编写并行程序从未如此简单，你需要的全部就是调用一下方法。 \n流程1）第一步：把集合转换为流stream\n2）第二步：操作stream流\nstream流在管道中经过中间操作（intermediate operation）的处理，最后由最终操作(terminal operation)得到前面处理的结果\n\n操作符\n\n\n\n\n\n\n\n\n两种：中间操作符、终止操作符\n中间操作符\n\n\n流方法\n含义\n示例\n\n\n\nfilter\n用于通过设置的条件过滤出元素\nList strings &#x3D; Arrays.asList(“abc”, “”, “bc”, “efg”, “abcd”,””, “jkl”);List filtered &#x3D; strings.stream().filter(string -&gt; !string.isEmpty()).collect(Collectors.toList());\n\n\ndistinct\n返回一个元素各异（根据流所生成元素的hashCode和equals方法实现）的流。\nList numbers &#x3D; Arrays.asList(1, 2, 1, 3, 3, 2, 4);numbers.stream().filter(i -&gt; i % 2 &#x3D;&#x3D; 0).distinct().forEach(System.out::println);\n\n\nlimit\n会返回一个不超过给定长度的流。\nList strings &#x3D; Arrays.asList(“abc”, “abc”, “bc”, “efg”, “abcd”,”jkl”, “jkl”);List limited &#x3D; strings.stream().limit(3).collect(Collectors.toList());\n\n\nskip\n返回一个扔掉了前n个元素的流。\nList strings &#x3D; Arrays.asList(“abc”, “abc”, “bc”, “efg”, “abcd”,”jkl”, “jkl”);List skiped &#x3D; strings.stream().skip(3).collect(Collectors.toList());\n\n\nmap\n接受一个函数作为参数。这个函数会被应用到每个元素上，并将其映射成一个新的元素（使用映射一词，是因为它和转换类似，但其中的细微差别在于它是“创建一个新版本”而不是去“修改”）。\nList strings &#x3D; Arrays.asList(“abc”, “abc”, “bc”, “efg”, “abcd”,”jkl”, “jkl”);List mapped &#x3D; strings.stream().map(str-&gt;str+”-itcast”).collect(Collectors.toList());\n\n\nflatMap\n使用flatMap方法的效果是，各个数组并不是分别映射成一个流，而是映射成流的内容。所有使用map(Arrays::stream)时生成的单个流都被合并起来，即扁平化为一个流。\nList strings &#x3D; Arrays.asList(“abc”, “abc”, “bc”, “efg”, “abcd”,”jkl”, “jkl”);Stream flatMap &#x3D; strings.stream().flatMap(Java8StreamTest::getCharacterByString);\n\n\nsorted\n返回排序后的流\nList strings1 &#x3D; Arrays.asList(“abc”, “abd”, “aba”, “efg”, “abcd”,”jkl”, “jkl”);List sorted1 &#x3D; strings1.stream().sorted().collect(Collectors.toList());\n\n\n\n\n\n\n\n\n\n\n\n示例代码：\n1）filter\n/**\n * 功能描述:根据条件过滤集合数据\n * @return : void\n */\n@Test\npublic void filter()&#123;\n    List&lt;String> strings = Arrays.asList(\"abc\", \"\", \"bc\", \"efg\", \"abcd\",\"\", \"jkl\");\n    List&lt;String> filtered = strings.stream().filter(string -> !string.isEmpty()).collect(Collectors.toList());\n    out.println(filtered);\n&#125;\n\n2）distinct\n/**\n * 功能描述:去除集合中重复数据\n * @return : void\n */\n@Test\npublic void distinct()&#123;\n    List&lt;String> strings = Arrays.asList(\"abc\", \"abc\", \"bc\", \"efg\", \"abcd\",\"jkl\", \"jkl\");\n    List&lt;String> distincted = strings.stream().distinct().collect(Collectors.toList());\n    out.println(distincted);\n&#125;\n\n3）limit\n/**\n * 功能描述:指定获取集合前x条数据，重新构造一个新的集合\n * @return : void\n */\n@Test\npublic void limit()&#123;\n    List&lt;String> strings = Arrays.asList(\"abc\", \"abc\", \"bc\", \"efg\", \"abcd\",\"jkl\", \"jkl\");\n    List&lt;String> limited = strings.stream().limit(3).collect(Collectors.toList());\n    out.println(limited);\n&#125;\n\n4）skip\n/**\n * 功能描述:排除集合前x条数据，把后面的数据重新构造一个新的集合\n * @return : void\n */\n@Test\n    public void skip()&#123;\n    List&lt;String> strings = Arrays.asList(\"abc\", \"abc\", \"bc\", \"efg\", \"abcd\",\"jkl\", \"jkl\");\n    List&lt;String> skiped = strings.stream().skip(3).collect(Collectors.toList());\n    out.println(skiped);\n&#125;\n\n5）map\n/**\n * 功能描述:对集合中所有元素统一处理\n * @return : void\n */\n@Test\npublic void map()&#123;\n    List&lt;String> strings = Arrays.asList(\"abc\", \"abc\", \"bc\", \"efg\", \"abcd\",\"jkl\", \"jkl\");\n    List&lt;String> mapped = strings.stream().map(str->str+\"-itcast\").collect(Collectors.toList());\n    out.println(mapped);\n&#125;\n\n6）flatMap\n/**\n * 功能描述:对集合中所有元素统一处理\n * @return : void\n */\n@Test\npublic void flatMap()&#123;\n    List&lt;String> strings = Arrays.asList(\"abc\", \"abc\", \"bc\", \"efg\", \"abcd\",\"jkl\", \"jkl\");\n    Stream&lt;String> stringStream = strings.stream().map(x -> x);\n    Stream&lt;String> stringStream1 = strings.stream().flatMap(x -> Arrays.asList(x.split(\" \")).stream());\n&#125;\n\n7）sorted\n/**\n * 功能描述 : 对集合进行排序\n * @return : void\n */\n@Test\npublic void sorted()&#123;\n    List&lt;String> strings1 = Arrays.asList(\"abc\", \"abd\", \"aba\", \"efg\", \"abcd\",\"jkl\", \"jkl\");\n    List&lt;String> strings2 = Arrays.asList(\"张三\", \"李四\", \"王五\", \"赵柳\", \"张哥\",\"李哥\", \"王哥\");\n    List&lt;Integer> strings3 = Arrays.asList(10, 2, 30, 22, 1,0, -9);\n    List&lt;String> sorted1 = strings1.stream().sorted().collect(Collectors.toList());\n    List&lt;String> sorted2 = strings2.stream().sorted(Collections.reverseOrder(Collator.getInstance(Locale.CHINA))).collect(Collectors.toList());\n    List&lt;Integer> sorted3 = strings3.stream().sorted().collect(Collectors.toList());\n    out.println(sorted1);\n    out.println(sorted2);\n    out.println(sorted3);\n&#125;\n\n Map、flatMap区别\nmap：对流中每一个元素进行处理\nflatMap：流扁平化，让你把一个流中的“每个值”都换成另一个流，然后把所有的流连接起来成为一个流 \n总结：map是对一级元素进行操作，flatmap是对二级元素操作。\n\n本质区别：map返回一个值；flatmap返回一个流，多个值。\n应用场景：map对集合中每个元素加工,返回加工后结果；flatmap对集合中每个元素加工后，做扁平化处理后（拆分层级，放到同一层）然后返回\n\n/**\n * 方法一\n * 功能描述:  通过使用map、flatMap把字符串转换为字符输出对比区别\n * @return : void\n */\n@Test\npublic void flatMap2Map()&#123;\n    List&lt;String> strings = Arrays.asList(\"abc\", \"abc\", \"bc\", \"efg\", \"abcd\",\"jkl\", \"jkl\");\n    final Stream&lt;Character> flatMap = strings.stream().flatMap(Java8StreamTest::getCharacterByString);\n    flatMap.forEach(System.out::println);\n    //----------------------------------------------\n    final Stream&lt;Stream&lt;Character>> mapStream = strings.stream().map(Java8StreamTest::getCharacterByString);\n    //mapStream.forEach(System.out::println);\n    out.println(\"------------------------------------------------\");\n    mapStream.forEach(stream-> &#123;stream.forEach(character->&#123;System.out.println(character);&#125;);&#125;);\n\n&#125;\n\n\n\n\n\n\n\n\n\n\n公共方法（字符串转换为字符流）\n/**\n* 功能描述:字符串转换为字符流\n* @param str\n* @return : java.util.stream.Stream&lt;java.lang.Character>\n*/\npublic static Stream&lt;Character> getCharacterByString(String str) &#123;\n    List&lt;Character> characterList = new ArrayList&lt;>();\n    for (Character character : str.toCharArray()) &#123;\n    \tcharacterList.add(character);\n    &#125;\n    return characterList.stream();\n&#125;\n\n终止操作符\n\n\n流方法\n含义\n示例\n\n\n\nanyMatch\n检查是否至少匹配一个元素，返回boolean。\nList strings &#x3D; Arrays.asList(“abc”, “abd”, “aba”, “efg”, “abcd”,”jkl”, “jkl”);boolean b &#x3D; strings.stream().anyMatch(s -&gt; s &#x3D;&#x3D; “abc”);\n\n\nallMatch\n检查是否匹配所有元素，返回boolean。\nList strings &#x3D; Arrays.asList(“abc”, “abd”, “aba”, “efg”, “abcd”,”jkl”, “jkl”);boolean b &#x3D; strings.stream().allMatch(s -&gt; s &#x3D;&#x3D; “abc”);\n\n\nnoneMatch\n检查是否没有匹配所有元素，返回boolean。\nList strings &#x3D; Arrays.asList(“abc”, “abd”, “aba”, “efg”, “abcd”,”jkl”, “jkl”);boolean b &#x3D; strings.stream().noneMatch(s -&gt; s &#x3D;&#x3D; “abc”);\n\n\nfindAny\n将返回当前流中的任意元素。\nList strings &#x3D; Arrays.asList(“cv”, “abd”, “aba”, “efg”, “abcd”,”jkl”, “jkl”);Optional any &#x3D; strings.stream().findAny();\n\n\nfindFirst\n返回第一个元素\nList strings &#x3D; Arrays.asList(“cv”, “abd”, “aba”, “efg”, “abcd”,”jkl”, “jkl”);Optional first &#x3D; strings.stream().findFirst();\n\n\nforEach\n遍历流\nList strings &#x3D; Arrays.asList(“cv”, “abd”, “aba”, “efg”, “abcd”,”jkl”, “jkl”);strings.stream().forEach(s -&gt; out.println(s));\n\n\ncollect\n收集器，将流转换为其他形式。\nList strings &#x3D; Arrays.asList(“cv”, “abd”, “aba”, “efg”, “abcd”,”jkl”, “jkl”);Set set &#x3D; strings.stream().collect(Collectors.toSet());List list &#x3D; strings.stream().collect(Collectors.toList());Map&lt;String, String&gt; map &#x3D; strings.stream().collect(Collectors.toMap(v -&gt;v.concat(“_name”), v1 -&gt; v1, (v1, v2) -&gt; v1));\n\n\nreduce\n可以将流中元素反复结合起来，得到一个值。\nList strings &#x3D; Arrays.asList(“cv”, “abd”, “aba”, “efg”, “abcd”,”jkl”, “jkl”);Optional reduce &#x3D; strings.stream().reduce((acc,item) -&gt; {return acc+item;});if(reduce.isPresent())out.println(reduce.get());\n\n\ncount\n返回流中元素总数。\nList strings &#x3D; Arrays.asList(“cv”, “abd”, “aba”, “efg”, “abcd”,”jkl”, “jkl”);long count &#x3D; strings.stream().count();\n\n\n\n\n\n\n\n\n\n\n\n示例代码\n1）anyMatch\n/**\n * 功能描述 : 判断集合中是否至少存在一个元素满足条件\n * @return : void\n */\n@Test\npublic void anyMatch()&#123;\n    List&lt;String> strings = Arrays.asList(\"abc\", \"abd\", \"aba\", \"efg\", \"abcd\",\"jkl\", \"jkl\");\n    boolean b = strings.stream().anyMatch(s -> s == \"abc\");\n    out.println(b);\n&#125;\n\n2）allMatch\n/**\n * 功能描述 : 判断集合中是否所有元素都满足条件\n * @return : void\n */\n@Test\npublic void allMatch()&#123;\n    List&lt;String> strings = Arrays.asList(\"abc\", \"abd\", \"aba\", \"efg\", \"abcd\",\"jkl\", \"jkl\");\n    boolean b = strings.stream().allMatch(s -> s == \"abc\");\n    out.println(b);\n&#125;\n\n3）noneMatch\n/**\n * 功能描述 : 判断集合中是否所有元素都不满足条件\n * @return : void\n */\n@Test\npublic void noneMatch()&#123;\n    List&lt;String> strings = Arrays.asList(\"abc\", \"abd\", \"aba\", \"efg\", \"abcd\",\"jkl\", \"jkl\");\n    boolean b = strings.stream().noneMatch(s -> s == \"abc\");\n    out.println(b);\n&#125;\n\n4）findAny\n/**\n * 功能描述 : 返回当前流中任意元素\n * @return : void\n */\n@Test\npublic void findAny()&#123;\n    List&lt;String> strings = Arrays.asList(\"cv\", \"abd\", \"aba\", \"efg\", \"abcd\",\"jkl\", \"jkl\");\n    Optional&lt;String> any = strings.stream().findAny();\n    if(any.isPresent()) out.println(any.get());\n&#125;\n\n5）findFirst\n/**\n * 功能描述 : 返回当前流中第一个元素\n * @return : void\n */\n@Test\npublic void findFirst()&#123;\n    List&lt;String> strings = Arrays.asList(\"cv\", \"abd\", \"aba\", \"efg\", \"abcd\",\"jkl\", \"jkl\");\n    Optional&lt;String> first = strings.stream().findFirst();\n    if(first.isPresent()) out.println(first.get());\n&#125;\n\n6）forEach java \n/**\n * 功能描述 : 遍历流\n * @return : void\n */\n@Test\npublic void foreach()&#123;\n    List&lt;String> strings = Arrays.asList(\"cv\", \"abd\", \"aba\", \"efg\", \"abcd\",\"jkl\", \"jkl\");\n    strings.stream().forEach(s -> out.println(s));\n&#125;\n\n7）collect\n/**\n * 功能描述 : 流转换为其他形式\n * @return : void\n */\n@Test\npublic void collect()&#123;\n    List&lt;String> strings = Arrays.asList(\"cv\", \"abd\", \"aba\", \"efg\", \"abcd\",\"jkl\", \"jkl\");\n    Set&lt;String> set = strings.stream().collect(Collectors.toSet());\n    List&lt;String> list = strings.stream().collect(Collectors.toList());\n    Map&lt;String, String> map = strings.stream().collect(Collectors.toMap(v ->v.concat(\"_name\"), v1 -> v1, (v1, v2) -> v1));\n    out.println(set);\n    out.println(list);\n    out.println(map);\n&#125;\n\n8）reduce\n/**\n * 功能描述 : 将流中元素反复结合起来，得到一个值\n * @return : void\n */\n@Test\npublic void reduce()&#123;\n    List&lt;String> strings = Arrays.asList(\"cv\", \"abd\", \"aba\", \"efg\", \"abcd\",\"jkl\", \"jkl\");\n    //reduce方法一\n    Optional&lt;String> reduce1 = strings.stream().reduce((acc,item) -> &#123;return acc+item;&#125;);\n    //reduce方法二\n    String reduce2 = strings.stream().reduce(\"itcast\", (acc, item) -> &#123;\n    \treturn acc + item;\n    &#125;);\n    //reduce方法三\n    ArrayList&lt;String> reduce3 = strings.stream().reduce(\n        new ArrayList&lt;String>(),\n   \t\tnew BiFunction&lt;ArrayList&lt;String>, String, ArrayList&lt;String>>() &#123;\n    \t\t@Override\n    \t\tpublic ArrayList&lt;String> apply(ArrayList&lt;String> acc, String item) &#123;\n    \t\t\tacc.add(item);\n    \t\t\treturn acc;\n    \t\t&#125;\n    \t&#125;, \n        new BinaryOperator&lt;ArrayList&lt;String>>() &#123;\n   \t\t\t@Override\n    \t\tpublic ArrayList&lt;String> apply(ArrayList&lt;String> acc, ArrayList&lt;String> item) &#123;\n    \t\treturn acc;\n    \t\t&#125;\n    \t&#125;\n    );\n    if(reduce1.isPresent())out.println(reduce1.get());\n    out.println(reduce2);\n    out.println(reduce3);\n&#125;\n\n9）count\n/**\n* 功能描述 : 返回流中元素总数\n* @return : void\n*/\n@Test\npublic void count()&#123;\n    List&lt;String> strings = Arrays.asList(\"cv\", \"abd\", \"aba\", \"efg\", \"abcd\",\"jkl\", \"jkl\");\n    long count = strings.stream().count();\n    out.println(count);\n&#125;\n注意：文章中因排序部分用到外部比较器，需要导入外部jar包\n&lt;!--apache集合操作工具包-->\n&lt;dependency>\n    &lt;groupId>org.apache.commons&lt;/groupId>\n    &lt;artifactId>commons-collections4&lt;/artifactId>\n    &lt;version>4.4&lt;/version>\n&lt;/dependency>\n\n","slug":"Java8 Stream详解","date":"2022-07-09T07:49:18.688Z","categories_index":"java","tags_index":"java,Stream","author_index":"小李不在_"},{"id":"3244bafd4b77bc1eda4a2f2a047e0e05","title":"MybatisPlus","content":"一、MyBatis-Plus1.简介MyBatis-Plus (opens new window)（简称 MP）是一个 MyBatis (opens new window)的增强工具，在 MyBatis 的基础上只做增强不做改变，为简化开发、提高效率而生。\n\n\n\n\n\n\n\n\n\n我们的愿景是成为 MyBatis 最好的搭档，就像 魂斗罗 中的 1P、2P，基友搭配，效率翻倍。\n\n2.特性\n无侵入：只做增强不做改变，引入它不会对现有工程产生影响，如丝般顺滑\n损耗小：启动即会自动注入基本 CURD，性能基本无损耗，直接面向对象操作\n强大的 CRUD 操作：内置通用 Mapper、通用 Service，仅仅通过少量配置即可实现单表大部分 CRUD 操作，更有强大的条件构造器，满足各类使用需求\n支持 Lambda 形式调用：通过 Lambda 表达式，方便的编写各类查询条件，无需再担心字段写错\n支持主键自动生成：支持多达 4 种主键策略（内含分布式唯一 ID 生成器 - Sequence），可自由配置，完美解决主键问题\n支持 ActiveRecord 模式：支持 ActiveRecord 形式调用，实体类只需继承 Model 类即可进行强大的 CRUD 操作\n支持自定义全局通用操作：支持全局通用方法注入（ Write once, use anywhere ）\n内置代码生成器：采用代码或者 Maven 插件可快速生成 Mapper 、 Model 、 Service 、 Controller 层代码，支持模板引擎，更有超多自定义配置等您来使用\n内置分页插件：基于 MyBatis 物理分页，开发者无需关心具体操作，配置好插件之后，写分页等同于普通 List 查询\n分页插件支持多种数据库：支持 MySQL、MariaDB、Oracle、DB2、H2、HSQL、SQLite、Postgre、SQLServer 等多种数据库\n内置性能分析插件：可输出 SQL 语句以及其执行时间，建议开发测试时启用该功能，能快速揪出慢查询\n内置全局拦截插件：提供全表 delete 、 update 操作智能分析阻断，也可自定义拦截规则，预防误操作\n\n3.支持数据库\n\n\n\n\n\n\n\n\n任何能使用 MyBatis 进行 CRUD, 并且支持标准 SQL 的数据库，具体支持情况如下，如果不在下列表查看分页部分教程 PR 您的支持。\n\nMySQL，Oracle，DB2，H2，HSQL，SQLite，PostgreSQL，SQLServer，Phoenix，Gauss ，ClickHouse，Sybase，OceanBase，Firebird，Cubrid，Goldilocks，csiidb\n达梦数据库，虚谷数据库，人大金仓数据库，南大通用(华库)数据库，南大通用数据库，神通数据库，瀚高数据库\n\n4.框架结构\n\n\n\n5.官方地址\n\n\n\n\n\n\n\n\n官方网站：https://baomidou.com/\n官方文档：https://baomidou.com/pages/24112f/\n二、入门案例1.开发环境\nIDE：IDEA 2019.3.5\nJDK：JDK8+\n构建工具：Maven 3.5.4\nMySQL：MySQL 8.0.24\nNavicat：Navicat Premium 15\nSpring Boot：2.6.7\nMyBatis-Plus：3.5.1\n\n2.建库建表\n打开Navicat运行以下SQL脚本进行建库建表\nCREATE DATABASE `mybatis_plus` /*!40100 DEFAULT CHARACTER SET utf8mb4 */; \nuse `mybatis_plus`; \nCREATE TABLE `user` ( \n    `id` bigint(20) NOT NULL COMMENT '主键ID', \n    `name` varchar(30) DEFAULT NULL COMMENT '姓名', \n    `age` int(11) DEFAULT NULL COMMENT '年龄', \n    `email` varchar(50) DEFAULT NULL COMMENT '邮箱', \n    PRIMARY KEY (`id`) \n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n\n插入几条测试数据\nINSERT INTO user (id, name, age, email) VALUES \n(1, 'Jone', 18, 'test1@baomidou.com'), \n(2, 'Jack', 20, 'test2@baomidou.com'), \n(3, 'Tom', 28, 'test3@baomidou.com'), \n(4, 'Sandy', 21, 'test4@baomidou.com'), \n(5, 'Billie', 24, 'test5@baomidou.com');\n\n3.创建工程\n使用Spring Initializer快速初始化一个 Spring Boot 工程\n\n\n\n\n\n\n\n\n引入MyBatis-Plus的依赖\n&lt;dependency>\n    &lt;groupId>com.baomidou&lt;/groupId>\n    &lt;artifactId>mybatis-plus-boot-starter&lt;/artifactId>\n    &lt;version>3.5.1&lt;/version>\n&lt;/dependency>\n\n安装Lombok插件\n\n\n4.配置编码\n配置application.yml文件\n#配置端口\nserver:\n  port: 80\n\nspring:\n  #配置数据源\n  datasource:\n    #配置数据源类型\n    type: com.zaxxer.hikari.HikariDataSource\n    #配置连接数据库的信息\n    driver-class-name: com.mysql.cj.jdbc.Driver\n    url: jdbc:mysql://localhost:3306/mybatis_plus?characterEncoding=utf-8&amp;useSSL=false\n    username: &#123;username&#125;\n    password: &#123;password&#125;\n\n#MyBatis-Plus相关配置\nmybatis-plus:\n  configuration:\n    #配置日志\n    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl\n\n在 Spring Boot 启动类中添加 @MapperScan 注解，扫描 Mapper 文件夹\n@SpringBootApplication\n@MapperScan(\"指定Mapper接口所在的包\")\npublic class MybatisPlusDemoApplication &#123;\n\tpublic static void main(String[] args) &#123;\n\t\tSpringApplication.run(MybatisPlusDemoApplication.class, args);\n\t&#125;\n&#125;\n\n编写实体类 User.java（此处使用了 Lombok 简化代码）\n@Data\npublic class User &#123;\n    private Long id;\n    private String name;\n    private Integer age;\n    private String email;\n&#125;\n\n编写 Mapper 包下的 UserMapper接口\npublic interface UserMapper extends BaseMapper&lt;User> &#123;&#125;\n\n5.测试查询\n编写一个测试类MyBatisPlusTest.java\n@SpringBootTest\npublic class MyBatisPlusTest &#123;\n    @Resource\n    private UserMapper userMapper;\n\n    /**\n     * 测试查询所有数据\n     */\n    @Test\n    void testSelectList()&#123;\n        //通过条件构造器查询一个list集合，若没有条件，则可以设置null为参数\n        List&lt;User> users = userMapper.selectList(null);\n        users.forEach(System.out::println);\n    &#125;\n&#125;\n\n控制台打印查询结果\n\n\n\n三、增删改查1.BaseMapper&lt;T&gt;\n\n\n\n\n\n\n\n\n说明:\n\n通用 CRUD 封装BaseMapper 接口，为 Mybatis-Plus 启动时自动解析实体表关系映射转换为 Mybatis 内部对象注入容器\n泛型 T 为任意实体对象\n参数 Serializable 为任意类型主键 Mybatis-Plus 不推荐使用复合主键约定每一张表都有自己的唯一 id 主键\n对象 Wrapper 为条件构造器\n\nMyBatis-Plus中的基本CRUD在内置的BaseMapper中都已得到了实现，因此我们继承该接口以后可以直接使用。\n本次演示的CRUD操作不包含参数带有条件构造器的方法，关于条件构造器将单独在一个章节进行演示。\n\n\n\n\n\n\n\n\n\n\nBaseMapper中提供的CRUD方法：\n\n增加：Insert\n// 插入一条记录\nint insert(T entity);\n\n删除：Delete\n// 根据 entity 条件，删除记录\nint delete(@Param(Constants.WRAPPER) Wrapper&lt;T> wrapper);\n// 删除（根据ID 批量删除）\nint deleteBatchIds(@Param(Constants.COLLECTION) Collection&lt;? extends Serializable> idList);\n// 根据 ID 删除\nint deleteById(Serializable id);\n// 根据 columnMap 条件，删除记录\nint deleteByMap(@Param(Constants.COLUMN_MAP) Map&lt;String, Object> columnMap);\n\n修改：Update\n// 根据 whereWrapper 条件，更新记录\nint update(@Param(Constants.ENTITY) T updateEntity, @Param(Constants.WRAPPER) Wrapper&lt;T> whereWrapper);\n// 根据 ID 修改\nint updateById(@Param(Constants.ENTITY) T entity);\n\n查询：Selete\n// 根据 ID 查询\nT selectById(Serializable id);\n// 根据 entity 条件，查询一条记录\nT selectOne(@Param(Constants.WRAPPER) Wrapper&lt;T> queryWrapper);\n\n// 查询（根据ID 批量查询）\nList&lt;T> selectBatchIds(@Param(Constants.COLLECTION) Collection&lt;? extends Serializable> idList);\n// 根据 entity 条件，查询全部记录\nList&lt;T> selectList(@Param(Constants.WRAPPER) Wrapper&lt;T> queryWrapper);\n// 查询（根据 columnMap 条件）\nList&lt;T> selectByMap(@Param(Constants.COLUMN_MAP) Map&lt;String, Object> columnMap);\n// 根据 Wrapper 条件，查询全部记录\nList&lt;Map&lt;String, Object>> selectMaps(@Param(Constants.WRAPPER) Wrapper&lt;T> queryWrapper);\n// 根据 Wrapper 条件，查询全部记录。注意： 只返回第一个字段的值\nList&lt;Object> selectObjs(@Param(Constants.WRAPPER) Wrapper&lt;T> queryWrapper);\n\n// 根据 entity 条件，查询全部记录（并翻页）\nIPage&lt;T> selectPage(IPage&lt;T> page, @Param(Constants.WRAPPER) Wrapper&lt;T> queryWrapper);\n// 根据 Wrapper 条件，查询全部记录（并翻页）\nIPage&lt;Map&lt;String, Object>> selectMapsPage(IPage&lt;T> page, @Param(Constants.WRAPPER) Wrapper&lt;T> queryWrapper);\n// 根据 Wrapper 条件，查询总记录数\nInteger selectCount(@Param(Constants.WRAPPER) Wrapper&lt;T> queryWrapper);\n\n2.调用Mapper层实现CRUD2.1\t插入\n\n\n\n\n\n\n\n\n\n最终执行的结果，所获取的id为1527206783590903810\n这是因为MyBatis-Plus在实现插入数据时，会默认基于雪花算法的策略生成id\n/**\n  * 测试插入一条数据\n  * MyBatis-Plus在实现插入数据时，会默认基于雪花算法的策略生成id\n  */\n@Test\npublic void testInsert()&#123;\n    User user = new User();\n    user.setName(\"Vz\");\n    user.setAge(21);\n    user.setEmail(\"vz@oz6.cn\");\n    int result = userMapper.insert(user);\n    System.out.println(result > 0 ? \"添加成功！\" : \"添加失败！\");\n    System.out.println(\"受影响的行数为：\" + result);\n    //1527206783590903810（当前 id 为雪花算法自动生成的id）\n    System.out.println(\"id自动获取\" + user.getId());\n&#125;\n\n\n\n2.2\t删除\na、根据ID删除数据\n\n\n\n\n\n\n\n\n调用方法：int deleteById(Serializable id);\n/**\n  * 测试根据id删除一条数据\n  */\n@Test\npublic void testDeleteById()&#123;\n    int result = userMapper.deleteById(1527206783590903810L);\n    System.out.println(result > 0 ? \"删除成功！\" : \"删除失败！\");\n    System.out.println(\"受影响的行数为：\" + result);\n&#125;\n\n\n\nb、根据ID批量删除数据\n\n\n\n\n\n\n\n\n调用方法：int deleteBatchIds(@Param(Constants.COLLECTION) Collection&lt;? extends Serializable&gt; idList);\n/**\n  * 测试通过id批量删除数据\n  */\n@Test\npublic void testDeleteBatchIds()&#123;\n    List&lt;Long> ids = Arrays.asList(6L,7L,8L);\n    int result = userMapper.deleteBatchIds(ids);\n    System.out.println(result > 0 ? \"删除成功！\" : \"删除失败！\");\n    System.out.println(\"受影响的行数为：\" + result);\n&#125;\n\n\n\nc、根据Map条件删除数据\n\n\n\n\n\n\n\n\n调用方法：int deleteByMap(@Param(Constants.COLUMN_MAP) Map&lt;String, Object&gt; columnMap);\n/**\n   * 测试根据Map集合中所设置的条件删除数据\n   */\n@Test\npublic void testDeleteByMap()&#123;\n    //当前演示为根据name和age删除数据\n    //执行SQL为：DELETE FROM user WHERE name = ? AND age = ?\n    Map&lt;String,Object> map = new HashMap&lt;>();\n    map.put(\"name\",\"Vz\");\n    map.put(\"age\",21);\n    int result = userMapper.deleteByMap(map);\n    System.out.println(result > 0 ? \"删除成功！\" : \"删除失败！\");\n    System.out.println(\"受影响的行数为：\" + result);\n&#125;\n\n\n\n2.3\t修改\n\n\n\n\n\n\n\n\n调用方法：int updateById(@Param(Constants.ENTITY) T entity);\n/**\n  * 测试根据id修改用户信息\n  */\n@Test\npublic void testUpdateById()&#123;\n    //执行SQL为： UPDATE user SET name=?, age=?, email=? WHERE id=?\n    User user = new User();\n    user.setId(6L);\n    user.setName(\"VzUpdate\");\n    user.setAge(18);\n    user.setEmail(\"Vz@sina.com\");\n    int result = userMapper.updateById(user);\n    System.out.println(result > 0 ? \"修改成功！\" : \"修改失败！\");\n    System.out.println(\"受影响的行数为：\" + result);\n&#125;\n\n\n\n2.4\t查询\na、根据ID查询用户信息\n\n\n\n\n\n\n\n\n调用方法：T selectById(Serializable id);\n/**\n  * 测试根据id查询用户数据\n  */\n@Test\npublic void testSelectById()&#123;\n    User user = userMapper.selectById(1L);\n    System.out.println(user);\n&#125;\n\n\n\nb、根据多个ID查询多个用户信息\n\n\n\n\n\n\n\n\n调用方法：List selectBatchIds(@Param(Constants.COLLECTION) Collection&lt;? extends Serializable&gt; idList);\n/**\n  * 根据多个id查询用户数据\n  */\n@Test\npublic void testSelectBatchIds()&#123;\n    //执行SQL为：SELECT id,name,age,email FROM user WHERE id IN ( ? , ? , ? )\n    List&lt;Long> ids = Arrays.asList(1L,2L,3L);\n    List&lt;User> users = userMapper.selectBatchIds(ids);\n    users.forEach(System.out::println);\n&#125;\n\n\n\n\n\nc、根据Map条件查询用户信息\n\n\n\n\n\n\n\n\n调用方法：List selectByMap(@Param(Constants.COLUMN_MAP) Map&lt;String, Object&gt; columnMap);\n/**\n  * 根据Map所设置的条件查询用户\n  */\n@Test\npublic void testSelectByMap()&#123;\n    //执行SQL为：SELECT id,name,age,email FROM user WHERE age = ?\n    Map&lt;String,Object> map = new HashMap&lt;>();\n    map.put(\"age\",18);\n    List&lt;User> users = userMapper.selectByMap(map);\n    users.forEach(System.out::println);\n&#125;\n\n\n\nd、查询所有用户信息\n\n\n\n\n\n\n\n\n调用方法：List selectList(@Param(Constants.WRAPPER) Wrapper queryWrapper);\n/**\n  * 测试查询所有数据\n  */\n@Test\nvoid testSelectList()&#123;\n    List&lt;User> users = userMapper.selectList(null);\n    users.forEach(System.out::println);\n&#125;\n\n\n\n3.通用Service\n\n\n\n\n\n\n\n\n说明:\n\n通用 Service CRUD 封装IService接口，进一步封装 CRUD 采用 get 查询单行 remove 删除 list 查询集合 page 分页 前缀命名方式区分 Mapper 层避免混淆，\n泛型 T 为任意实体对象\n建议如果存在自定义通用 Service 方法的可能，请创建自己的 IBaseService 继承 Mybatis-Plus 提供的基类\n对象 Wrapper 为 条件构造器\n\nMyBatis-Plus中有一个接口 **IService**和其实现类 **ServiceImpl**，封装了常见的业务层逻辑，详情查看源码IService和ServiceImpl\n因此我们在使用的时候仅需在自己定义的**Service接口中继承IService接口，在自己的实现类中实现自己的Service并继承ServiceImpl**即可\n\n\n\n\n\n\n\n\n\n\nIService中的CRUD方法\n\n增加：Save、SaveOrUpdate\n// 插入一条记录（选择字段，策略插入）\nboolean save(T entity);\n// 插入（批量）\nboolean saveBatch(Collection&lt;T> entityList);\n// 插入（批量）\nboolean saveBatch(Collection&lt;T> entityList, int batchSize);\n\n// TableId 注解存在更新记录，否插入一条记录\nboolean saveOrUpdate(T entity);\n// 根据updateWrapper尝试更新，否继续执行saveOrUpdate(T)方法\nboolean saveOrUpdate(T entity, Wrapper&lt;T> updateWrapper);\n// 批量修改插入\nboolean saveOrUpdateBatch(Collection&lt;T> entityList);\n// 批量修改插入\nboolean saveOrUpdateBatch(Collection&lt;T> entityList, int batchSize);\n\n删除：Remove\n// 根据 entity 条件，删除记录\nboolean remove(Wrapper&lt;T> queryWrapper);\n// 根据 ID 删除\nboolean removeById(Serializable id);\n// 根据 columnMap 条件，删除记录\nboolean removeByMap(Map&lt;String, Object> columnMap);\n// 删除（根据ID 批量删除）\nboolean removeByIds(Collection&lt;? extends Serializable> idList);\n\n修改：Update\n// 根据 UpdateWrapper 条件，更新记录 需要设置sqlset\nboolean update(Wrapper&lt;T> updateWrapper);\n// 根据 whereWrapper 条件，更新记录\nboolean update(T updateEntity, Wrapper&lt;T> whereWrapper);\n// 根据 ID 选择修改\nboolean updateById(T entity);\n// 根据ID 批量更新\nboolean updateBatchById(Collection&lt;T> entityList);\n// 根据ID 批量更新\nboolean updateBatchById(Collection&lt;T> entityList, int batchSize);\n\n查询：Get、List、Count\n// 根据 ID 查询\nT getById(Serializable id);\n// 根据 Wrapper，查询一条记录。结果集，如果是多个会抛出异常，随机取一条加上限制条件 wrapper.last(\"LIMIT 1\")\nT getOne(Wrapper&lt;T> queryWrapper);\n// 根据 Wrapper，查询一条记录\nT getOne(Wrapper&lt;T> queryWrapper, boolean throwEx);\n// 根据 Wrapper，查询一条记录\nMap&lt;String, Object> getMap(Wrapper&lt;T> queryWrapper);\n// 根据 Wrapper，查询一条记录\n&lt;V> V getObj(Wrapper&lt;T> queryWrapper, Function&lt;? super Object, V> mapper);\n\n\n// 查询所有\nList&lt;T> list();\n// 查询列表\nList&lt;T> list(Wrapper&lt;T> queryWrapper);\n// 查询（根据ID 批量查询）\nCollection&lt;T> listByIds(Collection&lt;? extends Serializable> idList);\n// 查询（根据 columnMap 条件）\nCollection&lt;T> listByMap(Map&lt;String, Object> columnMap);\n// 查询所有列表\nList&lt;Map&lt;String, Object>> listMaps();\n// 查询列表\nList&lt;Map&lt;String, Object>> listMaps(Wrapper&lt;T> queryWrapper);\n// 查询全部记录\nList&lt;Object> listObjs();\n// 查询全部记录\n&lt;V> List&lt;V> listObjs(Function&lt;? super Object, V> mapper);\n// 根据 Wrapper 条件，查询全部记录\nList&lt;Object> listObjs(Wrapper&lt;T> queryWrapper);\n// 根据 Wrapper 条件，查询全部记录\n&lt;V> List&lt;V> listObjs(Wrapper&lt;T> queryWrapper, Function&lt;? super Object, V> mapper);\n\n// 查询总记录数\nint count();\n// 根据 Wrapper 条件，查询总记录数\nint count(Wrapper&lt;T> queryWrapper);\n\n分页：Page\n// 根据 ID 查询\nT getById(Serializable id);\n// 根据 Wrapper，查询一条记录。结果集，如果是多个会抛出异常，随机取一条加上限制条件 wrapper.last(\"LIMIT 1\")\nT getOne(Wrapper&lt;T> queryWrapper);\n// 根据 Wrapper，查询一条记录\nT getOne(Wrapper&lt;T> queryWrapper, boolean throwEx);\n// 根据 Wrapper，查询一条记录\nMap&lt;String, Object> getMap(Wrapper&lt;T> queryWrapper);\n// 根据 Wrapper，查询一条记录\n&lt;V> V getObj(Wrapper&lt;T> queryWrapper, Function&lt;? super Object, V> mapper);\n\n4.调用Service层操作数据\n\n\n\n\n\n\n\n\n我们在自己的Service接口中通过继承MyBatis-Plus提供的IService接口，不仅可以获得其提供的CRUD方法，而且还可以使用自身定义的方法。\n\n创建UserService并继承IService\n/**\n  * UserService继承IService模板提供的基础功能 \n  */\npublic interface UserService extends IService&lt;User> &#123;&#125;\n\n创建UserService的实现类并继承ServiceImpl\n/**\n  * ServiceImpl实现了IService，提供了IService中基础功能的实现 \n  * 若ServiceImpl无法满足业务需求，则可以使用自定的UserService定义方法，并在实现类中实现\n  */\n@Service\npublic class UserServiceImpl extends ServiceImpl&lt;UserMapper,User> implements UserService&#123;&#125;\n\n测试查询记录数\n\n\n\n\n\n\n\n\n\n调用方法：int count();\n@Test\npublic void testGetCount()&#123;\n    //查询总记录数\n    //执行的SQL为：SELECT COUNT( * ) FROM user\n    long count = userService.count();\n    System.out.println(\"总记录数：\" + count);\n&#125;\n\n测试批量插入数据\n\n\n\n\n\n\n\n\n\n调用方法：boolean saveBatch(Collection entityList);\n@Test\npublic void test()&#123;\n    List&lt;User> list = new ArrayList&lt;>();\n    for (int i = 1; i &lt;= 10; i++) &#123;\n        User user = new User();\n        user.setName(\"Vz\"+i);\n        user.setAge(20+i);\n        list.add(user);\n    &#125;\n    boolean b = userService.saveBatch(list);\n    System.out.println(b ? \"添加成功！\" : \"添加失败！\");\n&#125;\n\n四、常用注解\n\n\n\n\n\n\n\n\nMyBatis-Plus提供的注解可以帮我们解决一些数据库与实体之间相互映射的问题。\n1.@TableName\n\n\n\n\n\n\n\n\n经过以上的测试，在使用MyBatis-Plus实现基本的CRUD时，我们并没有指定要操作的表，只是在Mapper接口继承BaseMapper时，设置了泛型User，而操作的表为user表，由此得出结论，MyBatis-Plus在确定操作的表时，由BaseMapper的泛型决定，即实体类型决定，且默认操作的表名和实体类型的类名一致。\n1.1\t引出问题\n\n\n\n\n\n\n\n\n\n若实体类类型的类名和要操作的表的表名不一致，会出现什么问题？\n\n我们将表user更名为t_user，测试查询功能\n\n\n程序抛出异常，Table ‘mybatis_plus.user’ doesn’t exist，因为现在的表名为t_user，而默认操作的表名和实体类型的类名一致，即user表\n\n\n\n1.2\t解决问题\na、使用注解解决问题\n\n\n\n\n\n\n\n\n在实体类类型上添加@TableName(&quot;t_user&quot;)，标识实体类对应的表，即可成功执行SQL语句\n@Data\n@TableName(\"t_user\")\npublic class User &#123;\n    private Long id;\n    private String name;\n    private Integer age;\n    private String email;\n&#125;\n\n\n\nb、使用全局配置解决问题\n\n\n\n\n\n\n\n\n在开发的过程中，我们经常遇到以上的问题，即实体类所对应的表都有固定的前缀，例如 t_ 或 tbl_ 此时，可以使用MyBatis-Plus提供的全局配置，为实体类所对应的表名设置默认的前缀，那么就不需要在每个实体类上通过@TableName标识实体类对应的表\nmybatis-plus:\n  global-config:\n    db-config:\n      # 设置实体类所对应的表的统一前缀\n      table-prefix: t_\n\n\n\n\n\n2.@TableId\n\n\n\n\n\n\n\n\n经过以上的测试，MyBatis-Plus在实现CRUD时，会默认将id作为主键列，并在插入数据时，默认基于雪花算法的策略生成id\n2.1\t引出问题\n\n\n\n\n\n\n\n\n\n若实体类和表中表示主键的不是id，而是其他字段，例如uid，MyBatis-Plus会自动识别uid为主键列吗？\n\n我们实体类中的属性id改为uid，将表中的字段id也改为uid，测试添加功能\n\n\n\n程序抛出异常，Field ‘uid’ doesn’t have a default value，说明MyBatis-Plus没有将uid作为主键赋值\n\n\n\n2.2\t解决问题\n\n\n\n\n\n\n\n\n\n在实体类中uid属性上通过@TableId将其标识为主键，即可成功执行SQL语句\n@Date\npublic class User &#123;\n    @TableId\n    private Long uid;\n    private String name;\n    private Integer age;\n    private String email;\n&#125;\n\n\n\n2.3\t@TableId的value属性\n\n\n\n\n\n\n\n\n\n若实体类中主键对应的属性为id，而表中表示主键的字段为uid，此时若只在属性id上添加注解@TableId，则抛出异常**Unknown column ‘id’ in ‘field list’**，即MyBatis-Plus仍然会将id作为表的主键操作，而表中表示主键的是字段uid此时需要通过@TableId注解的value属性，指定表中的主键字段，@TableId(&quot;uid&quot;)或@TableId(value=&quot;uid&quot;)\n\n2.4\t@TableId的type属性\n\n\n\n\n\n\n\n\n\ntype属性用来定义主键策略：默认雪花算法\n常用的主键策略：\n\n\n\n值\n描述\n\n\n\nIdType.ASSIGN_ID（默认）\n基于雪花算法的策略生成数据id，与数据库id是否设置自增无关\n\n\nIdType.AUTO\n使用数据库的自增策略，注意，该类型请确保数据库设置了id自增，\n\n\n配置全局主键策略：\n#MyBatis-Plus相关配置\nmybatis-plus:\n  configuration:\n    #配置日志\n    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl\n  global-config:\n    db-config:\n      #配置mp的主键策略为自增\n      id-type: auto\n      # 设置实体类所对应的表的统一前缀\n      table-prefix: t_\n\n\n\n3.@TbaleField\n\n\n\n\n\n\n\n\n经过以上的测试，我们可以发现，MyBatis-Plus在执行SQL语句时，要保证实体类中的属性名和表中的字段名一致\n如果实体类中的属性名和字段名不一致的情况，会出现什么问题呢？\n3.1\t情况一\n若实体类中的属性使用的是驼峰命名风格，而表中的字段使用的是下划线命名风格\n例如实体类属性userName，表中字段user_name\n此时MyBatis-Plus会自动将下划线命名风格转化为驼峰命名风格\n相当于在MyBatis中配置\n3.2\t情况二\n\n\n\n\n\n\n\n\n\n若实体类中的属性和表中的字段不满足情况1\n例如实体类属性name，表中字段username\n此时需要在实体类属性上使用@TableField(&quot;username&quot;)设置属性所对应的字段名\npublic class User &#123;\n    @TableId(\"uid\")\n    private Long id;\n    @TableField(\"username\")\n    private String name;\n    private Integer age;\n    private String email;\n&#125;\n\n\n\n4.@TableLogic4.1\t逻辑删除\n\n\n\n\n\n\n\n\n\n物理删除：真实删除，将对应数据从数据库中删除，之后查询不到此条被删除的数据\n逻辑删除：假删除，将对应数据中代表是否被删除字段的状态修改为“被删除状态”，之后在数据库中仍旧能看到此条数据记录\n使用场景：可以进行数据恢复\n4.2\t实现逻辑删除\n\n数据库中创建逻辑删除状态列，设置默认值为0\n\n\n实体类中添加逻辑删除属性\n\n\n测试删除功能，真正执行的是修改\npublic void testDeleteById()&#123;\n    int result = userMapper.deleteById(1527472864163348482L);\n    System.out.println(result > 0 ? \"删除成功！\" : \"删除失败！\");\n    System.out.println(\"受影响的行数为：\" + result);\n&#125;\n\n\n\n此时执行查询方法，查询的结果为自动添加条件is_deleted=0\n\n\n\n五、条件构造器1.Wrapper介绍\n\nWrapper ： 条件构造抽象类，最顶端父类\n\nAbstractWrapper ： 用于查询条件封装，生成 sql 的 where 条件\n\nQueryWrapper ： 查询条件封装\n\nUpdateWrapper ： Update 条件封装\n\nAbstractLambdaWrapper ： 使用Lambda 语法\n\nLambdaQueryWrapper ：用于Lambda语法使用的查询Wrapper\n\nLambdaUpdateWrapper ： Lambda 更新封装Wrapper\n\n\n\n\n\n\n\n\n2.QueryWrapper\n组装查询条件\n\n\n\n\n\n\n\n\n\n执行SQL：SELECT uid AS id,username AS name,age,email,is_deleted FROM t_user WHERE is_deleted&#x3D;0 AND (username LIKE ? AND age BETWEEN ? AND ? AND email IS NOT NULL)\npublic void test01()&#123;\n    //查询用户名包含a，年龄在20到30之间，邮箱信息不为null的用户信息\n    QueryWrapper&lt;User> queryWrapper = new QueryWrapper&lt;>();\n    queryWrapper.like(\"username\",\"a\").between(\"age\",20,30).isNotNull(\"email\");\n    List&lt;User> users = userMapper.selectList(queryWrapper);\n    users.forEach(System.out::println);\n&#125;\n\n组装排序条件\n\n\n\n\n\n\n\n\n\n执行SQL：SELECT uid AS id,username AS name,age,email,is_deleted FROM t_user WHERE is_deleted&#x3D;0 ORDER BY age DESC,id ASC\npublic void test02()&#123;\n    //查询用户信息，按照年龄的降序排序，若年龄相同，则按照id升序排序\n    QueryWrapper&lt;User> queryWrapper = new QueryWrapper&lt;>();\n    queryWrapper.orderByDesc(\"age\").orderByAsc(\"id\");\n    List&lt;User> users = userMapper.selectList(queryWrapper);\n    users.forEach(System.out::println);\n&#125;\n\n组装删除条件\n\n\n\n\n\n\n\n\n\n执行SQL：UPDATE t_user SET is_deleted&#x3D;1 WHERE is_deleted&#x3D;0 AND (email IS NULL)\npublic void test03()&#123;\n    //删除邮箱地址为null的用户信息\n    QueryWrapper&lt;User> queryWrapper = new QueryWrapper&lt;>();\n    queryWrapper.isNull(\"email\");\n    int result = userMapper.delete(queryWrapper);\n    System.out.println(result > 0 ? \"删除成功！\" : \"删除失败！\");\n    System.out.println(\"受影响的行数为：\" + result);\n&#125;\n\n条件的优先级\n\n\n\n\n\n\n\n\n\n执行SQL：UPDATE t_user SET user_name&#x3D;?, email&#x3D;? WHERE is_deleted&#x3D;0 AND (age &gt; ? AND user_name LIKE ? OR email IS NULL)\npublic void test04()&#123;\n    //将（年龄大于20并且用户名中包含有a）或邮箱为null的用户信息修改\n    UpdateWrapper&lt;User> updateWrapper = new UpdateWrapper&lt;>();\n    updateWrapper.gt(\"age\",20).like(\"username\",\"a\").or().isNull(\"email\");\n    User user = new User();\n    user.setName(\"Oz\");\n    user.setEmail(\"test@oz6.com\");\n\n    int result = userMapper.update(user, updateWrapper);\n    System.out.println(result > 0 ? \"修改成功！\" : \"修改失败！\");\n    System.out.println(\"受影响的行数为：\" + result);\n&#125;\n\n\n\n\n\n\n\n\n\n\n执行SQL：UPDATE t_user SET username&#x3D;?, email&#x3D;? WHERE is_deleted&#x3D;0 AND (username LIKE ? AND (age &gt; ? OR email IS NULL))\npublic void test05()&#123;\n    //将用户名中包含有a并且（年龄大于20或邮箱为null）的用户信息修改\n    UpdateWrapper&lt;User> updateWrapper = new UpdateWrapper&lt;>();\n    updateWrapper.like(\"username\",\"a\").and(i->i.gt(\"age\",20).or().isNull(\"email\"));\n    User user = new User();\n    user.setName(\"Vz7797\");\n    user.setEmail(\"test@ss8o.com\");\n\n    int result = userMapper.update(user, updateWrapper);\n    System.out.println(result > 0 ? \"修改成功！\" : \"修改失败！\");\n    System.out.println(\"受影响的行数为：\" + result);\n&#125;\n\n组装select子句\n\n\n\n\n\n\n\n\n\n执行SQL：SELECT username,age,email FROM t_user WHERE is_deleted&#x3D;0\npublic void test06()&#123;\n    //查询用户的用户名、年龄、邮箱信息\n    QueryWrapper&lt;User> queryWrapper = new QueryWrapper&lt;>();\n    queryWrapper.select(\"username\",\"age\",\"email\");\n    List&lt;Map&lt;String, Object>> maps = userMapper.selectMaps(queryWrapper);\n    maps.forEach(System.out::println);\n&#125;\n\n实现子查询\n\n\n\n\n\n\n\n\n\n执行SQL：SELECT uid AS id,user_name AS name,age,email,is_deleted FROM t_user WHERE is_deleted&#x3D;0 AND (uid IN (select uid from t_user where uid &lt;&#x3D; 100))\npublic void test07()&#123;\n    //查询id小于等于100的用户信息\n    QueryWrapper&lt;User> queryWrapper = new QueryWrapper&lt;>();\n    queryWrapper.inSql(\"uid\", \"select uid from t_user where uid &lt;= 100\");\n    List&lt;User> list = userMapper.selectList(queryWrapper);\n    list.forEach(System.out::println);\n&#125;\n\n3.UpdateWrapper\n\n\n\n\n\n\n\n\nUpdateWrapper不仅拥有QueryWrapper的组装条件功能，还提供了set方法进行修改对应条件的数据库信息\npublic void test08()&#123;\n    //将用户名中包含有a并且（年龄大于20或邮箱为null）的用户信息修改\n    UpdateWrapper&lt;User> updateWrapper = new UpdateWrapper&lt;>();\n    updateWrapper.like(\"username\",\"a\").and( i -> i.gt(\"age\",20).or().isNull(\"email\")).set(\"email\",\"svip@qq.com\");\n    int result = userMapper.update(null, updateWrapper);\n    System.out.println(result > 0 ? \"修改成功！\" : \"修改失败！\");\n    System.out.println(\"受影响的行数为：\" + result);\n&#125;\n\n\n\n4.condition\n\n\n\n\n\n\n\n\n在真正开发的过程中，组装条件是常见的功能，而这些条件数据来源于用户输入，是可选的，因此我们在组装这些条件时，必须先判断用户是否选择了这些条件，若选择则需要组装该条件，若没有选择则一定不能组装，以免影响SQL执行的结果\n\n思路一\n\n\n\n\n\n\n\n\n\n执行SQL：SELECT uid AS id,user_name AS name,age,email,is_deleted FROM t_user WHERE is_deleted&#x3D;0 AND (user_name LIKE ? AND age &lt;&#x3D; ?)\npublic void test09()&#123;\n    String username = \"a\";\n    Integer ageBegin = null;\n    Integer ageEnd = 30;\n    QueryWrapper&lt;User> queryWrapper = new QueryWrapper&lt;>();\n    if(StringUtils.isNotBlank(username))&#123;\n        //isNotBlank判断某个字符创是否不为空字符串、不为null、不为空白符\n        queryWrapper.like(\"user_name\", username);\n    &#125;\n    if(ageBegin != null)&#123;\n        queryWrapper.ge(\"age\", ageBegin);\n    &#125;\n    if(ageEnd != null)&#123;\n        queryWrapper.le(\"age\", ageEnd);\n    &#125;\n    List&lt;User> list = userMapper.selectList(queryWrapper);\n    list.forEach(System.out::println);\n&#125;\n\n思路二\n\n\n\n\n\n\n\n\n\n上面的实现方案没有问题，但是代码比较复杂，我们可以使用带condition参数的重载方法构建查询条件，简化代码的编写\npublic void test10()&#123;\n    String username = \"a\";\n    Integer ageBegin = null;\n    Integer ageEnd = 30;\n    QueryWrapper&lt;User> queryWrapper = new QueryWrapper&lt;>();\n    queryWrapper.like(StringUtils.isNotBlank(username), \"user_name\", username)\n        .ge(ageBegin != null, \"age\", ageBegin)\n        .le(ageEnd != null, \"age\", ageEnd);\n    List&lt;User> list = userMapper.selectList(queryWrapper);\n    list.forEach(System.out::println);\n&#125;\n\n5.LambdaQueryWrapper\n\n\n\n\n\n\n\n\n功能等同于QueryWrapper，提供了Lambda表达式的语法可以避免填错列名。\npublic void test11()&#123;\n    String username = \"a\";\n    Integer ageBegin = null;\n    Integer ageEnd = 30;\n    LambdaQueryWrapper&lt;User> queryWrapper = new LambdaQueryWrapper&lt;>();\n    queryWrapper.like(StringUtils.isNotBlank(username), User::getName, username)\n        .ge(ageBegin != null, User::getAge, ageBegin)\n        .le(ageEnd != null, User::getAge, ageEnd);\n    List&lt;User> list = userMapper.selectList(queryWrapper);\n    list.forEach(System.out::println);\n&#125;\n\n\n\n6.LambdaUpdateWrapper\n\n\n\n\n\n\n\n\n功能等同于UpdateWrapper，提供了Lambda表达式的语法可以避免填错列名。\npublic void test12()&#123;\n    //将用户名中包含有a并且（年龄大于20或邮箱为null）的用户信息修改\n    LambdaUpdateWrapper&lt;User> updateWrapper = new LambdaUpdateWrapper&lt;>();\n    updateWrapper.like(User::getName, \"a\")\n        .and(i -> i.gt(User::getAge, 20).or().isNull(User::getEmail));\n    updateWrapper.set(User::getName, \"小黑\").set(User::getEmail,\"abc@atguigu.com\");\n    int result = userMapper.update(null, updateWrapper);\n    System.out.println(\"result：\"+result);\n&#125;\n\n\n\n六、常用插件1.分页插件\n\n\n\n\n\n\n\n\nMyBatis Plus自带分页插件，只要简单的配置即可实现分页功能\n\n添加配置类MyBatisPlusConfig\n@Configuration\n@MapperScan(\"com.atguigu.mybatisplus.mapper\")\npublic class MyBatisPlusConfig &#123;\n    @Bean\n    public MybatisPlusInterceptor mybatisPlusInterceptor()&#123;\n        MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor();\n        //添加分页插件\n        interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL));\n        return interceptor;\n    &#125;\n&#125;\n\n编写测试方法\n@Test\npublic void testPage()&#123;\n    //new Page()中的两个参数分别是当前页码，每页显示数量\n    Page&lt;User> page = userMapper.selectPage(new Page&lt;>(1, 2), null);\n    List&lt;User> users = page.getRecords();\n    users.forEach(System.out::println);\n&#125;\n\n2.自定义分页\n\n\n\n\n\n\n\n\n上面调用的是MyBatis-Plus提供的带有分页的方法，那么我们自己定义的方法如何实现分页呢？\n\n在UserMapper接口中定义一个方法\n/**\n  * 根据年龄查询用户列表，分页显示 \n  * @param page 分页对象,xml中可以从里面进行取值,传递参数 Page 即自动分页,必须放在第一位 \n  * @param age 年龄 \n  * @return \n  */\nPage&lt;User> selectPageVo(@Param(\"page\") Page&lt;User> page,@Param(\"age\") Integer age);\n\n在UserMapper.xml中编写SQL实现该方法\n&lt;select id=\"selectPageVo\" resultType=\"User\">\n    select id,username as name,age,email from t_user where age > #&#123;age&#125;\n&lt;/select>\n\n编写测试方法\n@Test\npublic void testPageVo()&#123;\n    Page&lt;User> page = userMapper.selectPageVo(new Page&lt;User>(1,2), 20);\n    List&lt;User> users = page.getRecords();\n    users.forEach(System.out::println);\n&#125;\n\n3.乐观锁\n\n\n\n\n\n\n\n\n作用：当要更新一条记录的时候，希望这条记录没有被别人更新\n乐观锁的实现方式：\n\n取出记录时，获取当前 version\n更新时，带上这个 version\n执行更新时， set version &#x3D; newVersion where version &#x3D; oldVersion\n如果 version 不对，就更新失败\n\n3.1\t场景\n\n一件商品，成本价是80元，售价是100元。老板先是通知小李，说你去把商品价格增加50元。小李正在玩游戏，耽搁了一个小时。正好一个小时后，老板觉得商品价格增加到150元，价格太高，可能会影响销量。又通知小王，你把商品价格降低30元。\n此时，小李和小王同时操作商品后台系统。小李操作的时候，系统先取出商品价格100元；小王也在操作，取出的商品价格也是100元。小李将价格加了50元，并将100+50&#x3D;150元存入了数据库；小王将商品减了30元，并将100-30&#x3D;70元存入了数据库。是的，如果没有锁，小李的操作就完全被小王的覆盖了。\n现在商品价格是70元，比成本价低10元。几分钟后，这个商品很快出售了1千多件商品，老板亏1万多。\n\n3.2\t乐观锁与悲观锁\n\n上面的故事，如果是乐观锁，小王保存价格前，会检查下价格是否被人修改过了。如果被修改过了，则重新取出的被修改后的价格，150元，这样他会将120元存入数据库。\n如果是悲观锁，小李取出数据后，小王只能等小李操作完之后，才能对价格进行操作，也会保证最终的价格是120元。\n\n3.3\t模拟修改冲突\n\n数据库中增加商品表\nCREATE TABLE t_product ( \n    id BIGINT(20) NOT NULL COMMENT '主键ID', \n    NAME VARCHAR(30) NULL DEFAULT NULL COMMENT '商品名称', \n    price INT(11) DEFAULT 0 COMMENT '价格', \n    VERSION INT(11) DEFAULT 0 COMMENT '乐观锁版本号', \n    PRIMARY KEY (id) \n);\n\n添加一条数据\nINSERT INTO t_product (id, NAME, price) VALUES (1, '外星人笔记本', 100);\n\n添加一个实体类Product\n@Data\npublic class Product &#123;\n    private Long id;\n    private String name;\n    private Integer price;\n    private Integer version;\n&#125;\n\n添加一个Mapper接口ProductMapper\npublic interface ProductMapper extends BaseMapper&lt;Product> &#123;&#125;\n\n测试方法\n@Test\npublic void testProduct01()&#123;\n    //1.小李获取商品价格\n    Product productLi = productMapper.selectById(1);\n    System.out.println(\"小李获取的商品价格为：\" + productLi.getPrice());\n\n    //2.小王获取商品价格\n    Product productWang = productMapper.selectById(1);\n    System.out.println(\"小李获取的商品价格为：\" + productWang.getPrice());\n\n    //3.小李修改商品价格+50\n    productLi.setPrice(productLi.getPrice()+50);\n    productMapper.updateById(productLi);\n\n    //4.小王修改商品价格-30\n    productWang.setPrice(productWang.getPrice()-30);\n    productMapper.updateById(productWang);\n\n    //5.老板查询商品价格\n    Product productBoss = productMapper.selectById(1);\n    System.out.println(\"老板获取的商品价格为：\" + productBoss.getPrice());\n&#125;\n\n执行结果\n\n\n\n3.4\t乐观锁解决问题\n\n实体类version字段添加注解@Version\n@Data\npublic class Product &#123;\n    private Long id;\n    private String name;\n    private Integer price;\n    @Version\n    private Integer version;\n&#125;\n\n添加乐观锁插件配置\n@Bean\npublic MybatisPlusInterceptor mybatisPlusInterceptor()&#123;\n    MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor();\n    //添加分页插件\n    interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL));\n    //添加乐观锁插件\n    interceptor.addInnerInterceptor(new OptimisticLockerInnerInterceptor());\n    return interceptor;\n&#125;\n\n再次执行测试方法\n\n\n\n\n\n\n\n\n\n小李查询商品信息：\n​\tSELECT id,name,price,version FROM t_product WHERE id&#x3D;?\n小王查询商品信息：\n​\tSELECT id,name,price,version FROM t_product WHERE id&#x3D;?\n小李修改商品价格，自动将version+1\n​\tUPDATE t_product SET name&#x3D;?, price&#x3D;?, version&#x3D;? WHERE id&#x3D;? AND version&#x3D;?\n​\tParameters: 外星人笔记本(String), 150(Integer), 1(Integer), 1(Long), 0(Integer)\n小王修改商品价格，此时version已更新，条件不成立，修改失败\n​\tUPDATE t_product SET name&#x3D;?, price&#x3D;?, version&#x3D;? WHERE id&#x3D;? AND version&#x3D;?\n​\tParameters: 外星人笔记本(String), 70(Integer), 1(Integer), 1(Long), 0(Integer)\n最终，小王修改失败，查询价格：150\n​\tSELECT id,name,price,version FROM t_product WHERE id&#x3D;?\n\n优化执行流程\n@Test\npublic void testProduct01()&#123;\n    //1.小李获取商品价格\n    Product productLi = productMapper.selectById(1);\n    System.out.println(\"小李获取的商品价格为：\" + productLi.getPrice());\n\n    //2.小王获取商品价格\n    Product productWang = productMapper.selectById(1);\n    System.out.println(\"小李获取的商品价格为：\" + productWang.getPrice());\n\n    //3.小李修改商品价格+50\n    productLi.setPrice(productLi.getPrice()+50);\n    productMapper.updateById(productLi);\n\n    //4.小王修改商品价格-30\n    productWang.setPrice(productWang.getPrice()-30);\n    int result = productMapper.updateById(productWang);\n    if(result == 0)&#123;\n        //操作失败，重试\n        Product productNew = productMapper.selectById(1);\n        productNew.setPrice(productNew.getPrice()-30);\n        productMapper.updateById(productNew);\n    &#125;\n\n    //5.老板查询商品价格\n    Product productBoss = productMapper.selectById(1);\n    System.out.println(\"老板获取的商品价格为：\" + productBoss.getPrice());\n&#125;\n\n\n\n\n七、通用枚举\n\n\n\n\n\n\n\n\n表中的有些字段值是固定的，例如性别（男或女），此时我们可以使用MyBatis-Plus的通用枚举来实现\n\n数据库表添加字段sex\n\n\n创建通用枚举类型\n@Getter\npublic enum SexEnum &#123;\n    MALE(1, \"男\"),\n    FEMALE(2, \"女\");\n\n    @EnumValue //将注解所标识的属性的值存储到数据库中\n    private int sex;\n    private String sexName;\n\n    SexEnum(Integer sex, String sexName) &#123;\n        this.sex = sex;\n        this.sexName = sexName;\n    &#125;\n&#125;\n\nUser实体类中添加属性sex\npublic class User &#123;\n    private Long id;\n    @TableField(\"username\")\n    private String name;\n    private Integer age;\n    private String email;\n\n    @TableLogic\n    private int isDeleted;  //逻辑删除\n\n    private SexEnum sex;\n&#125;\n\n配置扫描通用枚举\n#MyBatis-Plus相关配置\nmybatis-plus:\n  #指定mapper文件所在的地址\n  mapper-locations: classpath:mapper/*.xml\n  configuration:\n    #配置日志\n    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl\n  global-config:\n    banner: off\n    db-config:\n      #配置mp的主键策略为自增\n      id-type: auto\n      # 设置实体类所对应的表的统一前缀\n      table-prefix: t_\n  #配置类型别名所对应的包\n  type-aliases-package: com.atguigu.mybatisplus.pojo\n  # 扫描通用枚举的包\n  type-enums-package: com.atguigu.mybatisplus.enums\n\n执行测试方法\n@Test\npublic void test()&#123;\n    User user = new User();\n    user.setName(\"admin\");\n    user.setAge(33);\n    user.setSex(SexEnum.MALE);\n    int result = userMapper.insert(user);\n    System.out.println(\"result:\"+result);\n&#125;\n\n八、多数据源\n\n\n\n\n\n\n\n\n适用于多种场景：纯粹多库、 读写分离、 一主多从、 混合模式等\n场景说明：\n我们创建两个库，分别为：mybatis_plus（以前的库不动）与mybatis_plus_1（新建），将mybatis_plus库的product表移动到mybatis_plus_1库，这样每个库一张表，通过一个测试用例分别获取用户数据与商品数据，如果获取到说明多库模拟成功\n1.创建数据库及表\n创建数据库mybatis_plus_1和表&#96;product\nCREATE DATABASE `mybatis_plus_1` /*!40100 DEFAULT CHARACTER SET utf8mb4 */;\nuse `mybatis_plus_1`; \nCREATE TABLE product ( \n    id BIGINT(20) NOT NULL COMMENT '主键ID', \n    name VARCHAR(30) NULL DEFAULT NULL COMMENT '商品名称', \n    price INT(11) DEFAULT 0 COMMENT '价格', \n    version INT(11) DEFAULT 0 COMMENT '乐观锁版本号', \n    PRIMARY KEY (id) \n);\n\n添加测试数据\nINSERT INTO product (id, NAME, price) VALUES (1, '外星人笔记本', 100);\n\n删除mybatis_plus库中的product表 \nuse mybatis_plus; \nDROP TABLE IF EXISTS product;\n\n2.新建工程引入依赖\n\n\n\n\n\n\n\n\n自行新建一个Spring Boot工程并选择MySQL驱动及Lombok依赖\n引入MyBaits-Plus的依赖及多数据源的依赖\n&lt;dependency>\n    &lt;groupId>com.baomidou&lt;/groupId>\n    &lt;artifactId>mybatis-plus-boot-starter&lt;/artifactId>\n    &lt;version>3.5.1&lt;/version>\n&lt;/dependency>\n\n&lt;dependency>\n    &lt;groupId>com.baomidou&lt;/groupId>\n    &lt;artifactId>dynamic-datasource-spring-boot-starter&lt;/artifactId>\n    &lt;version>3.5.0&lt;/version>\n&lt;/dependency>\n\n\n\n3.编写配置文件spring:\n  # 配置数据源信息\n  datasource:\n    dynamic:\n      # 设置默认的数据源或者数据源组,默认值即为master\n      primary: master\n      # 严格匹配数据源,默认false.true未匹配到指定数据源时抛异常,false使用默认数据源\n      strict: false\n      datasource:\n        master:\n          url: jdbc:mysql://localhost:3306/mybatis_plus?characterEncoding=utf-8&amp;useSSL=false\n          driver-class-name: com.mysql.cj.jdbc.Driver\n          username: root\n          password: 132537\n        slave_1:\n          url: jdbc:mysql://localhost:3306/mybatis_plus_1?characterEncoding=utf-8&amp;useSSL=false\n          driver-class-name: com.mysql.cj.jdbc.Driver\n          username: root\n          password: 132537\n\n\n\n4.创建实体类\n新建一个User实体类（如果数据库表名有t_前缀记得配置）\n@Data\npublic class User &#123;\n    private Long id;\n    private String name;\n    private Integer age;\n    private String email;\n&#125;\n\n新建一个实体类Product\n@Data\npublic class Product &#123;\n    private Long id;\n    private String name;\n    private Integer price;\n    private Integer version;\n&#125;\n\n5.创建Mapper及Service\n新建接口UserMapper\npublic interface UserMapper extends BaseMapper&lt;User> &#123;&#125;\n\n新建接口ProductMapper\npublic interface ProductMapper extends BaseMapper&lt;Product> &#123;&#125;\n\n新建Service接口UserService指定操作的数据源\n@DS(\"master\") //指定操作的数据源，master为user表\npublic interface UserService extends IService&lt;User> &#123;&#125;\n\n新建Service接口ProductService指定操作的数据源\n@DS(\"slave_1\")\npublic interface ProductService extends IService&lt;Product> &#123;&#125;\n\n自行建立Service的实现类\n...\n\n6.编写测试方法\n\n\n\n\n\n\n\n\n记得在启动类中添加注解@MapperScan()\nclass TestDatasourceApplicationTests &#123;\n\t@Resource\n\tUserService userService;\n\n\t@Resource\n\tProductService productService;\n\n\t@Test\n\tvoid contextLoads() &#123;\n\t\tUser user = userService.getById(1L);\n\t\tProduct product = productService.getById(1L);\n\t\tSystem.out.println(\"User = \" + user);\n\t\tSystem.out.println(\"Product = \" + product);\n\t&#125;\n\n&#125;\n\n\n九、MyBatisX插件\n\n\n\n\n\n\n\n\nMyBatis-Plus为我们提供了强大的mapper和service模板，能够大大的提高开发效率。\n但是在真正开发过程中，MyBatis-Plus并不能为我们解决所有问题，例如一些复杂的SQL，多表联查，我们就需要自己去编写代码和SQL语句，我们该如何快速的解决这个问题呢，这个时候可以使用MyBatisX插件。\nMyBatisX一款基于 IDEA 的快速开发插件，为效率而生。\n1.安装MyBatisX插件\n\n\n\n\n\n\n\n\n打开IDEA，File-&gt; Setteings-&gt;Plugins-&gt;MyBatisX，搜索栏搜索MyBatisX然后安装。\n\n2.快速生成代码\n新建一个Spring Boot项目引入依赖（创建工程时记得勾选lombok及mysql驱动）\n&lt;dependency>\n    &lt;groupId>com.baomidou&lt;/groupId>\n    &lt;artifactId>mybatis-plus-boot-starter&lt;/artifactId>\n    &lt;version>3.5.1&lt;/version>\n&lt;/dependency>\n\n&lt;dependency>\n    &lt;groupId>com.baomidou&lt;/groupId>\n    &lt;artifactId>dynamic-datasource-spring-boot-starter&lt;/artifactId>\n    &lt;version>3.5.0&lt;/version>\n&lt;/dependency>\n\n配置数据源信息\nspring:\n  datasource:\n    type: com.zaxxer.hikari.HikariDataSource\n    driver-class-name: com.mysql.cj.jdbc.Driver\n    url: jdbc:mysql://localhost:3306/mybatis_plus?characterEncoding=utf-8&amp;useSSL=false\n    username: root\n    password: 132537\n\n在IDEA中与数据库建立链接\n\n\n填写数据库信息并保存\n\n\n找到我们需要生成的表点击右键\n\n\n填写完信息以后下一步\n\n\n继续填写信息\n\n\n大功告成（真特么好用yyds）\n\n\n\n3.快速生成CRUD\n\n\n\n\n\n\n\n\nMyBaitsX可以根据我们在Mapper接口中输入的方法名快速帮我们生成对应的sql语句\n\n\n十、代码生成器package com.example.dockertest;\n\nimport com.baomidou.mybatisplus.annotation.DbType;\nimport com.baomidou.mybatisplus.annotation.IdType;\nimport com.baomidou.mybatisplus.generator.AutoGenerator;\nimport com.baomidou.mybatisplus.generator.config.DataSourceConfig;\nimport com.baomidou.mybatisplus.generator.config.GlobalConfig;\nimport com.baomidou.mybatisplus.generator.config.PackageConfig;\nimport com.baomidou.mybatisplus.generator.config.StrategyConfig;\nimport com.baomidou.mybatisplus.generator.config.rules.DateType;\nimport com.baomidou.mybatisplus.generator.config.rules.NamingStrategy;\nimport org.junit.Test;\n\npublic class mp &#123;\n\n    @Test\n    public void run() &#123;\n        //一般写在test中\n        // 1、创建代码生成器\n        AutoGenerator mpg = new AutoGenerator();\n\n        // 2、全局配置\n        GlobalConfig gc = new GlobalConfig();\n        //使用绝对路径\n        gc.setOutputDir(\"F:\\\\guli_parent\\\\service\\\\service-edu\" + \"/src/main/java\");\n        gc.setAuthor(\"LMZovo\"); //作者\n        gc.setOpen(false); //生成后是否打开资源管理器\n        gc.setFileOverride(false); //重新生成时文件是否覆盖\n        gc.setServiceName(\"%sService\");    //去掉Service接口的首字母I\n        gc.setIdType(IdType.ID_WORKER_STR); //主键策略 Long不用加str，string要加\n        gc.setDateType(DateType.ONLY_DATE);//定义生成的实体类中日期类型\n        gc.setSwagger2(true);//开启Swagger2模式\n\n        mpg.setGlobalConfig(gc);\n\n        // 3、数据源配置\n        DataSourceConfig dsc = new DataSourceConfig();\n        dsc.setUrl(\"jdbc:mysql://localhost:3307/guli?serverTimezone=GMT%2B8\");\n        dsc.setDriverName(\"com.mysql.cj.jdbc.Driver\");\n        dsc.setUsername(\"root\");\n        dsc.setPassword(\"lmz0521\");\n        dsc.setDbType(DbType.MYSQL);\n        mpg.setDataSource(dsc);\n\n        // 4、包配置\n        PackageConfig pc = new PackageConfig();\n        pc.setParent(\"com.guli\");\n        pc.setModuleName(\"eduService\"); //模块名\n        pc.setController(\"controller\");\n        pc.setEntity(\"entity\");\n        pc.setService(\"service\");\n        pc.setMapper(\"mapper\");\n        mpg.setPackageInfo(pc);\n\n        // 5、策略配置\n        StrategyConfig strategy = new StrategyConfig();\n        strategy.setInclude(\"edu_teacher\"); //数据库中表名\n        strategy.setNaming(NamingStrategy.underline_to_camel);//数据库表映射到实体的命名策略\n        strategy.setTablePrefix(pc.getModuleName() + \"_\"); //生成实体时去掉表前缀\n\n        strategy.setColumnNaming(NamingStrategy.underline_to_camel);//数据库表字段映射到实体的命名策略\n        strategy.setEntityLombokModel(true); // lombok 模型 @Accessors(chain = true) setter链式操作\n\n        strategy.setRestControllerStyle(true); //restful api风格控制器\n        strategy.setControllerMappingHyphenStyle(true); //url中驼峰转连字符\n\n        mpg.setStrategy(strategy);\n        // 6、执行\n        mpg.execute();\n    &#125;\n&#125;\n\n","slug":"MybatisPlus","date":"2022-06-19T12:43:38.059Z","categories_index":"mybatisPlus","tags_index":"mybatisPlus","author_index":"小李不在_"},{"id":"dffa3dc092427bd4c66bed12d5783ad5","title":"凸包算法-Andrew算法","content":"\nclass Solution &#123;\n    public int[][] outerTrees(int[][] trees) &#123;\n        int n = trees.length;\n        if (n &lt; 4) &#123;\n            return trees;\n        &#125;\n        /* 按照 x 大小进行排序，如果 x 相同，则按照 y 的大小进行排序 */\n        Arrays.sort(trees, (a, b) -> &#123;\n            if (a[0] == b[0]) &#123;\n                return a[1] - b[1];\n            &#125;\n            return a[0] - b[0];\n        &#125;);\n        List&lt;Integer> list = new ArrayList&lt;>();\n        boolean[] used = new boolean[n];\n        /* list[0] 需要入栈两次，不进行标记 */\n        list.add(0);\n        /* 求出凸包的下半部分 */\n        for (int i = 1; i &lt; n; i++) &#123;\n            while (list.size() > 1 &amp;&amp; cross(trees[list.get(list.size() - 2)], trees[list.get(list.size() - 1)], trees[i]) &lt; 0) &#123;\n                used[list.get(list.size() - 1)] = false;\n                list.remove(list.size() - 1);\n            &#125;\n            used[i] = true;\n            list.add(i);\n        &#125;\n        int m = list.size();\n        /* 求出凸包的上半部分 */\n        for (int i = n - 2; i >= 0; i--) &#123;\n            if (!used[i]) &#123;\n                while (list.size() > m &amp;&amp; cross(trees[list.get(list.size() - 2)], trees[list.get(list.size() - 1)], trees[i]) &lt; 0) &#123;\n                    used[list.get(list.size() - 1)] = false;\n                    list.remove(list.size() - 1);\n                &#125;\n                used[i] = true;\n                list.add(i);\n            &#125;\n        &#125;\n        /* list[0] 同时参与凸包的上半部分检测，因此需去掉重复的 list[0] */\n        list.remove(list.size() - 1);\n        int size = list.size();\n        int[][] res = new int[size][2];\n        for (int i = 0; i &lt; size; i++) &#123;\n            res[i] = trees[list.get(i)];\n        &#125;\n        return res;\n    &#125;\n\n    /*比较斜率是否为左拐,大于0说明是左拐\n     * (x2-x1)/(y2-y1) - (x3-x2)/(y3-y2) = (x2-x1)(y3-y2) - (x3-x2)(y2-y1)\n     * */\n    private int cross(int[] p, int[] q, int[] r) &#123;\n        return (q[0] - p[0]) * (r[1] - q[1]) - (q[1] - p[1]) * (r[0] - q[0]);\n    &#125;\n&#125;\n587\n","slug":"凸包算法-- Andrew 算法","date":"2022-06-11T13:28:51.911Z","categories_index":"数据结构","tags_index":"数据结构,算法","author_index":"小李不在_"},{"id":"781fb484634f3be0f1bf39d2ec5d0535","title":"字典树(前缀树)","content":"1\nclass Solution &#123;\n    public int findKthNumber(int n, int k) &#123;\n    int ans = 1;\n    while(k>1)&#123;\n        int count = dfs(ans,n);\n        //求出子树的数量和K比较，若大于k则在子树中找，否则在循环下一个节点\n        if(count&lt;k)&#123;\n            ans++;\n            k-=count;\n        &#125;else&#123;\n            ans*=10;\n            k--;\n        &#125;\n    &#125;\n    return ans;\n&#125;\n\n    //计算子树中的总数\n    public int dfs(long ans,long n)&#123;\n        int tem = 0;\n        long left = n;\n        long right = n;\n        while(left&lt;=right)&#123;\n            tem += Math.min(right,n) - left +1;\n            left*=10;\n            right=right*10+9;\n        &#125;\n        return tem;\n    &#125;\n&#125;\n2实现Trie\nclass Trie &#123;\n    Trie[] chileren;\n    boolean isExist;\n    public Trie() &#123;\n        chileren = new Trie[26];\n        isExist = false;\n    &#125;\n    \n    public void insert(String word) &#123;\n        Trie node = this;\n        for(int i=0;i&lt;word.length();i++)&#123;\n            char c = word.charAt(i);\n            int index = c - 'a';\n            if(node.chileren[index] == null)&#123;\n                node.chileren[index] = new Trie();\n            &#125;\n            node = node.chileren[index];\n        &#125;\n        node.isExist = true;\n    &#125;\n    \n    public boolean search(String word) &#123;\n        Trie node = searchWorld(word);\n        return node!=null &amp;&amp; node.isExist;\n    &#125;\n    \n    public boolean startsWith(String prefix) &#123;\n        return searchWorld(prefix)!=null;\n    &#125;\n\n    private Trie searchWorld(String str)&#123;\n        Trie node = this;\n        for(int i=0;i&lt;str.length();i++)&#123;\n            char c = str.charAt(i);\n            int index = c-'a';\n            if(node.chileren[index]==null)&#123;\n                return null;\n            &#125;\n            node = node.chileren[index];\n        &#125;\n        return node;\n    &#125;\n&#125;\n","slug":"字典树","date":"2022-06-11T13:28:51.903Z","categories_index":"数据结构","tags_index":"数据结构,算法","author_index":"小李不在_"},{"id":"d1408add887a68e7d3f5038df24f24f8","title":"约瑟夫环","content":"约瑟夫环——公式法（递推公式）\n","slug":"约瑟夫问题","date":"2022-06-11T13:28:51.903Z","categories_index":"数据结构","tags_index":"数据结构,算法","author_index":"小李不在_"},{"id":"a448dfd8ebb4408d1633f0dff8411f1c","title":"线段树","content":"leetcode\nclass NumArray &#123;\n    class TreeNode&#123;\n        int sum;\n        int start,end;\n        TreeNode left,right;\n        public TreeNode(int s,int e)&#123;\n            left = null;\n            right = null;\n            start = s;\n            end = e;\n        &#125;\n    &#125;\n    TreeNode root = null;\n    private TreeNode buildTree(int[] nums,int start,int end)&#123;\n        if(start > end)&#123;\n            return null;\n        &#125;\n        TreeNode res = new TreeNode(start,end);\n        if(start == end)&#123;\n            res.sum = nums[start];\n        &#125;else&#123;\n            int mid = start + (end - start)/2;\n            res.left = buildTree(nums,start,mid);\n            res.right = buildTree(nums,mid+1,end); \n            res.sum = res.left.sum + res.right.sum;\n        &#125;\n        return res;\n    &#125;\n    public NumArray(int[] nums) &#123;\n        root = buildTree(nums,0,nums.length - 1);\n    &#125;\n\n    private void update(TreeNode root,int i,int val)&#123;\n        if(root.start == root.end)&#123;\n            root.sum = val;\n        &#125;else&#123;\n            int mid = root.start + (root.end - root.start)/2;\n            if(i&lt;=mid)&#123;\n                update(root.left,i,val);\n            &#125;else&#123;\n                update(root.right,i,val);\n            &#125;\n            root.sum = root.left.sum + root.right.sum;\n        &#125;\n    &#125;\n    \n    public void update(int index, int val) &#123;\n        update(root,index,val);\n    &#125;\n    \n    private int query(TreeNode root,int i,int j)&#123;\n        if(root.start == i&amp;&amp;root.end == j)&#123;\n            return root.sum;\n        &#125;else&#123;\n            int mid = root.start + (root.end - root.start)/2;\n            if(j&lt;=mid)&#123;\n                return query(root.left,i,j);\n            &#125;else if(i>=mid+1)&#123;\n                return query(root.right,i,j);\n            &#125;else&#123;\n                return query(root.left,i,mid) + query(root.right,mid+1,j);\n            &#125;\n        &#125;\n    &#125;\n    public int sumRange(int left, int right) &#123;\n        return query(root,left,right);\n    &#125;\n&#125;\n\n/**\n * Your NumArray object will be instantiated and called as such:\n * NumArray obj = new NumArray(nums);\n * obj.update(index,val);\n * int param_2 = obj.sumRange(left,right);\n */\n","slug":"线段树","date":"2022-06-11T13:28:51.895Z","categories_index":"数据结构","tags_index":"数据结构,算法","author_index":"小李不在_"},{"id":"c4317418140da87757f2c4ade40f3f4c","title":"实现LRU","content":"实际上底层维护双向链表和哈希表，将新查询的数据或插入的数据移动到链表头，若再插入数据时容量不足则从链表尾部删除\nclass LRUCache &#123;\n    Map&lt;Integer, Node> map;\n    DoubleLinkedList cache;\n    int capacity;\n\n    public LRUCache(int capacity) &#123;\n        this.capacity = capacity;\n        map = new HashMap&lt;>();\n        cache = new DoubleLinkedList();\n    &#125;\n\n    public int get(int key) &#123;\n        if (!map.containsKey(key)) &#123;\n            return -1;\n        &#125;\n        int val = map.get(key).value;\n        put(key, val);\n        return val;\n    &#125;\n\n    public void put(int key, int value) &#123;\n        Node newNode = new Node(key, value);\n        if (map.containsKey(key)) &#123;\n            cache.delete(map.get(key));\n            map.put(key, newNode);\n            cache.addFirst(newNode);\n        &#125; else &#123;\n            if (capacity == map.size()) &#123;\n                int k = cache.deleteLast(newNode);\n                map.remove(k);\n            &#125;\n            cache.addFirst(newNode);\n            map.put(key, newNode);\n        &#125;\n    &#125;\n\n     class Node &#123;\n        int key;\n        int value;\n        Node prev;\n        Node next;\n\n        public Node(int key, int value) &#123;\n            this.key = key;\n            this.value = value;\n        &#125;\n    &#125;\n\n     class DoubleLinkedList &#123;\n        Node head;\n        Node tail;\n\n        public DoubleLinkedList() &#123;\n            head = new Node(0, 0);\n            tail = new Node(0, 0);\n            head.next = tail;\n            tail.prev = head;\n        &#125;\n\n        public void addFirst(Node node) &#123;\n            node.next = head.next;\n            node.prev = head;\n            head.next.prev = node;\n            head.next = node;\n        &#125;\n\n        public int delete(Node node) &#123;\n            int key = node.key;\n            node.prev.next = node.next;\n            node.next.prev = node.prev;\n            return key;\n        &#125;\n\n        public int deleteLast(Node node) &#123;\n            if (tail.prev == head) return -1;\n            return delete(tail.prev);\n        &#125;\n    &#125;\n&#125;\n\n","slug":"LRU缓存","date":"2022-06-11T13:26:26.264Z","categories_index":"数据结构","tags_index":"数据结构,算法","author_index":"小李不在_"},{"id":"fb29227b1d7a6ce56d78eec37318e1c8","title":"背包dp","content":"1\nclass Solution &#123;\n    public boolean canPartition(int[] nums) &#123;\n        int len = nums.length;\n        int sum = 0;\n        for (int num : nums) &#123;\n            sum += num;\n        &#125;\n        if (sum % 2 == 1) &#123;\n            return false;\n        &#125;\n        int target = sum / 2;\n        boolean[] dp = new boolean[target + 1];\n        // dp[0] = true;有没有都没影响\n        if (nums[0] &lt;= target) &#123;\n            dp[nums[0]] = true;\n        &#125;\n        for (int i = 1; i &lt; len; i++) &#123;\n            for (int j = target; j >= 0 &amp;&amp; nums[i] &lt;= j; j--) &#123;\n                //逆序遍历是不能覆盖之前的值，因为只用一维数组，当前元素的值由上一行或上一行左边某个值得来\n                dp[j] = dp[j] || dp[j - nums[i]];\n            &#125;\n            if (dp[target]) &#123;\n                return true;\n            &#125;\n        &#125;\n        return dp[target];\n    &#125;\n&#125;\n\n2\nclass Solution &#123;\n    public int numSquares(int n) &#123;\n        //dp[i] 表示当前数字i最少由几个完全平方数构成\n        //dp[i] = Math.Min(dp[i],dp[i-j*j]+1);\n        int[] dp = new int[n+1];\n        Arrays.fill(dp,Integer.MAX_VALUE);\n        dp[0] = 0;\n        for(int i=1;i*i&lt;=n;i++)&#123;\n            int x = i*i;\n            for(int j = x;j&lt;=n;j++)&#123;\n                dp[j] = Math.min(dp[j],dp[j-x]+1);\n            &#125;\n        &#125;\n        return dp[n];\n    &#125;\n&#125;\n\n标签：动态规划\n首先初始化长度为 n+1 的数组 dp，每个位置都为 0\n如果 n 为 0，则结果为 0\n对数组进行遍历，下标为 i，每次都将当前数字先更新为最大的结果，即 dp[i]=i，比如 i=4，最坏结果为 4=1+1+1+1 即为 4 个数字\n动态转移方程为：dp[i] = MIN(dp[i], dp[i - j * j] + 1)，i 表示当前数字，j*j 表示平方数\n时间复杂度：O(n*sqrt(n))O(n∗sqrt(n))，sqrt 为平方根\nclass Solution &#123;\n    public int numSquares(int n) &#123;\n        //dp[i] 表示当前数字i最少由几个完全平方数构成\n        //dp[i] = Math.Min(dp[i],dp[i-j*j]+1);\n        int[] dp = new int[n+1];\n        for(int i=1;i&lt;=n;i++)&#123;\n            dp[i] = i; //每次最坏的情况就是+1\n            for(int j = 1;i-j*j>=0;j++)&#123;\n                dp[i] = Math.min(dp[i],dp[i-j*j]+1);\n            &#125;\n        &#125;\n        return dp[n];\n    &#125;\n&#125;\n\n\n","slug":"背包dp","date":"2022-06-11T13:26:26.264Z","categories_index":"数据结构","tags_index":"数据结构,算法","author_index":"小李不在_"},{"id":"546eab39c80ef1d176f6354aacd8516e","title":"290场周赛","content":"\n1.6041. 多个数组求交集\nclass Solution &#123;\n    public List&lt;Integer> intersection(int[][] nums) &#123;\n        List&lt;Integer> list = new ArrayList&lt;>();\n        int[] res = new int[1001];\n        for(int[] num:nums)&#123;\n            for(int i=0;i&lt;num.length;i++)&#123;\n                res[num[i]]++;\n            &#125;\n        &#125;\n        for(int i=0;i&lt;res.length;i++)&#123;\n            if(res[i]==nums.length)&#123;\n                list.add(i);\n            &#125;\n        &#125;\n        return list;\n    &#125;\n&#125;\n\n\n\n2.6042. 统计圆内格点数目模拟，圆包括的最大范围内\nclass Solution &#123;\n    public int countLatticePoints(int[][] circles) &#123;\n        int maxX = 0, maxY = 0, minX = Integer.MAX_VALUE, minY = Integer.MAX_VALUE;\n        for (int[] c : circles) &#123;\n            minX = Math.min(minX, c[0] - c[2]);\n            minY = Math.min(minY, c[1] - c[2]);\n            maxX = Math.max(maxX, c[0] + c[2]);\n            maxY = Math.max(maxY, c[1] + c[2]);\n        &#125;\n        int res = 0;\n        for (int i = minX; i &lt;= maxX; i++) &#123;\n            for (int j = minY; j &lt;= maxY; j++) &#123;\n                for (int[] c : circles) &#123;\n                    int tmp = (i - c[0]) * (i - c[0]) + (j - c[1]) * (j - c[1]);\n                    if (tmp &lt;= c[2] * c[2]) &#123;\n                        res++;\n                        break;\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n        return res;\n    &#125;\n&#125;\n\n\n\n36043. 统计包含每个点的矩形数目\nclass Solution &#123;\n    public int[] countRectangles(int[][] rectangles, int[][] points) &#123;\n        //哈希表key为高度，List为宽度的集合。\n        HashMap&lt;Integer, List&lt;Integer>> map = new HashMap&lt;>();\n        for (int[] rectangle : rectangles) &#123;\n            int l = rectangle[0];\n            int h = rectangle[1];\n            List&lt;Integer> list = map.getOrDefault(h, new ArrayList&lt;>());\n            list.add(l);\n            map.put(h, list);\n        &#125;\n        //由于需要对宽度的列表使用二分法，所以需要排序。\n        for (int key : map.keySet()) &#123;\n            Collections.sort(map.get(key));\n        &#125;\n        int[] ans = new int[points.length];\n        for (int i = 0; i &lt; points.length; i++) &#123;\n            int[] p = points[i];\n            int x = p[0];\n            int y = p[1];\n            int count = 0;\n            //本题重点，枚举可能的高度，并找到当前高度下，合法的矩形数量。\n            for (int h = 100; h >= 1; h--) &#123;\n                //枚举高度已经比point的高度还小了，不可能再找到合法矩形了。\n                if (h &lt; y) break;\n                //不存在以当前h为高度的矩形，跳过。\n                if (!map.containsKey(h)) continue;\n                //二分搜索，并累加答案\n                count += binarySearch(map.get(h), x);\n            &#125;\n            ans[i] = count;\n        &#125;\n        return ans;\n\n    &#125;\n\n    public int binarySearch(List&lt;Integer> nums, int k) &#123;\n        //二分法找nums中有多少元素大于等于k。\n        int n = nums.size();\n        int left = 0;\n        int right = n - 1;\n        while (left &lt; right) &#123;\n            int mid = left + (right - left) / 2;\n            if (nums.get(mid) >= k) &#123;\n                right = mid;\n            &#125; else &#123;\n                left = mid + 1;\n            &#125;\n        &#125;\n        return nums.get(right) >= k ? n - right : 0;\n    &#125;\n&#125;\n\n\n\n46044. 花期内花的数目\nclass Solution &#123;\n    public int[] fullBloomFlowers(int[][] flowers, int[] persons) &#123;\n        List&lt;Integer> in = new ArrayList&lt;>();\n        List&lt;Integer> out = new ArrayList&lt;>();\n        for (int[] f : flowers) &#123;\n            in.add(f[0]);\n            out.add(f[1]);\n        &#125;\n        in.sort((o1, o2) -> o1 - o2);\n        out.sort((o1, o2) -> o1 - o2);\n        int[] res = new int[persons.length];\n        for (int i = 0; i &lt; persons.length; i++) &#123;\n            int left = 0,right=in.size()-1;\n            int cnt = 0;\n            //计算开花数量\n            while(left&lt;right)&#123;\n                int mid = left+(right-left+1)/2;\n                if(in.get(mid)>persons[i])&#123;\n                    right = mid-1;\n                &#125;else&#123;\n                    left = mid;\n                &#125;\n            &#125;\n            if(in.get(left)&lt;=persons[i])&#123;\n                cnt+=(left+1);\n            &#125;\n            //计算凋谢数量\n            left = 0;\n            right = out.size()-1;\n            while(left&lt;right)&#123;\n                int mid = left+(right-left+1)/2;\n                if(out.get(mid)>=persons[i])&#123;\n                    right = mid-1;\n                &#125;else&#123;\n                    left = mid;\n                &#125;\n            &#125;\n            if(out.get(left)&lt;persons[i])&#123;\n                cnt-=(left+1);\n            &#125;\n            res[i] = cnt;\n        &#125;\n        return res;\n    &#125;\n    \n&#125;\n","slug":"290场周赛","date":"2022-06-11T13:26:26.256Z","categories_index":"数据结构","tags_index":"数据结构,算法,周赛","author_index":"小李不在_"},{"id":"c18469ab20e7b093d36b4a61728d07eb","title":"并查集","content":"\nclass Solution &#123;\n    public double[] calcEquation(List&lt;List&lt;String>> equations, double[] values, List&lt;List&lt;String>> queries) &#123;\n        int equationsSize = equations.size();\n        UnionFind unionFind = new UnionFind(2 * equationsSize); //最大需要两倍空间（每个list有两个字母）\n        //第一步，预处理，将变量的值与id进行映射，使得并查集的底层用数组实现，方便编码\n        Map&lt;String, Integer> map = new HashMap&lt;>(2 * equationsSize);//初始化map将字母关系转化为数字\n        int id = 0; //对应values中索引和映射字母\n        for (int i = 0; i &lt; equationsSize; i++) &#123;\n            List&lt;String> equation = equations.get(i);\n            String var1 = equation.get(0);\n            String var2 = equation.get(1);\n            if (!map.containsKey(var1)) &#123;\n                map.put(var1, id++);\n            &#125;\n            if (!map.containsKey(var2)) &#123;\n                map.put(var2, id++);\n            &#125;\n            //并查询查询之前执行一次合并操作\n            unionFind.union(map.get(var1), map.get(var2), values[i]);\n        &#125;\n        //第二步  做查询\n        int queriesSize = queries.size();\n        double[] res = new double[queriesSize];\n        for (int i = 0; i &lt; queriesSize; i++) &#123;\n            String var1 = queries.get(i).get(0);\n            String var2 = queries.get(i).get(1);\n            //得到需要查询的字母对应的id\n            Integer id1 = map.get(var1);\n            Integer id2 = map.get(var2);\n            if (id1 == null || id2 == null) &#123;\n                res[i] = -1.0;\n            &#125; else &#123;\n                //两个节点都存在，则转化为和父节点的关系进行比较\n                res[i] = unionFind.isConnected(id1, id2);\n            &#125;\n        &#125;\n        return res;\n    &#125;\n\n    class UnionFind &#123;\n        private int[] parent; //表示每个节点对应的父节点的id\n        private double[] weight; //表示节点指向父节点的权值\n\n        public UnionFind(int n) &#123;\n            this.parent = new int[n];\n            this.weight = new double[n];\n            //初始化，所有的父节点开始都是指向自己\n            for (int i = 0; i &lt; n; i++) &#123;\n                parent[i] = i;\n                weight[i] = 1.0d;\n            &#125;\n        &#125;\n\n        /**\n         * 合并操作\n         *\n         * @param x，y   两个节点\n         * @param value 有向边的权值\n         */\n        public void union(int x, int y, double value) &#123;\n            //找到两个节点对应的父节点\n            int rootx = find(x);\n            int rooty = find(y);\n            if (rootx == rooty) &#123;\n                return;\n            &#125;\n            parent[rootx] = rooty;\n            weight[rootx] = weight[y] * value / weight[x];\n        &#125;\n\n        /**\n         * 路径压缩\n         *\n         * @param id 输入节点的id\n         * @return 根节点的id\n         */\n        private int find(int id) &#123;\n            if (id != parent[id]) &#123;\n                //根据上一次节点的权值来更新当前节点的权值\n                int preNode = parent[id];\n                parent[id] = find(parent[id]);\n                weight[id] *= weight[preNode];\n            &#125;\n            return parent[id];\n        &#125;\n\n        public double isConnected(int x, int y) &#123;\n            int rootX = find(x);\n            int rootY = find(y);\n            if (rootX == rootY) &#123;\n                return weight[x] / weight[y];\n            &#125; else &#123;\n                //说明不在一个集合中\n                return -1;\n            &#125;\n        &#125;\n    &#125;\n&#125;\nhot100-除法求值\n","slug":"并查集","date":"2022-06-11T13:26:26.256Z","categories_index":"数据结构","tags_index":"数据结构,算法","author_index":"小李不在_"},{"id":"779600de7239585350eddc687c9afdbb","title":"CAS","content":"CAS与volatileCAS — compareAndSet()，内部实现了原子性（）\npublic void withdraw(Integer amount) &#123;\n    // 需要不断尝试，直到成功为止\n    while (true) &#123;\n        // 比如拿到了旧值 1000\n        int prev = balance.get();\n        // 在这个基础上 1000-10 = 990\n        int next = prev - amount;\n         /*\n         compareAndSet 正是做这个检查，在 set 前，先比较 prev 与当前值\n         - 不一致了，next 作废，返回 false 表示失败\n         比如，别的线程已经做了减法，当前值已经被减成了 990\n         那么本线程的这次 990 就作废了，进入 while 下次循环重试\n         - 一致，以 next 设置为新值，返回 true 表示成功\n         */\n        if (balance.compareAndSet(prev, next)) &#123;\n            break;\n        &#125;\n    &#125;\n&#125;\n\n其实 CAS 的底层是 lock cmpxchg 指令（X86 架构），在单核 CPU 和多核 CPU 下都能够保证【比较-交\n换】的原子性。\n在多核状态下，某个核执行到带 lock 的指令时，CPU 会让总线锁住，当这个核把此指令执行完毕，再\n开启总线。这个过程中不会被线程的调度机制所打断，保证了多个线程对内存操作的准确性，是原子的。\n\nvolatile\n获取共享变量时，为了保证变量的可见性，需要使用volatile修饰\n它可以用来修饰成员变量和静态成员变量，他可以避免线程从自己的工作缓存中查找变量的值，必须到主存中获取它的值，线程操作volatile变量都是直接操作主存，即一个线程对volatile变量的修改，对另一个线程可见\nCAS必须借助volatile才能读取到共享变量的最新值来实现【比较并交换】的效果\n\n\n为什么无锁效率高:无锁情况下，即使重试失败，线程始终在高速运行，没有停歇，而 synchronized 会让线程在没有获得锁的时候，\n发生上下文切换，进入阻塞。\n但无锁情况下，因为线程要保持运行，需要额外 CPU 的支持，CPU 在这里就好比高速跑道，没有额外的跑\n道，线程想高速运行也无从谈起，虽然不会进入阻塞，但由于没有分到时间片，仍然会进入可运行状态，还\n是会导致上下文切换。\n\n\nCAS的特点：结合CAS和volatile可以实现无锁并发，适用于线程少，多核CPU的场景下\nCAS是基于乐观锁的思想\nsynchronized是基于悲观锁的思想\nCAS体现的是无锁并发、无阻塞并发\n因为没有使用synchronized，所以线程不会进入阻塞，这是效率提升的因素之一\n\n但如果竞争激烈，重试必然会频繁发生，反而效率会受到影响\n\n","slug":"CAS","date":"2022-06-11T13:20:41.435Z","categories_index":"JUC","tags_index":"JUC,java,多线程","author_index":"小李不在_"},{"id":"8719a59ea15091ad0c2facf954842244","title":"java内存模型(JMM)","content":"java内存模型(JMM)java内存模型：JMM即java Memory Model，它定义了内存、工作内存抽象概念、底层对CPU寄存器、缓存、硬件内存、CPU指令优化等\nJMM体现在以下几个方面：​\t1.原子性：保证指令不会受到线程上下文切换的影响\n​\t2.可见性：保证指令不会受到CPU缓存的影响\n​\t3.有序性：保证指令不会受到CPU指令并行优化的影响\n\n可见性：存在的问题：\nmain 线程对 run 变量的修改对于 t 线程不可见，导致了 t 线程无法停止：\nstatic boolean run = true;\npublic static void main(String[] args) throws InterruptedException &#123;\n Thread t = new Thread(()->&#123;\n while(run)&#123;\n // ....\n &#125;\n &#125;);\n t.start();\n sleep(1);\n run = false; // 线程t不会如预想的停下来\n&#125;\n\n程序不会停止\n1.初始状态， t 线程刚开始从主内存读取了 run 的值到工作内存\n\n2.因为 t 线程要频繁从主内存中读取 run 的值，JIT 编译器会将 run 的值缓存至自己工作内存中的高速缓存中，\n减少对主存中 run 的访问，提高效率\n\n3.1 秒之后，main 线程修改了 run 的值，并同步至主存，而 t 是从自己工作内存中的高速缓存中读取这个变量\n的值，结果永远是旧值\n\n\n解决：\n添加volatile修饰符：（只能保证可见性，不能保证原子性）注意：\n想要保证原子性还需要使用synchronized或者ReentrantLock\nsynchronized也可以保证可见性，但是性能比较低，底层依赖于monitar\n它可以用来修饰成员变量和静态成员变量\n他可以避免线程从自己的工作缓存中查找变量的值，必须到主存中获取它的值，线程操作 volatile 变量都是直接操作主存\n\n\n有序性：JVM会在不影响正确性的前提下，可以调整语句的执行顺序\n重排序可能导致程序的运行结果与预期结果不一致\n使用volatile可以禁止掉重排序\n\nvolatile原理volatile的底层实现原理是内存屏障，Memory Barrier（Memory Fence）\n对volatile变量的写指令后会加入写屏障\n\n对volatile变量的读指令之前会加入读屏障\n\n\n1.如何保证可见性：写屏障(sfence)保证在该屏障之前的，对共享变量的改动，都同步到主存当中，而不是使用缓存中的数据\npublic void actor(I_Result r) &#123;\n    num = 2;\n    ready = ture; //ready 是volatile赋值带写屏障\n    //写屏障\n&#125;\n\n读屏障(ifence)保证在该屏障之后，对共享变量的读取，加载的是主存中最新数据，而不是使用缓存中的数据\npublic void actor(I_Result r)&#123;\n    //读屏障\n    //ready 是volatile读取值带读屏障\n    if(ready) &#123;\n        r,r1 = num + num;\n    &#125;else&#123;\n        r.r1 = 1;\n    &#125;\n&#125;\n\n\n\n\n2.如何保证有序性：写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后\n读屏障会确保指令重排序时，不会将读屏障之后的代码排在读屏障之前\n\nhappens-before规则：happens-before规定了对共享变量的写操作对其他线程的读操作可见，它是可见性与有序性的一套规则总结，抛开以下happens-before规则，JMM并不能保证一个线程对共享变量的写，对于其他线程对该共享变量的读可见\n\n1.线程解锁m之前对变量的写，对于接下来对m加锁的其他线程对该变量的读可见static int x;\nstatic Object m = new Object();\n\nnew Thread(()->&#123;\n    synchronized(m)&#123;\n        x = 10;\n    &#125;\n&#125;,\"t1\").start();\n\nnew Thread(()->&#123;\n    synchronized(m)&#123;\n        System.out.println(x);\n    &#125;\n&#125;,\"t2\").start();\n\n\n2.线程对volatile变量的写，对接下来其他线程对该变量的读可见volatile static int x;\n\nnew Thread(()->&#123;\n \tx = 10;\n&#125;,\"t1\").start();\n\nnew Thread(()->&#123;\n \tSystem.out.println(x);\n&#125;,\"t2\").start();\n\n\n3.线程start前对变量的写，对该线程开启后对该变量的读可见static int x;\nx = 10;\n\nnew Thread(()->&#123;\n \tSystem.out.println(x);\n&#125;,\"t2\").start();\n\n\n4.线程结束前对变量的写，对其它线程得知它结束后的读可见（比如其他线程调用isAlive或join等待它结束）static int x;\n\nThread t1 = new Thread(()->&#123;\n \tx = 10;\n&#125;,\"t1\");\n\nt1.start();\nt1.join();\n\nSystem.out.println(x);\n\n\n5.线程t1打断t2前对变量的写，对于其他线程得知t2被打断后对变量的读可见static int x;\npublic static void main(String[] args) &#123;\n    \n Thread t2 = new Thread(()->&#123;\n \twhile(true) &#123;\n \t\tif(Thread.currentThread().isInterrupted()) &#123;\n \t\t\tSystem.out.println(x);\n \t\t\tbreak;\n \t\t&#125;\n \t&#125;\n &#125;,\"t2\");\n    \n t2.start();\n    \n new Thread(()->&#123;\n \tsleep(1);\n \tx = 10;\n \tt2.interrupt();\n &#125;,\"t1\").start();\n    \n while(!t2.isInterrupted()) &#123;\n \tThread.yield();\n &#125;\n System.out.println(x);\n&#125;\n\n\n6.对变量默认值(0，false，null)的写操作，对其他线程对该变量的读可见\n7.具有传递性volatile static int x;\nstatic int y;\n\nnew Thread(()->&#123;\n \ty = 10;\n \tx = 20;\n&#125;,\"t1\").start();\n\nnew Thread(()->&#123;\n \t// x=20 对 t2 可见, 同时 y=10 也对 t2 可见\n \tSystem.out.println(x);\n&#125;,\"t2\").start();","slug":"java内存模型(JMM)","date":"2022-06-11T13:15:23.102Z","categories_index":"JUC","tags_index":"JUC,java,多线程","author_index":"小李不在_"},{"id":"489d7b6b150f5087fe22abf19dc56ce1","title":"wait/notify，join，park/Unpark","content":"wait&#x2F;notify，join，park&#x2F;Unparkwait&#x2F;notify的原理：\n1.Owner发现线程条件不满足，调用wait方法，即可进入WaitSet变为WAITING状态\n2.BLOCKED和WAITING的线程都处于阻塞状态，不占用CPU时间片\n3.BLOCKED线程会在Owner线程释放锁时唤醒\n4.WAITING线程会在Owner线程调用notify或notifyAll时唤醒，但唤醒后并不意味着立即所得锁，仍需要进入EntryList重新竞争\n\n\nAPI介绍：1.obj.wait()：让进入object监视器的线程到waitSet等待\n2.obj.wait(long timeout)：让进入object监视器的线程到waitSet等待，属性值为最长等待时间\n3.obj.notify()：让object上正在waitSet等待的线程中挑一个唤醒\n4.obj.notifyAll()：让Object上正在waitSet等待的线程全部唤醒\n它们都是线程之间进行写作的手段，都是Object对象的方法，必须获得此对象的锁才能调用方法\n\n\nwait和notify的正确使用：\n1.sleep(long n)和wait(long n)的区别：①：sleep是Thread的方法，而wait是Object的方法\n②：sleep不需要强制和synchronized配合使用，但是wait需要和synchronized一起使用\n③：sleep在睡眠的同时，不会释放对象锁，但是wait在等待的时候会释放对象锁\n④：它们的状态都会变为TIMED_WAITING\n\njoin原理:join的底层使用到了保护性暂停的设计模式\n源码：\npublic final synchronized void join(long millis)\n    throws InterruptedException &#123;\n    \t//记录最初时间\n        long base = System.currentTimeMillis();\n    \t//记录已经经历的时间\n        long now = 0;\n\t\t//传入的时间小于0，抛异常\n        if (millis &lt; 0) &#123;\n            throw new IllegalArgumentException(\"timeout value is negative\");\n        &#125;\n\t\t//等于0就是一直等待，调用wait(0)\n        if (millis == 0) &#123;\n            while (isAlive()) &#123;\n                wait(0);\n            &#125;\n        &#125; else &#123;\n            while (isAlive()) &#123;\n                //delay表示传入的参数减去已经经历的时间，小于0就结束\n                long delay = millis - now;\n                if (delay &lt;= 0) &#123;\n                    break;\n                &#125;\n                //将delay设置为参数，防止唤醒错误的问题\n                wait(delay);\n        \t\t//判断已经经历的时间\n                now = System.currentTimeMillis() - base;\n            &#125;\n        &#125;\n    &#125;\n\n\n保护性暂停的设计模式：\n\npark、Unpark1.基本使用：\n它们是LockSupport类中的方法\nLockSupport.park()； &#x2F;&#x2F;暂停当前线程\nLockSupport.unpark(暂停线程对象);   &#x2F;&#x2F;恢复某个线程的运行\n注意：\nunpark可以在一个线程调用park方法之前使用，等该线程调用park方法后会立即恢复运行\n\n与wait和notify比较1.wait,notify和notifyAll 必须配合Object Monitor一起使用(即先获取到对象锁)，而unpark不用\n\n2.park和unpark是以线程为单位来阻塞和唤醒线程，而notify只能随机唤醒一个等待的线程\n\n3.park和unpark可以先unpark，但是wait和notify不能先notify\n\n\n原理：每个线程都有自己的一个Parker对象(底层有C实现)，由三部分组成 _counter _cond _nutex\n线程就像一个旅行者，Parker就像它随身携带的背包，条件变量就像背包中的帐篷，_counter就像背包中的备用粮食(0为耗尽，1为充足)\n调用park就是要看是否需要休息\n​\t如果备用粮食充足则不需要休息\n​\t如果备用粮食耗尽就需要休息\n调用unpark就好比让备用粮食处于充足状态\n​\t如果此时线程在休息，就唤醒它\n​\t如果此时线程正在运行，那么它下次调用park方法，仅消耗掉备用粮食，不需要休息\n​\t因为背包空间有限，多次调用unpark仅仅会补充一份备用粮食\n","slug":"waitnotify，join，parkUnpark","date":"2022-06-11T13:10:26.016Z","categories_index":"JUC","tags_index":"JUC,java,多线程","author_index":"小李不在_"},{"id":"de5cee1035d10664a305cb1a74a3c58a","title":"ReentrantLock原理","content":"\nReentrantLock原理：\n\n1.非公平锁的实现原理：\n加锁解锁流程：先从构造器来看，默认为非公平锁实现\npublic ReentrantLock() &#123;\n\tsync = new NonfairSync();\n&#125;\n\nNonfairSync 继承自 AQS\n\n没有竞争时：\n\n第一个竞争出现时（state表示是否被加锁）\n\nThread-1 执行流程1.CAS尝试将state从0改为1，结果失败了\n2.进入tryAcquire方法，重新尝试，此时state已经是1，结果仍然失败\n3.进入addWaiter方法，构造Node队列\n①：图中黄色三角表示Node的wautStatus状态，默认为0正常状态\n\n②：Node的创建是懒惰的\n\n③：第一个Node称为Dummy（哨兵），用来占位，不关联线程\n\n\n\n当前线程进入acquireQueued方法1.acquireQueued方法会在一个死循环中不断尝试获取锁，失败后就会被park阻塞\n\n2.如果自己是在哨兵node下一个，就会再次进入tryAcquire方法尝试获取锁，此时state仍为1，失败\n\n3.进入shouldParkAfterAcquore方法，将前去node的waitStatus改为-1，返回false\n\n\n4.shouldParkAfterFailedAcquire方法执行完毕回到acquireQueued方法，再次tryAcquire尝试获得锁，此时state还是1，获取失败\n\n5.当再次进入 shouldParkAfterFailedAcquire 时，此时因为i其前驱node的waitState已经是-1，此时返回true\n\n6.进入parkAndCheckInterrupt，Thread-1被park阻塞(图中用灰色表示)\n\n\n\n再次有多个线程经历上述过程竞争失败，变成这个样子\n\n当Thread-0释放锁，则进入tryRelease方法：1.设置exclusiveOwnerThread为null--表示当前没有线程持有锁\n\n2.设置state为0\n\n\n等待队列不为null，并且前驱节点的waitStatus &#x3D; -1，则进入unparkSuccessor方法\n找到队列中距离head最近的一个Node，unpark让其恢复运行，本例中为Thread-1\n回到Thread-1的acquireQueued方法\n\n\n若加锁成功（没有竞争），则：exclusiveOwnerThread为Thread-1，state值为1\n\nhead指向刚刚Thread-1所在的Node，并将Thread-1刚刚所在的Node清空Thread(不关联线程)\n\n原本的前驱节点从链表中断开，被垃圾回收\n\n\n如果此时有新的线程来进行竞争**(非公平的体现)**\n则可能又被Thread-4占据锁资源\nThread-4被设置为exclusiveOwnerThread，state = 1\n\nThread-1再次进入acquireQueued方法，若尝试获取锁失败，则进入等待队列被park\n\n\n\n2.可重入原理：static final class NonfairSync extends Sync &#123;\n    // ...\n    // Sync 继承过来的方法, 方便阅读, 放在此处\n    final boolean nonfairTryAcquire(int acquires) &#123;\n        final Thread current = Thread.currentThread();\n        int c = getState();\n        if (c == 0) &#123;\n            if (compareAndSetState(0, acquires)) &#123;\n                setExclusiveOwnerThread(current);\n                return true;\n            &#125;\n        &#125;\n        // 如果已经获得了锁, 线程还是当前线程, 表示发生了锁重入\n        else if (current == getExclusiveOwnerThread()) &#123;\n            // state++\n            int nextc = c + acquires;\n            if (nextc &lt; 0) // overflow\n                throw new Error(\"Maximum lock count exceeded\");\n            setState(nextc);\n            return true;\n        &#125;\n        return false;\n    &#125;\n\n    // Sync 继承过来的方法, 方便阅读, 放在此处\n    protected final boolean tryRelease(int releases) &#123;\n        // state--\n        int c = getState() - releases;\n        if (Thread.currentThread() != getExclusiveOwnerThread())\n            throw new IllegalMonitorStateException();\n        boolean free = false;\n        // 支持锁重入, 只有 state 减为 0, 才释放成功\n        if (c == 0) &#123;\n            free = true;\n            setExclusiveOwnerThread(null);\n        &#125;\n        setState(c);\n        return free;\n    &#125;\n&#125;\n\n\n总结：当再次分配到资源时，因为自己之前就已经拿到了锁，则会让state自增，当解锁时让state自减\n\n\n3.可打断原理\n① 不可打断模式：在此模式下，即使被其他线程打断(interrupt方法)，仍会驻留在AQS队列中，等待获取到锁之后才能继续运行(是继续运行，只是将打断标记设置为true)\n\n② 可打断模式：当被其他线程调用interrupt方式时抛出异常\n\n\n4.公平锁实现原理：与非公平锁的区别就是，调用公平锁的方法会先判断AQS等待队列中是否前驱节点，没有等待的线程才会去调用cas方法竞争锁\n\n\n5.条件变量的实现原理：每个条件变量其实就对应着一个等待队列，其实现类是 ConditionObject\n\nawait流程：开始 Thread-0 持有锁，调用 await，进入 ConditionObject 的 addConditionWaiter 方法\n创建新的 Node 状态为 -2（Node.CONDITION），关联 Thread-0，加入等待队列尾部\n\n接下来进入 AQS 的 fullyRelease 方法，释放同步器上的锁\n\nunpark AQS 队列中的下一个节点，竞争锁，假设没有其他竞争线程，那么 Thread-1 竞争成功\n\npark 阻塞 Thread-0\n\n\n\nsignal流程：假设 Thread-1 要来唤醒 Thread-0\n\n进入 ConditionObject 的 doSignal 方法，取得等待队列中第一个 Node，即 Thread-0 所在 Node\n\n执行 transferForSignal 方法，将该 Node 加入 AQS 队列尾部，将 Thread-0 的 waitStatus 改为 0，Thread-3 的waitStatus 改为 -1\n\nThread-1 释放锁，进入 unlock 方法\n","slug":"ReentrantLock","date":"2022-06-11T13:07:20.302Z","categories_index":"JUC","tags_index":"JUC,java,多线程","author_index":"小李不在_"},{"id":"e1b3118af0455ea0158a80d4d6b7a3a6","title":"synchronized关键字","content":"\n\n\nsynchronized 解决方案\n互斥为了避免临界区的竞态条件发生，有多种手段可以达到目的。\n阻塞式的解决方案：synchronized，Lock\n\n非阻塞式的解决方案：原子变量\n\nsynchronized，来解决上述问题，即俗称的【对象锁】，它采用互斥的方式让同一时刻至多只有一个线程能持有\n【对象锁】，其它线程再想获取这个【对象锁】时就会阻塞住。这样就能保证拥有锁的线程可以安全的执行临界区\n内的代码，不用担心线程上下文切换\nsynchronized实际上是用对象锁保证了临界区内代码的原子性，临界区内的代码是不可分割的，不会被线程切换所打断\n\n\n考察synchronized锁住的是哪个对象1.锁住的是n1-（this）\n@Slf4j(topic = \"c.Number\")\nclass Number&#123;\n public synchronized void a() &#123;\n log.debug(\"1\");\n &#125;\n public synchronized void b() &#123;\n log.debug(\"2\");\n &#125;\n&#125;\npublic static void main(String[] args) &#123;\n Number n1 = new Number();\n new Thread(()->&#123; n1.a(); &#125;).start();\n new Thread(()->&#123; n1.b(); &#125;).start();\n&#125;\n\n2.若synchronized加在静态方法上，则锁住的是当前类的运行时类对象（.class）\n\n\n变量的线程安全分析：\n1.成员变量和静态变量是否线程安全？如果它们没有被共享，则是线程安全的\n如果它们被共享了，根据它们的状态是否能被改变，又分为两种情况\n如果只有读操作，则线程安全\n\n如果有读写操作，则这段代码是临界区，需要考虑线程安全\n\n\n2.局部变量是否线程安全局部变量是线程安全的\n但局部变量引用的对象则未必\n如果该对象没有逃离方法的作用访问。它是线程安全的\n\n如果该对象逃离方法的作用范围，需要考虑线程安全（如使用return）\n\n\n3.线程安全的多个方法组合在一起不一定线程安全，需要在组合方法上添加线程安全保护\n4.不可变类线程安全如String、Integer都是不可变类，内部的状态不可变，因此线程安全\n\n\njava对象的结构：\n1.对象头：①：Mark Word：hashcode、分代年龄、状态、加锁状态位\n\n②：Klass word：类型指针（什么类型的对象）\n\n\n2.对象体：成员变量的信息\n\n\nJava 对象头：以 32 位虚拟机为例\n\n64 位虚拟机 Mark Word\n\n\nMonitor概念Monitor被翻译为监视器或者管程\n每个Java对象都可以关联一个Monitor对象，如果使用synchronized给对象上锁（重量级）之后，该对象头的Mark Word中就被设置指向Monitor的指针\nMonitor结构如下:\n\n1.刚开始Monitor种Owner为null\n2.当Thread-2执行synchronized(obj) 就会将Monitor的所有者Owner置为Thread-2，Monitor种只能有一个Owner\n3，在Thread-2上锁的过程种，如果Thread-3，4，5也来执行synchronized(obj) ，就会进入EntryList BLOCKED\n4.Thread-2执行完同步代码块的内容，然后唤醒EntryList种的等待线程来竞争锁，竞争是非公平的\n5.图中WaitSet种的Thread-0，Thread-1是之前获得过锁，当条件不满足WAITING状态的线程，后面讲wait-notify\n时分析\n**注意：**\n\nsynchronized必须时进入同一个monitor才有上述效果\n\n不加synchronized的对象不会关联监视器，不遵从以上规则\n\n\nsynchronized原理进阶：\n轻量级锁：使用场景：如果一个对象虽然有多线程访问，但多线程访问的时间是错开的（也就是没有竞争），那么可以使用轻量级锁\n轻量级锁对使用者是透明的，语法仍然为synchronized\n1.创建锁记录(Lock Record)，每个线程的栈帧都会包含一个锁的记录，内存可以存储锁对象的Mark Word\n\n\n2.让锁记录中Object reference 指向锁对象，并且尝试用cas替换Object中的Mark Word，将Mark Word的值存入锁记录（若Mark Word值已经被其他线程所修改则替换失败）\n\n\n3.如果cas替换成功，对象头中存储了锁记录地址和状态 00，表示由该线程给对象加锁\n\n\n\n如果cas失败：1.其他线程已经持有了该Object的轻量级锁，此时表明有竞争，进入锁膨胀过程\n\n2.如果是自己执行了synchronized锁重入，那么再添加一条Lock Record作为重入的计数&lt;br /&gt;![1646820022734.png](https://cdn.nlark.com/yuque/0/2022/png/26737039/1647331695203-2b372579-5ee7-4efc-ae87-c2252e2679c6.png#clientId=u46ad077f-3ef3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=ui&amp;id=lrT5o&amp;margin=%5Bobject%20Object%5D&amp;name=1646820022734.png&amp;originHeight=359&amp;originWidth=597&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=109184&amp;status=done&amp;style=none&amp;taskId=u75c465ef-1c37-456f-8a81-ec82f3f14d3&amp;title=)\n\n\n解锁：1.当退出synchronized代码块(解锁时) 如果有取值为null的锁记录，表示有重入，这时重置锁记录，表示重入计数减1\n\n\n2.当退出synchronized代码块时，锁记录的值不为null，这是使用cas将Mark Word的值恢复给对象头\n\n    成功，则解锁成功\n\n    失败，说明轻量级锁进行了锁膨胀或已经升级为重量级锁，进入重量级锁解锁流程\n\n\n\n2.锁膨胀：如果在尝试加轻量级锁的过程中，CAS操作无法成功，这时一种情况就是有其他线程为此对象加上了轻量级锁(有竞争)，这时需要进行锁膨胀，将轻量级锁变为重量级锁\n\n1.当Thread-1进行轻量级加锁时，Thread-0已经对该对象加了轻量级锁\n\n2.这时Thread-1加轻量级锁失败，进入锁膨胀流程①：即为Object对象申请Monitor锁，让Object指向重量级锁地址（后两位数字变为10）\n\n②：然后自己进入Monitor的EntryList BLOCKED\n\n\n\n3.当Thread-0退出同步块解锁时，使用cas将Mark Word的值恢复给对象头，失败，这时会进入重量级解锁流程：即按照Monitor地址找到Monitor对象，将Owner设置为null，唤醒EntryList中的BLOCKED线程\n\n3.自旋优化：（比较适合多核CPU）重量级锁竞争的时候，还可以使用自旋来进行优化，如果当前线程自旋成功（即这时候持有锁线程已经退出了同步块，释放了锁），这时当前线程就可以避免阻塞 (阻塞会发生上下文切换，消耗性能)\n自旋成功的情况：\n\n自旋失败的情况：\n\n注意：\n1.在java6之后自旋锁是自适应的，比如对象刚刚的一次自选操作成功过，那么认为这次自旋成功的可能性会高，就会多自旋几次；反之，就是少自旋甚至不自旋，比较只能\n2.自旋会占用CPU时间，单核CPU自旋就是浪费，多核CPU自旋才能发挥优势\n3.java 7 以后不能控制是否开启自旋功能\n\n\n4.偏向锁：轻量级锁在没有竞争时(就自己这个线程)，每次重入仍然需要执行CAS操作（性能损耗）\njava6中引入了偏向锁来做进一步优化：只有第一次使用CAS将线程ID设置到对象的Mark Word头，之后发现这个线程ID是自己的就没有表示竞争，不用重新CAS。以后只要不发生竞争，这个对象就归该线程所有\n\n\n4.1 偏向状态：回忆对象头格式：\n\n一个对象创建时：\n1.如果开启了偏向锁(默认开启)，那么对象创建后，markword值的后三位为101(biased_lock字段表示是否开启偏向锁，1为开启)，此时他的thread、epoc、age都为0\n\n2.偏向锁是默认延迟的，不会在程序启动时立即生效，如果想避免延迟，可以加参数来禁用延迟\n\n3.如果没有开启偏向锁，那么对象创建后，markword值为001，此时他的hashcode、age、都为0，第一次用到hashcode时才会赋值\n\n4.处于偏向锁的对象解锁后，线程id仍存储于对象头中\n\n注意：\n当我们的程序本身就是线程很多，那么偏向锁就不适用，可以通过参数来禁用：\n\n添加VM参数： -xx:-UseBiasedLocking来禁用偏向锁\n\n\n4.2 撤销偏向锁—调用对象的hashcode方法当我们调用对象的hashcode方法就会禁用掉偏向锁\n原因：通过对象头的结构可知，Mark Word 的空间是有限的，当我们开启偏向锁，就会存储线程id，而没有空间存储hashcode，所以我们调用hashcode方法，就会关闭偏向锁，清除掉线程id替换为hashcode\n\n为什么轻量级锁和重量级锁不会有上述问题？\n轻量级锁会存储在线程栈帧的锁记录中\n重量级锁会将hashcode存储在Monitor对象中，解锁时再进行还原\n只有偏向锁没有额外的空间，所以会有上述问题\n\n\n4.3 撤销偏向锁—其他线程使用对象当其他线程使用偏向锁对象时，会将偏向锁升级为轻量级锁\n\n4.4 撤销偏向锁—调用wait&#x2F;notify只有重量级锁才有这两个方法，所以调用会将偏向锁或轻量级锁转换为重量级锁\n\n4.5 批量重偏向如果对象虽然被多个线程访问，但是没有竞争，这时偏向了线程T1的对象仍有机会重新偏向T2，重偏向会重置对象的Thread ID(线程ID)\n当撤销偏向锁的阈值超过了20次，jvm会觉得是不是偏向错了呢？于是会给在这些对象加锁时重新偏向至加锁线程\n\n4.6 批量撤销当撤销偏向锁的阈值超过了40次，jvm会觉得自己偏向错了，根本就不该偏向，就会把整个类的所有对象变为不可偏向的，新建的对象也是不可偏向的\n\n5.锁消除java运行时有一个JIT即时编译器，会对java字节码进一步优化，反复运行的代码超过一定的阈值就会进行即时优化，当发现变量不会存在线程安全问题，JIT就会把多余的synchronized去掉\n\n\n6.锁的粗化public void test1()&#123;\n     for(int i=0;i&lt;1000;i++)&#123;\n         synchronized(Test.class)&#123;\n             sout(\"hello\");\n         &#125;\n     &#125;\n&#125;\n锁粗化后：扩大锁的范围，避免反复加锁和释放锁\npublic void test1()&#123;\n     synchronized(Test.class)&#123;\n         for(int i=0;i&lt;1000;i++)&#123;\n             sout(\"hello\");\n         &#125;\n     &#125;\n&#125;\n","slug":"synchronized关键字","date":"2022-06-11T12:58:01.936Z","categories_index":"JUC","tags_index":"JUC,java,多线程","author_index":"小李不在_"},{"id":"dffb2abec4fa02f1174c155cbd8d7f1a","title":"java线程","content":"java线程\n创建和启动线程1.new Thread：public static void test1() &#123;\n       Thread t = new Thread() &#123;\n           //执行的方法\n           @Override\n           public void run() &#123;\n               log.debug(\"running\");\n           &#125;\n       &#125;;\n       //命名线程\n       t.setName(\"t1\");\n       //启动线程\n       t.start();\n   &#125;\n\n\n2.使用Runnable配合Thread（将需要执行的任务与创建线程分离，更灵活）public static void main(String[] args) &#123;\n   Runnable r = new Runnable() &#123;\n       @Override\n       public void run() &#123;\n          log.debug(\"running\");\n       &#125;\n   &#125;;\n    Thread t = new Thread(r, \"t2\");\n    t.start();\n&#125;\n\n\n原理：Thread和Runnable的关系方法一：实际上是手动重写了run方法，就会执行子类的run方法\n方法二：在构造器中传入一个Runnable实例，内部在初始化方法将runnable实例赋值给了Thread中的一个成员变量。Thread类中的Run方法会判断runnable对象是否为null，不为null就运行Thread的run方法\n\n总结：方法一就是把线程和任务合并，方法二就是把线程和任务分开了\n\n用Runnable更容易与线程池等高级API配合\n\n用Runnable让任务脱离了Thread继承体系，更灵活\n\n\n3.FutureTask 配合 ThreadFutureTask 能够接收 Callable 类型的参数，用来处理有返回结果的情况\npublic static void main(String[] args) throws Exception &#123;\n    // 创建任务对象\n    FutureTask&lt;Integer> task3 = new FutureTask&lt;>(() -> &#123;\n        log.debug(\"hello\");\n        return 100;\n    &#125;);\n    // 参数1 是任务对象; 参数2 是线程名字，推荐\n    new Thread(task3, \"t3\").start();\n    // 主线程阻塞，同步等待 task 执行完毕的结果\n    Integer result = task3.get();\n    log.debug(\"结果是:&#123;&#125;\", result);\n&#125;\n\n\n查看进程线程的方法\nwindows任务管理器可以查看进程和线程数，也可以用来杀死进程tasklist 查看进程taskkill 杀死进程\n\nlinuxps -fe 查看所有进程ps -fT -p  查看某个进程（PID）的所有线程kill 杀死进程top 按大写 H 切换是否显示线程top -H -p  查看某个进程（PID）的所有线程\n\nJavajps 命令查看所有 Java 进程jstack  查看某个 Java 进程（PID）的所有线程状态jconsole 来查看某个 Java 进程中线程的运行情况（图形界面）\njconsole 远程监控配置需要以如下方式运行你的 java 类\njava -Djava.rmi.server.hostname=`ip地址` -Dcom.sun.management.jmxremote -\nDcom.sun.management.jmxremote.port=`连接端口` -Dcom.sun.management.jmxremote.ssl=是否安全连接 -\nDcom.sun.management.jmxremote.authenticate=是否认证 java类\n\n修改 &#x2F;etc&#x2F;hosts 文件将 127.0.0.1 映射至主机名如果要认证访问，还需要做如下步骤复制 jmxremote.password 文件修改 jmxremote.password 和 jmxremote.access 文件的权限为 600 即文件所有者可读写连接时填入 controlRole（用户名），R&amp;D（密码）\n\n线程运行原理栈与栈帧：JVM中由堆，栈，方法区所组成，其中栈内存就是给线程使用的，每个线程启动后，虚拟机就会为其分配一块栈内存\n每个栈由多个栈帧组成，对应着每次方法调用所占用的内存\n\n每个线程只能有一个活动栈帧，对应着当前正在执行的方法\n\n\n线程上下文切换：从使用CPU到不使用CPU的状态就是一次上下文切换\n因为以下一些原因导致 cpu 不再执行当前的线程，转而执行另一个线程的代码\n线程的 cpu 时间片用完\n\n垃圾回收\n\n有更高优先级的线程需要运行\n\n线程自己调用了 sleep、yield、wait、join、park、synchronized、lock 等方法\n\n当 Context Switch 发生时，需要由操作系统保存当前线程的状态，并恢复另一个线程的状态，Java 中对应的概念就是程序计数器（Program Counter Register），它的作用是记住下一条 jvm 指令的执行地址，是线程私有的\n状态包括程序计数器、虚拟机栈中每个栈帧的信息，如局部变量、操作数栈、返回地址等\n\nContext Switch 频繁发生会影响性能\n\n\n常见方法：\n1.start 和 run：start()：启动一个新线程，在新的线程运行 run 方法中的代码\n\n**注意：**start 方法只是让线程进入就绪，里面代码不一定立刻运行（CPU 的时间片还没分给它）。每个线程对象的start方法只能调用一次，如果调用了多次会出现IllegalThreadStateException\n\nrun()：新线程启动后会调用的方法\n\n如果在构造 Thread 对象时传递了 Runnable 参数，则线程启动后会调用 Runnable 中的 run 方法，否则默认不执行任何操作。但可以创建 Thread 的子类对象，来覆盖默认行为\n\n\n2.sleep和yield：sleep\n\n1.调用sleep会让当前线程从Running进入Timed Waiting状态**（阻塞）**\n\n2.其他线程使用interrupt方法打断正在睡眠的线程，此时sleep方法会抛出InterrupedException\n\n3.睡眠结束后的线程未必会立即执行\n\n4.建议使用TimeUnit的sleep代替Thread的sleep来获得更好的可读性\n\nyield\n\n1.调用yield会让当前线程从Running进入Runnable**就绪**状态，然后调度执行其他线程\n\n2.具体的实现依赖于操作系统的任务调度器（可能没有其他线程，调用yield后还是会分给当前线程）\n\n\n区别：操作系统的时间调度器可以将cpu分配给就绪状态的线程，但是不能分配给阻塞状态的线程\n\n3.优先级：setPriority() 默认为5 范围是1-10\n4.join：等待调用join的线程运行结束join可以有参数，表示最多等待的时间（毫秒）\n线程的同步（需要等待结果的返回）\n\n\n5.interrupt：打断正在运行的线程打断 sleep，wait，join 的线程会重置打断标记为false\nisInterrupted():可以获取打断标记，正常运行的线程并不会直接被打断，可通过打断标记判断，若被打断则结束线程\ninterrupted():判断完是否被打断之后，会清楚打断标记（true-&gt;false）\n\n多线程设计模式之两阶段终止：T1线程‘’优雅的‘’终止线程T2   优雅：给T2一个做其他事情的机会（通过我们写的代码）\n\n错误思路\n使用线程对象的 stop() 方法停止线程stop 方法会真正杀死线程，如果这时线程锁住了共享资源，那么当它被杀死后就再也没有机会释放锁，其它线程将永远无法获取锁\n\n\n使用 System.exit(int) 方法停止线程目的仅是停止一个线程，但这种做法会让整个程序都停止\n\n\n两阶段终止模式：\n\n6.不推荐使用的方法这些方法已过时，容易破坏同步代码块，造成线程死锁\nstop() \t\t\t\t\t\t停止线程运行\nsuspend() \t\t\t\t挂起（暂停）线程运行\nresume() \t\t\t\t\t恢复线程运行\n\n主线程和守护线程setDaemon(true)：表示为守护线程  \t默认为false\n当主线程结束后。守护线程会被强制结束\njava中垃圾回收器就是一种守护线程\nTomcat中的Acceptor个Poller线程都是守护线程，所以Tomcat接收到shutdown命令后，不会等待它们处理完当前请求\n\n线程的5种状态：这是从操作系统层面来描述的\n初始状态：仅在语言层面创建了线程对象，还未与操作系统线程关联\n可运行状态：（就绪状态）指该线程已经被创建（与操作系统线程关联），可由CPU调度执行\n运行状态：指获取了CPU时间片运行中的状态\n当CPU时间片用完，会从运行状态转换至可运行状态，会导致线程的上下文切换\n\n阻塞状态：\n如果调用了阻塞API，比如BIO读写文件，这时该线程实际上不会用到CPU，会导致线程上下文切换，进入阻塞状态\n\n等BIO操作完毕，会由操作系统唤醒阻塞的线程，转换至【可运行状态】\n\n与【可运行状态】的区别是，对于阻塞状态的线程来说，只要它们一直不唤醒，调度器就不会考虑它们\n\n终止状态：表示线程已经执行完毕，生命周期已经结束，不会再转换为其他状态\n\n线程的6种状态\n根据Thread State枚举类的描述，进行分类\n\nNEW：线程刚被创建，但是还没调用start()方法\nRUNNABLE：当调用了start()方法之后，java API层面的RUNNABLE状态涵盖了操作系统层面的[可运行状态]，\n[运行状态]、[阻塞状态]（由于BIO导致的线程阻塞，在Java里无法区分，认为是可运行的）\nBLOCKED ， WAITING ， TIMED_WAITING：都是 Java API 层面对【阻塞状态】的细分，后面会在状态转换一节\n详述\nTERMINATED：当线程代码运行结束\n","slug":"java线程","date":"2022-06-11T12:49:10.748Z","categories_index":"JUC","tags_index":"JUC,java,多线程","author_index":"小李不在_"},{"id":"6ce63568dd0197dd5234fafddc6d369d","title":"进程线程并行并发","content":"\n进程和线程：\n进程：资源分配的最小单位程序由指令和数据组成，但这些指令需要运行，数据要读写，就必须将指令加载到CPU，数据加载至内存。在指令运行过程种还须需要用到磁盘，网络等设备。进程就是用来加载指令，管理内存，管理IO的\n\n当一个程序被运行，从磁盘加载这个程序的代码到内存种，这时就开启了一个进程\n\n进程可以理解为程序的一个实例。大部分程序可以同时运行多个进程（如记事本，浏览器等）但也有的程序只能启动一个线程（qq音乐等）\n\n\n线程：java中最小的调度单位一个进程内可以分为一到多个线程\n\n一个线程就是一个指令流，将指令流种的一条条指令以一定的顺序交给CPU执行\n\njava中，线程作为最小调度单位，进程作为资源分配的最小单位，在Windows中进程是不活动的，只是作为线程的容器\n\n\n对比：1.进程基本上是相互独立的，而线程存在于进程内，是进程的一个子集\n\n2.进程拥有共享的资源，如内存空间，仅其内部的线程共享\n\n3.进程之间的通信较为复杂\n\n    ①.同一台计算机的进程通信称为IPC\n\n    ②.不同的计算机之间的进程通信，需要通过网络，遵守共同的协议，如HTTP\n\n4.线程的通信相对简单，因为他们共享进程内的内存，一个例子就是多个线程可以访问同一个共享变量\n\n5.线程更加轻量，线程上下文切换成本一般要比进程上下文成本低\n\n\n并行和并发：单核CPU下，线程实际上还是串行执行的，操作系统中有一个组件叫做任务调度器，将cpu的时间片（很短）分给不同的线程使用，由于cpu在线程间的切换很快，人类感觉是同时运行的，总结就是：微观穿行，宏观并行\n\n一般会将这种线程轮流使用CPU的做法称为并发，concurrent\n多核CPU下，每个核都可以调度运行线程，这时候线程是并行的\n并发：同一时间应对多件事情的能力\n\n\n并行：同一时间动手去做多件事情的能力\n\n\n应用之异步调用\n同步：需要等待结果返回，才能继续运行\n异步：不需要等待结果返回就能继续运行\n1) 设计多线程可以让方法执行变为异步的（即不要巴巴干等着）比如说读取磁盘文件时，假设读取操作花费了 5 秒钟，如果没有线程调度机制，这 5 秒 cpu 什么都做不了，其它代码都得暂停…\n\n2) 结论比如在项目中，视频文件需要转换格式等操作比较费时，这时开一个新线程处理视频转换，避免阻塞主线程tomcat 的异步 servlet 也是类似的目的，让用户线程处理耗时较长的操作，避免阻塞 tomcat 的工作线程ui 程序中，开线程进行其他操作，避免阻塞 ui 线程\n","slug":"进程线程并行并发","date":"2022-06-11T12:36:30.645Z","categories_index":"JUC","tags_index":"JUC,java,多线程","author_index":"小李不在_"},{"id":"c1f6d722cc4602038235f2e7924e8ff2","title":"MySQL事务","content":"事务\n事务的基础知识：在MySQL中只有InnoDB存储引擎支持事务\n\n1.数据库事务的概述：事务是数据库区别于文件系统的重要特征之一，当我们有了事务就会让数据库始终保持一致性，同时我们还可以通过事务的机制恢复到某个时间点\n\n\n基本概念：事务：是一组逻辑单元，使数据从一种状态转换到另一种状态\n事务处理原则：保证所有事务作为一个工作单元来执行，即使出现了故障都不能改变这种执行方式，一个事务中执行多个操作，要么都被提交，要么全部放弃，回滚到最初的状态\n如：转账操作就是一个事务，不能让钱的总额改变\n\n事务的ACID特征：\n1.原子性原子性指事务是一个不可分割的工作单位，要么全部提交，要么全部失败回滚\n\n\n2.一致性一致性是指事务在执行前后，数据从一个合法性状态，变换到另一个合法性的状态（满足实际规定）\n\n例如：A有100元，去取钱不能多余100元（因为规定钱不能为负数）\n\n            A给B转账，要保证A和B的余额总数转账前后相同\n\n\n3.隔离性指一个事务的执行不能被其他事务干扰，即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的过程中各个事务之间不能互相干扰\n\n\n4.持久性一旦事务进行了提交，则对数据的改变是永久性的，不会被接下来的其他操作影响\n\n持久性是通过事务日志来保证的，日志包括了重做日志和回滚日志，当我们通过事务对数据进行修改的时候，首先会将数据库的变化信息记录到重做日志中，然后再对数据库中对应的行进行修改，这样的好处是，即使数据库宕机，数据库重启后也能找到没有更新到数据库中的重做日志，重新执行，从而使事务具有持久性\n\n总结：ACID是事务的四大特征，原子性是基础，隔离性是手段，一致性是约束条件，而持久性是我们的目的\n数据库事务其实就是数据库操作者为了方便，把需要保证原子性，隔离性，一致性，持久性的一个或多个数据库操作成为一个事务\n\n事务的状态活动的：事务对应的数据库操作正在执行中\n部分提交：事务操作执行完成，还未刷盘将数据保存到磁盘\n失败的：事务处于活动或部分提交状态时，遇到了一些错误导致事务停止执行\n中止的：当事务一部分变为失败的状态，回滚到之前的状态，回滚完毕后成为事务中止的\n提交的：一个处于部分提交的状态通过修改过的数据同步到磁盘上\n\n\n如何使用事务？\n事务的完整过程：1.开启事务\n2.一系列的DML操作\n3.事务的状态：（事务结束）\n    提交：COMMIT\n\n    中止：ROLLBACK\n\n\n1.显式事务使用关键字开启事务（两种方式）\n\n    start transaction （使用该方式可以设置是否只读？可以读写（默认read write）？一致性读？）\n\n    begin\n\n保存点（savepoint）可以控制回滚到保存点而不是回滚到最初状态\n\n\n2.隐式事务关键字：autocommit（自动提交）\n默认开启自动提交的状态下，我们的每一个DML操作都是一个隐式事务，会自动提交\n如果我们显式的开启了事务，那么DML操作就不会自动提交数据\n\n隐式提交数据的情况：1.数据定义语言（DDL）CREATE、ALTER、DROP等操作\n2.使用或修改MySQL数据库中的表，如：ALTER USER、CREATE USER等\n3.事务控制或关于锁定的语句\n当一个事务还没进行提交或回滚操作时，又显式的开启了一个事务，那么会隐式提交上一个事务\n\n当前的autocommit系统变量的值为OFF，手动变为ON会隐式提交前面语句的事务\n\n使用LOCK TABLES等关于锁定语句也会隐式提交前面语句所属的事务\n\n4.加载数据的语句\n使用LOAD DATA语句来批量向数据库中导入数据时，也会隐式的提交前面语句所属的事务\n\n5.关于MySQL复制的一些语句\n使用START SLAVE、STOP SLAVE、RESET SLAVE等语句也会隐式的提交前面语句所属的事务\n\n6.一些其他语句\n使用ANALYZE TABLE（分析表） 检查表，优化表等操作也会隐式的提交前面语句所属的事务\n\n\n\n数据并发问题：\n1.脏写对于两个事务A，B，如果事务A修改了另一个事务B修改过的数据，那就说明发生了脏写\n\n\n2.脏读事务A读取了已经被事务B更新但还未提交的数据，如果事务B进行回滚，那么A读取的内容就是临时且无效的\n\n\n3.不可重复读事务A读取了一个字段，然后事务B更新了该字段，之后事务A再次进行读取，发现数据改变了\n\n\n4.幻读事务A从一个表中读取了一个字段，然后事务B在该表中插入了一些新的行，之后事务A再次读取同一个表，就会多出几行\n\n\n事务的隔离级别：（隔离级别越高，并发性越差）1.读未提交：解决脏写\n2.读已提交：解决脏读、脏写\n3.可重复读：解决脏写，脏读，不可重复读 （MySQL默认）\n4.可串行化：均解决\n\n事务日志：事务的隔离性是由锁机制实现\n而事务的原子性，一致性，持久性由事务的redo日志undo日志来保证\nREDO LOG 重做日志，提供再写入操作，恢复提交事务修改的页操作，用来保证事务的持久性\n\nUNDO LOG  回滚日志，回滚行记录到某个特定版本，用来保证事务的原子性和一直性\n\n\n\nREDO日志的优点和特点：优点：\n1.redo日志降低了刷盘频率\n\n2.redo日志占用的空间非常小\n\n特点：\n\nredo日志是顺序写入磁盘的在执行事务的过程中，每执行一条语句，就可能产生若干条redo日志，这些日志是按照产生的顺序写入磁盘的，也就是使用顺序IO，效率比随机IO快\n\n\n事务执行过程中，redo log 不断记录redo log是存储引擎层产生的，而bin log是数据库层产生的，在一个事务执行过程中，一直不断的向redo log顺序记录，而bin log直到事务提交才会一次性写入bin log文件中\n\n\nUNDO日志undo log 的产生也会伴随着redo log的产生，因为undo log也需要持久性的保护\n\n作用：1.回滚数据\n2.MVCC\n","slug":"事务","date":"2022-06-11T12:25:00.191Z","categories_index":"MySQL","tags_index":"MySQL,事务","author_index":"小李不在_"},{"id":"55817b11714364db5e90bcd7c8c20421","title":"MySQL中的锁","content":"\nMySQL中的锁在数据库中，除传统的计算资源（如CPU、RAM、I&#x2F;O等）的争用以外，数据也是一种供许多用户共享的资源。为保证数据的一致性，需要对 并发操作进行控制 ，因此产生了 锁 。同时 锁机制 也为实现MySQL的各个隔离级别提供了保证。 锁冲突也是影响数据库并发访问性能的一个重要因素。所以锁对数据库而言显得尤其重要，也更加复杂。\n\n并发问题的解决方案：1.读操作利用MVCC(多版本并发控制)，写操作进行加锁\n2.读写均进行加锁（读-写  彼此需要排队执行，影响性能）\n\n分类：\n\n1.从数据操作类型分类：读锁、写锁：读锁：也称共享锁。或S锁 针对同一份数据，多个事务的读操作可以同时进行而不会互相影响也不会互相阻塞\n\n写锁：也称排他锁。或X锁 当前写操作没完成前，会阻断其他写锁和读锁，确保给定的时间中，只有一个事务可以执行\n\n注意：对于InnoDB来说，读锁和写锁可以加在表上，也可以加在行上，MyISAM不能加在行上\n\n2.从数据操作的粒度划分：表级锁，页级锁，行锁为了尽可能的提高数据库的并发度，每次锁定的数据的范围越小越好，理论上每次只锁定当前操作的数据的方案会得到最大的并发度，但是管理锁很耗费资源，因此数据库系统需要在高并发响应和系统性能两个方面进行平衡，这就是锁粒度的概念\n\n表锁：锁定整张表，是MySQL最基本的锁策略，可以避免死锁，但是并发量大大降低\n\n① 表级别的S锁和X锁（不建议在InnoDB中使用）\n② 意向锁：不需要显示的添加InnoDB支持多粒度锁，允许行级锁和表级锁共存\n1.意向锁的存在是为了协调行锁和表锁的关系，支持多粒度（表锁和行锁）的锁共存\n2.意向锁是一种不与行级锁冲突的表级锁\n3.表明某个事务正在某些行持有了锁或者该事务准备去持有锁\n\n意向锁分为两种：1.意向共享锁：事务有意对表中的某些行加共享锁\n\n2.意向排他锁：事务有意对表中的某些行加排他锁\n\n\n意向锁需要解决的问题：如果我们给某一行数据加了排他锁，数据库会自动给更大一级的空间，比如数据页或数据表加上意向锁，告诉其他人这个数据页或数据表已经有人上过排他锁了\n\n③ 自增锁（保证主键唯一性）\n④ 元数据锁（MDL锁）：不需要显示的添加当对一个表做增删改查操作的时候，加MDL读锁，当要对表结构变更操作的时候，加MDL写锁\n\nInnoDB中行锁：只在存储引擎层实现优点：锁的力度小，发生锁冲突的概率低，可以实现高并发\n缺点：对于锁的开销比较大，加锁会比较慢，容易出现死锁\nInnoDB与MyISAM最大的区别：一是支持事务，二是支持行级锁\n\n① 记录锁：仅仅把一条记录锁上（同样有S和X两种锁）\n② 间隙锁（gap锁）：仅仅为了方式插入幻影记录，出现幻读，在某个区间范围加锁\n间隙锁可能会导致死锁两个事务锁定了统一个范围，就会导致均不能对该范围进行操作\n\n\n③ 临键锁：相当于前两种锁的合体，相当于给间隙锁加上一个闭区间\n④ 插入意向锁：一个事务在插入一条记录的时候需要判断一下插入的位置是否被别的事务加了gap锁，若有则需要等待，直到那一个事务进行提交,但是InnoDB规定事务在等待的时候页需要在内存中生成一个锁结构，就是插入意向锁\n\n插入意向锁是一种gap锁，并不是意向锁，在insert操作时产生\n\n\n页锁：页锁的开销介于表锁和行锁之间，也会出现死锁，并发度一般\n\n\n3.从对待锁的态度分类：乐观锁和悲观锁（两种设计思想，并不是具体实现）\n\n\n悲观锁（Pessimistic Locking）悲观锁是一种思想，顾名思义，就是很悲观，对数据被其他事务的修改持保守态度，会通过数据库自身的锁机制来实现，从而保证数据操作的排它性。悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会 阻塞 直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁，当其他线程想要访问数据时，都需要阻塞挂起。Java中 synchronized 和 ReentrantLock 等独占锁就是悲观锁思想的实现。\n\n\n\n乐观锁（Optimistic Locking）乐观锁认为对同一数据的并发操作不会总发生，属于小概率事件，不用每次都对数据上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，也就是不采用数据库自身的锁机制，而是通过程序来实现。在程序上，我们可以采用 版本号机制 或者 CAS机制 实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量。在Java中 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁begin;select * from student where id &lt;&#x3D;8 and id &gt; 3 for update;的一种实现方式：CAS实现的。\n\n乐观锁的版本号机制在表中设计一个 版本字段 version ，第一次读的时候，会获取 version 字段的取值。然后对数据进行更新或删除操作时，会执行 UPDATE … SET version&#x3D;version+1 WHERE version&#x3D;version 。此时如果已经有事务对这条数据进行了更改，修改就不会成功。\n\n乐观锁的时间戳机制时间戳和版本号机制一样，也是在更新提交的时候，将当前数据的时间戳和更新之前取得的时间戳进行比较，如果两者一致则更新成功，否则就是版本冲突。你能看到乐观锁就是程序员自己控制数据并发操作的权限，基本是通过给数据行增加一个戳（版本号或者时间戳），从而证明当前拿到的数据是否最新。\n\n\n\n两种锁的适用场景从这两种锁的设计思想中，我们总结一下乐观锁和悲观锁的适用场景：\n乐观锁 适合 读操作多 的场景，相对来说写的操作比较少。它的优点在于 程序实现 ， 不存在死锁问题，不过适用场景也会相对乐观，因为它阻止不了除了程序以外的数据库操作。\n悲观锁 适合 写操作多 的场景，因为写的操作具有 排它性 。采用悲观锁的方式，可以在数据库层面阻止其他事务对该数据的操作权限，防止 读 - 写 和 写 - 写 的冲突\n\n4.按照加锁的方式进行划分：显式锁和隐式锁\n5.全局锁锁定整个数据库，当你需要让整个数据库处于只读状态，其他线程的DML和DDL操作会被阻塞，全局锁的典型使用场景是：做全库逻辑备份\n\n6.死锁两个事务都持有对方需要的锁，并且在等待对方释放，并且双方都不会释放自己的锁\n如何处理死锁？\n1.等待，直到超时（可以设置超时时间）\n2.死锁的检测机制（wait-for grap算法）\n\n如何避免死锁：1.合理设计索引，是业务SQL尽可能通过索引定位更少的行，减少锁竞争\n2.调整业务逻辑SQL执行顺序，避免更新&#x2F;删除长时间持有锁的SQL在事务前面\n3.避免大事务，可以将大事务拆分成多个小事务来进行处理，小事务缩短锁定资源的时间，发生锁冲突的几率更小\n4.在并发比较高的系统中，不要显示的加锁，特别是在事务中显示加锁\n5.降低隔离级别\n\n结构解析：\n\n锁所在的事务信息 ：不论是 表锁 还是 行锁 ，都是在事务执行过程中生成的，哪个事务生成了这个 锁结构 ，这里就记录这个事务的信息。此 锁所在的事务信息 在内存结构中只是一个指针，通过指针可以找到内存中关于该事务的更多信息，比方说事务id等。 \n索引信息 ：对于 行锁 来说，需要记录一下加锁的记录是属于哪个索引的。这里也是一个指针。 \n表锁／行锁信息 ：表锁结构 和 行锁结构 在这个位置的内容是不同的：表锁：记载着是对哪个表加的锁，还有其他的一些信息。行锁：记载了三个重要的信息：Space ID ：记录所在表空间。Page Number ：记录所在页号。n_bits ：对于行锁来说，一条记录就对应着一个比特位，一个页面中包含很多记录，用不同的比特位来区分到底是哪一条记录加了锁。为此在行锁结构的末尾放置了一堆比特位，这个n_bits 属性代表使用了多少比特位。n_bits的值一般都比页面中记录条数多一些。主要是为了之后在页面中插入了新记录后也不至于重新分配锁结构 \ntype_mode ：这是一个32位的数，被分成了 lock_mode 、 lock_type 和 rec_lock_type 三个部分，如图所示：\n\n锁的模式（ lock_mode ），占用低4位，可选的值如下：LOCK_IS （十进制的 0 ）：表示共享意向锁，也就是 IS锁 。LOCK_IX （十进制的 1 ）：表示独占意向锁，也就是 IX锁 。LOCK_S （十进制的 2 ）：表示共享锁，也就是 S锁 。LOCK_X （十进制的 3 ）：表示独占锁，也就是 X锁 。LOCK_AUTO_INC （十进制的 4 ）：表示 AUTO-INC锁 。在InnoDB存储引擎中，LOCK_IS，LOCK_IX，LOCK_AUTO_INC都算是表级锁的模式，LOCK_S和LOCK_X既可以算是表级锁的模式，也可以是行级锁的模式。锁的类型（ lock_type ），占用第5～8位，不过现阶段只有第5位和第6位被使用：LOCK_TABLE （十进制的 16 ），也就是当第5个比特位置为1时，表示表级锁。LOCK_REC （十进制的 32 ），也就是当第6个比特位置为1时，表示行级锁。行锁的具体类型（ rec_lock_type ），使用其余的位来表示。只有在 lock_type 的值为LOCK_REC 时，也就是只有在该锁为行级锁时，才会被细分为更多的类型：LOCK_ORDINARY （十进制的 0 ）：表示 next-key锁 。LOCK_GAP （十进制的 512 ）：也就是当第10个比特位置为1时，表示 gap锁 。LOCK_REC_NOT_GAP （十进制的 1024 ）：也就是当第11个比特位置为1时，表示正经 记录锁 。LOCK_INSERT_INTENTION （十进制的 2048 ）：也就是当第12个比特位置为1时，表示插入意向锁。其他的类型：还有一些不常用的类型我们就不多说了。is_waiting 属性呢？基于内存空间的节省，所以把 is_waiting 属性放到了 type_mode 这个32位的数字中：LOCK_WAIT （十进制的 256 ） ：当第9个比特位置为 1 时，表示 is_waiting 为 true ，也就是当前事务尚未获取到锁，处在等待状态；当这个比特位为 0 时，表示 is_waiting 为false ，也就是当前事务获取锁成功。\n\n其他信息 ：为了更好的管理系统运行过程中生成的各种锁结构而设计了各种哈希表和链表。 \n一堆比特位 ：如果是 行锁结构 的话，在该结构末尾还放置了一堆比特位，比特位的数量是由上边提到的 n_bits 属性表示的。InnoDB数据页中的每条记录在 记录头信息 中都包含一个 heap_no 属性，伪记录 Infimum 的heap_no 值为 0 ， Supremum 的 heap_no 值为 1 ，之后每插入一条记录， heap_no 值就增1。 锁结构 最后的一堆比特位就对应着一个页面中的记录，一个比特位映射一个 heap_no ，即一个比特位映射到页内的一条记录。\n\n","slug":"MySQL中的锁","date":"2022-06-11T12:23:16.177Z","categories_index":"MySQL","tags_index":"MySQL","author_index":"小李不在_"},{"id":"70425fba86b2c28266d9c33de675b2d8","title":"索引优化与查询优化","content":"索引优化与查询优化哪些维度可以进行数据库调优？\n1.索引失效、没有充分利用索引 — 建立索引\n2.关联查询太多join（设计缺陷或不得已的需求） – sql优化\n3..服务器调优及各个参数设置（缓冲，线程数等） – 调整my.cnf\n4.数据过多 – 分库分表\nsql查询优化的大体方向 —\n物理查询优化：通过索引和表连接等奇数来进行优化\n\n逻辑查询优化：通过SQL等价变换提升查询效率，也就是换一种查询写法\n\n关联查询优化：\n情况一：左外连接\n情况二：内连接内连接中若只能有一个字段有索引，则被驱动表的字段有索引成本较低\n对于内连接中，在两个表的连接条件都存在索引的情况下，会选择数据少的表作为驱动表（小表驱动大表）\n均没有索引也符合\t小表驱动大表的规则\n\n总结：小的结果集驱动大的结果集（过滤之后的表的行数*每行的大小，并不是表中的总数据）\n为被驱动表匹配的条件增加索引（减少内层表的循环匹配次数）\n增大join buffer size的大小（一次缓存的数据越多，那么内层包的扫描的次数就越少）\n减少驱动表不必要的字段的查询（字段越少，join buffer 缓存的数据就越多）\nMySQL8.0新特性：废弃了之前的BNLJ 加入hash join且默认使用\n\n\n排序优化：问题：在where条件字段上添加索引，为什么还要在order by 字段上添加索引呢？\n在MySQL中支持两种排序方式，分别是filesort和index方式（filesort比较耗时间）\nindex排序中，索引可以保证数据的有序性，不需要再次进行排序，效率更高\n\nfilesort排序一般在内存中进行，占用的CPU过多，如果待排序的结果较大，会产生临时文件io到磁盘进行排序，效率低\n\n\n优化建议：1.SQL中，可以在where语句和order by 语句中使用到索引，目的是避免where的全表扫描和order by的File Sort排序，但是在某些极端的情况下，也有不使用索引可能比使用索引的效率要高\n2.尽量使用index完成order by排序，如果where和order by后面是相同的列就使用单列索引，不同的列就使用联合索引\n3.无法使用index时，需要对FileSort方式进行调优\n\norder by顺序错误也会导致索引失效，也是最左前缀法则\norder by排序方向反了也会导致索引失效（如id升序，age降序）字段的排序方向要相同（都升序或降序）\n数据未进行过滤（where未过滤）导致数据过多可能导致索引失效\n\n总结：1.当两个索引同时存在的时候，MySQL会自动选择最优的方案，但是随着数据量的变化，选择的索引也会随之变化\n2.当范围条件和group by或者order by 的字段出现二选一时，优先观察条件字段的过滤数量，如果过滤的数据足够多，而需要排序的数据并不多时，优先把索引放在范围字段上，反之，同理\n\n\nFileSort算法：双路排序和单路排序排序的字段若不在索引列上，则filesort会有两种算法：双路排序和单路排序\n双路排序 （慢）MySQL 4.1之前是使用双路排序 ，字面意思就是两次扫描磁盘，最终得到数据， 读取行指针和order by列 ，对他们进行排序，然后扫描已经排序好的列表，按照列表中的值重新从列表中读取对应的数据输出\n从磁盘取排序字段，在buffer进行排序，再从 磁盘取其他字段 。\n取一批数据，要对磁盘进行两次扫描，众所周知，IO是很耗时的，所以在mysql4.1之后，出现了第二种改进的算法，就是单路排序。\n单路排序 （快）从磁盘读取查询需要的 所有列 ，按照order by列在buffer对它们进行排序，然后扫描排序后的列表进行输出， 它的效率更快一些，避免了第二次读取数据。并且把随机IO变成了顺序IO，但是它会使用更多的空间， 因为它把每一行都保存在内存中了。\n\n普通索引和唯一索引优化：11.1 查询过程假设，执行查询的语句是 select id from test where k&#x3D;5。对于普通索引来说，查找到满足条件的第一个记录(5,500)后，需要查找下一个记录，直到碰到第一个不满足k&#x3D;5条件的记录。对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。那么，这个不同带来的性能差距会有多少呢？答案是， 微乎其微 。\n11.2 更新过程为了说明普通索引和唯一索引对更新语句性能的影响这个问题，介绍一下change buffer。当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下， InooDB会将这些更新操作缓存在change buffer中 ，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行changebuffer中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。将change buffer中的操作应用到原数据页，得到最新结果的过程称为 merge 。除了 访问这个数据页 会触发merge外，系统有 后台线程会定期 merge。在 数据库正常关闭（shutdown） 的过程中，也会执行merge操作。如果能够将更新操作先记录在change buffer， 减少读磁盘 ，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够 避免占用内存 ，提高内存利用率。唯一索引的更新就不能使用change buffer ，实际上也只有普通索引可以使用。如果要在这张表中插入一个新记录(4,400)的话，InnoDB的处理流程是怎样的？\n11.3 change buffer的使用场景：只能使用于普通索引\n\n普通索引和唯一索引应该怎么选择？其实，这两类索引在查询能力上是没差别的，主要考虑的是对 更新性能 的影响。所以，建议你 尽量选择普通索引 。\n在实际使用中会发现， 普通索引 和 change buffer 的配合使用，对于 数据量大 的表的更新优化还是很明显的。\n如果所有的更新后面，都马上 伴随着对这个记录的查询 ，那么你应该 关闭change buffer 。而在其他情况下，change buffer都能提升更新性能。\n由于唯一索引用不上change buffer的优化机制，因此如果 业务可以接受 ，从性能角度出发建议优先考虑非唯一索引。但是如果”业务可能无法确保”的情况下，怎么处理呢？首先， 业务正确性优先 。我们的前提是“业务代码已经保证不会写入重复数据”的情况下，讨论性能问题。如果业务不能保证，或者业务就是要求数据库来做约束，那么没得选，必须创建唯一索引。这种情况下，本节的意义在于，如果碰上了大量插入数据慢、内存命中率低的时候，给你多提供一个排查思路。然后，在一些“ 归档库 ”的场景，你是可以考虑使用唯一索引的。比如，线上数据只需要保留半年，然后历史数据保存在归档库。这时候，归档数据已经是确保没有唯一键冲突了。要提高归档效率，可以考虑把表里面的唯一索引改成普通索引。\n\n\n其他查询优化策略：\n1.EXISTS 和 IN：具体看表的大小，要符合小表驱动大表的原则\n如\nSELECT * FROM A WHERE id IN (SELECT id FROM B)；——————①\nSELECT * FROM A WHERE EXISTS (SELECT id FROM B WHERE B.id &#x3D; A.id)；——————②\n若A为小表，则使用②EXISTS\n若B为小表，则使用①IN\n\n2.COUNT(*) he COUNT(具体字段)：问：在 MySQL 中统计数据表的行数，可以使用三种方式： SELECT COUNT(*) 、 SELECT COUNT(1) 和SELECT COUNT(具体字段) ，使用这三者之间的查询效率是怎样的？\n答：\n1.COUNT(*)和COUNT(1)都是对所有结果进行COUNT，本质上没有区别，\n①如果使用MyISAM存储引擎，则复杂度为O(1)，因为MyISAM存储引擎中有一个mata信息记录了表中的记录数（row_count）而一致性则由表级锁来保证\n②如果使用InnoDB存储引擎则复杂度为O(n)，因为InnoDB支持事务，采用行级锁和MVCC机制，无法像MyISAM一样维护一个row_count变量，需要全表扫描\n2.在InnoDB存储引擎中，如果采用COUNT(具体字段)来统计数据行数，要尽量使用二级索引，因为主键索引使用的是聚簇索引，包含的信息较多，而对于COUNT(*)和COUNT(1)来说，它们不需要查找具体的行，只是统计行数，系统会自动采用占用空间更小的二级索引来进行统计\n如果存在多个二级索引，则会使用key_len更小的二级索引进行扫描，当没有二级索引的时候，才会使用主键索引来进行统计\n\n3.关于SELECT * FROM 某个表：在表查询中，建议明确字段，不要使用*作为查询的字段列表，推荐使用SELECT 具体字段 来进行查询\n\n原因：①：MySQL在解析的过程中，会通过查询数据字典将  ‘*‘  转换为所有字段的名称，会大大的耗费资源和时间\n②：无法使用覆盖索引\n\n4.LIMIT 1 对优化的影响针对的是会扫描全表的SQL语句，如果你可以确定结果集只有一条，那么加上LIMIT 1 的时候，当找到一条结果的时候就不会继续进行扫描了，这样会加快查询速度\n如果数据表对字段已经建立了唯一索引，那么可以通过索引进行查询，不会对全表进行扫描，那么就不需要再加LIMIT 1\n\n5.多使用COMMIT进行手动提交COMMIT会释放资源：\n​\t1.回滚段上用户恢复数据的信息\n​\t2.被程序语句获得的锁\n​\t3.redo &#x2F; undo log buffer中的空间\n​\t4.管理上述三种资源中的内部花费\n\n索引失效的情况\n全值匹配查询字段与所有的索引一一对应才可以使所有索引都生效\n\n最左前缀法则如由id，name，phone组成的联合索引，只查询name和phone则索引不生效，必须严格按照创建索引的顺序\n\n计算、函数、类型转换（手动或自动）导致索引失效如：EXPLAIN SELECT SQL_NO_CACHE * FROM student WHERE student.name LIKE ‘abc%’;\nEXPLAIN SELECT SQL_NO_CACHE * FROM student WHERE LEFT(student.name,3) &#x3D; ‘abc’;\n使用left则会导致索引失效  原因是不知道name的值，而是把所有的值全取出再去前三个字符，判断是否与abc相等，并不会使用到索引\n\n返回条件右边的列索引失效create index idx_age_name_classid on student(age，classid，name);   &#x2F;&#x2F;创建索引\nEXPLAIN SELECT SQL_NO_CACHE * FROM studentWHERE student.age&#x3D;30 AND student.classId&gt;20 AND student.name &#x3D; ‘abc’ ;\n上述sql name未使用索引（与写的条件的顺序无关 ）\n\n改正：创建索引的时候把name写到返回条件classid的前面create index idx_age_name_classid on student(age,name,classid);\n\n不等于(!&#x3D;或者&lt;&gt;)导致索引失效原因：在B+树中，若查找具体某个值如（where id &#x3D; 1） 则可以精确查找，但是不等于则无法查找，所以不等于会导致索引失效，只能一个一个去查找再判断是否相等\n\nis null可以使用索引，is not null 不能使用索引与上述不等于的情况类似，is null相当于等于某个值（值为null） 而is not null 相当于不等于某个值，不能使用索引判断\n\nlike以通配符%开头导致索引失效如where name like ‘%abc’；\n\nor前后存在非索引的列导致索引失效EXPLAIN SELECT SQL_NO_CACHE * FROM student WHERE age &#x3D; 10 OR classid &#x3D; 100;\n若上述SQL只有age或classid作为索引则会导致索引失效，只有or前后的字段有索引才可以生效\n\n数据库和表的字符集统一不同的字符集进行比较之前需要进行转换，使用到转换函数，导致索引失效\n\n总结：1.对于单列索引，尽量选择针对当前查询过滤性更好的索引\n2.在选择组合索引的时候，当前查询中过滤性最好的索引越靠前越好\n过滤性越好，筛选剩余的数据越少，给后面查询的压力越小\n\n3.在选择组合索引的时候，尽量选择能够包含当前查询中的where子句中更多字段的索引\n4.在选择组合索引的时候，如果某个字段可能出现范围查询时，尽量把这个字段放在索引次序的最后面\n索引（条件）下推：（ICP）例如：\n聚合索引 zipcode_lastname_id\nEXPLAIN SELECT * FROM people\nWHERE zipcode &#x3D; ‘00001’\nAND lastname LIKE ‘%张%’\nAND address LIKE ‘%北京%’\n上述SQL语句就使用到索引下推，lastname的模糊查询导致索引失效，但是优化器并没有在使用完zipcode字段索引后就进行回表去查询数据，而是直接对lastname进行模糊查询，再过滤掉一部分数据后再进行回表，这种情况就叫索引下推（ICP)\n\nICP使用条件：1.ICP可以用于InnoDB和MyISAM表，对于InnoDB表，ICP仅用于二级索引。ICP的目标是减少全行读取次数，从而减少IO操作\n2.当SQL使用覆盖索引时，不支持ICP\n3.相关子查询不能使用ICP\n\n优先考虑覆盖索引1.覆盖索引：一个索引包含了满足查询结果的数据就叫做覆盖索引\n简单来说就是：索引列+主键 包含select 到 from 之间查询的列\n\n好处：1.避免Innodb表进行索引的二次查询（回表）\nInnodb中，二级索引在叶子节点中保存的数据是行的主键信息，如果是用二级索引查询数据，在查到相应的键值后，还需要进行二次查询来获取真实数据\n在覆盖索引中，二级索引的键值可以获取我们需要的数据，避免了对主键的二次查询，减少了IO操作，提升了查询效率\n2.可以把随机IO成顺序IO加快查询效率\n由于覆盖索引是按照键值的顺序存储的，对于IO密集型的范围查找来说，对比随机从磁盘读取每一行的数据IO要少的多，因此利用覆盖索引在访问时也可以把磁盘的随机读取IO转变为顺序IO。\n若不使用覆盖索引，需要进行回表操作，而不同的区可能处于不同的位置，会导致加载更多的磁盘数据\n\n弊端：索引字段的维护需要付出代价，因此在建立冗余索引来支持覆盖索引时就需要权衡考虑\n\n主键的设计：\n1.自增id存在的问题：\n1.可靠性不高：存在自增id回溯的问题，8.0版本进行了修复\n\n\n2.安全性不高对外暴漏的接口可以非常容易的猜测对应的信息，如：user&#x2F;1这样的接口，从而对数据进行爬取\n\n\n3.性能差：自增id的性能差，需要再数据库服务器端生成\n\n4.交互多：业务还需要额外执行一次类似last_insert_id()的函数才能知道刚才插入的自增值，再多进行一次网络交互，在海量的并发系统中，多一条sql就多一次性能的开销\n\n5.局部唯一性：最重要的一点，自增id是局部唯一，只是在当前数据库实例中唯一，而不是全局唯一（在任意服务器间都是唯一的），在分布式系统说是噩梦\n\n2.业务字段作为主键：不太合适1.不能使用会员卡号作为主键\n​\t如果会员卡号不再使用注销了，就可以再给其他人用该卡号，会导致数据库中查询出该卡号的消费信息是上一个人的\n2.身份证号或电话也不能作为主键\n​\t电话注销，手机也存在被运营商收回再利用的情况\n​\t身份证号属于个人隐私，也不能使用\n\n\n设计主键的建议:非核心业务：对应表的主键自增ID 如日志，监控等信息\n核心业务：主键的设计应该是全局唯一且单调自增，全局唯一保证各个系统中都是唯一的，单调递增是希望插入时不影响数据库性能\n\n子查询优化\n子查询执行效率不高的原因：1.执行子查询时，MySQL需要为内层查询语句的查询结果建立一个临时表，然后外层查询语句从临时表中查询记录，查询完毕后再撤销临时表，这样会消耗过多的CPU和IO资源，产生大量慢查询\n2.子查询的结果集存储的临时表，不论是内存临时表还是磁盘临时表都不会存在索引，所以查询性能会受到一定的影响\n3.对于返回结果集比较大的子查询，其对查询性能也有一定的影响\n\n优化：建议在MySQL中使用连接（join）查询来替代子查询，连接查询不需要建立临时表，其速度比子查询要快，而且可以添加索引进一步优化性能\n","slug":"索引优化与查询优化","date":"2022-06-11T12:12:38.267Z","categories_index":"MySQL","tags_index":"MySQL","author_index":"小李不在_"},{"id":"4a36e618a4b7e38da744c1d2baebbf87","title":"范式","content":"\n范式：在关系型数据库中，关于数据表设计的基本原则，规则就成为范式\n目前关系型数据库有六种常见范式，按照范式级别，从低到高分别是：第一范式（1NF）、第二范式（2NF）、第三范式（3NF）、巴斯-科德范式（BCNF）、第四范式(4NF）和第五范式（5NF，又称完美范式）。\n\n数据库的范式设计越高阶，冗余度就越低，同时高阶的范式一定符合低阶范式的要求，最低要求为第一范式\n一般来说，在关系型数据库设计中，最高也就遵循到BCNF(巴斯范式），普遍还是3NF，但也不是绝对，有时候为了提高某些查询性能，我们还需要破坏范式规则，也就是反范式化\n\n第一范式:确保数据表中每个字段的值必须具有原子性，也就是说每个数据表中每个字段的值为不可再次拆分的最小单元数据\n\n第二范式：在满足第一范式的基础上，还要满足数据表中的每一条记录都是可唯一标识的，而且所有的非主键字段，都必须完全依赖主键，不能只依赖主键的一部分\n例如：成绩表中，学号和课程号可以决定成绩，但是学号不能决定成绩，课程号也不能决定成绩，\n所以（学号、课程号）–》成绩  就是完全依赖关系\n\n第三范式：在第二范式的基础上，确保数据表中的每一个非主键字段都和主键字段直接相关，也就是说，要求数据表中的所有非主键字段不能依赖于其他非主键字段\n即：\n不能存在非主键字段A依赖于非主键B，而非主键B又依赖于主键C，即存在A-&gt;B-&gt;C的关系\n\n总结：1.第一范式，确保了每列保持原子性\n2.第二范式，确保了每列都和主键完全依赖\n3.第三范式，确保了每列都和主键列直接相关而不能间接相关（A-&gt;B,B-&gt;C，不能是A-&gt;B-&gt;C）\n优点：数据的标准化有助于消除数据库中的数据冗余，第三范式通常被认为在性能，扩展性和数据完整性方面达到了最好的平衡\n缺点：范式的使用可能会降低查询效率，因为范式的等级越高，设计出来的数据表就越多，越精细，数据的冗余度越低，进行数据查询的时候可能就需要关联多张表，也可能导致一些索引策略失效\n\n\n反范式化：不能只按照范式的要求进行数据库表的设计，要遵循业务优先的原则\n有时候可以考虑适当增加冗余的字段来减少表的关联查询，从而达到对性能优化的效果，增加冗余字段就是反范式化\n\n规范化 vs 性能\n为满足某种商业目标 , 数据库性能比规范化数据库更重要\n在数据规范化的同时 , 要综合考虑数据库的性能\n通过在给定的表中添加额外的字段，以大量减少需要从中搜索信息所需的时间\n通过在给定的表中插入计算列，以方便查询\n\n\n反范式化的新问题：1.存储空间变大了\n2.一个表中字段做了修改，另一个表中冗余的字段也需要同步修改，否则数据不一致\n3.若采用存储过程来支持数据的更新、删除等操作，如果更新频繁会很消耗系统资源\n4.在数据量小的情况下，反范式化不能体现性能的优势，可能还会让数据库表的设计更加复杂\n\n使用场景：当冗余信息有价值或者能大幅度提升查询效率的时候才会使用反范式化\n\n1.增加冗余字段的建议：①：冗余字段不需要经常进行修改\n②：冗余字段查询的时候不可或缺\n\n2.历史快照、历史数据的需要比如订单中的收货人，地址等信息，每次发生的订单收货信息都属于历史数据，需要进行保存，但是用户随时有可能对收货信息进行修改，所以冗余字段的保存是十分必要的\n\n3.数据仓库的设计中通常使用反范式化数据仓库通常用来存储历史信息，对于信息的修改比较少，但是设置冗余字段可能更利于数据分析\n\n4.巴斯范式 BCNF","slug":"范式","date":"2022-06-11T11:53:14.859Z","categories_index":"MySQL","tags_index":"MySQL","author_index":"小李不在_"},{"id":"fdf7bb567823aed005b212decd2fd46a","title":"数据表的设计原则","content":"\n数据表的设计原则：（具体根据实际情况）1.数据表的个数越少越好\n2.数据表中的字段越少越好\n3.数据表中联合主键的字段个数越少越好\n​\t联合主键的字段越多，导致占用的索引空间较大\n4.使用主键和外键越多越好\n​\t此处的外键并不一定是指数据库中的外键，而是指一种业务逻辑关系，表和表字段之间有一对一、一对多的逻辑关系，也可以在业务逻辑层进行实现\n","slug":"数据表的设计原则","date":"2022-06-11T11:53:14.856Z","categories_index":"MySQL","tags_index":"MySQL","author_index":"小李不在_"},{"id":"c027261888329c6d8eabd6851937e11d","title":"MVCC","content":"\n多版本并发控制：MVCC就是通过数据行的多个版本来管理实现数据库的并发控制，这项技术使得在InnoDB的事务隔离级别下执行一直性读操作有了保证，换言之就是为了查询一些正在被另一个事务更新的行，并且可以看到他们被更新之前的值，这样在做查询的时候就不用等待另一个事务释放锁\n\nMVCC的实现依赖于：隐藏字段、Undo Log、ReadViewMySQL中只有InnoDB存储引擎支持MVCC\nMySQL中默认的隔离级别是可重复读，解决了脏读和不可重复读的问题，但是MVCC可以不采用锁机制，而是通过乐观锁的方式来解决不可重复读和幻读的问题！\n\n隐藏字段、Undo Log版本链：trx_id：每次一个事务对某条聚簇索引记录进行改动时，都会把该事务的事务id复制给trx_id隐藏列\nroll_pointer：每次对某条聚簇索引进行改动 时，都会把旧的版本写入undo日志中，这个隐藏列相当于一个指针，可通过它来找到该记录修改之前的信息\n每次对记录进行改动，都会记录一条undo日志，每条undo日志也都有一个 roll_pointer 属性（ INSERT 操作对应的undo日志没有该属性，因为该记录并没有更早的版本），可以将这些 undo日志都连起来，串成一个链表：\n\n对该记录每次更新后，都会将旧值放到一条 undo日志 中，就算是该记录的一个旧版本，随着更新次数的增多，所有的版本都会被 roll_pointer 属性连接成一个链表，我们把这个链表称之为 版本链 ，版本链的头节点就是当前记录最新的值。每个版本中还包含生成该版本时对应的 事务id 。\n\nReadView：（核心）\n1.什么时ReadView？在MVCC机制中，多个事务对同一个行记录进行更新会产生多个历史快照，这些历史快照保存在Undo Log中。如果一个事务想要查询这个行记录，需要读取哪个版本的行记录呢？这时就需要用到ReadView了，帮我们解决可见性的问题\nReadView就是一个事务在使用MVCC机制进行快照读取操作时产生的读视图，当事务启动时，会根据数据库系统当前的一个快照，InnoDB为每个事务构造了一个数组，用来记录并维护系统当前活跃事务的id（活跃就是启动了事务但是没有提交）\n\nMVCC整体操作流程\n首先获取事务自己的版本号，也就是事务 ID；\n获取 ReadView；\n查询得到的数据，然后与 ReadView 中的事务版本号进行比较；\n如果不符合 ReadView 规则，就需要从 Undo Log 中获取历史快照；\n最后返回符合规则的数据。\n\n\n总结：MVCC只有在读已提交和可重复读两种隔离级别的事务在执行快照读操作时访问记录版本链的过程，这样使不同事务的读-写、写-读操作并发执行，提升系统性能\n核心点在于ReadView的原理，读已提交和可重复读这两个隔离级别的很大不同就是生成ReadView的时机不同：\nREAD COMMITTD在每次进行普通的SELECT操作前都会生成一个ReadView\n\nREPEATABLE READ只会在第一次进行普通的SELECT操作前生成一个ReadView，之后的查询都重复使用这个ReadView\n\n\n通过MVCC可以解决的问题：1.读写之间阻塞的问。通过MVCC可以让读写互相不阻塞，即读不阻塞写，写不阻塞读，这样就可以提升事务并发处理能力\n2.降低了死锁的概率。因为MVCC采用了乐观锁的方式，读取数据时并不需要加锁，对于写操作，也只锁定了必要的行\n3.解决快照读的问题。当我们查询数据库在某个时间点的快照时，只能看到这个时间点之前事务提交更新的结果，而不能看到这个时间点之后事务提交的更新结果\n","slug":"MVCC","date":"2022-06-11T11:53:14.852Z","categories_index":"MySQL","tags_index":"MySQL","author_index":"小李不在_"},{"id":"0cb8b12f38f1e4c52cf2229e17b82a90","title":"Dubbo源码分析","content":"准备什么是 Dubbo?Apache Dubbo (incubating) |ˈdʌbəʊ|  是一款高性能、轻量级的开源 Java RPC 框架。\n根据 Dubbo 官方文档的介绍，Dubbo 提供了六大核心能力\n\n面向接口代理的高性能RPC调用。\n智能容错和负载均衡。\n服务自动注册和发现。\n高度可扩展能力。\n运行期流量调度。\n可视化的服务治理与运维。\n\n\n简单来说就是： Dubbo 不光可以帮助我们调用远程服务，还提供了一些其他开箱即用的功能比如智能负载均衡。\nDubbo 目前已经有接近 34.4 k 的 Star  。\n在 2020 年度 OSC 中国开源项目 评选活动中，Dubbo 位列开发框架和基础组件类项目的第7名。想比几年前来说，热度和排名有所下降。\n\nDubbo 是由阿里开源，后来加入了 Apache 。正式由于 Dubbo 的出现，才使得越来越多的公司开始使用以及接受分布式架构。\n\n为什么要用 Dubbo?随着互联网的发展，网站的规模越来越大，用户数量越来越多。单一应用架构 、垂直应用架构无法满足我们的需求，这个时候分布式服务架构就诞生了。\n分布式服务架构下，系统被拆分成不同的服务比如短信服务、安全服务，每个服务独立提供系统的某个核心服务。\n我们可以使用 Java RMI（Java Remote Method Invocation）、Hessian这种支持远程调用的框架来简单地暴露和引用远程服务。但是！当服务越来越多之后，服务调用关系越来越复杂。当应用访问压力越来越大后，负载均衡以及服务监控的需求也迫在眉睫。我们可以用 F5 这类硬件来做负载均衡，但这样增加了成本，并且存在单点故障的风险。\n不过，Dubbo 的出现让上述问题得到了解决。Dubbo 帮助我们解决了什么问题呢？\n\n负载均衡 ： 同一个服务部署在不同的机器时该调用那一台机器上的服务。\n服务调用链路生成  ： 随着系统的发展，服务越来越多，服务间依赖关系变得错踪复杂，甚至分不清哪个应用要在哪个应用之前启动，架构师都不能完整的描述应用的架构关系。Dubbo 可以为我们解决服务之间互相是如何调用的。\n服务访问压力以及时长统计、资源调度和治理 ：基于访问压力实时管理集群容量，提高集群利用率。\n……\n\n\n另外，Dubbo 除了能够应用在分布式系统中，也可以应用在现在比较火的微服务系统中。不过，由于 Spring Cloud 在微服务中应用更加广泛，所以，我觉得一般我们提 Dubbo 的话，大部分是分布式系统的情况。\n\nDubbo 的架构设计官方文档中的框架设计章节 已经介绍的非常详细了，我这里把两个比较重要的点再提一下。\n\n核心角色\n上述节点简单介绍以及他们之间的关系：\n\nContainer： 服务运行容器，负责加载、运行服务提供者。必须。\nProvider： 暴露服务的服务提供方，会向注册中心注册自己提供的服务。必须。\nConsumer： 调用远程服务的服务消费方，会向注册中心订阅自己所需的服务。必须。\nRegistry： 服务注册与发现的注册中心。注册中心会返回服务提供者地址列表给消费者。非必须。\nMonitor： 统计服务的调用次数和调用时间的监控中心。服务消费者和提供者会定时发送统计数据到监控中心。 非必须。\n\n一些用于自测的小问题（面试中可能会遇到）：\n\n注册中心的作用？ 注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互。\n监控中心的作用？ 监控中心负责统计各服务调用次数，调用时间等。\n服务提供者宕机后，注册中心会做什么？  注册中心会立即推送事件通知消费者。\n注册中心和监控中心都宕机的话，服务都会挂掉吗？ 不会。两者都宕机也不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表。注册中心和监控中心都是可选的，服务消费者可以直连服务提供者。\n\n\n整体设计下图是 Dubbo 的整体设计，从下至上分为十层，各层均为单向依赖。\n\n\n\n\n\n\n\n\n\n左边淡蓝背景的为服务消费方使用的接口，右边淡绿色背景的为服务提供方使用的接口，位于中轴线上的为双方都用到的接口。\n\n\nconfig 配置层：Dubbo相关的配置。支持代码配置，同时也支持基于 Spring  来做配置，以 ServiceConfig, ReferenceConfig 为中心\nproxy 服务代理层：调用远程方法像调用本地的方法一样简单的一个关键，真实调用过程依赖代理类，以 ServiceProxy 为中心。\nregistry 注册中心层：封装服务地址的注册与发现。\ncluster 路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心。\nmonitor 监控层：RPC 调用次数和调用时间监控，以 Statistics 为中心。\nprotocol 远程调用层：封装 RPC 调用，以 Invocation, Result 为中心。\nexchange 信息交换层：封装请求响应模式，同步转异步，以 Request, Response 为中心。\ntransport 网络传输层：抽象 mina 和 netty 为统一接口，以 Message 为中心。\nserialize 数据序列化层 ：对需要在网络传输的数据进行序列化。\n\n\n基本设计原则\n微内核架构Dubbo 采用微内核（Microkernel） + 插件（Plugin） 模式，简单来说就是微内核架构。微内核只负责组装插件。\n何为微内核架构呢？ 《软件架构模式》 这本书是这样介绍的：\n\n\n\n\n\n\n\n\n\n微内核架构模式（有时被称为插件架构模式）是实现基于产品应用程序的一种自然模式。基于产品的应用程序是已经打包好并且拥有不同版本，可作为第三方插件下载的。然后，很多公司也在开发、发布自己内部商业应用像有版本号、说明及可加载插件式的应用软件（这也是这种模式的特征）。微内核系统可让用户添加额外的应用如插件，到核心应用，继而提供了可扩展性和功能分离的用法。\n微内核架构包含两类组件：核心系统（core system） 和 插件模块（plug-in modules）。\n\n核心系统提供系统所需核心能力，插件模块可以扩展系统的功能。因此， 基于微内核架构的系统，非常易于扩展功能。\n我们常见的一些IDE，都可以看作是基于微内核架构设计的。绝大多数 IDE比如IDEA、VSCode都提供了插件来丰富自己的功能。\n正是因为Dubbo基于微内核架构，才使得我们可以随心所欲替换Dubbo的功能点。比如你觉得Dubbo 的序列化模块实现的不满足自己要求，没关系啊！你自己实现一个序列化模块就好了啊！\n通常情况下，微核心都会采用 Factory、IoC、OSGi 等方式管理插件生命周期。Dubbo 不想依赖 Spring 等 IoC 容器，也不想自已造一个小的 IoC 容器（过度设计），因此采用了一种最简单的 Factory 方式管理插件 ：JDK 标准的 SPI 扩展机制 （java.util.ServiceLoader）。\n\nURL 传递配置信息采用 URL 作为配置信息的统一格式，所有扩展点都通过传递 URL 携带配置信息。有什么好处呢？  形成规范，提升代码可读性，降低代码理解成本。\n\n模块分包\n\n\n\n\n\n\n\n\n以下内容来自官方文档：https://dubbo.apache.org/zh/docs/v2.7/dev/design/ 。\n\n模块说明：\n\ndubbo-common 公共逻辑模块：包括 Util 类和通用模型。\ndubbo-remoting 远程通讯模块：相当于 Dubbo 协议的实现，如果 RPC 用 RMI协议则不需要使用此包。\ndubbo-rpc 远程调用模块：抽象各种协议，以及动态代理，只包含一对一的调用，不关心集群的管理。\ndubbo-cluster 集群模块：将多个服务提供方伪装为一个提供方，包括：负载均衡, 容错，路由等，集群的地址列表可以是静态配置的，也可以是由注册中心下发。\ndubbo-registry 注册中心模块：基于注册中心下发地址的集群方式，以及对各种注册中心的抽象。\ndubbo-monitor 监控模块：统计服务调用次数，调用时间的，调用链跟踪的服务。\ndubbo-config 配置模块：是 Dubbo 对外的 API，用户通过 Config 使用Dubbo，隐藏 Dubbo 所有细节。\ndubbo-container 容器模块：是一个 Standlone 的容器，以简单的 Main 加载 Spring 启动，因为服务通常不需要 Tomcat&#x2F;JBoss 等 Web 容器的特性，没必要用 Web 容器去加载服务。\n\n\n前言在《如何自己实现一个 RPC框架》中我们介绍到一个最基本的 RPC 框架应该包括下面几部分:\n\n注册中心 ：注册中心负责服务地址的注册与查找，相当于目录服务。\n网络传输 ：既然我们要调用远程的方法，就要发送网络请求来传递目标类和方法的信息以及方法的参数等数据到服务提供端。\n序列化和反序列化 ：要在网络传输数据就要涉及到序列化。\n动态代理 ：屏蔽程方法调用的底层细节。\n负载均衡  ： 避免单个服务器响应同一请求，容易造成服务器宕机、崩溃等问题。\n传输协议 ：这个协议是客户端（服务消费方）和服务端（服务提供方）交流的基础。\n\n更完善的一点的 RPC 框架可能还有监控模块。\nDubbo 是比较成熟的 RPC 框架了，它当然满足我们所说的这些要求，我们看一下 Dubbo 源码的模块结构就可以看出来了。\n\nDubbo 核心模块介绍\ndubbo-common(公共逻辑模块)\n这部分主要是一些通用工具类（Util）比如Dubbo 对 SPI（org.apache.dubbo.common.extension）、时间轮算法(org.apache.dubbo.common.timer)的实现都放在这个模块下。\n除了工具类之外，dubbo-common 还包括一些通用模型比如 URL（Dubbo 通过URL 传递配置信息）。\n\ndubbo-remoting (网络传输模块)\n想要调用远程方法，必然涉及到网络传输。网络传输模块很大程度决定了Dubbo的性能和稳定性，所以，这块的设计非常重要。\ndubbo-remoting-api 模块是整个网络传输模块的抽象，定义了一些网络传输模块必须要实现的接口以及通用的一些实现，dubbo-remoting 模块下的其他模块都要对其进行实现。\n从上图可以看出，Dubbo 的网络传输模块有多种实现方式。除了我们比较熟悉的 Netty 实现方式之外，还有Grizzly、Mina等实现方式。\nNetty、Grizzly、Mina三者都是基于 Java NIO，并且Netty相比于其他两者封装和设计的要更好一些。\n\ndubbo-registry (注册中心模块)\n注册中心相当于服务提供者和消费者中间的桥梁，负责服务地址的注册与查找，相当于目录服务。\ndubbo-registry-api 模块是整个注册中心传输模块的抽象，定义了一些注册中心模块必须要实现的接口以及通用的一些实现。\nDubbo 的注册中心输模块也有多种实现方式。除了我们比较熟悉的 zookeeper、nacos 实现方式之外，还有mutilcast、redis等实现方式。\n一般情况下，我们都是使用zookeeper作为注册中心，这也是 Dubbo 官方推荐的一种方式。\n\n\ndubbo-config(配置模块)\n我们在源码环境那一节中提到： dubbo-demo 模块下，包含了 3 种不同类型（xml、api、annotation）配置方式使用 Dubbo 的demo。\ndubbo-config  就是对这些配置方式的实现。\n\ndubbo-config-api ：API配置方式的实现（纯代码使用）。\ndubbo-config-spring ：XML和注解方式的实现。\n\n\ndubbo-monitor (监控模块)监控模块主要统计服务调用次数，调用时间的，调用链跟踪的服务。\n从上图可以看出，监控模块只有一个默认实现。\n\ndubbo-rpc(远程调用模块)\ndubbo-rpc 模块抽象了各种协议，以及动态代理，只包含一对一的调用，不关心集群的管理。\n从“远程调用模块” 这个名字中，我们大概就能推断出 dubbo-rpc 模块依赖了网络传输模块（dubbo-remoting）。\ndubbo-rpc-api 模块是整个远程调用模块的抽象，定义了一些远程调用模块必须要实现的接口以及通用的一些实现。\nDubbo 本身就提供了多种协议实现比如 dubbo协议、hession协议、gRPC协议，不过官方更推荐使用dubbo协议。并且，还给出了一份性能测试报告。\n\ndubbo-cluster(集群模块)\ndubbo-cluster 模块将多个服务提供方伪装为一个提供方，包括：负载均衡, 容错，路由等，集群的地址列表可以是静态配置的，也可以是由注册中心下发。\n\n前言你给面试官说：“我阅读过 Dubbo 的源码，觉得那块设计的比较好”。结果，你自己连Dubbo 源码阅读环境都没搭建过的话，尴尬不？\nDubbo官方也有对应的源码环境搭建教程（@源码构建），不过我的更详细完善一点。并且，更清晰易懂。一些你们可能我踩的坑，我都提前指了出来，避免没有必要的时间浪费。\n\n环境准备\nIDEA：建议使用 IDEA 作为 IDE。\nMaven 3.6.5 ：Dubbo 使用 maven 作为构建工具。\nJDK 1.8  ：JDK 1.8 版本即可。\n\n\nDubbo 源码阅读环境搭建\n克隆项目到本地我们先克隆项目到本地(建议 fork 一份项目到自己的仓库中再克隆，版本建议 dubbo-2.6.4)。\ngit clone https://github.com/apache/dubbo.git dubbo\n\n\n使用 IDEA 打开项目项目克隆完成之后，推荐使用 IDEA 打开。打开之后，可能需要一会时间下载项目所依赖的 jar包，我们喝杯咖啡，耐心等待即可。\n\n\n\n\n\n\n\n\n\n下载jar包的过程中，很可能会遇到某些 jar 包出现问题的情况，导致项目多处报红，显示相关依赖导入错误。解决的办法就是：你去自己本地的 Maven仓库找到对应的  jar 包，将其删除，然后重新导入项目下载即可。\n\n构建项目如果我们的项目相关的 jar 包下载完成，我们就可以开始构建项目了。你可以使用下面两种方式的任意一种：\n（1）使用下面的命令构建项目了：\nmvn install -Dmaven.test.skip #构建并跳过单元测试\n\n（2）不同过命令的方式：\n首先点击跳过测试，然后点击clean 和 install。\n\n\n验证源码环境是否搭建成功这些事情做完之后，我们需要验证一下 Dubbo 源码阅读环境是否真的搭建成功了。怎么来验证呢？\n非常简单，不需要自己手动写 Demo 了。项目源码已经自带了一些使用 Dubbo 的Demo，我们直接运行即可。\n我们找到 dubbo-demo 这个文件夹，里面包含了 3 种不同类型（xml、api、annotation）使用方式的 demo，可以帮助我们节省掉大量写 Demo 的时间。\n\n这些 Demo 都是使用 zookeepeer 作为注册中心的，所以我们还需要提前下载 zookeeper 到本地。\n我这里建议下载 3.4.12 版本的 zookeeper ,避免出现其他问题。我们直接使用 Docker 进行下载就行了，方便简单。\ndocker pull zookeeper:3.4.12\n\n然后，使用下面的命令运行。\ndocker run -d --name zookeeper3.4.12 -p 2181:2181 zookeeper:3.4.12\n\n我们随便找到一个 Demo ，我这里以 api 使用的方式来说明一下。\n我们找到 dubbo-demo-api 这个文件夹，然后先启动服务提供者，再启动服务生产者：\n\n启动服务提供者 ：直接运行 dubbo-demo-api-provider （服务提供者）下的 Application  即可。服务提供者启动成功之后，控制台会打印出服务被注册的一些信息。\n启动服务消费者 ：直接运行 dubbo-demo-api-consumer （服务提供者）下的 Application  即可。服务消费者启动成功之后，控制台会打印出调用服务提供者的sayHello()方法返回的结果。\n\n启动过程中可能会出现的问题：java.nio.channels.UnresolvedAddressException 。\n出现这种问题的原因大概是你的 JDK 版本是 JDK14,你只需要将 JDK 版本调整到对应的 JDK 8 即可。\n\n源码分析\nDubbo SPI1.简介SPI 全称为 Service Provider Interface，是一种服务发现机制。SPI 的本质是将接口实现类的全限定名配置在文件中，并由服务加载器读取配置文件，加载实现类。这样可以在运行时，动态为接口替换实现类。正因此特性，我们可以很容易的通过 SPI 机制为我们的程序提供拓展功能。SPI 机制在第三方框架中也有所应用，比如 Dubbo 就是通过 SPI 机制加载所有的组件。不过，Dubbo 并未使用 Java 原生的 SPI 机制，而是对其进行了增强，使其能够更好的满足需求。在 Dubbo 中，SPI 是一个非常重要的模块。基于 SPI，我们可以很容易的对 Dubbo 进行拓展。如果大家想要学习 Dubbo 的源码，SPI 机制务必弄懂。接下来，我们先来了解一下 Java SPI 与 Dubbo SPI 的用法，然后再来分析 Dubbo SPI 的源码。\n需要特别说明的是，本篇文章以及本系列其他文章所分析的源码版本均为 dubbo-2.6.4。因此大家在阅读文章的过程中，需注意将代码版本切换到 dubbo-2.6.4 tag 上。\n\n2.SPI 示例\n2.1 Java SPI 示例前面简单介绍了 SPI 机制的原理，本节通过一个示例演示 Java SPI 的使用方法。首先，我们定义一个接口，名称为 Robot。\npublic interface Robot &#123;\n    void sayHello();\n&#125;\n\n接下来定义两个实现类，分别为 OptimusPrime 和 Bumblebee。\npublic class OptimusPrime implements Robot &#123;\n    \n    @Override\n    public void sayHello() &#123;\n        System.out.println(\"Hello, I am Optimus Prime.\");\n    &#125;\n&#125;\n\npublic class Bumblebee implements Robot &#123;\n\n    @Override\n    public void sayHello() &#123;\n        System.out.println(\"Hello, I am Bumblebee.\");\n    &#125;\n&#125;\n\n接下来 META-INF/services 文件夹下创建一个文件，名称为 Robot 的全限定名  org.apache.spi.Robot。文件内容为实现类的全限定的类名，如下：\norg.apache.spi.OptimusPrime\norg.apache.spi.Bumblebee\n\n做好所需的准备工作，接下来编写代码进行测试。\npublic class JavaSPITest &#123;\n\n    @Test\n    public void sayHello() throws Exception &#123;\n        ServiceLoader&lt;Robot> serviceLoader = ServiceLoader.load(Robot.class);\n        System.out.println(\"Java SPI\");\n        serviceLoader.forEach(Robot::sayHello);\n    &#125;\n&#125;\n\n最后来看一下测试结果，如下：\n\n从测试结果可以看出，我们的两个实现类被成功的加载，并输出了相应的内容。关于 Java SPI 的演示先到这里，接下来演示 Dubbo SPI。\n\n2.2 Dubbo SPI 示例Dubbo 并未使用 Java SPI，而是重新实现了一套功能更强的 SPI 机制。Dubbo SPI 的相关逻辑被封装在了 ExtensionLoader 类中，通过 ExtensionLoader，我们可以加载指定的实现类。Dubbo SPI 所需的配置文件需放置在 META-INF/dubbo 路径下，配置内容如下。\noptimusPrime &#x3D; org.apache.spi.OptimusPrime\nbumblebee &#x3D; org.apache.spi.Bumblebee\n\n与 Java SPI 实现类配置不同，Dubbo SPI 是通过键值对的方式进行配置，这样我们可以按需加载指定的实现类。另外，在测试 Dubbo SPI 时，需要在 Robot 接口上标注 @SPI 注解。下面来演示 Dubbo SPI 的用法：\npublic class DubboSPITest &#123;\n\n    @Test\n    public void sayHello() throws Exception &#123;\n        ExtensionLoader&lt;Robot> extensionLoader = \n            ExtensionLoader.getExtensionLoader(Robot.class);\n        Robot optimusPrime = extensionLoader.getExtension(\"optimusPrime\");\n        optimusPrime.sayHello();\n        Robot bumblebee = extensionLoader.getExtension(\"bumblebee\");\n        bumblebee.sayHello();\n    &#125;\n&#125;\n\n测试结果如下：\n\nDubbo SPI 除了支持按需加载接口实现类，还增加了 IOC 和 AOP 等特性，这些特性将会在接下来的源码分析章节中一一进行介绍。\n\n3. Dubbo SPI 源码分析上面简单演示了 Dubbo SPI 的使用方法。我们首先通过 ExtensionLoader 的 getExtensionLoader 方法获取一个 ExtensionLoader 实例，然后再通过 ExtensionLoader 的 getExtension 方法获取拓展类对象。这其中，getExtensionLoader 方法用于从缓存中获取与拓展类对应的 ExtensionLoader，若缓存未命中，则创建一个新的实例。该方法的逻辑比较简单，本章就不进行分析了。下面我们从 ExtensionLoader 的 getExtension 方法作为入口，对拓展类对象的获取过程进行详细的分析。\npublic T getExtension(String name) &#123;\n    if (name == null || name.length() == 0)\n        throw new IllegalArgumentException(\"Extension name == null\");\n    if (\"true\".equals(name)) &#123;\n        // 获取默认的拓展实现类\n        return getDefaultExtension();\n    &#125;\n    // Holder，顾名思义，用于持有目标对象\n    Holder&lt;Object> holder = cachedInstances.get(name);\n    if (holder == null) &#123;\n        cachedInstances.putIfAbsent(name, new Holder&lt;Object>());\n        holder = cachedInstances.get(name);\n    &#125;\n    Object instance = holder.get();\n    // 双重检查\n    if (instance == null) &#123;\n        synchronized (holder) &#123;\n            instance = holder.get();\n            if (instance == null) &#123;\n                // 创建拓展实例\n                instance = createExtension(name);\n                // 设置实例到 holder 中\n                holder.set(instance);\n            &#125;\n        &#125;\n    &#125;\n    return (T) instance;\n&#125;\n\n上面代码的逻辑比较简单，首先检查缓存，缓存未命中则创建拓展对象。下面我们来看一下创建拓展对象的过程是怎样的。\nprivate T createExtension(String name) &#123;\n    // 从配置文件中加载所有的拓展类，可得到“配置项名称”到“配置类”的映射关系表\n    Class&lt;?> clazz = getExtensionClasses().get(name);\n    if (clazz == null) &#123;\n        throw findException(name);\n    &#125;\n    try &#123;\n        T instance = (T) EXTENSION_INSTANCES.get(clazz);\n        if (instance == null) &#123;\n            // 通过反射创建实例\n            EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance());\n            instance = (T) EXTENSION_INSTANCES.get(clazz);\n        &#125;\n        // 向实例中注入依赖\n        injectExtension(instance);\n        Set&lt;Class&lt;?>> wrapperClasses = cachedWrapperClasses;\n        if (wrapperClasses != null &amp;&amp; !wrapperClasses.isEmpty()) &#123;\n            // 循环创建 Wrapper 实例\n            for (Class&lt;?> wrapperClass : wrapperClasses) &#123;\n                // 将当前 instance 作为参数传给 Wrapper 的构造方法，并通过反射创建 Wrapper 实例。\n                // 然后向 Wrapper 实例中注入依赖，最后将 Wrapper 实例再次赋值给 instance 变量\n                instance = injectExtension(\n                    (T) wrapperClass.getConstructor(type).newInstance(instance));\n            &#125;\n        &#125;\n        return instance;\n    &#125; catch (Throwable t) &#123;\n        throw new IllegalStateException(\"...\");\n    &#125;\n&#125;\n\ncreateExtension 方法的逻辑稍复杂一下，包含了如下的步骤：\n\n通过 getExtensionClasses 获取所有的拓展类\n通过反射创建拓展对象\n向拓展对象中注入依赖\n将拓展对象包裹在相应的 Wrapper 对象中\n\n以上步骤中，第一个步骤是加载拓展类的关键，第三和第四个步骤是 Dubbo IOC 与 AOP 的具体实现。在接下来的章节中，将会重点分析 getExtensionClasses 方法的逻辑，以及简单介绍 Dubbo IOC 的具体实现。\n\n3.1 获取所有的拓展类我们在通过名称获取拓展类之前，首先需要根据配置文件解析出拓展项名称到拓展类的映射关系表（Map&lt;名称, 拓展类&gt;），之后再根据拓展项名称从映射关系表中取出相应的拓展类即可。相关过程的代码分析如下：\nprivate Map&lt;String, Class&lt;?>> getExtensionClasses() &#123;\n    // 从缓存中获取已加载的拓展类\n    Map&lt;String, Class&lt;?>> classes = cachedClasses.get();\n    // 双重检查\n    if (classes == null) &#123;\n        synchronized (cachedClasses) &#123;\n            classes = cachedClasses.get();\n            if (classes == null) &#123;\n                // 加载拓展类\n                classes = loadExtensionClasses();\n                cachedClasses.set(classes);\n            &#125;\n        &#125;\n    &#125;\n    return classes;\n&#125;\n\n这里也是先检查缓存，若缓存未命中，则通过 synchronized 加锁。加锁后再次检查缓存，并判空。此时如果 classes 仍为 null，则通过 loadExtensionClasses 加载拓展类。下面分析 loadExtensionClasses 方法的逻辑。\nprivate Map&lt;String, Class&lt;?>> loadExtensionClasses() &#123;\n    // 获取 SPI 注解，这里的 type 变量是在调用 getExtensionLoader 方法时传入的\n    final SPI defaultAnnotation = type.getAnnotation(SPI.class);\n    if (defaultAnnotation != null) &#123;\n        String value = defaultAnnotation.value();\n        if ((value = value.trim()).length() > 0) &#123;\n            // 对 SPI 注解内容进行切分\n            String[] names = NAME_SEPARATOR.split(value);\n            // 检测 SPI 注解内容是否合法，不合法则抛出异常\n            if (names.length > 1) &#123;\n                throw new IllegalStateException(\"more than 1 default extension name on extension...\");\n            &#125;\n\n            // 设置默认名称，参考 getDefaultExtension 方法\n            if (names.length == 1) &#123;\n                cachedDefaultName = names[0];\n            &#125;\n        &#125;\n    &#125;\n\n    Map&lt;String, Class&lt;?>> extensionClasses = new HashMap&lt;String, Class&lt;?>>();\n    // 加载指定文件夹下的配置文件\n    loadDirectory(extensionClasses, DUBBO_INTERNAL_DIRECTORY);\n    loadDirectory(extensionClasses, DUBBO_DIRECTORY);\n    loadDirectory(extensionClasses, SERVICES_DIRECTORY);\n    return extensionClasses;\n&#125;\n\nloadExtensionClasses 方法总共做了两件事情，一是对 SPI 注解进行解析，二是调用 loadDirectory 方法加载指定文件夹配置文件。SPI 注解解析过程比较简单，无需多说。下面我们来看一下 loadDirectory 做了哪些事情。\nprivate void loadDirectory(Map&lt;String, Class&lt;?>> extensionClasses, String dir) &#123;\n    // fileName = 文件夹路径 + type 全限定名 \n    String fileName = dir + type.getName();\n    try &#123;\n        Enumeration&lt;java.net.URL> urls;\n        ClassLoader classLoader = findClassLoader();\n        // 根据文件名加载所有的同名文件\n        if (classLoader != null) &#123;\n            urls = classLoader.getResources(fileName);\n        &#125; else &#123;\n            urls = ClassLoader.getSystemResources(fileName);\n        &#125;\n        if (urls != null) &#123;\n            while (urls.hasMoreElements()) &#123;\n                java.net.URL resourceURL = urls.nextElement();\n                // 加载资源\n                loadResource(extensionClasses, classLoader, resourceURL);\n            &#125;\n        &#125;\n    &#125; catch (Throwable t) &#123;\n        logger.error(\"...\");\n    &#125;\n&#125;\n\nloadDirectory 方法先通过 classLoader 获取所有资源链接，然后再通过 loadResource 方法加载资源。我们继续跟下去，看一下 loadResource 方法的实现。\nprivate void loadResource(Map&lt;String, Class&lt;?>> extensionClasses, \n\tClassLoader classLoader, java.net.URL resourceURL) &#123;\n    try &#123;\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(resourceURL.openStream(), \"utf-8\"));\n        try &#123;\n            String line;\n            // 按行读取配置内容\n            while ((line = reader.readLine()) != null) &#123;\n                // 定位 # 字符\n                final int ci = line.indexOf('#');\n                if (ci >= 0) &#123;\n                    // 截取 # 之前的字符串，# 之后的内容为注释，需要忽略\n                    line = line.substring(0, ci);\n                &#125;\n                line = line.trim();\n                if (line.length() > 0) &#123;\n                    try &#123;\n                        String name = null;\n                        int i = line.indexOf('=');\n                        if (i > 0) &#123;\n                            // 以等于号 = 为界，截取键与值\n                            name = line.substring(0, i).trim();\n                            line = line.substring(i + 1).trim();\n                        &#125;\n                        if (line.length() > 0) &#123;\n                            // 加载类，并通过 loadClass 方法对类进行缓存\n                            loadClass(extensionClasses, resourceURL, \n                                      Class.forName(line, true, classLoader), name);\n                        &#125;\n                    &#125; catch (Throwable t) &#123;\n                        IllegalStateException e = new IllegalStateException(\"Failed to load extension class...\");\n                    &#125;\n                &#125;\n            &#125;\n        &#125; finally &#123;\n            reader.close();\n        &#125;\n    &#125; catch (Throwable t) &#123;\n        logger.error(\"Exception when load extension class...\");\n    &#125;\n&#125;\n\nloadResource 方法用于读取和解析配置文件，并通过反射加载类，最后调用 loadClass 方法进行其他操作。loadClass 方法用于主要用于操作缓存，该方法的逻辑如下：\nprivate void loadClass(Map&lt;String, Class&lt;?>> extensionClasses, java.net.URL resourceURL, \n    Class&lt;?> clazz, String name) throws NoSuchMethodException &#123;\n    \n    if (!type.isAssignableFrom(clazz)) &#123;\n        throw new IllegalStateException(\"...\");\n    &#125;\n\n    // 检测目标类上是否有 Adaptive 注解\n    if (clazz.isAnnotationPresent(Adaptive.class)) &#123;\n        if (cachedAdaptiveClass == null) &#123;\n            // 设置 cachedAdaptiveClass缓存\n            cachedAdaptiveClass = clazz;\n        &#125; else if (!cachedAdaptiveClass.equals(clazz)) &#123;\n            throw new IllegalStateException(\"...\");\n        &#125;\n        \n    // 检测 clazz 是否是 Wrapper 类型\n    &#125; else if (isWrapperClass(clazz)) &#123;\n        Set&lt;Class&lt;?>> wrappers = cachedWrapperClasses;\n        if (wrappers == null) &#123;\n            cachedWrapperClasses = new ConcurrentHashSet&lt;Class&lt;?>>();\n            wrappers = cachedWrapperClasses;\n        &#125;\n        // 存储 clazz 到 cachedWrapperClasses 缓存中\n        wrappers.add(clazz);\n        \n    // 程序进入此分支，表明 clazz 是一个普通的拓展类\n    &#125; else &#123;\n        // 检测 clazz 是否有默认的构造方法，如果没有，则抛出异常\n        clazz.getConstructor();\n        if (name == null || name.length() == 0) &#123;\n            // 如果 name 为空，则尝试从 Extension 注解中获取 name，或使用小写的类名作为 name\n            name = findAnnotationName(clazz);\n            if (name.length() == 0) &#123;\n                throw new IllegalStateException(\"...\");\n            &#125;\n        &#125;\n        // 切分 name\n        String[] names = NAME_SEPARATOR.split(name);\n        if (names != null &amp;&amp; names.length > 0) &#123;\n            Activate activate = clazz.getAnnotation(Activate.class);\n            if (activate != null) &#123;\n                // 如果类上有 Activate 注解，则使用 names 数组的第一个元素作为键，\n                // 存储 name 到 Activate 注解对象的映射关系\n                cachedActivates.put(names[0], activate);\n            &#125;\n            for (String n : names) &#123;\n                if (!cachedNames.containsKey(clazz)) &#123;\n                    // 存储 Class 到名称的映射关系\n                    cachedNames.put(clazz, n);\n                &#125;\n                Class&lt;?> c = extensionClasses.get(n);\n                if (c == null) &#123;\n                    // 存储名称到 Class 的映射关系\n                    extensionClasses.put(n, clazz);\n                &#125; else if (c != clazz) &#123;\n                    throw new IllegalStateException(\"...\");\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n如上，loadClass 方法操作了不同的缓存，比如 cachedAdaptiveClass、cachedWrapperClasses 和 cachedNames 等等。除此之外，该方法没有其他什么逻辑了。\n到此，关于缓存类加载的过程就分析完了。整个过程没什么特别复杂的地方，大家按部就班的分析即可，不懂的地方可以调试一下。接下来，我们来聊聊 Dubbo IOC 方面的内容。\n\n3.2 Dubbo IOCDubbo IOC 是通过 setter 方法注入依赖。Dubbo 首先会通过反射获取到实例的所有方法，然后再遍历方法列表，检测方法名是否具有 setter 方法特征。若有，则通过 ObjectFactory 获取依赖对象，最后通过反射调用 setter 方法将依赖设置到目标对象中。整个过程对应的代码如下：\nprivate T injectExtension(T instance) &#123;\n    try &#123;\n        if (objectFactory != null) &#123;\n            // 遍历目标类的所有方法\n            for (Method method : instance.getClass().getMethods()) &#123;\n                // 检测方法是否以 set 开头，且方法仅有一个参数，且方法访问级别为 public\n                if (method.getName().startsWith(\"set\")\n                    &amp;&amp; method.getParameterTypes().length == 1\n                    &amp;&amp; Modifier.isPublic(method.getModifiers())) &#123;\n                    // 获取 setter 方法参数类型\n                    Class&lt;?> pt = method.getParameterTypes()[0];\n                    try &#123;\n                        // 获取属性名，比如 setName 方法对应属性名 name\n                        String property = method.getName().length() > 3 ? \n                            method.getName().substring(3, 4).toLowerCase() + \n                            \tmethod.getName().substring(4) : \"\";\n                        // 从 ObjectFactory 中获取依赖对象\n                        Object object = objectFactory.getExtension(pt, property);\n                        if (object != null) &#123;\n                            // 通过反射调用 setter 方法设置依赖\n                            method.invoke(instance, object);\n                        &#125;\n                    &#125; catch (Exception e) &#123;\n                        logger.error(\"fail to inject via method...\");\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n    &#125; catch (Exception e) &#123;\n        logger.error(e.getMessage(), e);\n    &#125;\n    return instance;\n&#125;\n\n在上面代码中，objectFactory 变量的类型为 AdaptiveExtensionFactory，AdaptiveExtensionFactory 内部维护了一个 ExtensionFactory 列表，用于存储其他类型的 ExtensionFactory。Dubbo 目前提供了两种 ExtensionFactory，分别是 SpiExtensionFactory 和 SpringExtensionFactory。前者用于创建自适应的拓展，后者是用于从 Spring 的 IOC 容器中获取所需的拓展。这两个类的类的代码不是很复杂，这里就不一一分析了。\nDubbo IOC 目前仅支持 setter 方式注入，总的来说，逻辑比较简单易懂。\n\n4.总结本篇文章简单分别介绍了 Java SPI 与 Dubbo SPI 用法，并对 Dubbo SPI 的加载拓展类的过程进行了分析。另外，在 Dubbo SPI 中还有一块重要的逻辑这里没有进行分析，即 Dubbo SPI 的扩展点自适应机制。该机制的逻辑较为复杂，我们将会在下一篇文章中进行详细的分析。\n好了，本篇文章就先到这里了。如果文章中有错误不妥之处，欢迎大家提 issue 进行反馈，或者提 pull request 进行修正。让我们携手共建 Dubbo 社区。\n\n\n\n\n\n\n\n\n\n原文地址：https://dubbo.apache.org/zh/docsv2.7/dev/source/adaptive-extension/\n作者： Dubbo 官方\n\nDubbo SPI自适应性扩展1.原理在 Dubbo 中，很多拓展都是通过 SPI 机制进行加载的，比如 Protocol、Cluster、LoadBalance 等。有时，有些拓展并不想在框架启动阶段被加载，而是希望在拓展方法被调用时，根据运行时参数进行加载。这听起来有些矛盾。拓展未被加载，那么拓展方法就无法被调用（静态方法除外）。拓展方法未被调用，拓展就无法被加载。对于这个矛盾的问题，Dubbo 通过自适应拓展机制很好的解决了。自适应拓展机制的实现逻辑比较复杂，首先 Dubbo 会为拓展接口生成具有代理功能的代码。然后通过 javassist 或 jdk 编译这段代码，得到 Class 类。最后再通过反射创建代理类，整个过程比较复杂。为了让大家对自适应拓展有一个感性的认识，下面我们通过一个示例进行演示。这是一个与汽车相关的例子，我们有一个车轮制造厂接口 WheelMaker：\npublic interface WheelMaker &#123;\n    Wheel makeWheel(URL url);\n&#125;\n\nWheelMaker 接口的自适应实现类如下：\npublic class AdaptiveWheelMaker implements WheelMaker &#123;\n    public Wheel makeWheel(URL url) &#123;\n        if (url == null) &#123;\n            throw new IllegalArgumentException(\"url == null\");\n        &#125;\n        \n    \t// 1.从 URL 中获取 WheelMaker 名称\n        String wheelMakerName = url.getParameter(\"Wheel.maker\");\n        if (wheelMakerName == null) &#123;\n            throw new IllegalArgumentException(\"wheelMakerName == null\");\n        &#125;\n        \n        // 2.通过 SPI 加载具体的 WheelMaker\n        WheelMaker wheelMaker = ExtensionLoader\n            .getExtensionLoader(WheelMaker.class).getExtension(wheelMakerName);\n        \n        // 3.调用目标方法\n        return wheelMaker.makeWheel(url);\n    &#125;\n&#125;\n\nAdaptiveWheelMaker 是一个代理类，与传统的代理逻辑不同，AdaptiveWheelMaker 所代理的对象是在 makeWheel 方法中通过 SPI 加载得到的。makeWheel 方法主要做了三件事情：\n\n从 URL 中获取 WheelMaker 名称\n通过 SPI 加载具体的 WheelMaker 实现类\n调用目标方法\n\n接下来，我们来看看汽车制造厂 CarMaker 接口与其实现类。\npublic interface CarMaker &#123;\n    Car makeCar(URL url);\n&#125;\n\npublic class RaceCarMaker implements CarMaker &#123;\n    WheelMaker wheelMaker;\n \n    // 通过 setter 注入 AdaptiveWheelMaker\n    public setWheelMaker(WheelMaker wheelMaker) &#123;\n        this.wheelMaker = wheelMaker;\n    &#125;\n \n    public Car makeCar(URL url) &#123;\n        Wheel wheel = wheelMaker.makeWheel(url);\n        return new RaceCar(wheel, ...);\n    &#125;\n&#125;\n\nRaceCarMaker 持有一个 WheelMaker 类型的成员变量，在程序启动时，我们可以将 AdaptiveWheelMaker 通过 setter 方法注入到 RaceCarMaker 中。在运行时，假设有这样一个 url 参数传入：\ndubbo:&#x2F;&#x2F;192.168.0.101:20880&#x2F;XxxService?wheel.maker&#x3D;MichelinWheelMaker\n\nRaceCarMaker 的 makeCar 方法将上面的 url 作为参数传给 AdaptiveWheelMaker 的 makeWheel 方法，makeWheel 方法从 url 中提取 wheel.maker 参数，得到 MichelinWheelMaker。之后再通过 SPI 加载配置名为 MichelinWheelMaker 的实现类，得到具体的 WheelMaker 实例。\n上面的示例展示了自适应拓展类的核心实现 —- 在拓展接口的方法被调用时，通过 SPI 加载具体的拓展实现类，并调用拓展对象的同名方法。接下来，我们深入到源码中，探索自适应拓展类生成的过程。\n\n2.源码分析在对自适应拓展生成过程进行深入分析之前，我们先来看一下与自适应拓展息息相关的一个注解，即 Adaptive 注解。该注解的定义如下：\n@Documented\n@Retention(RetentionPolicy.RUNTIME)\n@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)\npublic @interface Adaptive &#123;\n    String[] value() default &#123;&#125;;\n&#125;\n\n从上面的代码中可知，Adaptive 可注解在类或方法上。当 Adaptive 注解在类上时，Dubbo 不会为该类生成代理类。注解在方法（接口方法）上时，Dubbo 则会为该方法生成代理逻辑。Adaptive 注解在类上的情况很少，在 Dubbo 中，仅有两个类被 Adaptive 注解了，分别是 AdaptiveCompiler 和 AdaptiveExtensionFactory。此种情况，表示拓展的加载逻辑由人工编码完成。更多时候，Adaptive 是注解在接口方法上的，表示拓展的加载逻辑需由框架自动生成。Adaptive 注解的地方不同，相应的处理逻辑也是不同的。注解在类上时，处理逻辑比较简单，本文就不分析了。注解在接口方法上时，处理逻辑较为复杂，本章将会重点分析此块逻辑。\n\n2.1 获取自适应拓展getAdaptiveExtension 方法是获取自适应拓展的入口方法，因此下面我们从这个方法进行分析。相关代码如下：\npublic T getAdaptiveExtension() &#123;\n    // 从缓存中获取自适应拓展\n    Object instance = cachedAdaptiveInstance.get();\n    if (instance == null) &#123;    // 缓存未命中\n        if (createAdaptiveInstanceError == null) &#123;\n            synchronized (cachedAdaptiveInstance) &#123;\n                instance = cachedAdaptiveInstance.get();\n                if (instance == null) &#123;\n                    try &#123;\n                        // 创建自适应拓展\n                        instance = createAdaptiveExtension();\n                        // 设置自适应拓展到缓存中\n                        cachedAdaptiveInstance.set(instance);\n                    &#125; catch (Throwable t) &#123;\n                        createAdaptiveInstanceError = t;\n                        throw new IllegalStateException(\"fail to create adaptive instance: ...\");\n                    &#125;\n                &#125;\n            &#125;\n        &#125; else &#123;\n            throw new IllegalStateException(\"fail to create adaptive instance:  ...\");\n        &#125;\n    &#125;\n\n    return (T) instance;\n&#125;\n\ngetAdaptiveExtension 方法首先会检查缓存，缓存未命中，则调用 createAdaptiveExtension 方法创建自适应拓展。下面，我们看一下 createAdaptiveExtension 方法的代码。\nprivate T createAdaptiveExtension() &#123;\n    try &#123;\n        // 获取自适应拓展类，并通过反射实例化\n        return injectExtension((T) getAdaptiveExtensionClass().newInstance());\n    &#125; catch (Exception e) &#123;\n        throw new IllegalStateException(\"Can not create adaptive extension ...\");\n    &#125;\n&#125;\n\ncreateAdaptiveExtension 方法的代码比较少，但却包含了三个逻辑，分别如下：\n\n调用 getAdaptiveExtensionClass 方法获取自适应拓展 Class 对象\n通过反射进行实例化\n调用 injectExtension 方法向拓展实例中注入依赖\n\n前两个逻辑比较好理解，第三个逻辑用于向自适应拓展对象中注入依赖。这个逻辑看似多余，但有存在的必要，这里简单说明一下。前面说过，Dubbo 中有两种类型的自适应拓展，一种是手工编码的，一种是自动生成的。手工编码的自适应拓展中可能存在着一些依赖，而自动生成的 Adaptive 拓展则不会依赖其他类。这里调用 injectExtension 方法的目的是为手工编码的自适应拓展注入依赖，这一点需要大家注意一下。关于 injectExtension 方法，前文已经分析过了，这里不再赘述。接下来，分析 getAdaptiveExtensionClass 方法的逻辑。\nprivate Class&lt;?> getAdaptiveExtensionClass() &#123;\n    // 通过 SPI 获取所有的拓展类\n    getExtensionClasses();\n    // 检查缓存，若缓存不为空，则直接返回缓存\n    if (cachedAdaptiveClass != null) &#123;\n        return cachedAdaptiveClass;\n    &#125;\n    // 创建自适应拓展类\n    return cachedAdaptiveClass = createAdaptiveExtensionClass();\n&#125;\n\ngetAdaptiveExtensionClass 方法同样包含了三个逻辑，如下：\n\n调用 getExtensionClasses 获取所有的拓展类\n检查缓存，若缓存不为空，则返回缓存\n若缓存为空，则调用 createAdaptiveExtensionClass 创建自适应拓展类\n\n这三个逻辑看起来平淡无奇，似乎没有多讲的必要。但是这些平淡无奇的代码中隐藏了着一些细节，需要说明一下。首先从第一个逻辑说起，getExtensionClasses 这个方法用于获取某个接口的所有实现类。比如该方法可以获取 Protocol 接口的 DubboProtocol、HttpProtocol、InjvmProtocol 等实现类。在获取实现类的过程中，如果某个实现类被 Adaptive 注解修饰了，那么该类就会被赋值给 cachedAdaptiveClass 变量。此时，上面步骤中的第二步条件成立（缓存不为空），直接返回 cachedAdaptiveClass 即可。如果所有的实现类均未被 Adaptive 注解修饰，那么执行第三步逻辑，创建自适应拓展类。相关代码如下：\nprivate Class&lt;?> createAdaptiveExtensionClass() &#123;\n    // 构建自适应拓展代码\n    String code = createAdaptiveExtensionClassCode();\n    ClassLoader classLoader = findClassLoader();\n    // 获取编译器实现类\n    com.alibaba.dubbo.common.compiler.Compiler compiler = ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.common.compiler.Compiler.class).getAdaptiveExtension();\n    // 编译代码，生成 Class\n    return compiler.compile(code, classLoader);\n&#125;\n\ncreateAdaptiveExtensionClass 方法用于生成自适应拓展类，该方法首先会生成自适应拓展类的源码，然后通过 Compiler 实例（Dubbo 默认使用 javassist 作为编译器）编译源码，得到代理类 Class 实例。接下来，我们把重点放在代理类代码生成的逻辑上，其他逻辑大家自行分析。\n\n2.2 自适应拓展类代码生成createAdaptiveExtensionClassCode 方法代码略多，约有两百行代码。因此本节将会对该方法的代码进行拆分分析，以帮助大家更好的理解代码逻辑。\n\n2.2.1 Adaptive 注解检测在生成代理类源码之前，createAdaptiveExtensionClassCode 方法首先会通过反射检测接口方法是否包含 Adaptive 注解。对于要生成自适应拓展的接口，Dubbo 要求该接口至少有一个方法被 Adaptive 注解修饰。若不满足此条件，就会抛出运行时异常。相关代码如下：\n// 通过反射获取所有的方法\nMethod[] methods = type.getMethods();\nboolean hasAdaptiveAnnotation = false;\n// 遍历方法列表\nfor (Method m : methods) &#123;\n    // 检测方法上是否有 Adaptive 注解\n    if (m.isAnnotationPresent(Adaptive.class)) &#123;\n        hasAdaptiveAnnotation = true;\n        break;\n    &#125;\n&#125;\n\nif (!hasAdaptiveAnnotation)\n    // 若所有的方法上均无 Adaptive 注解，则抛出异常\n    throw new IllegalStateException(\"No adaptive method on extension ...\");\n\n\n2.2.2 生成类通过 Adaptive 注解检测后，即可开始生成代码。代码生成的顺序与 Java 文件内容顺序一致，首先会生成 package 语句，然后生成 import 语句，紧接着生成类名等代码。整个逻辑如下：\n// 生成 package 代码：package + type 所在包\ncodeBuilder.append(\"package \").append(type.getPackage().getName()).append(\";\");\n// 生成 import 代码：import + ExtensionLoader 全限定名\ncodeBuilder.append(\"\\nimport \").append(ExtensionLoader.class.getName()).append(\";\");\n// 生成类代码：public class + type简单名称 + $Adaptive + implements + type全限定名 + &#123;\ncodeBuilder.append(\"\\npublic class \")\n    .append(type.getSimpleName())\n    .append(\"$Adaptive\")\n    .append(\" implements \")\n    .append(type.getCanonicalName())\n    .append(\" &#123;\");\n\n// $&#123;生成方法&#125;\n\ncodeBuilder.append(\"\\n&#125;\");\n\n这里使用 ${…} 占位符代表其他代码的生成逻辑，该部分逻辑将在随后进行分析。上面代码不是很难理解，下面直接通过一个例子展示该段代码所生成的内容。以 Dubbo 的 Protocol 接口为例，生成的代码如下：\npackage com.alibaba.dubbo.rpc;\nimport com.alibaba.dubbo.common.extension.ExtensionLoader;\npublic class Protocol$Adaptive implements com.alibaba.dubbo.rpc.Protocol &#123;\n    // 省略方法代码\n&#125;\n\n\n2.2.3 生成方法一个方法可以被 Adaptive 注解修饰，也可以不被修饰。这里将未被 Adaptive 注解修饰的方法称为“无 Adaptive 注解方法”，下面我们先来看看此种方法的代码生成逻辑是怎样的。\n\n2.2.3.1 无 Adaptive 注解方法代码生成逻辑对于接口方法，我们可以按照需求标注 Adaptive 注解。以 Protocol 接口为例，该接口的 destroy 和 getDefaultPort 未标注 Adaptive 注解，其他方法均标注了 Adaptive 注解。Dubbo 不会为没有标注 Adaptive 注解的方法生成代理逻辑，对于该种类型的方法，仅会生成一句抛出异常的代码。生成逻辑如下：\nfor (Method method : methods) &#123;\n    \n    // 省略无关逻辑\n\n    Adaptive adaptiveAnnotation = method.getAnnotation(Adaptive.class);\n    StringBuilder code = new StringBuilder(512);\n    // 如果方法上无 Adaptive 注解，则生成 throw new UnsupportedOperationException(...) 代码\n    if (adaptiveAnnotation == null) &#123;\n        // 生成的代码格式如下：\n        // throw new UnsupportedOperationException(\n        //     \"method \" + 方法签名 + of interface + 全限定接口名 + is not adaptive method!”)\n        code.append(\"throw new UnsupportedOperationException(\\\"method \")\n            .append(method.toString()).append(\" of interface \")\n            .append(type.getName()).append(\" is not adaptive method!\\\");\");\n    &#125; else &#123;\n        // 省略无关逻辑\n    &#125;\n    \n    // 省略无关逻辑\n&#125;\n\n以 Protocol 接口的 destroy 方法为例，上面代码生成的内容如下：\nthrow new UnsupportedOperationException(\n            \"method public abstract void com.alibaba.dubbo.rpc.Protocol.destroy() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!\");\n\n\n2.2.3.2 获取 URL 数据前面说过方法代理逻辑会从 URL 中提取目标拓展的名称，因此代码生成逻辑的一个重要的任务是从方法的参数列表或者其他参数中获取 URL 数据。举例说明一下，我们要为 Protocol 接口的 refer 和 export 方法生成代理逻辑。在运行时，通过反射得到的方法定义大致如下：\nInvoker refer(Class&lt;T> arg0, URL arg1) throws RpcException;\nExporter export(Invoker&lt;T> arg0) throws RpcException;\n\n对于 refer 方法，通过遍历 refer 的参数列表即可获取 URL 数据，这个还比较简单。对于 export 方法，获取 URL 数据则要麻烦一些。export 参数列表中没有 URL 参数，因此需要从 Invoker 参数中获取 URL 数据。获取方式是调用 Invoker 中可返回 URL 的 getter 方法，比如 getUrl。如果 Invoker 中无相关 getter 方法，此时则会抛出异常。整个逻辑如下：\nfor (Method method : methods) &#123;\n    Class&lt;?> rt = method.getReturnType();\n    Class&lt;?>[] pts = method.getParameterTypes();\n    Class&lt;?>[] ets = method.getExceptionTypes();\n\n    Adaptive adaptiveAnnotation = method.getAnnotation(Adaptive.class);\n    StringBuilder code = new StringBuilder(512);\n    if (adaptiveAnnotation == null) &#123;\n        // $&#123;无 Adaptive 注解方法代码生成逻辑&#125;\n    &#125; else &#123;\n    \tint urlTypeIndex = -1;\n        // 遍历参数列表，确定 URL 参数位置\n        for (int i = 0; i &lt; pts.length; ++i) &#123;\n            if (pts[i].equals(URL.class)) &#123;\n                urlTypeIndex = i;\n                break;\n            &#125;\n        &#125;\n        \n        // urlTypeIndex != -1，表示参数列表中存在 URL 参数\n        if (urlTypeIndex != -1) &#123;\n            // 为 URL 类型参数生成判空代码，格式如下：\n            // if (arg + urlTypeIndex == null) \n            //     throw new IllegalArgumentException(\"url == null\");\n            String s = String.format(\"\\nif (arg%d == null) throw new IllegalArgumentException(\\\"url == null\\\");\",\n                                     urlTypeIndex);\n            code.append(s);\n\n            // 为 URL 类型参数生成赋值代码，形如 URL url = arg1\n            s = String.format(\"\\n%s url = arg%d;\", URL.class.getName(), urlTypeIndex);\n            code.append(s);\n            \n        // 参数列表中不存在 URL 类型参数\n        &#125; else &#123;\n            String attribMethod = null;\n\n            LBL_PTS:\n            // 遍历方法的参数类型列表\n            for (int i = 0; i &lt; pts.length; ++i) &#123;\n                // 获取某一类型参数的全部方法\n                Method[] ms = pts[i].getMethods();\n                // 遍历方法列表，寻找可返回 URL 的 getter 方法\n                for (Method m : ms) &#123;\n                    String name = m.getName();\n                    // 1. 方法名以 get 开头，或方法名大于3个字符\n                    // 2. 方法的访问权限为 public\n                    // 3. 非静态方法\n                    // 4. 方法参数数量为0\n                    // 5. 方法返回值类型为 URL\n                    if ((name.startsWith(\"get\") || name.length() > 3)\n                        &amp;&amp; Modifier.isPublic(m.getModifiers())\n                        &amp;&amp; !Modifier.isStatic(m.getModifiers())\n                        &amp;&amp; m.getParameterTypes().length == 0\n                        &amp;&amp; m.getReturnType() == URL.class) &#123;\n                        urlTypeIndex = i;\n                        attribMethod = name;\n                        \n                        // 结束 for (int i = 0; i &lt; pts.length; ++i) 循环\n                        break LBL_PTS;\n                    &#125;\n                &#125;\n            &#125;\n            if (attribMethod == null) &#123;\n                // 如果所有参数中均不包含可返回 URL 的 getter 方法，则抛出异常\n                throw new IllegalStateException(\"fail to create adaptive class for interface ...\");\n            &#125;\n\n            // 为可返回 URL 的参数生成判空代码，格式如下：\n            // if (arg + urlTypeIndex == null) \n            //     throw new IllegalArgumentException(\"参数全限定名 + argument == null\");\n            String s = String.format(\"\\nif (arg%d == null) throw new IllegalArgumentException(\\\"%s argument == null\\\");\",\n                                     urlTypeIndex, pts[urlTypeIndex].getName());\n            code.append(s);\n\n            // 为 getter 方法返回的 URL 生成判空代码，格式如下：\n            // if (argN.getter方法名() == null) \n            //     throw new IllegalArgumentException(参数全限定名 + argument getUrl() == null);\n            s = String.format(\"\\nif (arg%d.%s() == null) throw new IllegalArgumentException(\\\"%s argument %s() == null\\\");\",\n                              urlTypeIndex, attribMethod, pts[urlTypeIndex].getName(), attribMethod);\n            code.append(s);\n\n            // 生成赋值语句，格式如下：\n            // URL全限定名 url = argN.getter方法名()，比如 \n            // com.alibaba.dubbo.common.URL url = invoker.getUrl();\n            s = String.format(\"%s url = arg%d.%s();\", URL.class.getName(), urlTypeIndex, attribMethod);\n            code.append(s);\n        &#125;\n        \n        // 省略无关代码\n    &#125;\n    \n    // 省略无关代码\n&#125;\n\n上面代码有点多，需要耐心看一下。这段代码主要目的是为了获取 URL 数据，并为之生成判空和赋值代码。以 Protocol 的 refer 和 export 方法为例，上面的代码为它们生成如下内容（代码已格式化）：\nrefer:\nif (arg1 == null) \n    throw new IllegalArgumentException(\"url == null\");\ncom.alibaba.dubbo.common.URL url = arg1;\n\nexport:\nif (arg0 == null) \n    throw new IllegalArgumentException(\"com.alibaba.dubbo.rpc.Invoker argument == null\");\nif (arg0.getUrl() == null) \n    throw new IllegalArgumentException(\"com.alibaba.dubbo.rpc.Invoker argument getUrl() == null\");\ncom.alibaba.dubbo.common.URL url = arg0.getUrl();\n\n\n\n2.2.3.3 获取 Adaptive 注解值Adaptive 注解值 value 类型为 String[]，可填写多个值，默认情况下为空数组。若 value 为非空数组，直接获取数组内容即可。若 value 为空数组，则需进行额外处理。处理过程是将类名转换为字符数组，然后遍历字符数组，并将字符放入 StringBuilder 中。若字符为大写字母，则向 StringBuilder 中添加点号，随后将字符变为小写存入 StringBuilder 中。比如 LoadBalance 经过处理后，得到 load.balance。\nfor (Method method : methods) &#123;\n    Class&lt;?> rt = method.getReturnType();\n    Class&lt;?>[] pts = method.getParameterTypes();\n    Class&lt;?>[] ets = method.getExceptionTypes();\n\n    Adaptive adaptiveAnnotation = method.getAnnotation(Adaptive.class);\n    StringBuilder code = new StringBuilder(512);\n    if (adaptiveAnnotation == null) &#123;\n        // $&#123;无 Adaptive 注解方法代码生成逻辑&#125;\n    &#125; else &#123;\n        // $&#123;获取 URL 数据&#125;\n        \n        String[] value = adaptiveAnnotation.value();\n        // value 为空数组\n        if (value.length == 0) &#123;\n            // 获取类名，并将类名转换为字符数组\n            char[] charArray = type.getSimpleName().toCharArray();\n            StringBuilder sb = new StringBuilder(128);\n            // 遍历字节数组\n            for (int i = 0; i &lt; charArray.length; i++) &#123;\n                // 检测当前字符是否为大写字母\n                if (Character.isUpperCase(charArray[i])) &#123;\n                    if (i != 0) &#123;\n                        // 向 sb 中添加点号\n                        sb.append(\".\");\n                    &#125;\n                    // 将字符变为小写，并添加到 sb 中\n                    sb.append(Character.toLowerCase(charArray[i]));\n                &#125; else &#123;\n                    // 添加字符到 sb 中\n                    sb.append(charArray[i]);\n                &#125;\n            &#125;\n            value = new String[]&#123;sb.toString()&#125;;\n        &#125;\n        \n        // 省略无关代码\n    &#125;\n    \n    // 省略无关逻辑\n&#125;\n\n\n\n2.2.3.4 检测 Invocation 参数此段逻辑是检测方法列表中是否存在 Invocation 类型的参数，若存在，则为其生成判空代码和其他一些代码。相应的逻辑如下：\nfor (Method method : methods) &#123;\n    Class&lt;?> rt = method.getReturnType();\n    Class&lt;?>[] pts = method.getParameterTypes();    // 获取参数类型列表\n    Class&lt;?>[] ets = method.getExceptionTypes();\n\n    Adaptive adaptiveAnnotation = method.getAnnotation(Adaptive.class);\n    StringBuilder code = new StringBuilder(512);\n    if (adaptiveAnnotation == null) &#123;\n        // $&#123;无 Adaptive 注解方法代码生成逻辑&#125;\n    &#125; else &#123;\n        // $&#123;获取 URL 数据&#125;\n        \n        // $&#123;获取 Adaptive 注解值&#125;\n        \n        boolean hasInvocation = false;\n        // 遍历参数类型列表\n        for (int i = 0; i &lt; pts.length; ++i) &#123;\n            // 判断当前参数名称是否等于 com.alibaba.dubbo.rpc.Invocation\n            if (pts[i].getName().equals(\"com.alibaba.dubbo.rpc.Invocation\")) &#123;\n                // 为 Invocation 类型参数生成判空代码\n                String s = String.format(\"\\nif (arg%d == null) throw new IllegalArgumentException(\\\"invocation == null\\\");\", i);\n                code.append(s);\n                // 生成 getMethodName 方法调用代码，格式为：\n                //    String methodName = argN.getMethodName();\n                s = String.format(\"\\nString methodName = arg%d.getMethodName();\", i);\n                code.append(s);\n                \n                // 设置 hasInvocation 为 true\n                hasInvocation = true;\n                break;\n            &#125;\n        &#125;\n    &#125;\n    \n    // 省略无关逻辑\n&#125;\n\n\n\n2.2.3.5 生成拓展名获取逻辑本段逻辑用于根据 SPI 和 Adaptive 注解值生成“获取拓展名逻辑”，同时生成逻辑也受 Invocation 类型参数影响，综合因素导致本段逻辑相对复杂。本段逻辑可能会生成但不限于下面的代码：\nString extName = (url.getProtocol() == null ? \"dubbo\" : url.getProtocol());\n\n\n或\nString extName = url.getMethodParameter(methodName, \"loadbalance\", \"random\");\n\n\n亦或是\nString extName = url.getParameter(\"client\", url.getParameter(\"transporter\", \"netty\"));\n\n\n本段逻辑复杂之处在于条件分支比较多，大家在阅读源码时需要知道每个条件分支的意义是什么，否则不太容易看懂相关代码。下面开始分析本段逻辑。\nfor (Method method : methods) &#123;\n    Class&lt;?> rt = method.getReturnType();\n    Class&lt;?>[] pts = method.getParameterTypes();\n    Class&lt;?>[] ets = method.getExceptionTypes();\n\n    Adaptive adaptiveAnnotation = method.getAnnotation(Adaptive.class);\n    StringBuilder code = new StringBuilder(512);\n    if (adaptiveAnnotation == null) &#123;\n        // $无 Adaptive 注解方法代码生成逻辑&#125;\n    &#125; else &#123;\n        // $&#123;获取 URL 数据&#125;\n        \n        // $&#123;获取 Adaptive 注解值&#125;\n        \n        // $&#123;检测 Invocation 参数&#125;\n        \n        // 设置默认拓展名，cachedDefaultName 源于 SPI 注解值，默认情况下，\n        // SPI 注解值为空串，此时 cachedDefaultName = null\n        String defaultExtName = cachedDefaultName;\n        String getNameCode = null;\n        \n        // 遍历 value，这里的 value 是 Adaptive 的注解值，2.2.3.3 节分析过 value 变量的获取过程。\n        // 此处循环目的是生成从 URL 中获取拓展名的代码，生成的代码会赋值给 getNameCode 变量。注意这\n        // 个循环的遍历顺序是由后向前遍历的。\n        for (int i = value.length - 1; i >= 0; --i) &#123;\n            // 当 i 为最后一个元素的坐标时\n            if (i == value.length - 1) &#123;\n                // 默认拓展名非空\n                if (null != defaultExtName) &#123;\n                    // protocol 是 url 的一部分，可通过 getProtocol 方法获取，其他的则是从\n                    // URL 参数中获取。因为获取方式不同，所以这里要判断 value[i] 是否为 protocol\n                    if (!\"protocol\".equals(value[i]))\n                    \t// hasInvocation 用于标识方法参数列表中是否有 Invocation 类型参数\n                        if (hasInvocation)\n                            // 生成的代码功能等价于下面的代码：\n                            //   url.getMethodParameter(methodName, value[i], defaultExtName)\n                            // 以 LoadBalance 接口的 select 方法为例，最终生成的代码如下：\n                            //   url.getMethodParameter(methodName, \"loadbalance\", \"random\")\n                            getNameCode = String.format(\"url.getMethodParameter(methodName, \\\"%s\\\", \\\"%s\\\")\", value[i], defaultExtName);\n                    \telse\n                    \t\t// 生成的代码功能等价于下面的代码：\n\t                        //   url.getParameter(value[i], defaultExtName)\n\t                        getNameCode = String.format(\"url.getParameter(\\\"%s\\\", \\\"%s\\\")\", value[i], defaultExtName);\n                    else\n                    \t// 生成的代码功能等价于下面的代码：\n                        //   ( url.getProtocol() == null ? defaultExtName : url.getProtocol() )\n                        getNameCode = String.format(\"( url.getProtocol() == null ? \\\"%s\\\" : url.getProtocol() )\", defaultExtName);\n                    \n                // 默认拓展名为空\n                &#125; else &#123;\n                    if (!\"protocol\".equals(value[i]))\n                        if (hasInvocation)\n                        \t// 生成代码格式同上\n                            getNameCode = String.format(\"url.getMethodParameter(methodName, \\\"%s\\\", \\\"%s\\\")\", value[i], defaultExtName);\n\t                    else\n\t                    \t// 生成的代码功能等价于下面的代码：\n\t                        //   url.getParameter(value[i])\n\t                        getNameCode = String.format(\"url.getParameter(\\\"%s\\\")\", value[i]);\n                    else\n                    \t// 生成从 url 中获取协议的代码，比如 \"dubbo\"\n                        getNameCode = \"url.getProtocol()\";\n                &#125;\n            &#125; else &#123;\n                if (!\"protocol\".equals(value[i]))\n                    if (hasInvocation)\n                        // 生成代码格式同上\n                        getNameCode = String.format(\"url.getMethodParameter(methodName, \\\"%s\\\", \\\"%s\\\")\", value[i], defaultExtName);\n\t                else\n\t                \t// 生成的代码功能等价于下面的代码：\n\t                    //   url.getParameter(value[i], getNameCode)\n\t                    // 以 Transporter 接口的 connect 方法为例，最终生成的代码如下：\n\t                    //   url.getParameter(\"client\", url.getParameter(\"transporter\", \"netty\"))\n\t                    getNameCode = String.format(\"url.getParameter(\\\"%s\\\", %s)\", value[i], getNameCode);\n                else\n                    // 生成的代码功能等价于下面的代码：\n                    //   url.getProtocol() == null ? getNameCode : url.getProtocol()\n                    // 以 Protocol 接口的 connect 方法为例，最终生成的代码如下：\n                    //   url.getProtocol() == null ? \"dubbo\" : url.getProtocol()\n                    getNameCode = String.format(\"url.getProtocol() == null ? (%s) : url.getProtocol()\", getNameCode);\n            &#125;\n        &#125;\n        // 生成 extName 赋值代码\n        code.append(\"\\nString extName = \").append(getNameCode).append(\";\");\n        // 生成 extName 判空代码\n        String s = String.format(\"\\nif(extName == null) \" +\n                                 \"throw new IllegalStateException(\\\"Fail to get extension(%s) name from url(\\\" + url.toString() + \\\") use keys(%s)\\\");\",\n                                 type.getName(), Arrays.toString(value));\n        code.append(s);\n    &#125;\n    \n    // 省略无关逻辑\n&#125;\n\n\n上面代码比较复杂，不是很好理解。对于这段代码，建议大家写点测试用例，对 Protocol、LoadBalance 以及 Transporter 等接口的自适应拓展类代码生成过程进行调试。这里我以 Transporter 接口的自适应拓展类代码生成过程举例说明。首先看一下 Transporter 接口的定义，如下：\n@SPI(\"netty\")\npublic interface Transporter &#123;\n\t// @Adaptive(&#123;server, transporter&#125;)\n    @Adaptive(&#123;Constants.SERVER_KEY, Constants.TRANSPORTER_KEY&#125;) \n    Server bind(URL url, ChannelHandler handler) throws RemotingException;\n\n    // @Adaptive(&#123;client, transporter&#125;)\n    @Adaptive(&#123;Constants.CLIENT_KEY, Constants.TRANSPORTER_KEY&#125;)\n    Client connect(URL url, ChannelHandler handler) throws RemotingException;\n&#125;\n\n\n下面对 connect 方法代理逻辑生成的过程进行分析，此时生成代理逻辑所用到的变量如下：\nString defaultExtName = \"netty\";\nboolean hasInvocation = false;\nString getNameCode = null;\nString[] value = [\"client\", \"transporter\"];\n\n\n下面对 value 数组进行遍历，此时 i &#x3D; 1, value[i] &#x3D; “transporter”，生成的代码如下：\ngetNameCode = url.getParameter(\"transporter\", \"netty\");\n\n\n接下来，for 循环继续执行，此时 i &#x3D; 0, value[i] &#x3D; “client”，生成的代码如下：\ngetNameCode = url.getParameter(\"client\", url.getParameter(\"transporter\", \"netty\"));\n\n\nfor 循环结束运行，现在为 extName 变量生成赋值和判空代码，如下：\nString extName = url.getParameter(\"client\", url.getParameter(\"transporter\", \"netty\"));\nif (extName == null) &#123;\n    throw new IllegalStateException(\n        \"Fail to get extension(com.alibaba.dubbo.remoting.Transporter) name from url(\" + url.toString()\n        + \") use keys([client, transporter])\");\n&#125;\n\n\n\n2.2.3.6 生成拓展加载与目标方法调用逻辑本段代码逻辑用于根据拓展名加载拓展实例，并调用拓展实例的目标方法。相关逻辑如下：\nfor (Method method : methods) &#123;\n    Class&lt;?> rt = method.getReturnType();\n    Class&lt;?>[] pts = method.getParameterTypes();\n    Class&lt;?>[] ets = method.getExceptionTypes();\n\n    Adaptive adaptiveAnnotation = method.getAnnotation(Adaptive.class);\n    StringBuilder code = new StringBuilder(512);\n    if (adaptiveAnnotation == null) &#123;\n        // $无 Adaptive 注解方法代码生成逻辑&#125;\n    &#125; else &#123;\n        // $&#123;获取 URL 数据&#125;\n        \n        // $&#123;获取 Adaptive 注解值&#125;\n        \n        // $&#123;检测 Invocation 参数&#125;\n        \n        // $&#123;生成拓展名获取逻辑&#125;\n        \n        // 生成拓展获取代码，格式如下：\n        // type全限定名 extension = (type全限定名)ExtensionLoader全限定名\n        //     .getExtensionLoader(type全限定名.class).getExtension(extName);\n        // Tips: 格式化字符串中的 %&lt;s 表示使用前一个转换符所描述的参数，即 type 全限定名\n        s = String.format(\"\\n%s extension = (%&lt;s)%s.getExtensionLoader(%s.class).getExtension(extName);\",\n                        type.getName(), ExtensionLoader.class.getSimpleName(), type.getName());\n        code.append(s);\n\n\t\t// 如果方法返回值类型非 void，则生成 return 语句。\n        if (!rt.equals(void.class)) &#123;\n            code.append(\"\\nreturn \");\n        &#125;\n\n        // 生成目标方法调用逻辑，格式为：\n        //     extension.方法名(arg0, arg2, ..., argN);\n        s = String.format(\"extension.%s(\", method.getName());\n        code.append(s);\n        for (int i = 0; i &lt; pts.length; i++) &#123;\n            if (i != 0)\n                code.append(\", \");\n            code.append(\"arg\").append(i);\n        &#125;\n        code.append(\");\");   \n    &#125;\n    \n    // 省略无关逻辑\n&#125;\n\n\n以 Protocol 接口举例说明，上面代码生成的内容如下：\ncom.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol) ExtensionLoader\n    .getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName);\nreturn extension.refer(arg0, arg1);\n\n\n\n2.2.3.7 生成完整的方法本节进行代码生成的收尾工作，主要用于生成方法定义的代码。相关逻辑如下：\nfor (Method method : methods) &#123;\n    Class&lt;?> rt = method.getReturnType();\n    Class&lt;?>[] pts = method.getParameterTypes();\n    Class&lt;?>[] ets = method.getExceptionTypes();\n\n    Adaptive adaptiveAnnotation = method.getAnnotation(Adaptive.class);\n    StringBuilder code = new StringBuilder(512);\n    if (adaptiveAnnotation == null) &#123;\n        // $无 Adaptive 注解方法代码生成逻辑&#125;\n    &#125; else &#123;\n        // $&#123;获取 URL 数据&#125;\n        \n        // $&#123;获取 Adaptive 注解值&#125;\n        \n        // $&#123;检测 Invocation 参数&#125;\n        \n        // $&#123;生成拓展名获取逻辑&#125;\n        \n        // $&#123;生成拓展加载与目标方法调用逻辑&#125;\n    &#125;\n&#125;\n    \n// public + 返回值全限定名 + 方法名 + (\ncodeBuilder.append(\"\\npublic \")\n    .append(rt.getCanonicalName())\n    .append(\" \")\n    .append(method.getName())\n    .append(\"(\");\n\n// 添加参数列表代码\nfor (int i = 0; i &lt; pts.length; i++) &#123;\n    if (i > 0) &#123;\n        codeBuilder.append(\", \");\n    &#125;\n    codeBuilder.append(pts[i].getCanonicalName());\n    codeBuilder.append(\" \");\n    codeBuilder.append(\"arg\").append(i);\n&#125;\ncodeBuilder.append(\")\");\n\n// 添加异常抛出代码\nif (ets.length > 0) &#123;\n    codeBuilder.append(\" throws \");\n    for (int i = 0; i &lt; ets.length; i++) &#123;\n        if (i > 0) &#123;\n            codeBuilder.append(\", \");\n        &#125;\n        codeBuilder.append(ets[i].getCanonicalName());\n    &#125;\n&#125;\ncodeBuilder.append(\" &#123;\");\ncodeBuilder.append(code.toString());\ncodeBuilder.append(\"\\n&#125;\");\n\n\n以 Protocol 的 refer 方法为例，上面代码生成的内容如下：\npublic com.alibaba.dubbo.rpc.Invoker refer(java.lang.Class arg0, com.alibaba.dubbo.common.URL arg1) &#123;\n    // 方法体\n&#125;\n\n\n\n3.总结到此，关于自适应拓展的原理，实现就分析完了。总的来说自适应拓展整个逻辑还是很复杂的，并不是很容易弄懂。因此，大家在阅读该部分源码时，耐心一些。同时多进行调试，也可以通过生成好的代码思考代码的生成逻辑。好了，本篇文章就分析到这里。\n\n\n\n\n\n\n\n\n\n原文地址：https://dubbo.apache.org/zh/docsv2.7/dev/source/directory/\n作者： Dubbo 官方\n本文介绍了服务目录的原理和实现细节。\n\n服务目录1. 简介本篇文章，将开始分析 Dubbo 集群容错方面的源码。集群容错源码包含四个部分，分别是:\n\n服务目录 Directory\n服务路由 Router\n集群 Cluster\n负载均衡 LoadBalance。\n\n这几个部分的源码逻辑相对比较独立，我们将会分四篇文章进行分析。\n本篇文章作为集群容错的开篇文章，将和大家一起分析服务目录相关的源码。在进行深入分析之前，我们先来了解一下：服务目录是什么？\n服务目录中存储了一些和服务提供者有关的信息，通过服务目录，服务消费者可获取到服务提供者的信息，比如 ip、端口、服务协议等。通过这些信息，服务消费者就可通过 Netty 等客户端进行远程调用。\n在一个服务集群中，服务提供者数量并不是一成不变的，如果集群中新增了一台机器，相应地在服务目录中就要新增一条服务提供者记录。或者，如果服务提供者的配置修改了，服务目录中的记录也要做相应的更新。如果这样说，服务目录和注册中心的功能不就雷同了吗？确实如此，这里这么说是为了方便大家理解。实际上服务目录在获取注册中心的服务配置信息后，会为每条配置信息生成一个 Invoker 对象，并把这个 Invoker 对象存储起来，这个 Invoker 才是服务目录最终持有的对象。Invoker 有什么用呢？看名字就知道了，这是一个具有远程调用功能的对象。讲到这大家应该知道了什么是服务目录了，它可以看做是 Invoker 集合，且这个集合中的元素会随注册中心的变化而进行动态调整。\n关于服务目录这里就先介绍这些，大家先有个大致印象。接下来我们通过继承体系图来了解一下服务目录的家族成员都有哪些。\n\n2. 继承体系服务目录目前内置的实现有两个，分别为 StaticDirectory 和 RegistryDirectory，它们均是 AbstractDirectory 的子类。AbstractDirectory 实现了 Directory 接口，这个接口包含了一个重要的方法定义，即 list(Invocation)，用于列举 Invoker。下面我们来看一下他们的继承体系图。\n\n如上，Directory 继承自 Node 接口，Node 这个接口继承者比较多，像 Registry、Monitor、Invoker 等均继承了这个接口。这个接口包含了一个获取配置信息的方法 getUrl，实现该接口的类可以向外提供配置信息。另外，大家注意看 RegistryDirectory 实现了 NotifyListener 接口，当注册中心节点信息发生变化后，RegistryDirectory 可以通过此接口方法得到变更信息，并根据变更信息动态调整内部 Invoker 列表。\n\n3. 源码分析本章将分析 AbstractDirectory 和它两个子类的源码。AbstractDirectory 封装了 Invoker 列举流程，具体的列举逻辑则由子类实现，这是典型的模板模式。所以，接下来我们先来看一下 AbstractDirectory 的源码。\npublic List&lt;Invoker&lt;T>> list(Invocation invocation) throws RpcException &#123;\n    if (destroyed) &#123;\n        throw new RpcException(\"Directory already destroyed...\");\n    &#125;\n    \n    // 调用 doList 方法列举 Invoker，doList 是模板方法，由子类实现\n    List&lt;Invoker&lt;T>> invokers = doList(invocation);\n    \n    // 获取路由 Router 列表\n    List&lt;Router> localRouters = this.routers;\n    if (localRouters != null &amp;&amp; !localRouters.isEmpty()) &#123;\n        for (Router router : localRouters) &#123;\n            try &#123;\n                // 获取 runtime 参数，并根据参数决定是否进行路由\n                if (router.getUrl() == null || router.getUrl().getParameter(Constants.RUNTIME_KEY, false)) &#123;\n                    // 进行服务路由\n                    invokers = router.route(invokers, getConsumerUrl(), invocation);\n                &#125;\n            &#125; catch (Throwable t) &#123;\n                logger.error(\"Failed to execute router: ...\");\n            &#125;\n        &#125;\n    &#125;\n    return invokers;\n&#125;\n\n// 模板方法，由子类实现\nprotected abstract List&lt;Invoker&lt;T>> doList(Invocation invocation) throws RpcException;\n\n上面就是 AbstractDirectory 的 list 方法源码，这个方法封装了 Invoker 的列举过程。如下：\n\n调用 doList 获取 Invoker 列表\n根据 Router 的 getUrl 返回值为空与否，以及 runtime 参数决定是否进行服务路由\n\n以上步骤中，doList 是模板方法，需由子类实现。Router 的 runtime 参数这里简单说明一下，这个参数决定了是否在每次调用服务时都执行路由规则。如果 runtime 为 true，那么每次调用服务前，都需要进行服务路由。这个对性能造成影响，配置时需要注意。\n关于 AbstractDirectory 就分析这么多，下面开始分析子类的源码。\n\n3.1 StaticDirectory:静态目录服务StaticDirectory 即静态服务目录，顾名思义，它内部存放的 Invoker 是不会变动的。所以，理论上它和不可变 List 的功能很相似。下面我们来看一下这个类的实现。\npublic class StaticDirectory&lt;T> extends AbstractDirectory&lt;T> &#123;\n\n    // Invoker 列表\n    private final List&lt;Invoker&lt;T>> invokers;\n    // 省略构造方法\n    @Override\n    public Class&lt;T> getInterface() &#123;\n        // 获取接口类\n        return invokers.get(0).getInterface();\n    &#125;\n    \n    // 检测服务目录是否可用\n    @Override\n    public boolean isAvailable() &#123;\n        if (isDestroyed()) &#123;\n            return false;\n        &#125;\n        for (Invoker&lt;T> invoker : invokers) &#123;\n            if (invoker.isAvailable()) &#123;\n                // 只要有一个 Invoker 是可用的，就认为当前目录是可用的\n                return true;\n            &#125;\n        &#125;\n        return false;\n    &#125;\n\n    @Override\n    public void destroy() &#123;\n        if (isDestroyed()) &#123;\n            return;\n        &#125;\n        // 调用父类销毁逻辑\n        super.destroy();\n        // 遍历 Invoker 列表，并执行相应的销毁逻辑\n        for (Invoker&lt;T> invoker : invokers) &#123;\n            invoker.destroy();\n        &#125;\n        invokers.clear();\n    &#125;\n\n    @Override\n    protected List&lt;Invoker&lt;T>> doList(Invocation invocation) throws RpcException &#123;\n        // 列举 Inovker，也就是直接返回 invokers 成员变量\n        return invokers;\n    &#125;\n&#125;\n\n以上就是 StaticDirectory 的代码逻辑，很简单，就不多说了。下面来看看 RegistryDirectory，这个类的逻辑比较复杂。\n\n3.2 RegistryDirectory:动态服务目录RegistryDirectory 是一种动态服务目录，实现了 NotifyListener 接口。当注册中心服务配置发生变化后，RegistryDirectory 可收到与当前服务相关的变化。收到变更通知后，RegistryDirectory 可根据配置变更信息刷新 Invoker 列表。RegistryDirectory 中有几个比较重要的逻辑，第一是 Invoker 的列举逻辑，第二是接收服务配置变更的逻辑，第三是 Invoker 列表的刷新逻辑。接下来按顺序对这三块逻辑进行分析。\n\n3.2.1 列举 InvokerInvoker 列举逻辑封装在 doList 方法中，相关代码如下：\npublic List&lt;Invoker&lt;T>> doList(Invocation invocation) &#123;\n    if (forbidden) &#123;\n        // 服务提供者关闭或禁用了服务，此时抛出 No provider 异常\n        throw new RpcException(RpcException.FORBIDDEN_EXCEPTION,\n            \"No provider available from registry ...\");\n    &#125;\n    List&lt;Invoker&lt;T>> invokers = null;\n    // 获取 Invoker 本地缓存\n    Map&lt;String, List&lt;Invoker&lt;T>>> localMethodInvokerMap = this.methodInvokerMap;\n    if (localMethodInvokerMap != null &amp;&amp; localMethodInvokerMap.size() > 0) &#123;\n        // 获取方法名和参数列表\n        String methodName = RpcUtils.getMethodName(invocation);\n        Object[] args = RpcUtils.getArguments(invocation);\n        // 检测参数列表的第一个参数是否为 String 或 enum 类型\n        if (args != null &amp;&amp; args.length > 0 &amp;&amp; args[0] != null\n                &amp;&amp; (args[0] instanceof String || args[0].getClass().isEnum())) &#123;\n            // 通过 方法名 + 第一个参数名称 查询 Invoker 列表，具体的使用场景暂时没想到\n            invokers = localMethodInvokerMap.get(methodName + \".\" + args[0]);\n        &#125;\n        if (invokers == null) &#123;\n            // 通过方法名获取 Invoker 列表\n            invokers = localMethodInvokerMap.get(methodName);\n        &#125;\n        if (invokers == null) &#123;\n            // 通过星号 * 获取 Invoker 列表\n            invokers = localMethodInvokerMap.get(Constants.ANY_VALUE);\n        &#125;\n        \n        // 冗余逻辑，pull request #2861 移除了下面的 if 分支代码\n        if (invokers == null) &#123;\n            Iterator&lt;List&lt;Invoker&lt;T>>> iterator = localMethodInvokerMap.values().iterator();\n            if (iterator.hasNext()) &#123;\n                invokers = iterator.next();\n            &#125;\n        &#125;\n    &#125;\n\n\t// 返回 Invoker 列表\n    return invokers == null ? new ArrayList&lt;Invoker&lt;T>>(0) : invokers;\n&#125;\n\n以上代码进行多次尝试，以期从 localMethodInvokerMap 中获取到 Invoker 列表。一般情况下，普通的调用可通过方法名获取到对应的 Invoker 列表，泛化调用可通过 * 获取到 Invoker 列表。localMethodInvokerMap 源自 RegistryDirectory 类的成员变量 methodInvokerMap。doList 方法可以看做是对 methodInvokerMap 变量的读操作，至于对 methodInvokerMap 变量的写操作，下一节进行分析。\n\n3.2.2 接收服务变更通知RegistryDirectory 是一个动态服务目录，会随注册中心配置的变化进行动态调整。因此 RegistryDirectory 实现了 NotifyListener 接口，通过这个接口获取注册中心变更通知。下面我们来看一下具体的逻辑。\npublic synchronized void notify(List&lt;URL> urls) &#123;\n    // 定义三个集合，分别用于存放服务提供者 url，路由 url，配置器 url\n    List&lt;URL> invokerUrls = new ArrayList&lt;URL>();\n    List&lt;URL> routerUrls = new ArrayList&lt;URL>();\n    List&lt;URL> configuratorUrls = new ArrayList&lt;URL>();\n    for (URL url : urls) &#123;\n        String protocol = url.getProtocol();\n        // 获取 category 参数\n        String category = url.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY);\n        // 根据 category 参数将 url 分别放到不同的列表中\n        if (Constants.ROUTERS_CATEGORY.equals(category)\n                || Constants.ROUTE_PROTOCOL.equals(protocol)) &#123;\n            // 添加路由器 url\n            routerUrls.add(url);\n        &#125; else if (Constants.CONFIGURATORS_CATEGORY.equals(category)\n                || Constants.OVERRIDE_PROTOCOL.equals(protocol)) &#123;\n            // 添加配置器 url\n            configuratorUrls.add(url);\n        &#125; else if (Constants.PROVIDERS_CATEGORY.equals(category)) &#123;\n            // 添加服务提供者 url\n            invokerUrls.add(url);\n        &#125; else &#123;\n            // 忽略不支持的 category\n            logger.warn(\"Unsupported category ...\");\n        &#125;\n    &#125;\n    if (configuratorUrls != null &amp;&amp; !configuratorUrls.isEmpty()) &#123;\n        // 将 url 转成 Configurator\n        this.configurators = toConfigurators(configuratorUrls);\n    &#125;\n    if (routerUrls != null &amp;&amp; !routerUrls.isEmpty()) &#123;\n        // 将 url 转成 Router\n        List&lt;Router> routers = toRouters(routerUrls);\n        if (routers != null) &#123;\n            setRouters(routers);\n        &#125;\n    &#125;\n    List&lt;Configurator> localConfigurators = this.configurators;\n    this.overrideDirectoryUrl = directoryUrl;\n    if (localConfigurators != null &amp;&amp; !localConfigurators.isEmpty()) &#123;\n        for (Configurator configurator : localConfigurators) &#123;\n            // 配置 overrideDirectoryUrl\n            this.overrideDirectoryUrl = configurator.configure(overrideDirectoryUrl);\n        &#125;\n    &#125;\n\n    // 刷新 Invoker 列表\n    refreshInvoker(invokerUrls);\n&#125;\n\n如上，notify 方法首先是根据 url 的 category 参数对 url 进行分门别类存储，然后通过 toRouters 和 toConfigurators 将 url 列表转成 Router 和 Configurator 列表。最后调用 refreshInvoker 方法刷新 Invoker 列表。这里的 toRouters 和 toConfigurators 方法逻辑不复杂，大家自行分析。接下来，我们把重点放在 refreshInvoker 方法上。\n\n3.2.3 刷新 Invoker 列表refreshInvoker 方法是保证 RegistryDirectory 随注册中心变化而变化的关键所在。这一块逻辑比较多，接下来一一进行分析。\nprivate void refreshInvoker(List&lt;URL> invokerUrls) &#123;\n    // invokerUrls 仅有一个元素，且 url 协议头为 empty，此时表示禁用所有服务\n    if (invokerUrls != null &amp;&amp; invokerUrls.size() == 1 &amp;&amp; invokerUrls.get(0) != null\n            &amp;&amp; Constants.EMPTY_PROTOCOL.equals(invokerUrls.get(0).getProtocol())) &#123;\n        // 设置 forbidden 为 true\n        this.forbidden = true;\n        this.methodInvokerMap = null;\n        // 销毁所有 Invoker\n        destroyAllInvokers();\n    &#125; else &#123;\n        this.forbidden = false;\n        Map&lt;String, Invoker&lt;T>> oldUrlInvokerMap = this.urlInvokerMap;\n        if (invokerUrls.isEmpty() &amp;&amp; this.cachedInvokerUrls != null) &#123;\n            // 添加缓存 url 到 invokerUrls 中\n            invokerUrls.addAll(this.cachedInvokerUrls);\n        &#125; else &#123;\n            this.cachedInvokerUrls = new HashSet&lt;URL>();\n            // 缓存 invokerUrls\n            this.cachedInvokerUrls.addAll(invokerUrls);\n        &#125;\n        if (invokerUrls.isEmpty()) &#123;\n            return;\n        &#125;\n        // 将 url 转成 Invoker\n        Map&lt;String, Invoker&lt;T>> newUrlInvokerMap = toInvokers(invokerUrls);\n        // 将 newUrlInvokerMap 转成方法名到 Invoker 列表的映射\n        Map&lt;String, List&lt;Invoker&lt;T>>> newMethodInvokerMap = toMethodInvokers(newUrlInvokerMap);\n        // 转换出错，直接打印异常，并返回\n        if (newUrlInvokerMap == null || newUrlInvokerMap.size() == 0) &#123;\n            logger.error(new IllegalStateException(\"urls to invokers error ...\"));\n            return;\n        &#125;\n        // 合并多个组的 Invoker\n        this.methodInvokerMap = multiGroup ? toMergeMethodInvokerMap(newMethodInvokerMap) : newMethodInvokerMap;\n        this.urlInvokerMap = newUrlInvokerMap;\n        try &#123;\n            // 销毁无用 Invoker\n            destroyUnusedInvokers(oldUrlInvokerMap, newUrlInvokerMap);\n        &#125; catch (Exception e) &#123;\n            logger.warn(\"destroyUnusedInvokers error. \", e);\n        &#125;\n    &#125;\n&#125;\n\nrefreshInvoker 方法首先会根据入参 invokerUrls 的数量和协议头判断是否禁用所有的服务，如果禁用，则将 forbidden 设为 true，并销毁所有的 Invoker。若不禁用，则将 url 转成 Invoker，得到 &lt;url, Invoker&gt; 的映射关系。然后进一步进行转换，得到 &lt;methodName, Invoker 列表&gt; 映射关系。之后进行多组 Invoker 合并操作，并将合并结果赋值给 methodInvokerMap。methodInvokerMap 变量在 doList 方法中会被用到，doList 会对该变量进行读操作，在这里是写操作。当新的 Invoker 列表生成后，还要一个重要的工作要做，就是销毁无用的 Invoker，避免服务消费者调用已下线的服务的服务。\n接下来对 refreshInvoker 方法中涉及到的调用一一进行分析。按照顺序，先来分析 url 到 Invoker 的转换过程。\nprivate Map&lt;String, Invoker&lt;T>> toInvokers(List&lt;URL> urls) &#123;\n    Map&lt;String, Invoker&lt;T>> newUrlInvokerMap = new HashMap&lt;String, Invoker&lt;T>>();\n    if (urls == null || urls.isEmpty()) &#123;\n        return newUrlInvokerMap;\n    &#125;\n    Set&lt;String> keys = new HashSet&lt;String>();\n    // 获取服务消费端配置的协议\n    String queryProtocols = this.queryMap.get(Constants.PROTOCOL_KEY);\n    for (URL providerUrl : urls) &#123;\n        if (queryProtocols != null &amp;&amp; queryProtocols.length() > 0) &#123;\n            boolean accept = false;\n            String[] acceptProtocols = queryProtocols.split(\",\");\n            // 检测服务提供者协议是否被服务消费者所支持\n            for (String acceptProtocol : acceptProtocols) &#123;\n                if (providerUrl.getProtocol().equals(acceptProtocol)) &#123;\n                    accept = true;\n                    break;\n                &#125;\n            &#125;\n            if (!accept) &#123;\n                // 若服务提供者协议头不被消费者所支持，则忽略当前 providerUrl\n                continue;\n            &#125;\n        &#125;\n        // 忽略 empty 协议\n        if (Constants.EMPTY_PROTOCOL.equals(providerUrl.getProtocol())) &#123;\n            continue;\n        &#125;\n        // 通过 SPI 检测服务端协议是否被消费端支持，不支持则抛出异常\n        if (!ExtensionLoader.getExtensionLoader(Protocol.class).hasExtension(providerUrl.getProtocol())) &#123;\n            logger.error(new IllegalStateException(\"Unsupported protocol...\"));\n            continue;\n        &#125;\n        \n        // 合并 url\n        URL url = mergeUrl(providerUrl);\n\n        String key = url.toFullString();\n        if (keys.contains(key)) &#123;\n            // 忽略重复 url\n            continue;\n        &#125;\n        keys.add(key);\n        // 将本地 Invoker 缓存赋值给 localUrlInvokerMap\n        Map&lt;String, Invoker&lt;T>> localUrlInvokerMap = this.urlInvokerMap;\n        // 获取与 url 对应的 Invoker\n        Invoker&lt;T> invoker = localUrlInvokerMap == null ? null : localUrlInvokerMap.get(key);\n        // 缓存未命中\n        if (invoker == null) &#123;\n            try &#123;\n                boolean enabled = true;\n                if (url.hasParameter(Constants.DISABLED_KEY)) &#123;\n                    // 获取 disable 配置，取反，然后赋值给 enable 变量\n                    enabled = !url.getParameter(Constants.DISABLED_KEY, false);\n                &#125; else &#123;\n                    // 获取 enable 配置，并赋值给 enable 变量\n                    enabled = url.getParameter(Constants.ENABLED_KEY, true);\n                &#125;\n                if (enabled) &#123;\n                    // 调用 refer 获取 Invoker\n                    invoker = new InvokerDelegate&lt;T>(protocol.refer(serviceType, url), url, providerUrl);\n                &#125;\n            &#125; catch (Throwable t) &#123;\n                logger.error(\"Failed to refer invoker for interface...\");\n            &#125;\n            if (invoker != null) &#123;\n                // 缓存 Invoker 实例\n                newUrlInvokerMap.put(key, invoker);\n            &#125;\n            \n        // 缓存命中\n        &#125; else &#123;\n            // 将 invoker 存储到 newUrlInvokerMap 中\n            newUrlInvokerMap.put(key, invoker);\n        &#125;\n    &#125;\n    keys.clear();\n    return newUrlInvokerMap;\n&#125;\n\ntoInvokers 方法一开始会对服务提供者 url 进行检测，若服务消费端的配置不支持服务端的协议，或服务端 url 协议头为 empty 时，toInvokers 均会忽略服务提供方 url。必要的检测做完后，紧接着是合并 url，然后访问缓存，尝试获取与 url 对应的 invoker。如果缓存命中，直接将 Invoker 存入 newUrlInvokerMap 中即可。如果未命中，则需新建 Invoker。\ntoInvokers 方法返回的是 &lt;url, Invoker&gt; 映射关系表，接下来还要对这个结果进行进一步处理，得到方法名到 Invoker 列表的映射关系。这个过程由 toMethodInvokers 方法完成，如下：\nprivate Map&lt;String, List&lt;Invoker&lt;T>>> toMethodInvokers(Map&lt;String, Invoker&lt;T>> invokersMap) &#123;\n    // 方法名 -> Invoker 列表\n    Map&lt;String, List&lt;Invoker&lt;T>>> newMethodInvokerMap = new HashMap&lt;String, List&lt;Invoker&lt;T>>>();\n    List&lt;Invoker&lt;T>> invokersList = new ArrayList&lt;Invoker&lt;T>>();\n    if (invokersMap != null &amp;&amp; invokersMap.size() > 0) &#123;\n        for (Invoker&lt;T> invoker : invokersMap.values()) &#123;\n            // 获取 methods 参数\n            String parameter = invoker.getUrl().getParameter(Constants.METHODS_KEY);\n            if (parameter != null &amp;&amp; parameter.length() > 0) &#123;\n                // 切分 methods 参数值，得到方法名数组\n                String[] methods = Constants.COMMA_SPLIT_PATTERN.split(parameter);\n                if (methods != null &amp;&amp; methods.length > 0) &#123;\n                    for (String method : methods) &#123;\n                        // 方法名不为 *\n                        if (method != null &amp;&amp; method.length() > 0\n                                &amp;&amp; !Constants.ANY_VALUE.equals(method)) &#123;\n                            // 根据方法名获取 Invoker 列表\n                            List&lt;Invoker&lt;T>> methodInvokers = newMethodInvokerMap.get(method);\n                            if (methodInvokers == null) &#123;\n                                methodInvokers = new ArrayList&lt;Invoker&lt;T>>();\n                                newMethodInvokerMap.put(method, methodInvokers);\n                            &#125;\n                            // 存储 Invoker 到列表中\n                            methodInvokers.add(invoker);\n                        &#125;\n                    &#125;\n                &#125;\n            &#125;\n            invokersList.add(invoker);\n        &#125;\n    &#125;\n    \n    // 进行服务级别路由，参考 pull request #749\n    List&lt;Invoker&lt;T>> newInvokersList = route(invokersList, null);\n    // 存储 &lt;*, newInvokersList> 映射关系\n    newMethodInvokerMap.put(Constants.ANY_VALUE, newInvokersList);\n    if (serviceMethods != null &amp;&amp; serviceMethods.length > 0) &#123;\n        for (String method : serviceMethods) &#123;\n            List&lt;Invoker&lt;T>> methodInvokers = newMethodInvokerMap.get(method);\n            if (methodInvokers == null || methodInvokers.isEmpty()) &#123;\n                methodInvokers = newInvokersList;\n            &#125;\n            // 进行方法级别路由\n            newMethodInvokerMap.put(method, route(methodInvokers, method));\n        &#125;\n    &#125;\n    // 排序，转成不可变列表\n    for (String method : new HashSet&lt;String>(newMethodInvokerMap.keySet())) &#123;\n        List&lt;Invoker&lt;T>> methodInvokers = newMethodInvokerMap.get(method);\n        Collections.sort(methodInvokers, InvokerComparator.getComparator());\n        newMethodInvokerMap.put(method, Collections.unmodifiableList(methodInvokers));\n    &#125;\n    return Collections.unmodifiableMap(newMethodInvokerMap);\n&#125;\n\n上面方法主要做了三件事情， 第一是对入参进行遍历，然后从 Invoker 的 url 成员变量中获取 methods 参数，并切分成数组。随后以方法名为键，Invoker 列表为值，将映射关系存储到 newMethodInvokerMap 中。第二是分别基于类和方法对 Invoker 列表进行路由操作。第三是对 Invoker 列表进行排序，并转成不可变列表。关于 toMethodInvokers 方法就先分析到这，我们继续向下分析，这次要分析的多组服务的合并逻辑。\nprivate Map&lt;String, List&lt;Invoker&lt;T>>> toMergeMethodInvokerMap(Map&lt;String, List&lt;Invoker&lt;T>>> methodMap) &#123;\n    Map&lt;String, List&lt;Invoker&lt;T>>> result = new HashMap&lt;String, List&lt;Invoker&lt;T>>>();\n    // 遍历入参\n    for (Map.Entry&lt;String, List&lt;Invoker&lt;T>>> entry : methodMap.entrySet()) &#123;\n        String method = entry.getKey();\n        List&lt;Invoker&lt;T>> invokers = entry.getValue();\n        // group -> Invoker 列表\n        Map&lt;String, List&lt;Invoker&lt;T>>> groupMap = new HashMap&lt;String, List&lt;Invoker&lt;T>>>();\n        // 遍历 Invoker 列表\n        for (Invoker&lt;T> invoker : invokers) &#123;\n            // 获取分组配置\n            String group = invoker.getUrl().getParameter(Constants.GROUP_KEY, \"\");\n            List&lt;Invoker&lt;T>> groupInvokers = groupMap.get(group);\n            if (groupInvokers == null) &#123;\n                groupInvokers = new ArrayList&lt;Invoker&lt;T>>();\n                // 缓存 &lt;group, List&lt;Invoker>> 到 groupMap 中\n                groupMap.put(group, groupInvokers);\n            &#125;\n            // 存储 invoker 到 groupInvokers\n            groupInvokers.add(invoker);\n        &#125;\n        if (groupMap.size() == 1) &#123;\n            // 如果 groupMap 中仅包含一组键值对，此时直接取出该键值对的值即可\n            result.put(method, groupMap.values().iterator().next());\n        \n        // groupMap.size() > 1 成立，表示 groupMap 中包含多组键值对，比如：\n        // &#123;\n        //     \"dubbo\": [invoker1, invoker2, invoker3, ...],\n        //     \"hello\": [invoker4, invoker5, invoker6, ...]\n        // &#125;\n        &#125; else if (groupMap.size() > 1) &#123;\n            List&lt;Invoker&lt;T>> groupInvokers = new ArrayList&lt;Invoker&lt;T>>();\n            for (List&lt;Invoker&lt;T>> groupList : groupMap.values()) &#123;\n                // 通过集群类合并每个分组对应的 Invoker 列表\n                groupInvokers.add(cluster.join(new StaticDirectory&lt;T>(groupList)));\n            &#125;\n            // 缓存结果\n            result.put(method, groupInvokers);\n        &#125; else &#123;\n            result.put(method, invokers);\n        &#125;\n    &#125;\n    return result;\n&#125;\n\n上面方法首先是生成 group 到 Invoker 列表的映射关系表，若关系表中的映射关系数量大于1，表示有多组服务。此时通过集群类合并每组 Invoker，并将合并结果存储到 groupInvokers 中。之后将方法名与 groupInvokers 存到到 result 中，并返回，整个逻辑结束。\n接下来我们再来看一下 Invoker 列表刷新逻辑的最后一个动作 — 删除无用 Invoker。如下：\nprivate void destroyUnusedInvokers(Map&lt;String, Invoker&lt;T>> oldUrlInvokerMap, Map&lt;String, Invoker&lt;T>> newUrlInvokerMap) &#123;\n    if (newUrlInvokerMap == null || newUrlInvokerMap.size() == 0) &#123;\n        destroyAllInvokers();\n        return;\n    &#125;\n   \n    List&lt;String> deleted = null;\n    if (oldUrlInvokerMap != null) &#123;\n        // 获取新生成的 Invoker 列表\n        Collection&lt;Invoker&lt;T>> newInvokers = newUrlInvokerMap.values();\n        // 遍历老的 &lt;url, Invoker> 映射表\n        for (Map.Entry&lt;String, Invoker&lt;T>> entry : oldUrlInvokerMap.entrySet()) &#123;\n            // 检测 newInvokers 中是否包含老的 Invoker\n            if (!newInvokers.contains(entry.getValue())) &#123;\n                if (deleted == null) &#123;\n                    deleted = new ArrayList&lt;String>();\n                &#125;\n                // 若不包含，则将老的 Invoker 对应的 url 存入 deleted 列表中\n                deleted.add(entry.getKey());\n            &#125;\n        &#125;\n    &#125;\n\n    if (deleted != null) &#123;\n        // 遍历 deleted 集合，并到老的 &lt;url, Invoker> 映射关系表查出 Invoker，销毁之\n        for (String url : deleted) &#123;\n            if (url != null) &#123;\n                // 从 oldUrlInvokerMap 中移除 url 对应的 Invoker\n                Invoker&lt;T> invoker = oldUrlInvokerMap.remove(url);\n                if (invoker != null) &#123;\n                    try &#123;\n                        // 销毁 Invoker\n                        invoker.destroy();\n                    &#125; catch (Exception e) &#123;\n                        logger.warn(\"destroy invoker...\");\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\ndestroyUnusedInvokers 方法的主要逻辑是通过 newUrlInvokerMap 找出待删除 Invoker 对应的 url，并将 url 存入到 deleted 列表中。然后再遍历 deleted 列表，并从 oldUrlInvokerMap 中移除相应的 Invoker，销毁之。整个逻辑大致如此，不是很难理解。\n到此关于 Invoker 列表的刷新逻辑就分析了，这里对整个过程进行简单总结。如下：\n\n检测入参是否仅包含一个 url，且 url 协议头为 empty\n若第一步检测结果为 true，表示禁用所有服务，此时销毁所有的 Invoker\n若第一步检测结果为 false，此时将入参转为 Invoker 列表\n对上一步逻辑生成的结果进行进一步处理，得到方法名到 Invoker 的映射关系表\n合并多组 Invoker\n销毁无用 Invoker\n\nInvoker 的刷新逻辑还是比较复杂的，大家在看的过程中多写点 demo 进行调试，以加深理解。\n\n4. 总结本篇文章对 Dubbo 服务目录进行了较为详细的分析，篇幅主要集中在 RegistryDirectory 的源码分析上。从代码量上可以看出，想让本地服务目录和注册中心保持一致还是需要做很多事情的，并不简单。服务目录是 Dubbo 集群容错的一部分，也是比较基础的部分，所以大家应尽量搞懂。\n\n\n\n\n\n\n\n\n\n原文地址：https://dubbo.apache.org/zh/docsv2.7/dev/source/router/\n作者： Dubbo 官方\n\n服务路由1. 简介上一篇文章分析了集群容错的第一部分 — 服务目录 Directory。服务目录在刷新 Invoker 列表的过程中，会通过 Router 进行服务路由，筛选出符合路由规则的服务提供者。在详细分析服务路由的源码之前，先来介绍一下服务路由是什么。服务路由包含一条路由规则，路由规则决定了服务消费者的调用目标，即规定了服务消费者可调用哪些服务提供者。Dubbo 目前提供了三种服务路由实现，分别为：\n\n条件路由 ConditionRouter\n脚本路由 ScriptRouter\n标签路由 TagRouter。\n\n条件路由是我们最常使用的，标签路由是一个新的实现，暂时还未发布，该实现预计会在 2.7.x 版本中发布。本篇文章将分析条件路由相关源码，脚本路由和标签路由这里就不分析了。\n\n2. 源码分析条件路由规则由两个条件组成，分别用于对服务消费者和提供者进行匹配。比如有这样一条规则：\nhost &#x3D; 10.20.153.10 &#x3D;&gt; host &#x3D; 10.20.153.11\n\n该条规则表示 IP 为 10.20.153.10 的服务消费者只可调用 IP 为 10.20.153.11 机器上的服务，不可调用其他机器上的服务。条件路由规则的格式如下：\n[服务消费者匹配条件] &#x3D;&gt; [服务提供者匹配条件]\n\n如果服务消费者匹配条件为空，表示不对服务消费者进行限制。如果服务提供者匹配条件为空，表示对某些服务消费者禁用服务。官方文档中对条件路由进行了比较详细的介绍，大家可以参考下，这里就不过多说明了。\n条件路由实现类 ConditionRouter 在进行工作前，需要先对用户配置的路由规则进行解析，得到一系列的条件。然后再根据这些条件对服务进行路由。本章将分两节进行说明，2.1节介绍表达式解析过程。2.2 节介绍服务路由的过程。下面，我们先从表达式解析过程看起。\n\n2.1 表达式解析条件路由规则是一条字符串，对于 Dubbo 来说，它并不能直接理解字符串的意思，需要将其解析成内部格式才行。条件表达式的解析过程始于 ConditionRouter 的构造方法，下面一起看一下：\npublic ConditionRouter(URL url) &#123;\n    this.url = url;\n    // 获取 priority 和 force 配置\n    this.priority = url.getParameter(Constants.PRIORITY_KEY, 0);\n    this.force = url.getParameter(Constants.FORCE_KEY, false);\n    try &#123;\n        // 获取路由规则\n        String rule = url.getParameterAndDecoded(Constants.RULE_KEY);\n        if (rule == null || rule.trim().length() == 0) &#123;\n            throw new IllegalArgumentException(\"Illegal route rule!\");\n        &#125;\n        rule = rule.replace(\"consumer.\", \"\").replace(\"provider.\", \"\");\n        // 定位 => 分隔符\n        int i = rule.indexOf(\"=>\");\n        // 分别获取服务消费者和提供者匹配规则\n        String whenRule = i &lt; 0 ? null : rule.substring(0, i).trim();\n        String thenRule = i &lt; 0 ? rule.trim() : rule.substring(i + 2).trim();\n        // 解析服务消费者匹配规则\n        Map&lt;String, MatchPair> when = \n            StringUtils.isBlank(whenRule) || \"true\".equals(whenRule) \n                ? new HashMap&lt;String, MatchPair>() : parseRule(whenRule);\n        // 解析服务提供者匹配规则\n        Map&lt;String, MatchPair> then = \n            StringUtils.isBlank(thenRule) || \"false\".equals(thenRule) \n                ? null : parseRule(thenRule);\n        // 将解析出的匹配规则分别赋值给 whenCondition 和 thenCondition 成员变量\n        this.whenCondition = when;\n        this.thenCondition = then;\n    &#125; catch (ParseException e) &#123;\n        throw new IllegalStateException(e.getMessage(), e);\n    &#125;\n&#125;\n\n如上，ConditionRouter 构造方法先是对路由规则做预处理，然后调用 parseRule 方法分别对服务提供者和消费者规则进行解析，最后将解析结果赋值给 whenCondition 和 thenCondition 成员变量。ConditionRouter 构造方法不是很复杂，这里就不多说了。下面我们把重点放在 parseRule 方法上，在详细介绍这个方法之前，我们先来看一个内部类。\nprivate static final class MatchPair &#123;\n    final Set&lt;String> matches = new HashSet&lt;String>();\n    final Set&lt;String> mismatches = new HashSet&lt;String>();\n&#125;\n\nMatchPair 内部包含了两个 Set 类型的成员变量，分别用于存放匹配和不匹配的条件。这个类两个成员变量会在 parseRule 方法中被用到，下面来看一下。\nprivate static Map&lt;String, MatchPair> parseRule(String rule)\n        throws ParseException &#123;\n    // 定义条件映射集合\n    Map&lt;String, MatchPair> condition = new HashMap&lt;String, MatchPair>();\n    if (StringUtils.isBlank(rule)) &#123;\n        return condition;\n    &#125;\n    MatchPair pair = null;\n    Set&lt;String> values = null;\n    // 通过正则表达式匹配路由规则，ROUTE_PATTERN = ([&amp;!=,]*)\\s*([^&amp;!=,\\s]+)\n    // 这个表达式看起来不是很好理解，第一个括号内的表达式用于匹配\"&amp;\", \"!\", \"=\" 和 \",\" 等符号。\n    // 第二括号内的用于匹配英文字母，数字等字符。举个例子说明一下：\n    //    host = 2.2.2.2 &amp; host != 1.1.1.1 &amp; method = hello\n    // 匹配结果如下：\n    //     括号一      括号二\n    // 1.  null       host\n    // 2.   =         2.2.2.2\n    // 3.   &amp;         host\n    // 4.   !=        1.1.1.1 \n    // 5.   &amp;         method\n    // 6.   =         hello\n    final Matcher matcher = ROUTE_PATTERN.matcher(rule);\n    while (matcher.find()) &#123;\n       \t// 获取括号一内的匹配结果\n        String separator = matcher.group(1);\n        // 获取括号二内的匹配结果\n        String content = matcher.group(2);\n        // 分隔符为空，表示匹配的是表达式的开始部分\n        if (separator == null || separator.length() == 0) &#123;\n            // 创建 MatchPair 对象\n            pair = new MatchPair();\n            // 存储 &lt;匹配项, MatchPair> 键值对，比如 &lt;host, MatchPair>\n            condition.put(content, pair); \n        &#125; \n        \n        // 如果分隔符为 &amp;，表明接下来也是一个条件\n        else if (\"&amp;\".equals(separator)) &#123;\n            // 尝试从 condition 获取 MatchPair\n            if (condition.get(content) == null) &#123;\n                // 未获取到 MatchPair，重新创建一个，并放入 condition 中\n                pair = new MatchPair();\n                condition.put(content, pair);\n            &#125; else &#123;\n                pair = condition.get(content);\n            &#125;\n        &#125; \n        \n        // 分隔符为 =\n        else if (\"=\".equals(separator)) &#123;\n            if (pair == null)\n                throw new ParseException(\"Illegal route rule ...\");\n\n            values = pair.matches;\n            // 将 content 存入到 MatchPair 的 matches 集合中\n            values.add(content);\n        &#125; \n        \n        //  分隔符为 != \n        else if (\"!=\".equals(separator)) &#123;\n            if (pair == null)\n                throw new ParseException(\"Illegal route rule ...\");\n\n            values = pair.mismatches;\n            // 将 content 存入到 MatchPair 的 mismatches 集合中\n            values.add(content);\n        &#125;\n        \n        // 分隔符为 ,\n        else if (\",\".equals(separator)) &#123;\n            if (values == null || values.isEmpty())\n                throw new ParseException(\"Illegal route rule ...\");\n            // 将 content 存入到上一步获取到的 values 中，可能是 matches，也可能是 mismatches\n            values.add(content);\n        &#125; else &#123;\n            throw new ParseException(\"Illegal route rule ...\");\n        &#125;\n    &#125;\n    return condition;\n&#125;\n\n以上就是路由规则的解析逻辑，该逻辑由正则表达式和一个 while 循环以及数个条件分支组成。下面通过一个示例对解析逻辑进行演绎。示例为 host = 2.2.2.2 &amp; host != 1.1.1.1 &amp; method = hello。正则解析结果如下：\n    括号一      括号二\n1.  null       host\n2.   &#x3D;         2.2.2.2\n3.   &amp;         host\n4.   !&#x3D;        1.1.1.1\n5.   &amp;         method\n6.   &#x3D;         hello\n\n现在线程进入 while 循环：\n第一次循环：分隔符 separator &#x3D; null，content &#x3D; “host”。此时创建 MatchPair 对象，并存入到 condition 中，condition &#x3D; {“host”: MatchPair@123}\n第二次循环：分隔符 separator &#x3D; “&#x3D;”，content &#x3D; “2.2.2.2”，pair &#x3D; MatchPair@123。此时将 2.2.2.2 放入到 MatchPair@123  对象的 matches 集合中。 \n第三次循环：分隔符 separator &#x3D; “&amp;”，content &#x3D; “host”。host 已存在于 condition 中，因此 pair &#x3D; MatchPair@123。\n第四次循环：分隔符 separator &#x3D; “!&#x3D;”，content &#x3D; “1.1.1.1”，pair &#x3D; MatchPair@123。此时将 1.1.1.1 放入到 MatchPair@123  对象的 mismatches 集合中。 \n第五次循环：分隔符 separator &#x3D; “&amp;”，content &#x3D; “method”。condition.get(“method”) &#x3D; null，因此新建一个 MatchPair 对象，并放入到 condition 中。此时 condition &#x3D; {“host”: MatchPair@123, “method”: MatchPair@ 456}\n第六次循环：分隔符 separator &#x3D; “&#x3D;”，content &#x3D; “2.2.2.2”，pair &#x3D; MatchPair@456。此时将 hello 放入到 MatchPair@456  对象的 matches 集合中。 \n循环结束，此时 condition 的内容如下：\n&#123;\n    \"host\": &#123;\n        \"matches\": [\"2.2.2.2\"],\n        \"mismatches\": [\"1.1.1.1\"]\n    &#125;,\n    \"method\": &#123;\n        \"matches\": [\"hello\"],\n        \"mismatches\": []\n    &#125;\n&#125;\n\n路由规则的解析过程稍微有点复杂，大家可通过 ConditionRouter 的测试类对该逻辑进行测试。并且找一个表达式，对照上面的代码走一遍，加深理解。\n\n2.2 服务路由服务路由的入口方法是 ConditionRouter 的 route 方法，该方法定义在 Router 接口中。实现代码如下：\npublic &lt;T> List&lt;Invoker&lt;T>> route(List&lt;Invoker&lt;T>> invokers, URL url, Invocation invocation) throws RpcException &#123;\n    if (invokers == null || invokers.isEmpty()) &#123;\n        return invokers;\n    &#125;\n    try &#123;\n        // 先对服务消费者条件进行匹配，如果匹配失败，表明服务消费者 url 不符合匹配规则，\n        // 无需进行后续匹配，直接返回 Invoker 列表即可。比如下面的规则：\n        //     host = 10.20.153.10 => host = 10.0.0.10\n        // 这条路由规则希望 IP 为 10.20.153.10 的服务消费者调用 IP 为 10.0.0.10 机器上的服务。\n        // 当消费者 ip 为 10.20.153.11 时，matchWhen 返回 false，表明当前这条路由规则不适用于\n        // 当前的服务消费者，此时无需再进行后续匹配，直接返回即可。\n        if (!matchWhen(url, invocation)) &#123;\n            return invokers;\n        &#125;\n        List&lt;Invoker&lt;T>> result = new ArrayList&lt;Invoker&lt;T>>();\n        // 服务提供者匹配条件未配置，表明对指定的服务消费者禁用服务，也就是服务消费者在黑名单中\n        if (thenCondition == null) &#123;\n            logger.warn(\"The current consumer in the service blacklist...\");\n            return result;\n        &#125;\n        // 这里可以简单的把 Invoker 理解为服务提供者，现在使用服务提供者匹配规则对 \n        // Invoker 列表进行匹配\n        for (Invoker&lt;T> invoker : invokers) &#123;\n            // 若匹配成功，表明当前 Invoker 符合服务提供者匹配规则。\n            // 此时将 Invoker 添加到 result 列表中\n            if (matchThen(invoker.getUrl(), url)) &#123;\n                result.add(invoker);\n            &#125;\n        &#125;\n        \n        // 返回匹配结果，如果 result 为空列表，且 force = true，表示强制返回空列表，\n        // 否则路由结果为空的路由规则将自动失效\n        if (!result.isEmpty()) &#123;\n            return result;\n        &#125; else if (force) &#123;\n            logger.warn(\"The route result is empty and force execute ...\");\n            return result;\n        &#125;\n    &#125; catch (Throwable t) &#123;\n        logger.error(\"Failed to execute condition router rule: ...\");\n    &#125;\n    \n    // 原样返回，此时 force = false，表示该条路由规则失效\n    return invokers;\n&#125;\n\nroute 方法先是调用 matchWhen 对服务消费者进行匹配，如果匹配失败，直接返回 Invoker 列表。如果匹配成功，再对服务提供者进行匹配，匹配逻辑封装在了 matchThen 方法中。下面来看一下这两个方法的逻辑：\nboolean matchWhen(URL url, Invocation invocation) &#123;\n    // 服务消费者条件为 null 或空，均返回 true，比如：\n    //     => host != 172.22.3.91\n    // 表示所有的服务消费者都不得调用 IP 为 172.22.3.91 的机器上的服务\n    return whenCondition == null || whenCondition.isEmpty() \n        || matchCondition(whenCondition, url, null, invocation);  // 进行条件匹配\n&#125;\n\nprivate boolean matchThen(URL url, URL param) &#123;\n    // 服务提供者条件为 null 或空，表示禁用服务\n    return !(thenCondition == null || thenCondition.isEmpty()) \n        &amp;&amp; matchCondition(thenCondition, url, param, null);  // 进行条件匹配\n&#125;\n\n这两个方法长的有点像，不过逻辑上还是有差别的，大家注意看。这两个方法均调用了 matchCondition 方法，但它们所传入的参数是不同的。这个需要特别注意一下，不然后面的逻辑不好弄懂。下面我们对这几个参数进行溯源。matchWhen 方法向 matchCondition 方法传入的参数为 [whenCondition, url, null, invocation]，第一个参数 whenCondition 为服务消费者匹配条件，这个前面分析过。第二个参数 url 源自 route 方法的参数列表，该参数由外部类调用 route 方法时传入。比如：\nprivate List&lt;Invoker&lt;T>> route(List&lt;Invoker&lt;T>> invokers, String method) &#123;\n    Invocation invocation = new RpcInvocation(method, new Class&lt;?>[0], new Object[0]);\n    List&lt;Router> routers = getRouters();\n    if (routers != null) &#123;\n        for (Router router : routers) &#123;\n            if (router.getUrl() != null) &#123;\n                // 注意第二个参数\n                invokers = router.route(invokers, getConsumerUrl(), invocation);\n            &#125;\n        &#125;\n    &#125;\n    return invokers;\n&#125;\n\n上面这段代码来自 RegistryDirectory，第二个参数表示的是服务消费者 url。matchCondition 的 invocation 参数也是从这里传入的。\n接下来再来看看 matchThen 向 matchCondition 方法传入的参数 [thenCondition, url, param, null]。第一个参数不用解释了。第二个和第三个参数来自 matchThen 方法的参数列表，这两个参数分别为服务提供者 url 和服务消费者 url。搞清楚这些参数来源后，接下来就可以分析 matchCondition 方法了。\nprivate boolean matchCondition(Map&lt;String, MatchPair> condition, URL url, URL param, Invocation invocation) &#123;\n    // 将服务提供者或消费者 url 转成 Map\n    Map&lt;String, String> sample = url.toMap();\n    boolean result = false;\n    // 遍历 condition 列表\n    for (Map.Entry&lt;String, MatchPair> matchPair : condition.entrySet()) &#123;\n        // 获取匹配项名称，比如 host、method 等\n        String key = matchPair.getKey();\n        String sampleValue;\n        // 如果 invocation 不为空，且 key 为 method(s)，表示进行方法匹配\n        if (invocation != null &amp;&amp; (Constants.METHOD_KEY.equals(key) || Constants.METHODS_KEY.equals(key))) &#123;\n            // 从 invocation 获取被调用方法的名称\n            sampleValue = invocation.getMethodName();\n        &#125; else &#123;\n            // 从服务提供者或消费者 url 中获取指定字段值，比如 host、application 等\n            sampleValue = sample.get(key);\n            if (sampleValue == null) &#123;\n                // 尝试通过 default.xxx 获取相应的值\n                sampleValue = sample.get(Constants.DEFAULT_KEY_PREFIX + key);\n            &#125;\n        &#125;\n        \n        // --------------------✨ 分割线 ✨-------------------- //\n        \n        if (sampleValue != null) &#123;\n            // 调用 MatchPair 的 isMatch 方法进行匹配\n            if (!matchPair.getValue().isMatch(sampleValue, param)) &#123;\n                // 只要有一个规则匹配失败，立即返回 false 结束方法逻辑\n                return false;\n            &#125; else &#123;\n                result = true;\n            &#125;\n        &#125; else &#123;\n            // sampleValue 为空，表明服务提供者或消费者 url 中不包含相关字段。此时如果 \n            // MatchPair 的 matches 不为空，表示匹配失败，返回 false。比如我们有这样\n            // 一条匹配条件 loadbalance = random，假设 url 中并不包含 loadbalance 参数，\n            // 此时 sampleValue = null。既然路由规则里限制了 loadbalance 必须为 random，\n            // 但 sampleValue = null，明显不符合规则，因此返回 false\n            if (!matchPair.getValue().matches.isEmpty()) &#123;\n                return false;\n            &#125; else &#123;\n                result = true;\n            &#125;\n        &#125;\n    &#125;\n    return result;\n&#125;\n\n如上，matchCondition 方法看起来有点复杂，这里简单说明一下。分割线以上的代码实际上用于获取 sampleValue 的值，分割线以下才是进行条件匹配。条件匹配调用的逻辑封装在 isMatch 中，代码如下：\nprivate boolean isMatch(String value, URL param) &#123;\n    // 情况一：matches 非空，mismatches 为空\n    if (!matches.isEmpty() &amp;&amp; mismatches.isEmpty()) &#123;\n        // 遍历 matches 集合，检测入参 value 是否能被 matches 集合元素匹配到。\n        // 举个例子，如果 value = 10.20.153.11，matches = [10.20.153.*],\n        // 此时 isMatchGlobPattern 方法返回 true\n        for (String match : matches) &#123;\n            if (UrlUtils.isMatchGlobPattern(match, value, param)) &#123;\n                return true;\n            &#125;\n        &#125;\n        \n        // 如果所有匹配项都无法匹配到入参，则返回 false\n        return false;\n    &#125;\n\n    // 情况二：matches 为空，mismatches 非空\n    if (!mismatches.isEmpty() &amp;&amp; matches.isEmpty()) &#123;\n        for (String mismatch : mismatches) &#123;\n            // 只要入参被 mismatches 集合中的任意一个元素匹配到，就返回 false\n            if (UrlUtils.isMatchGlobPattern(mismatch, value, param)) &#123;\n                return false;\n            &#125;\n        &#125;\n        // mismatches 集合中所有元素都无法匹配到入参，此时返回 true\n        return true;\n    &#125;\n\n    // 情况三：matches 非空，mismatches 非空\n    if (!matches.isEmpty() &amp;&amp; !mismatches.isEmpty()) &#123;\n        // matches 和 mismatches 均为非空，此时优先使用 mismatches 集合元素对入参进行匹配。\n        // 只要 mismatches 集合中任意一个元素与入参匹配成功，就立即返回 false，结束方法逻辑\n        for (String mismatch : mismatches) &#123;\n            if (UrlUtils.isMatchGlobPattern(mismatch, value, param)) &#123;\n                return false;\n            &#125;\n        &#125;\n        // mismatches 集合元素无法匹配到入参，此时再使用 matches 继续匹配\n        for (String match : matches) &#123;\n            // 只要 matches 集合中任意一个元素与入参匹配成功，就立即返回 true\n            if (UrlUtils.isMatchGlobPattern(match, value, param)) &#123;\n                return true;\n            &#125;\n        &#125;\n        \n        // 全部失配，则返回 false\n        return false;\n    &#125;\n    \n    // 情况四：matches 和 mismatches 均为空，此时返回 false\n    return false;\n&#125;\n\nisMatch 方法逻辑比较清晰，由三个条件分支组成，用于处理四种情况。这里对四种情况下的匹配逻辑进行简单的总结，如下：\n\n\n\n\n条件\n过程\n\n\n\n情况一\nmatches 非空，mismatches 为空\n遍历 matches 集合元素，并与入参进行匹配。只要有一个元素成功匹配入参，即可返回 true。若全部失配，则返回 false。\n\n\n情况二\nmatches 为空，mismatches 非空\n遍历 mismatches 集合元素，并与入参进行匹配。只要有一个元素成功匹配入参，立即 false。若全部失配，则返回 true。\n\n\n情况三\nmatches 非空，mismatches 非空\n优先使用 mismatches 集合元素对入参进行匹配，只要任一元素与入参匹配成功，就立即返回 false，结束方法逻辑。否则再使用 matches 中的集合元素进行匹配，只要有任意一个元素匹配成功，即可返回 true。若全部失配，则返回 false\n\n\n情况四\nmatches 为空，mismatches 为空\n直接返回 false\n\n\nisMatch 方法是通过 UrlUtils 的 isMatchGlobPattern 方法进行匹配，因此下面我们再来看看 isMatchGlobPattern 方法的逻辑。\npublic static boolean isMatchGlobPattern(String pattern, String value, URL param) &#123;\n    if (param != null &amp;&amp; pattern.startsWith(\"$\")) &#123;\n        // 引用服务消费者参数，param 参数为服务消费者 url\n        pattern = param.getRawParameter(pattern.substring(1));\n    &#125;\n    // 调用重载方法继续比较\n    return isMatchGlobPattern(pattern, value);\n&#125;\n\npublic static boolean isMatchGlobPattern(String pattern, String value) &#123;\n    // 对 * 通配符提供支持\n    if (\"*\".equals(pattern))\n        // 匹配规则为通配符 *，直接返回 true 即可\n        return true;\n    if ((pattern == null || pattern.length() == 0)\n            &amp;&amp; (value == null || value.length() == 0))\n        // pattern 和 value 均为空，此时可认为两者相等，返回 true\n        return true;\n    if ((pattern == null || pattern.length() == 0)\n            || (value == null || value.length() == 0))\n        // pattern 和 value 其中有一个为空，表明两者不相等，返回 false\n        return false;\n\n    // 定位 * 通配符位置\n    int i = pattern.lastIndexOf('*');\n    if (i == -1) &#123;\n        // 匹配规则中不包含通配符，此时直接比较 value 和 pattern 是否相等即可，并返回比较结果\n        return value.equals(pattern);\n    &#125;\n    // 通配符 \"*\" 在匹配规则尾部，比如 10.0.21.*\n    else if (i == pattern.length() - 1) &#123;\n        // 检测 value 是否以“不含通配符的匹配规则”开头，并返回结果。比如:\n        // pattern = 10.0.21.*，value = 10.0.21.12，此时返回 true\n        return value.startsWith(pattern.substring(0, i));\n    &#125;\n    // 通配符 \"*\" 在匹配规则头部\n    else if (i == 0) &#123;\n        // 检测 value 是否以“不含通配符的匹配规则”结尾，并返回结果\n        return value.endsWith(pattern.substring(i + 1));\n    &#125;\n    // 通配符 \"*\" 在匹配规则中间位置\n    else &#123;\n        // 通过通配符将 pattern 分成两半，得到 prefix 和 suffix\n        String prefix = pattern.substring(0, i);\n        String suffix = pattern.substring(i + 1);\n        // 检测 value 是否以 prefix 开头，且以 suffix 结尾，并返回结果\n        return value.startsWith(prefix) &amp;&amp; value.endsWith(suffix);\n    &#125;\n&#125;\n\n以上就是 isMatchGlobPattern 两个重载方法的全部逻辑，这两个方法分别对普通的匹配过程，以及”引用消费者参数“和通配符匹配等特性提供了支持。这两个方法的逻辑不是很复杂，且代码中也进行了比较详细的注释，因此就不多说了。\n\n3. 总结本篇文章对条件路由的表达式解析和服务路由过程进行了较为细致的分析。总的来说，条件路由的代码还是有一些复杂的，需要静下心来看。在阅读条件路由代码的过程中，要多调试。一般的框架都会有单元测试，Dubbo 也不例外，因此大家可以直接通过 ConditionRouterTest 对条件路由进行调试，无需重头构建测试用例。\n\n\n\n\n\n\n\n\n\n原文地址：https://dubbo.apache.org/zh/docsv2.7/dev/source/cluster/\n作者： Dubbo 官方\n本文介绍了集群的原理和实现细节\n\n集群1.简介为了避免单点故障，现在的应用通常至少会部署在两台服务器上。对于一些负载比较高的服务，会部署更多的服务器。这样，在同一环境下的服务提供者数量会大于1。对于服务消费者来说，同一环境下出现了多个服务提供者。这时会出现一个问题，服务消费者需要决定选择哪个服务提供者进行调用。另外服务调用失败时的处理措施也是需要考虑的，是重试呢，还是抛出异常，亦或是只打印异常等。为了处理这些问题，Dubbo 定义了集群接口 Cluster 以及 Cluster Invoker。集群 Cluster 用途是将多个服务提供者合并为一个 Cluster Invoker，并将这个 Invoker 暴露给服务消费者。这样一来，服务消费者只需通过这个 Invoker 进行远程调用即可，至于具体调用哪个服务提供者，以及调用失败后如何处理等问题，现在都交给集群模块去处理。集群模块是服务提供者和服务消费者的中间层，为服务消费者屏蔽了服务提供者的情况，这样服务消费者就可以专心处理远程调用相关事宜。比如发请求，接受服务提供者返回的数据等。这就是集群的作用。\nDubbo 提供了多种集群实现，包含但不限于 Failover Cluster、Failfast Cluster 和 Failsafe Cluster 等。每种集群实现类的用途不同，接下来会一一进行分析。\n\n2. 集群容错在对集群相关代码进行分析之前，这里有必要先来介绍一下集群容错的所有组件。包含 Cluster、Cluster Invoker、Directory、Router 和 LoadBalance 等。\n\n集群工作过程可分为两个阶段，第一个阶段是在服务消费者初始化期间，集群 Cluster 实现类为服务消费者创建 Cluster Invoker 实例，即上图中的 merge 操作。第二个阶段是在服务消费者进行远程调用时。以 FailoverClusterInvoker 为例，该类型 Cluster Invoker 首先会调用 Directory 的 list 方法列举 Invoker 列表（可将 Invoker 简单理解为服务提供者）。Directory 的用途是保存 Invoker，可简单类比为 List。其实现类 RegistryDirectory 是一个动态服务目录，可感知注册中心配置的变化，它所持有的 Invoker 列表会随着注册中心内容的变化而变化。每次变化后，RegistryDirectory 会动态增删 Invoker，并调用 Router 的 route 方法进行路由，过滤掉不符合路由规则的 Invoker。当 FailoverClusterInvoker 拿到 Directory 返回的 Invoker 列表后，它会通过 LoadBalance 从 Invoker 列表中选择一个 Invoker。最后 FailoverClusterInvoker 会将参数传给 LoadBalance 选择出的 Invoker 实例的 invoke 方法，进行真正的远程调用。\n以上就是集群工作的整个流程，这里并没介绍集群是如何容错的。Dubbo 主要提供了这样几种容错方式：\n\nFailover Cluster - 失败自动切换\nFailfast Cluster - 快速失败\nFailsafe Cluster - 失败安全\nFailback Cluster - 失败自动恢复\nForking Cluster - 并行调用多个服务提供者\n\n下面开始分析源码。\n\n3.源码分析\n3.1 Cluster 实现类分析我们在上一章看到了两个概念，分别是集群接口 Cluster 和 Cluster Invoker，这两者是不同的。Cluster 是接口，而 Cluster Invoker 是一种 Invoker。服务提供者的选择逻辑，以及远程调用失败后的的处理逻辑均是封装在 Cluster Invoker 中。那么 Cluster 接口和相关实现类有什么用呢？用途比较简单，仅用于生成 Cluster Invoker。下面我们来看一下源码。\npublic class FailoverCluster implements Cluster &#123;\n\n    public final static String NAME = \"failover\";\n\n    @Override\n    public &lt;T> Invoker&lt;T> join(Directory&lt;T> directory) throws RpcException &#123;\n        // 创建并返回 FailoverClusterInvoker 对象\n        return new FailoverClusterInvoker&lt;T>(directory);\n    &#125;\n&#125;\n\n如上，FailoverCluster 总共就包含这几行代码，用于创建 FailoverClusterInvoker 对象，很简单。下面再看一个。\npublic class FailbackCluster implements Cluster &#123;\n\n    public final static String NAME = \"failback\";\n\n    @Override\n    public &lt;T> Invoker&lt;T> join(Directory&lt;T> directory) throws RpcException &#123;\n        // 创建并返回 FailbackClusterInvoker 对象\n        return new FailbackClusterInvoker&lt;T>(directory);\n    &#125;\n\n&#125;\n\n如上，FailbackCluster 的逻辑也是很简单，无需解释了。所以接下来，我们把重点放在各种 Cluster Invoker 上\n\n3.2 Cluster Invoker 分析我们首先从各种 Cluster Invoker 的父类 AbstractClusterInvoker 源码开始说起。前面说过，集群工作过程可分为两个阶段，第一个阶段是在服务消费者初始化期间，这个在服务引用那篇文章中分析过，就不赘述。第二个阶段是在服务消费者进行远程调用时，此时 AbstractClusterInvoker 的 invoke 方法会被调用。列举 Invoker，负载均衡等操作均会在此阶段被执行。因此下面先来看一下 invoke 方法的逻辑。\npublic Result invoke(final Invocation invocation) throws RpcException &#123;\n    checkWhetherDestroyed();\n    LoadBalance loadbalance = null;\n\n    // 绑定 attachments 到 invocation 中.\n    Map&lt;String, String> contextAttachments = RpcContext.getContext().getAttachments();\n    if (contextAttachments != null &amp;&amp; contextAttachments.size() != 0) &#123;\n        ((RpcInvocation) invocation).addAttachments(contextAttachments);\n    &#125;\n\n    // 列举 Invoker\n    List&lt;Invoker&lt;T>> invokers = list(invocation);\n    if (invokers != null &amp;&amp; !invokers.isEmpty()) &#123;\n        // 加载 LoadBalance\n        loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(invokers.get(0).getUrl()\n                .getMethodParameter(RpcUtils.getMethodName(invocation), Constants.LOADBALANCE_KEY, Constants.DEFAULT_LOADBALANCE));\n    &#125;\n    RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation);\n    \n    // 调用 doInvoke 进行后续操作\n    return doInvoke(invocation, invokers, loadbalance);\n&#125;\n\n// 抽象方法，由子类实现\nprotected abstract Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T>> invokers,\n                                       LoadBalance loadbalance) throws RpcException;\n\nAbstractClusterInvoker 的 invoke 方法主要用于列举 Invoker，以及加载 LoadBalance。最后再调用模板方法 doInvoke 进行后续操作。下面我们来看一下 Invoker 列举方法 list(Invocation) 的逻辑，如下：\nprotected List&lt;Invoker&lt;T>> list(Invocation invocation) throws RpcException &#123;\n    // 调用 Directory 的 list 方法列举 Invoker\n    List&lt;Invoker&lt;T>> invokers = directory.list(invocation);\n    return invokers;\n&#125;\n\n如上，AbstractClusterInvoker 中的 list 方法做的事情很简单，只是简单的调用了 Directory 的 list 方法，没有其他更多的逻辑了。Directory 即相关实现类在前文已经分析过，这里就不多说了。接下来，我们把目光转移到 AbstractClusterInvoker 的各种实现类上，来看一下这些实现类是如何实现 doInvoke 方法逻辑的。\n\n3.2.1 FailoverClusterInvokerFailoverClusterInvoker 在调用失败时，会自动切换 Invoker 进行重试。默认配置下，Dubbo 会使用这个类作为缺省 Cluster Invoker。下面来看一下该类的逻辑。\npublic class FailoverClusterInvoker&lt;T> extends AbstractClusterInvoker&lt;T> &#123;\n\n    // 省略部分代码\n\n    @Override\n    public Result doInvoke(Invocation invocation, final List&lt;Invoker&lt;T>> invokers, LoadBalance loadbalance) throws RpcException &#123;\n        List&lt;Invoker&lt;T>> copyinvokers = invokers;\n        checkInvokers(copyinvokers, invocation);\n        // 获取重试次数\n        int len = getUrl().getMethodParameter(invocation.getMethodName(), Constants.RETRIES_KEY, Constants.DEFAULT_RETRIES) + 1;\n        if (len &lt;= 0) &#123;\n            len = 1;\n        &#125;\n        RpcException le = null;\n        List&lt;Invoker&lt;T>> invoked = new ArrayList&lt;Invoker&lt;T>>(copyinvokers.size());\n        Set&lt;String> providers = new HashSet&lt;String>(len);\n        // 循环调用，失败重试\n        for (int i = 0; i &lt; len; i++) &#123;\n            if (i > 0) &#123;\n                checkWhetherDestroyed();\n                // 在进行重试前重新列举 Invoker，这样做的好处是，如果某个服务挂了，\n                // 通过调用 list 可得到最新可用的 Invoker 列表\n                copyinvokers = list(invocation);\n                // 对 copyinvokers 进行判空检查\n                checkInvokers(copyinvokers, invocation);\n            &#125;\n\n            // 通过负载均衡选择 Invoker\n            Invoker&lt;T> invoker = select(loadbalance, invocation, copyinvokers, invoked);\n            // 添加到 invoker 到 invoked 列表中\n            invoked.add(invoker);\n            // 设置 invoked 到 RPC 上下文中\n            RpcContext.getContext().setInvokers((List) invoked);\n            try &#123;\n                // 调用目标 Invoker 的 invoke 方法\n                Result result = invoker.invoke(invocation);\n                return result;\n            &#125; catch (RpcException e) &#123;\n                if (e.isBiz()) &#123;\n                    throw e;\n                &#125;\n                le = e;\n            &#125; catch (Throwable e) &#123;\n                le = new RpcException(e.getMessage(), e);\n            &#125; finally &#123;\n                providers.add(invoker.getUrl().getAddress());\n            &#125;\n        &#125;\n        \n        // 若重试失败，则抛出异常\n        throw new RpcException(..., \"Failed to invoke the method ...\");\n    &#125;\n&#125;\n\n如上，FailoverClusterInvoker 的 doInvoke 方法首先是获取重试次数，然后根据重试次数进行循环调用，失败后进行重试。在 for 循环内，首先是通过负载均衡组件选择一个 Invoker，然后再通过这个 Invoker 的 invoke 方法进行远程调用。如果失败了，记录下异常，并进行重试。重试时会再次调用父类的 list 方法列举 Invoker。整个流程大致如此，不是很难理解。下面我们看一下 select 方法的逻辑。\nprotected Invoker&lt;T> select(LoadBalance loadbalance, Invocation invocation, List&lt;Invoker&lt;T>> invokers, List&lt;Invoker&lt;T>> selected) throws RpcException &#123;\n    if (invokers == null || invokers.isEmpty())\n        return null;\n    // 获取调用方法名\n    String methodName = invocation == null ? \"\" : invocation.getMethodName();\n\n    // 获取 sticky 配置，sticky 表示粘滞连接。所谓粘滞连接是指让服务消费者尽可能的\n    // 调用同一个服务提供者，除非该提供者挂了再进行切换\n    boolean sticky = invokers.get(0).getUrl().getMethodParameter(methodName, Constants.CLUSTER_STICKY_KEY, Constants.DEFAULT_CLUSTER_STICKY);\n    &#123;\n        // 检测 invokers 列表是否包含 stickyInvoker，如果不包含，\n        // 说明 stickyInvoker 代表的服务提供者挂了，此时需要将其置空\n        if (stickyInvoker != null &amp;&amp; !invokers.contains(stickyInvoker)) &#123;\n            stickyInvoker = null;\n        &#125;\n        \n        // 在 sticky 为 true，且 stickyInvoker != null 的情况下。如果 selected 包含 \n        // stickyInvoker，表明 stickyInvoker 对应的服务提供者可能因网络原因未能成功提供服务。\n        // 但是该提供者并没挂，此时 invokers 列表中仍存在该服务提供者对应的 Invoker。\n        if (sticky &amp;&amp; stickyInvoker != null &amp;&amp; (selected == null || !selected.contains(stickyInvoker))) &#123;\n            // availablecheck 表示是否开启了可用性检查，如果开启了，则调用 stickyInvoker 的 \n            // isAvailable 方法进行检查，如果检查通过，则直接返回 stickyInvoker。\n            if (availablecheck &amp;&amp; stickyInvoker.isAvailable()) &#123;\n                return stickyInvoker;\n            &#125;\n        &#125;\n    &#125;\n    \n    // 如果线程走到当前代码处，说明前面的 stickyInvoker 为空，或者不可用。\n    // 此时继续调用 doSelect 选择 Invoker\n    Invoker&lt;T> invoker = doSelect(loadbalance, invocation, invokers, selected);\n\n    // 如果 sticky 为 true，则将负载均衡组件选出的 Invoker 赋值给 stickyInvoker\n    if (sticky) &#123;\n        stickyInvoker = invoker;\n    &#125;\n    return invoker;\n&#125;\n\n如上，select 方法的主要逻辑集中在了对粘滞连接特性的支持上。首先是获取 sticky 配置，然后再检测 invokers 列表中是否包含 stickyInvoker，如果不包含，则认为该 stickyInvoker 不可用，此时将其置空。这里的 invokers 列表可以看做是存活着的服务提供者列表，如果这个列表不包含 stickyInvoker，那自然而然的认为 stickyInvoker 挂了，所以置空。如果 stickyInvoker 存在于 invokers 列表中，此时要进行下一项检测 — 检测 selected 中是否包含 stickyInvoker。如果包含的话，说明 stickyInvoker 在此之前没有成功提供服务（但其仍然处于存活状态）。此时我们认为这个服务不可靠，不应该在重试期间内再次被调用，因此这个时候不会返回该 stickyInvoker。如果 selected 不包含 stickyInvoker，此时还需要进行可用性检测，比如检测服务提供者网络连通性等。当可用性检测通过，才可返回 stickyInvoker，否则调用 doSelect 方法选择 Invoker。如果 sticky 为 true，此时会将 doSelect 方法选出的 Invoker 赋值给 stickyInvoker。\n以上就是 select 方法的逻辑，这段逻辑看起来不是很复杂，但是信息量比较大。不搞懂 invokers 和 selected 两个入参的含义，以及粘滞连接特性，这段代码是不容易看懂的。所以大家在阅读这段代码时，不要忽略了对背景知识的理解。关于 select 方法先分析这么多，继续向下分析。\nprivate Invoker&lt;T> doSelect(LoadBalance loadbalance, Invocation invocation, List&lt;Invoker&lt;T>> invokers, List&lt;Invoker&lt;T>> selected) throws RpcException &#123;\n    if (invokers == null || invokers.isEmpty())\n        return null;\n    if (invokers.size() == 1)\n        return invokers.get(0);\n    if (loadbalance == null) &#123;\n        // 如果 loadbalance 为空，这里通过 SPI 加载 Loadbalance，默认为 RandomLoadBalance\n        loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(Constants.DEFAULT_LOADBALANCE);\n    &#125;\n    \n    // 通过负载均衡组件选择 Invoker\n    Invoker&lt;T> invoker = loadbalance.select(invokers, getUrl(), invocation);\n\n\t// 如果 selected 包含负载均衡选择出的 Invoker，或者该 Invoker 无法经过可用性检查，此时进行重选\n    if ((selected != null &amp;&amp; selected.contains(invoker))\n            || (!invoker.isAvailable() &amp;&amp; getUrl() != null &amp;&amp; availablecheck)) &#123;\n        try &#123;\n            // 进行重选\n            Invoker&lt;T> rinvoker = reselect(loadbalance, invocation, invokers, selected, availablecheck);\n            if (rinvoker != null) &#123;\n                // 如果 rinvoker 不为空，则将其赋值给 invoker\n                invoker = rinvoker;\n            &#125; else &#123;\n                // rinvoker 为空，定位 invoker 在 invokers 中的位置\n                int index = invokers.indexOf(invoker);\n                try &#123;\n                    // 获取 index + 1 位置处的 Invoker，以下代码等价于：\n                    //     invoker = invokers.get((index + 1) % invokers.size());\n                    invoker = index &lt; invokers.size() - 1 ? invokers.get(index + 1) : invokers.get(0);\n                &#125; catch (Exception e) &#123;\n                    logger.warn(\"... may because invokers list dynamic change, ignore.\");\n                &#125;\n            &#125;\n        &#125; catch (Throwable t) &#123;\n            logger.error(\"cluster reselect fail reason is : ...\");\n        &#125;\n    &#125;\n    return invoker;\n&#125;\n\ndoSelect 主要做了两件事，第一是通过负载均衡组件选择 Invoker。第二是，如果选出来的 Invoker 不稳定，或不可用，此时需要调用 reselect 方法进行重选。若 reselect 选出来的 Invoker 为空，此时定位 invoker 在 invokers 列表中的位置 index，然后获取 index + 1 处的 invoker，这也可以看做是重选逻辑的一部分。下面我们来看一下 reselect 方法的逻辑。\nprivate Invoker&lt;T> reselect(LoadBalance loadbalance, Invocation invocation,\n    List&lt;Invoker&lt;T>> invokers, List&lt;Invoker&lt;T>> selected, boolean availablecheck) throws RpcException &#123;\n\n    List&lt;Invoker&lt;T>> reselectInvokers = new ArrayList&lt;Invoker&lt;T>>(invokers.size() > 1 ? (invokers.size() - 1) : invokers.size());\n\n    // 下面的 if-else 分支逻辑有些冗余，pull request #2826 对这段代码进行了简化，可以参考一下\n    // 根据 availablecheck 进行不同的处理\n    if (availablecheck) &#123;\n        // 遍历 invokers 列表\n        for (Invoker&lt;T> invoker : invokers) &#123;\n            // 检测可用性\n            if (invoker.isAvailable()) &#123;\n                // 如果 selected 列表不包含当前 invoker，则将其添加到 reselectInvokers 中\n                if (selected == null || !selected.contains(invoker)) &#123;\n                    reselectInvokers.add(invoker);\n                &#125;\n            &#125;\n        &#125;\n        \n        // reselectInvokers 不为空，此时通过负载均衡组件进行选择\n        if (!reselectInvokers.isEmpty()) &#123;\n            return loadbalance.select(reselectInvokers, getUrl(), invocation);\n        &#125;\n\n    // 不检查 Invoker 可用性\n    &#125; else &#123;\n        for (Invoker&lt;T> invoker : invokers) &#123;\n            // 如果 selected 列表不包含当前 invoker，则将其添加到 reselectInvokers 中\n            if (selected == null || !selected.contains(invoker)) &#123;\n                reselectInvokers.add(invoker);\n            &#125;\n        &#125;\n        if (!reselectInvokers.isEmpty()) &#123;\n            // 通过负载均衡组件进行选择\n            return loadbalance.select(reselectInvokers, getUrl(), invocation);\n        &#125;\n    &#125;\n\n    &#123;\n        // 若线程走到此处，说明 reselectInvokers 集合为空，此时不会调用负载均衡组件进行筛选。\n        // 这里从 selected 列表中查找可用的 Invoker，并将其添加到 reselectInvokers 集合中\n        if (selected != null) &#123;\n            for (Invoker&lt;T> invoker : selected) &#123;\n                if ((invoker.isAvailable())\n                        &amp;&amp; !reselectInvokers.contains(invoker)) &#123;\n                    reselectInvokers.add(invoker);\n                &#125;\n            &#125;\n        &#125;\n        if (!reselectInvokers.isEmpty()) &#123;\n            // 再次进行选择，并返回选择结果\n            return loadbalance.select(reselectInvokers, getUrl(), invocation);\n        &#125;\n    &#125;\n    return null;\n&#125;\n\nreselect 方法总结下来其实只做了两件事情，第一是查找可用的 Invoker，并将其添加到 reselectInvokers 集合中。第二，如果 reselectInvokers 不为空，则通过负载均衡组件再次进行选择。其中第一件事情又可进行细分，一开始，reselect 从 invokers 列表中查找有效可用的 Invoker，若未能找到，此时再到 selected 列表中继续查找。关于 reselect 方法就先分析到这，继续分析其他的 Cluster Invoker。\n\n3.2.2 FailbackClusterInvokerFailbackClusterInvoker 会在调用失败后，返回一个空结果给服务消费者。并通过定时任务对失败的调用进行重传，适合执行消息通知等操作。下面来看一下它的实现逻辑。\npublic class FailbackClusterInvoker&lt;T> extends AbstractClusterInvoker&lt;T> &#123;\n\n    private static final long RETRY_FAILED_PERIOD = 5 * 1000;\n\n    private final ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(2,\n            new NamedInternalThreadFactory(\"failback-cluster-timer\", true));\n\n    private final ConcurrentMap&lt;Invocation, AbstractClusterInvoker&lt;?>> failed = new ConcurrentHashMap&lt;Invocation, AbstractClusterInvoker&lt;?>>();\n    private volatile ScheduledFuture&lt;?> retryFuture;\n\n    @Override\n    protected Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T>> invokers, LoadBalance loadbalance) throws RpcException &#123;\n        try &#123;\n            checkInvokers(invokers, invocation);\n            // 选择 Invoker\n            Invoker&lt;T> invoker = select(loadbalance, invocation, invokers, null);\n            // 进行调用\n            return invoker.invoke(invocation);\n        &#125; catch (Throwable e) &#123;\n            // 如果调用过程中发生异常，此时仅打印错误日志，不抛出异常\n            logger.error(\"Failback to invoke method ...\");\n            \n            // 记录调用信息\n            addFailed(invocation, this);\n            // 返回一个空结果给服务消费者\n            return new RpcResult();\n        &#125;\n    &#125;\n\n    private void addFailed(Invocation invocation, AbstractClusterInvoker&lt;?> router) &#123;\n        if (retryFuture == null) &#123;\n            synchronized (this) &#123;\n                if (retryFuture == null) &#123;\n                    // 创建定时任务，每隔5秒执行一次\n                    retryFuture = scheduledExecutorService.scheduleWithFixedDelay(new Runnable() &#123;\n\n                        @Override\n                        public void run() &#123;\n                            try &#123;\n                                // 对失败的调用进行重试\n                                retryFailed();\n                            &#125; catch (Throwable t) &#123;\n                                // 如果发生异常，仅打印异常日志，不抛出\n                                logger.error(\"Unexpected error occur at collect statistic\", t);\n                            &#125;\n                        &#125;\n                    &#125;, RETRY_FAILED_PERIOD, RETRY_FAILED_PERIOD, TimeUnit.MILLISECONDS);\n                &#125;\n            &#125;\n        &#125;\n        \n        // 添加 invocation 和 invoker 到 failed 中\n        failed.put(invocation, router);\n    &#125;\n\n    void retryFailed() &#123;\n        if (failed.size() == 0) &#123;\n            return;\n        &#125;\n        \n        // 遍历 failed，对失败的调用进行重试\n        for (Map.Entry&lt;Invocation, AbstractClusterInvoker&lt;?>> entry : new HashMap&lt;Invocation, AbstractClusterInvoker&lt;?>>(failed).entrySet()) &#123;\n            Invocation invocation = entry.getKey();\n            Invoker&lt;?> invoker = entry.getValue();\n            try &#123;\n                // 再次进行调用\n                invoker.invoke(invocation);\n                // 调用成功后，从 failed 中移除 invoker\n                failed.remove(invocation);\n            &#125; catch (Throwable e) &#123;\n                // 仅打印异常，不抛出\n                logger.error(\"Failed retry to invoke method ...\");\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n这个类主要由3个方法组成，首先是 doInvoker，该方法负责初次的远程调用。若远程调用失败，则通过 addFailed 方法将调用信息存入到 failed 中，等待定时重试。addFailed 在开始阶段会根据 retryFuture 为空与否，来决定是否开启定时任务。retryFailed 方法则是包含了失败重试的逻辑，该方法会对 failed 进行遍历，然后依次对 Invoker 进行调用。调用成功则将 Invoker 从 failed 中移除，调用失败则忽略失败原因。\n以上就是 FailbackClusterInvoker 的执行逻辑，不是很复杂，继续往下看。\n\n3.2.3 FailfastClusterInvokerFailfastClusterInvoker 只会发起一次调用，失败后立即抛出异常。通常用于非幂等性的写操作，比如新增记录。源码如下：\npublic class FailfastClusterInvoker&lt;T> extends AbstractClusterInvoker&lt;T> &#123;\n\n    @Override\n    public Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T>> invokers, LoadBalance loadbalance) throws RpcException &#123;\n        checkInvokers(invokers, invocation);\n        // 选择 Invoker\n        Invoker&lt;T> invoker = select(loadbalance, invocation, invokers, null);\n        try &#123;\n            // 调用 Invoker\n            return invoker.invoke(invocation);\n        &#125; catch (Throwable e) &#123;\n            if (e instanceof RpcException &amp;&amp; ((RpcException) e).isBiz()) &#123;\n                // 抛出异常\n                throw (RpcException) e;\n            &#125;\n            // 抛出异常\n            throw new RpcException(..., \"Failfast invoke providers ...\");\n        &#125;\n    &#125;\n&#125;\n\n如上，首先是通过 select 方法选择 Invoker，然后进行远程调用。如果调用失败，则立即抛出异常。FailfastClusterInvoker 就先分析到这，下面分析 FailsafeClusterInvoker。\n\n3.2.4 FailsafeClusterInvokerFailsafeClusterInvoker 是一种失败安全的 Cluster Invoker。所谓的失败安全是指，当调用过程中出现异常时，FailsafeClusterInvoker 仅会打印异常，而不会抛出异常。适用于写入审计日志等操作。下面分析源码。\npublic class FailsafeClusterInvoker&lt;T> extends AbstractClusterInvoker&lt;T> &#123;\n\n    @Override\n    public Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T>> invokers, LoadBalance loadbalance) throws RpcException &#123;\n        try &#123;\n            checkInvokers(invokers, invocation);\n            // 选择 Invoker\n            Invoker&lt;T> invoker = select(loadbalance, invocation, invokers, null);\n            // 进行远程调用\n            return invoker.invoke(invocation);\n        &#125; catch (Throwable e) &#123;\n\t\t\t// 打印错误日志，但不抛出\n            logger.error(\"Failsafe ignore exception: \" + e.getMessage(), e);\n            // 返回空结果忽略错误\n            return new RpcResult();\n        &#125;\n    &#125;\n&#125;\n\nFailsafeClusterInvoker 的逻辑和 FailfastClusterInvoker 的逻辑一样简单，无需过多说明。继续向下分析。\n\n3.2.5 ForkingClusterInvokerForkingClusterInvoker 会在运行时通过线程池创建多个线程，并发调用多个服务提供者。只要有一个服务提供者成功返回了结果，doInvoke 方法就会立即结束运行。ForkingClusterInvoker 的应用场景是在一些对实时性要求比较高读操作（注意是读操作，并行写操作可能不安全）下使用，但这将会耗费更多的资源。下面来看该类的实现。\npublic class ForkingClusterInvoker&lt;T> extends AbstractClusterInvoker&lt;T> &#123;\n    \n    private final ExecutorService executor = Executors.newCachedThreadPool(\n            new NamedInternalThreadFactory(\"forking-cluster-timer\", true));\n\n    @Override\n    public Result doInvoke(final Invocation invocation, List&lt;Invoker&lt;T>> invokers, LoadBalance loadbalance) throws RpcException &#123;\n        try &#123;\n            checkInvokers(invokers, invocation);\n            final List&lt;Invoker&lt;T>> selected;\n            // 获取 forks 配置\n            final int forks = getUrl().getParameter(Constants.FORKS_KEY, Constants.DEFAULT_FORKS);\n            // 获取超时配置\n            final int timeout = getUrl().getParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT);\n            // 如果 forks 配置不合理，则直接将 invokers 赋值给 selected\n            if (forks &lt;= 0 || forks >= invokers.size()) &#123;\n                selected = invokers;\n            &#125; else &#123;\n                selected = new ArrayList&lt;Invoker&lt;T>>();\n                // 循环选出 forks 个 Invoker，并添加到 selected 中\n                for (int i = 0; i &lt; forks; i++) &#123;\n                    // 选择 Invoker\n                    Invoker&lt;T> invoker = select(loadbalance, invocation, invokers, selected);\n                    if (!selected.contains(invoker)) &#123;\n                        selected.add(invoker);\n                    &#125;\n                &#125;\n            &#125;\n            \n            // ----------------------✨ 分割线1 ✨---------------------- //\n            \n            RpcContext.getContext().setInvokers((List) selected);\n            final AtomicInteger count = new AtomicInteger();\n            final BlockingQueue&lt;Object> ref = new LinkedBlockingQueue&lt;Object>();\n            // 遍历 selected 列表\n            for (final Invoker&lt;T> invoker : selected) &#123;\n                // 为每个 Invoker 创建一个执行线程\n                executor.execute(new Runnable() &#123;\n                    @Override\n                    public void run() &#123;\n                        try &#123;\n                            // 进行远程调用\n                            Result result = invoker.invoke(invocation);\n                            // 将结果存到阻塞队列中\n                            ref.offer(result);\n                        &#125; catch (Throwable e) &#123;\n                            int value = count.incrementAndGet();\n                            // 仅在 value 大于等于 selected.size() 时，才将异常对象\n                            // 放入阻塞队列中，请大家思考一下为什么要这样做。\n                            if (value >= selected.size()) &#123;\n                                // 将异常对象存入到阻塞队列中\n                                ref.offer(e);\n                            &#125;\n                        &#125;\n                    &#125;\n                &#125;);\n            &#125;\n            \n            // ----------------------✨ 分割线2 ✨---------------------- //\n            \n            try &#123;\n                // 从阻塞队列中取出远程调用结果\n                Object ret = ref.poll(timeout, TimeUnit.MILLISECONDS);\n                \n                // 如果结果类型为 Throwable，则抛出异常\n                if (ret instanceof Throwable) &#123;\n                    Throwable e = (Throwable) ret;\n                    throw new RpcException(..., \"Failed to forking invoke provider ...\");\n                &#125;\n                \n                // 返回结果\n                return (Result) ret;\n            &#125; catch (InterruptedException e) &#123;\n                throw new RpcException(\"Failed to forking invoke provider ...\");\n            &#125;\n        &#125; finally &#123;\n            RpcContext.getContext().clearAttachments();\n        &#125;\n    &#125;\n&#125;\n\nForkingClusterInvoker 的 doInvoker 方法比较长，这里通过两个分割线将整个方法划分为三个逻辑块。从方法开始到分割线1之间的代码主要是用于选出 forks 个 Invoker，为接下来的并发调用提供输入。分割线1和分割线2之间的逻辑通过线程池并发调用多个 Invoker，并将结果存储在阻塞队列中。分割线2到方法结尾之间的逻辑主要用于从阻塞队列中获取返回结果，并对返回结果类型进行判断。如果为异常类型，则直接抛出，否则返回。\n以上就是ForkingClusterInvoker 的 doInvoker 方法大致过程。我们在分割线1和分割线2之间的代码上留了一个问题，问题是这样的：为什么要在value &gt;= selected.size()的情况下，才将异常对象添加到阻塞队列中？这里来解答一下。原因是这样的，在并行调用多个服务提供者的情况下，只要有一个服务提供者能够成功返回结果，而其他全部失败。此时 ForkingClusterInvoker 仍应该返回成功的结果，而非抛出异常。在value &gt;= selected.size()时将异常对象放入阻塞队列中，可以保证异常对象不会出现在正常结果的前面，这样可从阻塞队列中优先取出正常的结果。\n关于 ForkingClusterInvoker 就先分析到这，接下来分析最后一个 Cluster Invoker。\n\n3.2.6 BroadcastClusterInvoker本章的最后，我们再来看一下 BroadcastClusterInvoker。BroadcastClusterInvoker 会逐个调用每个服务提供者，如果其中一台报错，在循环调用结束后，BroadcastClusterInvoker 会抛出异常。该类通常用于通知所有提供者更新缓存或日志等本地资源信息。源码如下。\npublic class BroadcastClusterInvoker&lt;T> extends AbstractClusterInvoker&lt;T> &#123;\n\n    @Override\n    public Result doInvoke(final Invocation invocation, List&lt;Invoker&lt;T>> invokers, LoadBalance loadbalance) throws RpcException &#123;\n        checkInvokers(invokers, invocation);\n        RpcContext.getContext().setInvokers((List) invokers);\n        RpcException exception = null;\n        Result result = null;\n        // 遍历 Invoker 列表，逐个调用\n        for (Invoker&lt;T> invoker : invokers) &#123;\n            try &#123;\n                // 进行远程调用\n                result = invoker.invoke(invocation);\n            &#125; catch (RpcException e) &#123;\n                exception = e;\n                logger.warn(e.getMessage(), e);\n            &#125; catch (Throwable e) &#123;\n                exception = new RpcException(e.getMessage(), e);\n                logger.warn(e.getMessage(), e);\n            &#125;\n        &#125;\n        \n        // exception 不为空，则抛出异常\n        if (exception != null) &#123;\n            throw exception;\n        &#125;\n        return result;\n    &#125;\n&#125;\n\n以上就是 BroadcastClusterInvoker 的代码，比较简单，就不多说了。\n\n4.总结本篇文章详细分析了集群容错的几种实现方式。集群容错对于 Dubbo 框架来说，是很重要的逻辑。集群模块处于服务提供者和消费者之间，对于服务消费者来说，集群可向其屏蔽服务提供者集群的情况，使其能够专心进行远程调用。除此之外，通过集群模块，我们还可以对服务之间的调用链路进行编排优化，治理服务。总的来说，对于 Dubbo 而言，集群容错相关逻辑是非常重要的。想要对 Dubbo 有比较深的理解，集群容错是必须要掌握的。\n关于集群模块就先分析到这，感谢阅读。\n本文介绍了负载均衡的原理和实现细节\n\n负载均衡1.简介LoadBalance 中文意思为负载均衡，它的职责是将网络请求，或者其他形式的负载“均摊”到不同的机器上。避免集群中部分服务器压力过大，而另一些服务器比较空闲的情况。通过负载均衡，可以让每台服务器获取到适合自己处理能力的负载。在为高负载服务器分流的同时，还可以避免资源浪费，一举两得。负载均衡可分为软件负载均衡和硬件负载均衡。在我们日常开发中，一般很难接触到硬件负载均衡。但软件负载均衡还是可以接触到的，比如 Nginx。在 Dubbo 中，也有负载均衡的概念和相应的实现。Dubbo 需要对服务消费者的调用请求进行分配，避免少数服务提供者负载过大。服务提供者负载过大，会导致部分请求超时。因此将负载均衡到每个服务提供者上，是非常必要的。Dubbo 提供了4种负载均衡实现，分别是基于权重随机算法的 RandomLoadBalance、基于最少活跃调用数算法的 LeastActiveLoadBalance、基于 hash 一致性的 ConsistentHashLoadBalance，以及基于加权轮询算法的 RoundRobinLoadBalance。这几个负载均衡算法代码不是很长，但是想看懂也不是很容易，需要大家对这几个算法的原理有一定了解才行。如果不是很了解，也没不用太担心。我们会在分析每个算法的源码之前，对算法原理进行简单的讲解，帮助大家建立初步的印象。\n本系列文章在编写之初是基于 Dubbo 2.6.4 的，近期，Dubbo 2.6.5 发布了，其中就有针对对负载均衡部分的优化。因此我们在分析完 2.6.4 版本后的源码后，会另外分析 2.6.5 更新的部分。其他的就不多说了，进入正题吧。\n\n2.源码分析在 Dubbo 中，所有负载均衡实现类均继承自 AbstractLoadBalance，该类实现了 LoadBalance 接口，并封装了一些公共的逻辑。所以在分析负载均衡实现之前，先来看一下 AbstractLoadBalance 的逻辑。首先来看一下负载均衡的入口方法 select，如下：\n@Override\npublic &lt;T> Invoker&lt;T> select(List&lt;Invoker&lt;T>> invokers, URL url, Invocation invocation) &#123;\n    if (invokers == null || invokers.isEmpty())\n        return null;\n    // 如果 invokers 列表中仅有一个 Invoker，直接返回即可，无需进行负载均衡\n    if (invokers.size() == 1)\n        return invokers.get(0);\n    \n    // 调用 doSelect 方法进行负载均衡，该方法为抽象方法，由子类实现\n    return doSelect(invokers, url, invocation);\n&#125;\n\nprotected abstract &lt;T> Invoker&lt;T> doSelect(List&lt;Invoker&lt;T>> invokers, URL url, Invocation invocation);\n\nselect 方法的逻辑比较简单，首先会检测 invokers 集合的合法性，然后再检测 invokers 集合元素数量。如果只包含一个 Invoker，直接返回该 Inovker 即可。如果包含多个 Invoker，此时需要通过负载均衡算法选择一个 Invoker。具体的负载均衡算法由子类实现，接下来章节会对这些子类一一进行详细分析。\nAbstractLoadBalance 除了实现了 LoadBalance 接口方法，还封装了一些公共逻辑，比如服务提供者权重计算逻辑。具体实现如下：\nprotected int getWeight(Invoker&lt;?> invoker, Invocation invocation) &#123;\n    // 从 url 中获取权重 weight 配置值\n    int weight = invoker.getUrl().getMethodParameter(invocation.getMethodName(), Constants.WEIGHT_KEY, Constants.DEFAULT_WEIGHT);\n    if (weight > 0) &#123;\n        // 获取服务提供者启动时间戳\n        long timestamp = invoker.getUrl().getParameter(Constants.REMOTE_TIMESTAMP_KEY, 0L);\n        if (timestamp > 0L) &#123;\n            // 计算服务提供者运行时长\n            int uptime = (int) (System.currentTimeMillis() - timestamp);\n            // 获取服务预热时间，默认为10分钟\n            int warmup = invoker.getUrl().getParameter(Constants.WARMUP_KEY, Constants.DEFAULT_WARMUP);\n            // 如果服务运行时间小于预热时间，则重新计算服务权重，即降权\n            if (uptime > 0 &amp;&amp; uptime &lt; warmup) &#123;\n                // 重新计算服务权重\n                weight = calculateWarmupWeight(uptime, warmup, weight);\n            &#125;\n        &#125;\n    &#125;\n    return weight;\n&#125;\n\nstatic int calculateWarmupWeight(int uptime, int warmup, int weight) &#123;\n    // 计算权重，下面代码逻辑上形似于 (uptime / warmup) * weight。\n    // 随着服务运行时间 uptime 增大，权重计算值 ww 会慢慢接近配置值 weight\n    int ww = (int) ((float) uptime / ((float) warmup / (float) weight));\n    return ww &lt; 1 ? 1 : (ww > weight ? weight : ww);\n&#125;\n\n上面是权重的计算过程，该过程主要用于保证当服务运行时长小于服务预热时间时，对服务进行降权，避免让服务在启动之初就处于高负载状态。服务预热是一个优化手段，与此类似的还有 JVM 预热。主要目的是让服务启动后“低功率”运行一段时间，使其效率慢慢提升至最佳状态。\n关于 AbstractLoadBalance 就先分析到这，接下来分析各个实现类的代码。首先，我们从 Dubbo 缺省的实现类 RandomLoadBalance 看起。\n\n2.1 RandomLoadBalanceRandomLoadBalance 是加权随机算法的具体实现，它的算法思想很简单。假设我们有一组服务器 servers &#x3D; [A, B, C]，他们对应的权重为 weights &#x3D; [5, 3, 2]，权重总和为10。现在把这些权重值平铺在一维坐标值上，[0, 5) 区间属于服务器 A，[5, 8) 区间属于服务器 B，[8, 10) 区间属于服务器 C。接下来通过随机数生成器生成一个范围在 [0, 10) 之间的随机数，然后计算这个随机数会落到哪个区间上。比如数字3会落到服务器 A 对应的区间上，此时返回服务器 A 即可。权重越大的机器，在坐标轴上对应的区间范围就越大，因此随机数生成器生成的数字就会有更大的概率落到此区间内。只要随机数生成器产生的随机数分布性很好，在经过多次选择后，每个服务器被选中的次数比例接近其权重比例。比如，经过一万次选择后，服务器 A 被选中的次数大约为5000次，服务器 B 被选中的次数约为3000次，服务器 C 被选中的次数约为2000次。\n以上就是 RandomLoadBalance 背后的算法思想，比较简单。下面开始分析源码。\npublic class RandomLoadBalance extends AbstractLoadBalance &#123;\n\n    public static final String NAME = \"random\";\n\n    private final Random random = new Random();\n\n    @Override\n    protected &lt;T> Invoker&lt;T> doSelect(List&lt;Invoker&lt;T>> invokers, URL url, Invocation invocation) &#123;\n        int length = invokers.size();\n        int totalWeight = 0;\n        boolean sameWeight = true;\n        // 下面这个循环有两个作用，第一是计算总权重 totalWeight，\n        // 第二是检测每个服务提供者的权重是否相同\n        for (int i = 0; i &lt; length; i++) &#123;\n            int weight = getWeight(invokers.get(i), invocation);\n            // 累加权重\n            totalWeight += weight;\n            // 检测当前服务提供者的权重与上一个服务提供者的权重是否相同，\n            // 不相同的话，则将 sameWeight 置为 false。\n            if (sameWeight &amp;&amp; i > 0\n                    &amp;&amp; weight != getWeight(invokers.get(i - 1), invocation)) &#123;\n                sameWeight = false;\n            &#125;\n        &#125;\n        \n        // 下面的 if 分支主要用于获取随机数，并计算随机数落在哪个区间上\n        if (totalWeight > 0 &amp;&amp; !sameWeight) &#123;\n            // 随机获取一个 [0, totalWeight) 区间内的数字\n            int offset = random.nextInt(totalWeight);\n            // 循环让 offset 数减去服务提供者权重值，当 offset 小于0时，返回相应的 Invoker。\n            // 举例说明一下，我们有 servers = [A, B, C]，weights = [5, 3, 2]，offset = 7。\n            // 第一次循环，offset - 5 = 2 > 0，即 offset > 5，\n            // 表明其不会落在服务器 A 对应的区间上。\n            // 第二次循环，offset - 3 = -1 &lt; 0，即 5 &lt; offset &lt; 8，\n            // 表明其会落在服务器 B 对应的区间上\n            for (int i = 0; i &lt; length; i++) &#123;\n                // 让随机值 offset 减去权重值\n                offset -= getWeight(invokers.get(i), invocation);\n                if (offset &lt; 0) &#123;\n                    // 返回相应的 Invoker\n                    return invokers.get(i);\n                &#125;\n            &#125;\n        &#125;\n        \n        // 如果所有服务提供者权重值相同，此时直接随机返回一个即可\n        return invokers.get(random.nextInt(length));\n    &#125;\n&#125;\n\nRandomLoadBalance 的算法思想比较简单，在经过多次请求后，能够将调用请求按照权重值进行“均匀”分配。当然 RandomLoadBalance 也存在一定的缺点，当调用次数比较少时，Random 产生的随机数可能会比较集中，此时多数请求会落到同一台服务器上。这个缺点并不是很严重，多数情况下可以忽略。RandomLoadBalance 是一个简单，高效的负载均衡实现，因此 Dubbo 选择它作为缺省实现。\n关于 RandomLoadBalance 就先到这了，接下来分析 LeastActiveLoadBalance。\n\n2.2 LeastActiveLoadBalanceLeastActiveLoadBalance 翻译过来是最小活跃数负载均衡。活跃调用数越小，表明该服务提供者效率越高，单位时间内可处理更多的请求。此时应优先将请求分配给该服务提供者。在具体实现中，每个服务提供者对应一个活跃数 active。初始情况下，所有服务提供者活跃数均为0。每收到一个请求，活跃数加1，完成请求后则将活跃数减1。在服务运行一段时间后，性能好的服务提供者处理请求的速度更快，因此活跃数下降的也越快，此时这样的服务提供者能够优先获取到新的服务请求、这就是最小活跃数负载均衡算法的基本思想。除了最小活跃数，LeastActiveLoadBalance 在实现上还引入了权重值。所以准确的来说，LeastActiveLoadBalance 是基于加权最小活跃数算法实现的。举个例子说明一下，在一个服务提供者集群中，有两个性能优异的服务提供者。某一时刻它们的活跃数相同，此时 Dubbo 会根据它们的权重去分配请求，权重越大，获取到新请求的概率就越大。如果两个服务提供者权重相同，此时随机选择一个即可。关于 LeastActiveLoadBalance 的背景知识就先介绍到这里，下面开始分析源码。\npublic class LeastActiveLoadBalance extends AbstractLoadBalance &#123;\n\n    public static final String NAME = \"leastactive\";\n\n    private final Random random = new Random();\n\n    @Override\n    protected &lt;T> Invoker&lt;T> doSelect(List&lt;Invoker&lt;T>> invokers, URL url, Invocation invocation) &#123;\n        int length = invokers.size();\n        // 最小的活跃数\n        int leastActive = -1;\n        // 具有相同“最小活跃数”的服务者提供者（以下用 Invoker 代称）数量\n        int leastCount = 0; \n        // leastIndexs 用于记录具有相同“最小活跃数”的 Invoker 在 invokers 列表中的下标信息\n        int[] leastIndexs = new int[length];\n        int totalWeight = 0;\n        // 第一个最小活跃数的 Invoker 权重值，用于与其他具有相同最小活跃数的 Invoker 的权重进行对比，\n        // 以检测是否“所有具有相同最小活跃数的 Invoker 的权重”均相等\n        int firstWeight = 0;\n        boolean sameWeight = true;\n\n        // 遍历 invokers 列表\n        for (int i = 0; i &lt; length; i++) &#123;\n            Invoker&lt;T> invoker = invokers.get(i);\n            // 获取 Invoker 对应的活跃数\n            int active = RpcStatus.getStatus(invoker.getUrl(), invocation.getMethodName()).getActive();\n            // 获取权重 - ⭐️\n            int weight = invoker.getUrl().getMethodParameter(invocation.getMethodName(), Constants.WEIGHT_KEY, Constants.DEFAULT_WEIGHT);\n            // 发现更小的活跃数，重新开始\n            if (leastActive == -1 || active &lt; leastActive) &#123;\n            \t// 使用当前活跃数 active 更新最小活跃数 leastActive\n                leastActive = active;\n                // 更新 leastCount 为 1\n                leastCount = 1;\n                // 记录当前下标值到 leastIndexs 中\n                leastIndexs[0] = i;\n                totalWeight = weight;\n                firstWeight = weight;\n                sameWeight = true;\n\n            // 当前 Invoker 的活跃数 active 与最小活跃数 leastActive 相同 \n            &#125; else if (active == leastActive) &#123;\n            \t// 在 leastIndexs 中记录下当前 Invoker 在 invokers 集合中的下标\n                leastIndexs[leastCount++] = i;\n                // 累加权重\n                totalWeight += weight;\n                // 检测当前 Invoker 的权重与 firstWeight 是否相等，\n                // 不相等则将 sameWeight 置为 false\n                if (sameWeight &amp;&amp; i > 0\n                    &amp;&amp; weight != firstWeight) &#123;\n                    sameWeight = false;\n                &#125;\n            &#125;\n        &#125;\n        \n        // 当只有一个 Invoker 具有最小活跃数，此时直接返回该 Invoker 即可\n        if (leastCount == 1) &#123;\n            return invokers.get(leastIndexs[0]);\n        &#125;\n\n        // 有多个 Invoker 具有相同的最小活跃数，但它们之间的权重不同\n        if (!sameWeight &amp;&amp; totalWeight > 0) &#123;\n        \t// 随机生成一个 [0, totalWeight) 之间的数字\n            int offsetWeight = random.nextInt(totalWeight);\n            // 循环让随机数减去具有最小活跃数的 Invoker 的权重值，\n            // 当 offset 小于等于0时，返回相应的 Invoker\n            for (int i = 0; i &lt; leastCount; i++) &#123;\n                int leastIndex = leastIndexs[i];\n                // 获取权重值，并让随机数减去权重值 - ⭐️\n                offsetWeight -= getWeight(invokers.get(leastIndex), invocation);\n                if (offsetWeight &lt;= 0)\n                    return invokers.get(leastIndex);\n            &#125;\n        &#125;\n        // 如果权重相同或权重为0时，随机返回一个 Invoker\n        return invokers.get(leastIndexs[random.nextInt(leastCount)]);\n    &#125;\n&#125;\n\n上面代码的逻辑比较多，我们在代码中写了大量的注释，有帮助大家理解代码逻辑。下面简单总结一下以上代码所做的事情，如下：\n\n遍历 invokers 列表，寻找活跃数最小的 Invoker\n如果有多个 Invoker 具有相同的最小活跃数，此时记录下这些 Invoker 在 invokers 集合中的下标，并累加它们的权重，比较它们的权重值是否相等\n如果只有一个 Invoker 具有最小的活跃数，此时直接返回该 Invoker 即可\n如果有多个 Invoker 具有最小活跃数，且它们的权重不相等，此时处理方式和 RandomLoadBalance 一致\n如果有多个 Invoker 具有最小活跃数，但它们的权重相等，此时随机返回一个即可\n\n以上就是 LeastActiveLoadBalance 大致的实现逻辑，大家在阅读的源码的过程中要注意区分活跃数与权重这两个概念，不要混为一谈。\n以上分析是基于 Dubbo 2.6.4 版本进行的，由于近期 Dubbo 2.6.5 发布了，并对 LeastActiveLoadBalance 进行了一些修改，下面简单来介绍一下修改内容。回到上面的源码中，我们在上面的代码中标注了两个黄色的五角星⭐️。两处标记对应的代码分别如下：\nint weight = invoker.getUrl().getMethodParameter(invocation.getMethodName(), Constants.WEIGHT_KEY, Constants.DEFAULT_WEIGHT);\noffsetWeight -= getWeight(invokers.get(leastIndex), invocation);\n\n问题出在服务预热阶段，第一行代码直接从 url 中取权重值，未被降权过。第二行代码获取到的是经过降权后的权重。第一行代码获取到的权重值最终会被累加到权重总和 totalWeight 中，这个时候会导致一个问题。offsetWeight 是一个在 [0, totalWeight) 范围内的随机数，而它所减去的是经过降权的权重。很有可能在经过 leastCount 次运算后，offsetWeight 仍然是大于0的，导致无法选中 Invoker。这个问题对应的 issue 为 #904，并在 pull request #2172 中被修复。具体的修复逻辑是将标注一处的代码修改为：\n// afterWarmup 等价于上面的 weight 变量，这样命名是为了强调该变量经过了 warmup 降权处理\nint afterWarmup = getWeight(invoker, invocation);\n\n另外，2.6.4 版本中的 LeastActiveLoadBalance 还有一个缺陷，即当一组 Invoker 具有相同的最小活跃数，且其中一个 Invoker 的权重值为1，此时这个 Invoker 无法被选中。缺陷代码如下：\nint offsetWeight = random.nextInt(totalWeight);\nfor (int i = 0; i &lt; leastCount; i++) &#123;\n    int leastIndex = leastIndexs[i];\n    offsetWeight -= getWeight(invokers.get(leastIndex), invocation);\n    if (offsetWeight &lt;= 0)    // ❌\n        return invokers.get(leastIndex);\n&#125;\n\n问题出在了offsetWeight &lt;= 0上，举例说明，假设有一组 Invoker 的权重为 5、2、1，offsetWeight 最大值为 7。假设 offsetWeight &#x3D; 7，你会发现，当 for 循环进行第二次遍历后 offsetWeight &#x3D; 7 - 5 - 2 &#x3D; 0，提前返回了。此时，此时权重为1的 Invoker 就没有机会被选中了。该问题在 Dubbo 2.6.5 中被修复了，修改后的代码如下：\nint offsetWeight = random.nextInt(totalWeight) + 1;\n\n以上就是 Dubbo 2.6.5 对 LeastActiveLoadBalance 的更新，内容不是很多，先分析到这。接下来分析基于一致性 hash 思想的 ConsistentHashLoadBalance。\n\n2.3 ConsistentHashLoadBalance一致性 hash 算法由麻省理工学院的 Karger 及其合作者于1997年提出的，算法提出之初是用于大规模缓存系统的负载均衡。它的工作过程是这样的，首先根据 ip 或者其他的信息为缓存节点生成一个 hash，并将这个 hash 投射到 [0, 2^32 - 1] 的圆环上。当有查询或写入请求时，则为缓存项的 key 生成一个 hash 值。然后查找第一个大于或等于该 hash 值的缓存节点，并到这个节点中查询或写入缓存项。如果当前节点挂了，则在下一次查询或写入缓存时，为缓存项查找另一个大于其 hash 值的缓存节点即可。大致效果如下图所示，每个缓存节点在圆环上占据一个位置。如果缓存项的 key 的 hash 值小于缓存节点 hash 值，则到该缓存节点中存储或读取缓存项。比如下面绿色点对应的缓存项将会被存储到 cache-2 节点中。由于 cache-3 挂了，原本应该存到该节点中的缓存项最终会存储到 cache-4 节点中。\n\n下面来看看一致性 hash 在 Dubbo 中的应用。我们把上图的缓存节点替换成 Dubbo 的服务提供者，于是得到了下图：\n\n这里相同颜色的节点均属于同一个服务提供者，比如 Invoker1-1，Invoker1-2，……, Invoker1-160。这样做的目的是通过引入虚拟节点，让 Invoker 在圆环上分散开来，避免数据倾斜问题。所谓数据倾斜是指，由于节点不够分散，导致大量请求落到了同一个节点上，而其他节点只会接收到了少量请求的情况。比如：\n\n如上，由于 Invoker-1 和 Invoker-2 在圆环上分布不均，导致系统中75%的请求都会落到 Invoker-1 上，只有 25% 的请求会落到 Invoker-2 上。解决这个问题办法是引入虚拟节点，通过虚拟节点均衡各个节点的请求量。\n到这里背景知识就普及完了，接下来开始分析源码。我们先从 ConsistentHashLoadBalance 的 doSelect 方法开始看起，如下：\npublic class ConsistentHashLoadBalance extends AbstractLoadBalance &#123;\n\n    private final ConcurrentMap&lt;String, ConsistentHashSelector&lt;?>> selectors = \n        new ConcurrentHashMap&lt;String, ConsistentHashSelector&lt;?>>();\n\n    @Override\n    protected &lt;T> Invoker&lt;T> doSelect(List&lt;Invoker&lt;T>> invokers, URL url, Invocation invocation) &#123;\n        String methodName = RpcUtils.getMethodName(invocation);\n        String key = invokers.get(0).getUrl().getServiceKey() + \".\" + methodName;\n\n        // 获取 invokers 原始的 hashcode\n        int identityHashCode = System.identityHashCode(invokers);\n        ConsistentHashSelector&lt;T> selector = (ConsistentHashSelector&lt;T>) selectors.get(key);\n        // 如果 invokers 是一个新的 List 对象，意味着服务提供者数量发生了变化，可能新增也可能减少了。\n        // 此时 selector.identityHashCode != identityHashCode 条件成立\n        if (selector == null || selector.identityHashCode != identityHashCode) &#123;\n            // 创建新的 ConsistentHashSelector\n            selectors.put(key, new ConsistentHashSelector&lt;T>(invokers, methodName, identityHashCode));\n            selector = (ConsistentHashSelector&lt;T>) selectors.get(key);\n        &#125;\n\n        // 调用 ConsistentHashSelector 的 select 方法选择 Invoker\n        return selector.select(invocation);\n    &#125;\n    \n    private static final class ConsistentHashSelector&lt;T> &#123;...&#125;\n&#125;\n\n如上，doSelect 方法主要做了一些前置工作，比如检测 invokers 列表是不是变动过，以及创建 ConsistentHashSelector。这些工作做完后，接下来开始调用 ConsistentHashSelector 的 select 方法执行负载均衡逻辑。在分析 select 方法之前，我们先来看一下一致性 hash 选择器 ConsistentHashSelector 的初始化过程，如下：\nprivate static final class ConsistentHashSelector&lt;T> &#123;\n\n    // 使用 TreeMap 存储 Invoker 虚拟节点\n    private final TreeMap&lt;Long, Invoker&lt;T>> virtualInvokers;\n\n    private final int replicaNumber;\n\n    private final int identityHashCode;\n\n    private final int[] argumentIndex;\n\n    ConsistentHashSelector(List&lt;Invoker&lt;T>> invokers, String methodName, int identityHashCode) &#123;\n        this.virtualInvokers = new TreeMap&lt;Long, Invoker&lt;T>>();\n        this.identityHashCode = identityHashCode;\n        URL url = invokers.get(0).getUrl();\n        // 获取虚拟节点数，默认为160\n        this.replicaNumber = url.getMethodParameter(methodName, \"hash.nodes\", 160);\n        // 获取参与 hash 计算的参数下标值，默认对第一个参数进行 hash 运算\n        String[] index = Constants.COMMA_SPLIT_PATTERN.split(url.getMethodParameter(methodName, \"hash.arguments\", \"0\"));\n        argumentIndex = new int[index.length];\n        for (int i = 0; i &lt; index.length; i++) &#123;\n            argumentIndex[i] = Integer.parseInt(index[i]);\n        &#125;\n        for (Invoker&lt;T> invoker : invokers) &#123;\n            String address = invoker.getUrl().getAddress();\n            for (int i = 0; i &lt; replicaNumber / 4; i++) &#123;\n                // 对 address + i 进行 md5 运算，得到一个长度为16的字节数组\n                byte[] digest = md5(address + i);\n                // 对 digest 部分字节进行4次 hash 运算，得到四个不同的 long 型正整数\n                for (int h = 0; h &lt; 4; h++) &#123;\n                    // h = 0 时，取 digest 中下标为 0 ~ 3 的4个字节进行位运算\n                    // h = 1 时，取 digest 中下标为 4 ~ 7 的4个字节进行位运算\n                    // h = 2, h = 3 时过程同上\n                    long m = hash(digest, h);\n                    // 将 hash 到 invoker 的映射关系存储到 virtualInvokers 中，\n                    // virtualInvokers 需要提供高效的查询操作，因此选用 TreeMap 作为存储结构\n                    virtualInvokers.put(m, invoker);\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\nConsistentHashSelector 的构造方法执行了一系列的初始化逻辑，比如从配置中获取虚拟节点数以及参与 hash 计算的参数下标，默认情况下只使用第一个参数进行 hash。需要特别说明的是，ConsistentHashLoadBalance 的负载均衡逻辑只受参数值影响，具有相同参数值的请求将会被分配给同一个服务提供者。ConsistentHashLoadBalance 不 关系权重，因此使用时需要注意一下。\n在获取虚拟节点数和参数下标配置后，接下来要做的事情是计算虚拟节点 hash 值，并将虚拟节点存储到 TreeMap 中。到此，ConsistentHashSelector 初始化工作就完成了。接下来，我们来看看 select 方法的逻辑。\npublic Invoker&lt;T> select(Invocation invocation) &#123;\n    // 将参数转为 key\n    String key = toKey(invocation.getArguments());\n    // 对参数 key 进行 md5 运算\n    byte[] digest = md5(key);\n    // 取 digest 数组的前四个字节进行 hash 运算，再将 hash 值传给 selectForKey 方法，\n    // 寻找合适的 Invoker\n    return selectForKey(hash(digest, 0));\n&#125;\n\nprivate Invoker&lt;T> selectForKey(long hash) &#123;\n    // 到 TreeMap 中查找第一个节点值大于或等于当前 hash 的 Invoker\n    Map.Entry&lt;Long, Invoker&lt;T>> entry = virtualInvokers.tailMap(hash, true).firstEntry();\n    // 如果 hash 大于 Invoker 在圆环上最大的位置，此时 entry = null，\n    // 需要将 TreeMap 的头节点赋值给 entry\n    if (entry == null) &#123;\n        entry = virtualInvokers.firstEntry();\n    &#125;\n\n    // 返回 Invoker\n    return entry.getValue();\n&#125;\n\n如上，选择的过程相对比较简单了。首先是对参数进行 md5 以及 hash 运算，得到一个 hash 值。然后再拿这个值到 TreeMap 中查找目标 Invoker 即可。\n到此关于 ConsistentHashLoadBalance 就分析完了。在阅读 ConsistentHashLoadBalance 源码之前，大家一定要先补充背景知识，不然很难看懂代码逻辑。\n\n2.4 RoundRobinLoadBalance本节，我们来看一下 Dubbo 中加权轮询负载均衡的实现 RoundRobinLoadBalance。在详细分析源码前，我们先来了解一下什么是加权轮询。这里从最简单的轮询开始讲起，所谓轮询是指将请求轮流分配给每台服务器。举个例子，我们有三台服务器 A、B、C。我们将第一个请求分配给服务器 A，第二个请求分配给服务器 B，第三个请求分配给服务器 C，第四个请求再次分配给服务器 A。这个过程就叫做轮询。轮询是一种无状态负载均衡算法，实现简单，适用于每台服务器性能相近的场景下。但现实情况下，我们并不能保证每台服务器性能均相近。如果我们将等量的请求分配给性能较差的服务器，这显然是不合理的。因此，这个时候我们需要对轮询过程进行加权，以调控每台服务器的负载。经过加权后，每台服务器能够得到的请求数比例，接近或等于他们的权重比。比如服务器 A、B、C 权重比为 5:2:1。那么在8次请求中，服务器 A 将收到其中的5次请求，服务器 B 会收到其中的2次请求，服务器 C 则收到其中的1次请求。\n以上就是加权轮询的算法思想，搞懂了这个思想，接下来我们就可以分析源码了。我们先来看一下 2.6.4 版本的 RoundRobinLoadBalance。\npublic class RoundRobinLoadBalance extends AbstractLoadBalance &#123;\n\n    public static final String NAME = \"roundrobin\";\n\n    private final ConcurrentMap&lt;String, AtomicPositiveInteger> sequences = \n        new ConcurrentHashMap&lt;String, AtomicPositiveInteger>();\n\n    @Override\n    protected &lt;T> Invoker&lt;T> doSelect(List&lt;Invoker&lt;T>> invokers, URL url, Invocation invocation) &#123;\n        // key = 全限定类名 + \".\" + 方法名，比如 com.xxx.DemoService.sayHello\n        String key = invokers.get(0).getUrl().getServiceKey() + \".\" + invocation.getMethodName();\n        int length = invokers.size();\n        // 最大权重\n        int maxWeight = 0;\n        // 最小权重\n        int minWeight = Integer.MAX_VALUE;\n        final LinkedHashMap&lt;Invoker&lt;T>, IntegerWrapper> invokerToWeightMap = new LinkedHashMap&lt;Invoker&lt;T>, IntegerWrapper>();\n        // 权重总和\n        int weightSum = 0;\n\n        // 下面这个循环主要用于查找最大和最小权重，计算权重总和等\n        for (int i = 0; i &lt; length; i++) &#123;\n            int weight = getWeight(invokers.get(i), invocation);\n            // 获取最大和最小权重\n            maxWeight = Math.max(maxWeight, weight);\n            minWeight = Math.min(minWeight, weight);\n            if (weight > 0) &#123;\n                // 将 weight 封装到 IntegerWrapper 中\n                invokerToWeightMap.put(invokers.get(i), new IntegerWrapper(weight));\n                // 累加权重\n                weightSum += weight;\n            &#125;\n        &#125;\n\n        // 查找 key 对应的对应 AtomicPositiveInteger 实例，为空则创建。\n        // 这里可以把 AtomicPositiveInteger 看成一个黑盒，大家只要知道\n        // AtomicPositiveInteger 用于记录服务的调用编号即可。至于细节，\n        // 大家如果感兴趣，可以自行分析\n        AtomicPositiveInteger sequence = sequences.get(key);\n        if (sequence == null) &#123;\n            sequences.putIfAbsent(key, new AtomicPositiveInteger());\n            sequence = sequences.get(key);\n        &#125;\n\n        // 获取当前的调用编号\n        int currentSequence = sequence.getAndIncrement();\n        // 如果最小权重小于最大权重，表明服务提供者之间的权重是不相等的\n        if (maxWeight > 0 &amp;&amp; minWeight &lt; maxWeight) &#123;\n            // 使用调用编号对权重总和进行取余操作\n            int mod = currentSequence % weightSum;\n            // 进行 maxWeight 次遍历\n            for (int i = 0; i &lt; maxWeight; i++) &#123;\n                // 遍历 invokerToWeightMap\n                for (Map.Entry&lt;Invoker&lt;T>, IntegerWrapper> each : invokerToWeightMap.entrySet()) &#123;\n\t\t\t\t\t// 获取 Invoker\n                    final Invoker&lt;T> k = each.getKey();\n                    // 获取权重包装类 IntegerWrapper\n                    final IntegerWrapper v = each.getValue();\n                    \n                    // 如果 mod = 0，且权重大于0，此时返回相应的 Invoker\n                    if (mod == 0 &amp;&amp; v.getValue() > 0) &#123;\n                        return k;\n                    &#125;\n                    \n                    // mod != 0，且权重大于0，此时对权重和 mod 分别进行自减操作\n                    if (v.getValue() > 0) &#123;\n                        v.decrement();\n                        mod--;\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n        \n        // 服务提供者之间的权重相等，此时通过轮询选择 Invoker\n        return invokers.get(currentSequence % length);\n    &#125;\n\n    // IntegerWrapper 是一个 int 包装类，主要包含了一个自减方法。\n    private static final class IntegerWrapper &#123;\n        private int value;\n\n        public void decrement() &#123;\n            this.value--;\n        &#125;\n        \n        // 省略部分代码\n    &#125;\n&#125;\n\n如上，RoundRobinLoadBalance 的每行代码都不是很难理解，但是将它们组合在一起之后，就不是很好理解了。所以下面我们举例进行说明，假设我们有三台服务器 servers &#x3D; [A, B, C]，对应的权重为 weights &#x3D; [2, 5, 1]。接下来对上面的逻辑进行简单的模拟。\nmod &#x3D; 0：满足条件，此时直接返回服务器 A\nmod &#x3D; 1：需要进行一次递减操作才能满足条件，此时返回服务器 B\nmod &#x3D; 2：需要进行两次递减操作才能满足条件，此时返回服务器 C\nmod &#x3D; 3：需要进行三次递减操作才能满足条件，经过递减后，服务器权重为 [1, 4, 0]，此时返回服务器 A\nmod &#x3D; 4：需要进行四次递减操作才能满足条件，经过递减后，服务器权重为 [0, 4, 0]，此时返回服务器 B\nmod &#x3D; 5：需要进行五次递减操作才能满足条件，经过递减后，服务器权重为 [0, 3, 0]，此时返回服务器 B\nmod &#x3D; 6：需要进行六次递减操作才能满足条件，经过递减后，服务器权重为 [0, 2, 0]，此时返回服务器 B\nmod &#x3D; 7：需要进行七次递减操作才能满足条件，经过递减后，服务器权重为 [0, 1, 0]，此时返回服务器 B\n经过8次调用后，我们得到的负载均衡结果为 [A, B, C, A, B, B, B, B]，次数比 A:B:C &#x3D; 2:5:1，等于权重比。当 sequence &#x3D; 8 时，mod &#x3D; 0，此时重头再来。从上面的模拟过程可以看出，当 mod &gt;&#x3D; 3 后，服务器 C 就不会被选中了，因为它的权重被减为0了。当 mod &gt;&#x3D; 4 后，服务器 A 的权重被减为0，此后 A 就不会再被选中。\n以上是 2.6.4 版本的 RoundRobinLoadBalance 分析过程，2.6.4 版本的 RoundRobinLoadBalance 在某些情况下存在着比较严重的性能问题，该问题最初是在 issue #2578 中被反馈出来。问题出在了 Invoker 的返回时机上，RoundRobinLoadBalance 需要在mod == 0 &amp;&amp; v.getValue() &gt; 0 条件成立的情况下才会被返回相应的 Invoker。假如 mod 很大，比如 10000，50000，甚至更大时，doSelect 方法需要进行很多次计算才能将 mod 减为0。由此可知，doSelect 的效率与 mod 有关，时间复杂度为 O(mod)。mod 又受最大权重 maxWeight 的影响，因此当某个服务提供者配置了非常大的权重，此时 RoundRobinLoadBalance 会产生比较严重的性能问题。这个问题被反馈后，社区很快做了回应。并对 RoundRobinLoadBalance 的代码进行了重构，将时间复杂度优化至了常量级别。这个优化可以说很好了，下面我们来学习一下优化后的代码。\npublic class RoundRobinLoadBalance extends AbstractLoadBalance &#123;\n\n    public static final String NAME = \"roundrobin\";\n\n    private final ConcurrentMap&lt;String, AtomicPositiveInteger> sequences = new ConcurrentHashMap&lt;String, AtomicPositiveInteger>();\n\n    private final ConcurrentMap&lt;String, AtomicPositiveInteger> indexSeqs = new ConcurrentHashMap&lt;String, AtomicPositiveInteger>();\n\n    @Override\n    protected &lt;T> Invoker&lt;T> doSelect(List&lt;Invoker&lt;T>> invokers, URL url, Invocation invocation) &#123;\n        String key = invokers.get(0).getUrl().getServiceKey() + \".\" + invocation.getMethodName();\n        int length = invokers.size();\n        int maxWeight = 0;\n        int minWeight = Integer.MAX_VALUE;\n        final List&lt;Invoker&lt;T>> invokerToWeightList = new ArrayList&lt;>();\n        \n        // 查找最大和最小权重\n        for (int i = 0; i &lt; length; i++) &#123;\n            int weight = getWeight(invokers.get(i), invocation);\n            maxWeight = Math.max(maxWeight, weight);\n            minWeight = Math.min(minWeight, weight);\n            if (weight > 0) &#123;\n                invokerToWeightList.add(invokers.get(i));\n            &#125;\n        &#125;\n        \n        // 获取当前服务对应的调用序列对象 AtomicPositiveInteger\n        AtomicPositiveInteger sequence = sequences.get(key);\n        if (sequence == null) &#123;\n            // 创建 AtomicPositiveInteger，默认值为0\n            sequences.putIfAbsent(key, new AtomicPositiveInteger());\n            sequence = sequences.get(key);\n        &#125;\n        \n        // 获取下标序列对象 AtomicPositiveInteger\n        AtomicPositiveInteger indexSeq = indexSeqs.get(key);\n        if (indexSeq == null) &#123;\n            // 创建 AtomicPositiveInteger，默认值为 -1\n            indexSeqs.putIfAbsent(key, new AtomicPositiveInteger(-1));\n            indexSeq = indexSeqs.get(key);\n        &#125;\n\n        if (maxWeight > 0 &amp;&amp; minWeight &lt; maxWeight) &#123;\n            length = invokerToWeightList.size();\n            while (true) &#123;\n                int index = indexSeq.incrementAndGet() % length;\n                int currentWeight = sequence.get() % maxWeight;\n\n                // 每循环一轮（index = 0），重新计算 currentWeight\n                if (index == 0) &#123;\n                    currentWeight = sequence.incrementAndGet() % maxWeight;\n                &#125;\n                \n                // 检测 Invoker 的权重是否大于 currentWeight，大于则返回\n                if (getWeight(invokerToWeightList.get(index), invocation) > currentWeight) &#123;\n                    return invokerToWeightList.get(index);\n                &#125;\n            &#125;\n        &#125;\n        \n        // 所有 Invoker 权重相等，此时进行普通的轮询即可\n        return invokers.get(sequence.incrementAndGet() % length);\n    &#125;\n&#125;\n\n上面代码的逻辑是这样的，每进行一轮循环，重新计算 currentWeight。如果当前 Invoker 权重大于 currentWeight，则返回该 Invoker。下面举例说明，假设服务器 [A, B, C] 对应权重 [5, 2, 1]。\n第一轮循环，currentWeight &#x3D; 1，可返回 A 和 B\n第二轮循环，currentWeight &#x3D; 2，返回 A\n第三轮循环，currentWeight &#x3D; 3，返回 A\n第四轮循环，currentWeight &#x3D; 4，返回 A\n第五轮循环，currentWeight &#x3D; 0，返回 A, B, C\n如上，这里的一轮循环是指 index 再次变为0所经历过的循环，这里可以把 index &#x3D; 0 看做是一轮循环的开始。每一轮循环的次数与 Invoker 的数量有关，Invoker 数量通常不会太多，所以我们可以认为上面代码的时间复杂度为常数级。\n重构后的 RoundRobinLoadBalance 看起来已经很不错了，但是在代码更新不久后，很快又被重构了。这次重构原因是新的 RoundRobinLoadBalance 在某些情况下选出的服务器序列不够均匀。比如，服务器 [A, B, C] 对应权重 [5, 1, 1]。进行7次负载均衡后，选择出来的序列为 [A, A, A, A, A, B, C]。前5个请求全部都落在了服务器 A上，这将会使服务器 A 短时间内接收大量的请求，压力陡增。而 B 和 C 此时无请求，处于空闲状态。而我们期望的结果是这样的 [A, A, B, A, C, A, A]，不同服务器可以穿插获取请求。为了增加负载均衡结果的平滑性，社区再次对 RoundRobinLoadBalance 的实现进行了重构，这次重构参考自 Nginx 的平滑加权轮询负载均衡。每个服务器对应两个权重，分别为 weight 和 currentWeight。其中 weight 是固定的，currentWeight 会动态调整，初始值为0。当有新的请求进来时，遍历服务器列表，让它的 currentWeight 加上自身权重。遍历完成后，找到最大的 currentWeight，并将其减去权重总和，然后返回相应的服务器即可。\n上面描述不是很好理解，下面还是举例进行说明。这里仍然使用服务器 [A, B, C] 对应权重 [5, 1, 1] 的例子说明，现在有7个请求依次进入负载均衡逻辑，选择过程如下：\n\n\n\n请求编号\ncurrentWeight 数组\n选择结果\n减去权重总和后的 currentWeight 数组\n\n\n\n1\n[5, 1, 1]\nA\n[-2, 1, 1]\n\n\n2\n[3, 2, 2]\nA\n[-4, 2, 2]\n\n\n3\n[1, 3, 3]\nB\n[1, -4, 3]\n\n\n4\n[6, -3, 4]\nA\n[-1, -3, 4]\n\n\n5\n[4, -2, 5]\nC\n[4, -2, -2]\n\n\n6\n[9, -1, -1]\nA\n[2, -1, -1]\n\n\n7\n[7, 0, 0]\nA\n[0, 0, 0]\n\n\n如上，经过平滑性处理后，得到的服务器序列为 [A, A, B, A, C, A, A]，相比之前的序列 [A, A, A, A, A, B, C]，分布性要好一些。初始情况下 currentWeight &#x3D; [0, 0, 0]，第7个请求处理完后，currentWeight 再次变为 [0, 0, 0]。\n以上就是平滑加权轮询的计算过程，接下来，我们来看看 Dubbo-2.6.5 是如何实现上面的计算过程的。\npublic class RoundRobinLoadBalance extends AbstractLoadBalance &#123;\n    public static final String NAME = \"roundrobin\";\n    \n    private static int RECYCLE_PERIOD = 60000;\n    \n    protected static class WeightedRoundRobin &#123;\n        // 服务提供者权重\n        private int weight;\n        // 当前权重\n        private AtomicLong current = new AtomicLong(0);\n        // 最后一次更新时间\n        private long lastUpdate;\n        \n        public void setWeight(int weight) &#123;\n            this.weight = weight;\n            // 初始情况下，current = 0\n            current.set(0);\n        &#125;\n        public long increaseCurrent() &#123;\n            // current = current + weight；\n            return current.addAndGet(weight);\n        &#125;\n        public void sel(int total) &#123;\n            // current = current - total;\n            current.addAndGet(-1 * total);\n        &#125;\n    &#125;\n\n    // 嵌套 Map 结构，存储的数据结构示例如下：\n    // &#123;\n    //     \"UserService.query\": &#123;\n    //         \"url1\": WeightedRoundRobin@123, \n    //         \"url2\": WeightedRoundRobin@456, \n    //     &#125;,\n    //     \"UserService.update\": &#123;\n    //         \"url1\": WeightedRoundRobin@123, \n    //         \"url2\": WeightedRoundRobin@456,\n    //     &#125;\n    // &#125;\n    // 最外层为服务类名 + 方法名，第二层为 url 到 WeightedRoundRobin 的映射关系。\n    // 这里我们可以将 url 看成是服务提供者的 id\n    private ConcurrentMap&lt;String, ConcurrentMap&lt;String, WeightedRoundRobin>> methodWeightMap = new ConcurrentHashMap&lt;String, ConcurrentMap&lt;String, WeightedRoundRobin>>();\n    \n    // 原子更新锁\n    private AtomicBoolean updateLock = new AtomicBoolean();\n    \n    @Override\n    protected &lt;T> Invoker&lt;T> doSelect(List&lt;Invoker&lt;T>> invokers, URL url, Invocation invocation) &#123;\n        String key = invokers.get(0).getUrl().getServiceKey() + \".\" + invocation.getMethodName();\n        // 获取 url 到 WeightedRoundRobin 映射表，如果为空，则创建一个新的\n        ConcurrentMap&lt;String, WeightedRoundRobin> map = methodWeightMap.get(key);\n        if (map == null) &#123;\n            methodWeightMap.putIfAbsent(key, new ConcurrentHashMap&lt;String, WeightedRoundRobin>());\n            map = methodWeightMap.get(key);\n        &#125;\n        int totalWeight = 0;\n        long maxCurrent = Long.MIN_VALUE;\n        \n        // 获取当前时间\n        long now = System.currentTimeMillis();\n        Invoker&lt;T> selectedInvoker = null;\n        WeightedRoundRobin selectedWRR = null;\n\n        // 下面这个循环主要做了这样几件事情：\n        //   1. 遍历 Invoker 列表，检测当前 Invoker 是否有\n        //      相应的 WeightedRoundRobin，没有则创建\n        //   2. 检测 Invoker 权重是否发生了变化，若变化了，\n        //      则更新 WeightedRoundRobin 的 weight 字段\n        //   3. 让 current 字段加上自身权重，等价于 current += weight\n        //   4. 设置 lastUpdate 字段，即 lastUpdate = now\n        //   5. 寻找具有最大 current 的 Invoker，以及 Invoker 对应的 WeightedRoundRobin，\n        //      暂存起来，留作后用\n        //   6. 计算权重总和\n        for (Invoker&lt;T> invoker : invokers) &#123;\n            String identifyString = invoker.getUrl().toIdentityString();\n            WeightedRoundRobin weightedRoundRobin = map.get(identifyString);\n            int weight = getWeight(invoker, invocation);\n            if (weight &lt; 0) &#123;\n                weight = 0;\n            &#125;\n            \n            // 检测当前 Invoker 是否有对应的 WeightedRoundRobin，没有则创建\n            if (weightedRoundRobin == null) &#123;\n                weightedRoundRobin = new WeightedRoundRobin();\n                // 设置 Invoker 权重\n                weightedRoundRobin.setWeight(weight);\n                // 存储 url 唯一标识 identifyString 到 weightedRoundRobin 的映射关系\n                map.putIfAbsent(identifyString, weightedRoundRobin);\n                weightedRoundRobin = map.get(identifyString);\n            &#125;\n            // Invoker 权重不等于 WeightedRoundRobin 中保存的权重，说明权重变化了，此时进行更新\n            if (weight != weightedRoundRobin.getWeight()) &#123;\n                weightedRoundRobin.setWeight(weight);\n            &#125;\n            \n            // 让 current 加上自身权重，等价于 current += weight\n            long cur = weightedRoundRobin.increaseCurrent();\n            // 设置 lastUpdate，表示近期更新过\n            weightedRoundRobin.setLastUpdate(now);\n            // 找出最大的 current \n            if (cur > maxCurrent) &#123;\n                maxCurrent = cur;\n                // 将具有最大 current 权重的 Invoker 赋值给 selectedInvoker\n                selectedInvoker = invoker;\n                // 将 Invoker 对应的 weightedRoundRobin 赋值给 selectedWRR，留作后用\n                selectedWRR = weightedRoundRobin;\n            &#125;\n            \n            // 计算权重总和\n            totalWeight += weight;\n        &#125;\n\n        // 对 &lt;identifyString, WeightedRoundRobin> 进行检查，过滤掉长时间未被更新的节点。\n        // 该节点可能挂了，invokers 中不包含该节点，所以该节点的 lastUpdate 长时间无法被更新。\n        // 若未更新时长超过阈值后，就会被移除掉，默认阈值为60秒。\n        if (!updateLock.get() &amp;&amp; invokers.size() != map.size()) &#123;\n            if (updateLock.compareAndSet(false, true)) &#123;\n                try &#123;\n                    ConcurrentMap&lt;String, WeightedRoundRobin> newMap = new ConcurrentHashMap&lt;String, WeightedRoundRobin>();\n                    // 拷贝\n                    newMap.putAll(map);\n                    \n                    // 遍历修改，即移除过期记录\n                    Iterator&lt;Entry&lt;String, WeightedRoundRobin>> it = newMap.entrySet().iterator();\n                    while (it.hasNext()) &#123;\n                        Entry&lt;String, WeightedRoundRobin> item = it.next();\n                        if (now - item.getValue().getLastUpdate() > RECYCLE_PERIOD) &#123;\n                            it.remove();\n                        &#125;\n                    &#125;\n                    \n                    // 更新引用\n                    methodWeightMap.put(key, newMap);\n                &#125; finally &#123;\n                    updateLock.set(false);\n                &#125;\n            &#125;\n        &#125;\n\n        if (selectedInvoker != null) &#123;\n            // 让 current 减去权重总和，等价于 current -= totalWeight\n            selectedWRR.sel(totalWeight);\n            // 返回具有最大 current 的 Invoker\n            return selectedInvoker;\n        &#125;\n        \n        // should not happen here\n        return invokers.get(0);\n    &#125;\n&#125;\n\n以上就是 Dubbo-2.6.5 版本的 RoundRobinLoadBalance，大家如果能够理解平滑加权轮询算法的计算过程，再配合代码中注释，理解上面的代码应该不难。\n\n3.总结本篇文章对 Dubbo 中的几种负载均衡实现进行了详细的分析，内容比较多，大家慢慢消化。理解负载均衡代码逻辑的关键之处在于对背景知识的理解，因此大家在阅读源码前，务必先了解每种负载均衡对应的背景知识。\n本文介绍了服务调用过程的原理和实现细节\n\n服务导出1. 简介在前面的文章中，我们分析了 Dubbo SPI、服务导出与引入、以及集群容错方面的代码。经过前文的铺垫，本篇文章我们终于可以分析服务调用过程了。Dubbo 服务调用过程比较复杂，包含众多步骤，比如发送请求、编解码、服务降级、过滤器链处理、序列化、线程派发以及响应请求等步骤。限于篇幅原因，本篇文章无法对所有的步骤一一进行分析。本篇文章将会重点分析请求的发送与接收、编解码、线程派发以及响应的发送与接收等过程，至于服务降级、过滤器链和序列化大家自行进行分析，也可以将其当成一个黑盒，暂时忽略也没关系。介绍完本篇文章要分析的内容，接下来我们进入正题吧。\n\n2. 源码分析在进行源码分析之前，我们先来通过一张图了解 Dubbo 服务调用过程。\n\n首先服务消费者通过代理对象 Proxy 发起远程调用，接着通过网络客户端 Client 将编码后的请求发送给服务提供方的网络层上，也就是 Server。Server 在收到请求后，首先要做的事情是对数据包进行解码。然后将解码后的请求发送至分发器 Dispatcher，再由分发器将请求派发到指定的线程池上，最后由线程池调用具体的服务。这就是一个远程调用请求的发送与接收过程。至于响应的发送与接收过程，这张图中没有表现出来。对于这两个过程，我们也会进行详细分析。\n\n2.1 服务调用方式Dubbo 支持同步和异步两种调用方式，其中异步调用还可细分为“有返回值”的异步调用和“无返回值”的异步调用。所谓“无返回值”异步调用是指服务消费方只管调用，但不关心调用结果，此时 Dubbo 会直接返回一个空的 RpcResult。若要使用异步特性，需要服务消费方手动进行配置。默认情况下，Dubbo 使用同步调用方式。\n本节以及其他章节将会使用 Dubbo 官方提供的 Demo 分析整个调用过程，下面我们从 DemoService 接口的代理类开始进行分析。Dubbo 默认使用 Javassist 框架为服务接口生成动态代理类，因此我们需要先将代理类进行反编译才能看到源码。这里使用阿里开源 Java 应用诊断工具 Arthas 反编译代理类，结果如下：\n/**\n * Arthas 反编译步骤：\n * 1. 启动 Arthas\n *    java -jar arthas-boot.jar\n *\n * 2. 输入编号选择进程\n *    Arthas 启动后，会打印 Java 应用进程列表，如下：\n *    [1]: 11232 org.jetbrains.jps.cmdline.Launcher\n *    [2]: 22370 org.jetbrains.jps.cmdline.Launcher\n *    [3]: 22371 com.alibaba.dubbo.demo.consumer.Consumer\n *    [4]: 22362 com.alibaba.dubbo.demo.provider.Provider\n *    [5]: 2074 org.apache.zookeeper.server.quorum.QuorumPeerMain\n * 这里输入编号 3，让 Arthas 关联到启动类为 com.....Consumer 的 Java 进程上\n *\n * 3. 由于 Demo 项目中只有一个服务接口，因此此接口的代理类类名为 proxy0，此时使用 sc 命令搜索这个类名。\n *    $ sc *.proxy0\n *    com.alibaba.dubbo.common.bytecode.proxy0\n *\n * 4. 使用 jad 命令反编译 com.alibaba.dubbo.common.bytecode.proxy0\n *    $ jad com.alibaba.dubbo.common.bytecode.proxy0\n *\n * 更多使用方法请参考 Arthas 官方文档：\n *   https://alibaba.github.io/arthas/quick-start.html\n */\npublic class proxy0 implements ClassGenerator.DC, EchoService, DemoService &#123;\n    // 方法数组\n    public static Method[] methods;\n    private InvocationHandler handler;\n\n    public proxy0(InvocationHandler invocationHandler) &#123;\n        this.handler = invocationHandler;\n    &#125;\n\n    public proxy0() &#123;\n    &#125;\n\n    public String sayHello(String string) &#123;\n        // 将参数存储到 Object 数组中\n        Object[] arrobject = new Object[]&#123;string&#125;;\n        // 调用 InvocationHandler 实现类的 invoke 方法得到调用结果\n        Object object = this.handler.invoke(this, methods[0], arrobject);\n        // 返回调用结果\n        return (String)object;\n    &#125;\n\n    /** 回声测试方法 */\n    public Object $echo(Object object) &#123;\n        Object[] arrobject = new Object[]&#123;object&#125;;\n        Object object2 = this.handler.invoke(this, methods[1], arrobject);\n        return object2;\n    &#125;\n&#125;\n\n如上，代理类的逻辑比较简单。首先将运行时参数存储到数组中，然后调用 InvocationHandler 接口实现类的 invoke 方法，得到调用结果，最后将结果转型并返回给调用方。关于代理类的逻辑就说这么多，继续向下分析。\npublic class InvokerInvocationHandler implements InvocationHandler &#123;\n\n    private final Invoker&lt;?> invoker;\n\n    public InvokerInvocationHandler(Invoker&lt;?> handler) &#123;\n        this.invoker = handler;\n    &#125;\n\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;\n        String methodName = method.getName();\n        Class&lt;?>[] parameterTypes = method.getParameterTypes();\n        \n        // 拦截定义在 Object 类中的方法（未被子类重写），比如 wait/notify\n        if (method.getDeclaringClass() == Object.class) &#123;\n            return method.invoke(invoker, args);\n        &#125;\n        \n        // 如果 toString、hashCode 和 equals 等方法被子类重写了，这里也直接调用\n        if (\"toString\".equals(methodName) &amp;&amp; parameterTypes.length == 0) &#123;\n            return invoker.toString();\n        &#125;\n        if (\"hashCode\".equals(methodName) &amp;&amp; parameterTypes.length == 0) &#123;\n            return invoker.hashCode();\n        &#125;\n        if (\"equals\".equals(methodName) &amp;&amp; parameterTypes.length == 1) &#123;\n            return invoker.equals(args[0]);\n        &#125;\n        \n        // 将 method 和 args 封装到 RpcInvocation 中，并执行后续的调用\n        return invoker.invoke(new RpcInvocation(method, args)).recreate();\n    &#125;\n&#125;\n\nInvokerInvocationHandler 中的 invoker 成员变量类型为 MockClusterInvoker，MockClusterInvoker 内部封装了服务降级逻辑。下面简单看一下：\npublic class MockClusterInvoker&lt;T> implements Invoker&lt;T> &#123;\n    \n    private final Invoker&lt;T> invoker;\n    \n    public Result invoke(Invocation invocation) throws RpcException &#123;\n        Result result = null;\n\n        // 获取 mock 配置值\n        String value = directory.getUrl().getMethodParameter(invocation.getMethodName(), Constants.MOCK_KEY, Boolean.FALSE.toString()).trim();\n        if (value.length() == 0 || value.equalsIgnoreCase(\"false\")) &#123;\n            // 无 mock 逻辑，直接调用其他 Invoker 对象的 invoke 方法，\n            // 比如 FailoverClusterInvoker\n            result = this.invoker.invoke(invocation);\n        &#125; else if (value.startsWith(\"force\")) &#123;\n            // force:xxx 直接执行 mock 逻辑，不发起远程调用\n            result = doMockInvoke(invocation, null);\n        &#125; else &#123;\n            // fail:xxx 表示消费方对调用服务失败后，再执行 mock 逻辑，不抛出异常\n            try &#123;\n                // 调用其他 Invoker 对象的 invoke 方法\n                result = this.invoker.invoke(invocation);\n            &#125; catch (RpcException e) &#123;\n                if (e.isBiz()) &#123;\n                    throw e;\n                &#125; else &#123;\n                    // 调用失败，执行 mock 逻辑\n                    result = doMockInvoke(invocation, e);\n                &#125;\n            &#125;\n        &#125;\n        return result;\n    &#125;\n    \n    // 省略其他方法\n&#125;\n\n服务降级不是本文重点，因此这里就不分析 doMockInvoke 方法了。考虑到前文已经详细分析过 FailoverClusterInvoker，因此本节略过 FailoverClusterInvoker，直接分析 DubboInvoker。\npublic abstract class AbstractInvoker&lt;T> implements Invoker&lt;T> &#123;\n    \n    public Result invoke(Invocation inv) throws RpcException &#123;\n        if (destroyed.get()) &#123;\n            throw new RpcException(\"Rpc invoker for service ...\");\n        &#125;\n        RpcInvocation invocation = (RpcInvocation) inv;\n        // 设置 Invoker\n        invocation.setInvoker(this);\n        if (attachment != null &amp;&amp; attachment.size() > 0) &#123;\n            // 设置 attachment\n            invocation.addAttachmentsIfAbsent(attachment);\n        &#125;\n        Map&lt;String, String> contextAttachments = RpcContext.getContext().getAttachments();\n        if (contextAttachments != null &amp;&amp; contextAttachments.size() != 0) &#123;\n            // 添加 contextAttachments 到 RpcInvocation#attachment 变量中\n            invocation.addAttachments(contextAttachments);\n        &#125;\n        if (getUrl().getMethodParameter(invocation.getMethodName(), Constants.ASYNC_KEY, false)) &#123;\n            // 设置异步信息到 RpcInvocation#attachment 中\n            invocation.setAttachment(Constants.ASYNC_KEY, Boolean.TRUE.toString());\n        &#125;\n        RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation);\n\n        try &#123;\n            // 抽象方法，由子类实现\n            return doInvoke(invocation);\n        &#125; catch (InvocationTargetException e) &#123;\n            // ...\n        &#125; catch (RpcException e) &#123;\n            // ...\n        &#125; catch (Throwable e) &#123;\n            return new RpcResult(e);\n        &#125;\n    &#125;\n\n    protected abstract Result doInvoke(Invocation invocation) throws Throwable;\n    \n    // 省略其他方法\n&#125;\n\n上面的代码来自 AbstractInvoker 类，其中大部分代码用于添加信息到 RpcInvocation#attachment 变量中，添加完毕后，调用 doInvoke 执行后续的调用。doInvoke 是一个抽象方法，需要由子类实现，下面到 DubboInvoker 中看一下。\npublic class DubboInvoker&lt;T> extends AbstractInvoker&lt;T> &#123;\n    \n    private final ExchangeClient[] clients;\n    \n    protected Result doInvoke(final Invocation invocation) throws Throwable &#123;\n        RpcInvocation inv = (RpcInvocation) invocation;\n        final String methodName = RpcUtils.getMethodName(invocation);\n        // 设置 path 和 version 到 attachment 中\n        inv.setAttachment(Constants.PATH_KEY, getUrl().getPath());\n        inv.setAttachment(Constants.VERSION_KEY, version);\n\n        ExchangeClient currentClient;\n        if (clients.length == 1) &#123;\n            // 从 clients 数组中获取 ExchangeClient\n            currentClient = clients[0];\n        &#125; else &#123;\n            currentClient = clients[index.getAndIncrement() % clients.length];\n        &#125;\n        try &#123;\n            // 获取异步配置\n            boolean isAsync = RpcUtils.isAsync(getUrl(), invocation);\n            // isOneway 为 true，表示“单向”通信\n            boolean isOneway = RpcUtils.isOneway(getUrl(), invocation);\n            int timeout = getUrl().getMethodParameter(methodName, Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT);\n\n            // 异步无返回值\n            if (isOneway) &#123;\n                boolean isSent = getUrl().getMethodParameter(methodName, Constants.SENT_KEY, false);\n                // 发送请求\n                currentClient.send(inv, isSent);\n                // 设置上下文中的 future 字段为 null\n                RpcContext.getContext().setFuture(null);\n                // 返回一个空的 RpcResult\n                return new RpcResult();\n            &#125; \n\n            // 异步有返回值\n            else if (isAsync) &#123;\n                // 发送请求，并得到一个 ResponseFuture 实例\n                ResponseFuture future = currentClient.request(inv, timeout);\n                // 设置 future 到上下文中\n                RpcContext.getContext().setFuture(new FutureAdapter&lt;Object>(future));\n                // 暂时返回一个空结果\n                return new RpcResult();\n            &#125; \n\n            // 同步调用\n            else &#123;\n                RpcContext.getContext().setFuture(null);\n                // 发送请求，得到一个 ResponseFuture 实例，并调用该实例的 get 方法进行等待\n                return (Result) currentClient.request(inv, timeout).get();\n            &#125;\n        &#125; catch (TimeoutException e) &#123;\n            throw new RpcException(..., \"Invoke remote method timeout....\");\n        &#125; catch (RemotingException e) &#123;\n            throw new RpcException(..., \"Failed to invoke remote method: ...\");\n        &#125;\n    &#125;\n    \n    // 省略其他方法\n&#125;\n\n上面的代码包含了 Dubbo 对同步和异步调用的处理逻辑，搞懂了上面的代码，会对 Dubbo 的同步和异步调用方式有更深入的了解。Dubbo 实现同步和异步调用比较关键的一点就在于由谁调用 ResponseFuture 的 get 方法。同步调用模式下，由框架自身调用 ResponseFuture 的 get 方法。异步调用模式下，则由用户调用该方法。ResponseFuture 是一个接口，下面我们来看一下它的默认实现类 DefaultFuture 的源码。\npublic class DefaultFuture implements ResponseFuture &#123;\n    \n    private static final Map&lt;Long, Channel> CHANNELS = \n        new ConcurrentHashMap&lt;Long, Channel>();\n\n    private static final Map&lt;Long, DefaultFuture> FUTURES = \n        new ConcurrentHashMap&lt;Long, DefaultFuture>();\n    \n    private final long id;\n    private final Channel channel;\n    private final Request request;\n    private final int timeout;\n    private final Lock lock = new ReentrantLock();\n    private final Condition done = lock.newCondition();\n    private volatile Response response;\n    \n    public DefaultFuture(Channel channel, Request request, int timeout) &#123;\n        this.channel = channel;\n        this.request = request;\n        \n        // 获取请求 id，这个 id 很重要，后面还会见到\n        this.id = request.getId();\n        this.timeout = timeout > 0 ? timeout : channel.getUrl().getPositiveParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT);\n        // 存储 &lt;requestId, DefaultFuture> 映射关系到 FUTURES 中\n        FUTURES.put(id, this);\n        CHANNELS.put(id, channel);\n    &#125;\n    \n    @Override\n    public Object get() throws RemotingException &#123;\n        return get(timeout);\n    &#125;\n\n    @Override\n    public Object get(int timeout) throws RemotingException &#123;\n        if (timeout &lt;= 0) &#123;\n            timeout = Constants.DEFAULT_TIMEOUT;\n        &#125;\n        \n        // 检测服务提供方是否成功返回了调用结果\n        if (!isDone()) &#123;\n            long start = System.currentTimeMillis();\n            lock.lock();\n            try &#123;\n                // 循环检测服务提供方是否成功返回了调用结果\n                while (!isDone()) &#123;\n                    // 如果调用结果尚未返回，这里等待一段时间\n                    done.await(timeout, TimeUnit.MILLISECONDS);\n                    // 如果调用结果成功返回，或等待超时，此时跳出 while 循环，执行后续的逻辑\n                    if (isDone() || System.currentTimeMillis() - start > timeout) &#123;\n                        break;\n                    &#125;\n                &#125;\n            &#125; catch (InterruptedException e) &#123;\n                throw new RuntimeException(e);\n            &#125; finally &#123;\n                lock.unlock();\n            &#125;\n            \n            // 如果调用结果仍未返回，则抛出超时异常\n            if (!isDone()) &#123;\n                throw new TimeoutException(sent > 0, channel, getTimeoutMessage(false));\n            &#125;\n        &#125;\n        \n        // 返回调用结果\n        return returnFromResponse();\n    &#125;\n    \n    @Override\n    public boolean isDone() &#123;\n        // 通过检测 response 字段为空与否，判断是否收到了调用结果\n        return response != null;\n    &#125;\n    \n    private Object returnFromResponse() throws RemotingException &#123;\n        Response res = response;\n        if (res == null) &#123;\n            throw new IllegalStateException(\"response cannot be null\");\n        &#125;\n        \n        // 如果调用结果的状态为 Response.OK，则表示调用过程正常，服务提供方成功返回了调用结果\n        if (res.getStatus() == Response.OK) &#123;\n            return res.getResult();\n        &#125;\n        \n        // 抛出异常\n        if (res.getStatus() == Response.CLIENT_TIMEOUT || res.getStatus() == Response.SERVER_TIMEOUT) &#123;\n            throw new TimeoutException(res.getStatus() == Response.SERVER_TIMEOUT, channel, res.getErrorMessage());\n        &#125;\n        throw new RemotingException(channel, res.getErrorMessage());\n    &#125;\n    \n    // 省略其他方法\n&#125;\n\n如上，当服务消费者还未接收到调用结果时，用户线程调用 get 方法会被阻塞住。同步调用模式下，框架获得 DefaultFuture 对象后，会立即调用 get 方法进行等待。而异步模式下则是将该对象封装到 FutureAdapter 实例中，并将 FutureAdapter 实例设置到 RpcContext 中，供用户使用。FutureAdapter 是一个适配器，用于将 Dubbo 中的 ResponseFuture 与 JDK 中的 Future 进行适配。这样当用户线程调用 Future 的 get 方法时，经过 FutureAdapter 适配，最终会调用 ResponseFuture 实现类对象的 get 方法，也就是 DefaultFuture 的 get 方法。\n到这里关于 Dubbo 几种调用方式的代码逻辑就分析完了，下面来分析请求数据的发送与接收，以及响应数据的发送与接收过程。\n\n2.2 服务消费方发送请求\n2.2.1 发送请求本节我们来看一下同步调用模式下，服务消费方是如何发送调用请求的。在深入分析源码前，我们先来看一张图。\n\n这张图展示了服务消费方发送请求过程的部分调用栈，略为复杂。从上图可以看出，经过多次调用后，才将请求数据送至 Netty NioClientSocketChannel。这样做的原因是通过 Exchange 层为框架引入 Request 和 Response 语义，这一点会在接下来的源码分析过程中会看到。其他的就不多说了，下面开始进行分析。首先分析 ReferenceCountExchangeClient 的源码。\nfinal class ReferenceCountExchangeClient implements ExchangeClient &#123;\n\n    private final URL url;\n    private final AtomicInteger referenceCount = new AtomicInteger(0);\n\n    public ReferenceCountExchangeClient(ExchangeClient client, ConcurrentMap&lt;String, LazyConnectExchangeClient> ghostClientMap) &#123;\n        this.client = client;\n        // 引用计数自增\n        referenceCount.incrementAndGet();\n        this.url = client.getUrl();\n        \n        // ...\n    &#125;\n\n    @Override\n    public ResponseFuture request(Object request) throws RemotingException &#123;\n        // 直接调用被装饰对象的同签名方法\n        return client.request(request);\n    &#125;\n\n    @Override\n    public ResponseFuture request(Object request, int timeout) throws RemotingException &#123;\n        // 直接调用被装饰对象的同签名方法\n        return client.request(request, timeout);\n    &#125;\n\n    /** 引用计数自增，该方法由外部调用 */\n    public void incrementAndGetCount() &#123;\n        // referenceCount 自增\n        referenceCount.incrementAndGet();\n    &#125;\n    \n        @Override\n    public void close(int timeout) &#123;\n        // referenceCount 自减\n        if (referenceCount.decrementAndGet() &lt;= 0) &#123;\n            if (timeout == 0) &#123;\n                client.close();\n            &#125; else &#123;\n                client.close(timeout);\n            &#125;\n            client = replaceWithLazyClient();\n        &#125;\n    &#125;\n    \n    // 省略部分方法\n&#125;\n\nReferenceCountExchangeClient 内部定义了一个引用计数变量 referenceCount，每当该对象被引用一次 referenceCount 都会进行自增。每当 close 方法被调用时，referenceCount 进行自减。ReferenceCountExchangeClient 内部仅实现了一个引用计数的功能，其他方法并无复杂逻辑，均是直接调用被装饰对象的相关方法。所以这里就不多说了，继续向下分析，这次是 HeaderExchangeClient。\npublic class HeaderExchangeClient implements ExchangeClient &#123;\n\n    private static final ScheduledThreadPoolExecutor scheduled = new ScheduledThreadPoolExecutor(2, new NamedThreadFactory(\"dubbo-remoting-client-heartbeat\", true));\n    private final Client client;\n    private final ExchangeChannel channel;\n    private ScheduledFuture&lt;?> heartbeatTimer;\n    private int heartbeat;\n    private int heartbeatTimeout;\n\n    public HeaderExchangeClient(Client client, boolean needHeartbeat) &#123;\n        if (client == null) &#123;\n            throw new IllegalArgumentException(\"client == null\");\n        &#125;\n        this.client = client;\n        \n        // 创建 HeaderExchangeChannel 对象\n        this.channel = new HeaderExchangeChannel(client);\n        \n        // 以下代码均与心跳检测逻辑有关\n        String dubbo = client.getUrl().getParameter(Constants.DUBBO_VERSION_KEY);\n        this.heartbeat = client.getUrl().getParameter(Constants.HEARTBEAT_KEY, dubbo != null &amp;&amp; dubbo.startsWith(\"1.0.\") ? Constants.DEFAULT_HEARTBEAT : 0);\n        this.heartbeatTimeout = client.getUrl().getParameter(Constants.HEARTBEAT_TIMEOUT_KEY, heartbeat * 3);\n        if (heartbeatTimeout &lt; heartbeat * 2) &#123;\n            throw new IllegalStateException(\"heartbeatTimeout &lt; heartbeatInterval * 2\");\n        &#125;\n        if (needHeartbeat) &#123;\n            // 开启心跳检测定时器\n            startHeartbeatTimer();\n        &#125;\n    &#125;\n\n    @Override\n    public ResponseFuture request(Object request) throws RemotingException &#123;\n        // 直接 HeaderExchangeChannel 对象的同签名方法\n        return channel.request(request);\n    &#125;\n\n    @Override\n    public ResponseFuture request(Object request, int timeout) throws RemotingException &#123;\n        // 直接 HeaderExchangeChannel 对象的同签名方法\n        return channel.request(request, timeout);\n    &#125;\n\n    @Override\n    public void close() &#123;\n        doClose();\n        channel.close();\n    &#125;\n    \n    private void doClose() &#123;\n        // 停止心跳检测定时器\n        stopHeartbeatTimer();\n    &#125;\n\n    private void startHeartbeatTimer() &#123;\n        stopHeartbeatTimer();\n        if (heartbeat > 0) &#123;\n            heartbeatTimer = scheduled.scheduleWithFixedDelay(\n                    new HeartBeatTask(new HeartBeatTask.ChannelProvider() &#123;\n                        @Override\n                        public Collection&lt;Channel> getChannels() &#123;\n                            return Collections.&lt;Channel>singletonList(HeaderExchangeClient.this);\n                        &#125;\n                    &#125;, heartbeat, heartbeatTimeout),\n                    heartbeat, heartbeat, TimeUnit.MILLISECONDS);\n        &#125;\n    &#125;\n\n    private void stopHeartbeatTimer() &#123;\n        if (heartbeatTimer != null &amp;&amp; !heartbeatTimer.isCancelled()) &#123;\n            try &#123;\n                heartbeatTimer.cancel(true);\n                scheduled.purge();\n            &#125; catch (Throwable e) &#123;\n                if (logger.isWarnEnabled()) &#123;\n                    logger.warn(e.getMessage(), e);\n                &#125;\n            &#125;\n        &#125;\n        heartbeatTimer = null;\n    &#125;\n    \n    // 省略部分方法\n&#125;\n\nHeaderExchangeClient 中很多方法只有一行代码，即调用 HeaderExchangeChannel 对象的同签名方法。那 HeaderExchangeClient 有什么用处呢？答案是封装了一些关于心跳检测的逻辑。心跳检测并非本文所关注的点，因此就不多说了，继续向下看。\nfinal class HeaderExchangeChannel implements ExchangeChannel &#123;\n    \n    private final Channel channel;\n    \n    HeaderExchangeChannel(Channel channel) &#123;\n        if (channel == null) &#123;\n            throw new IllegalArgumentException(\"channel == null\");\n        &#125;\n        \n        // 这里的 channel 指向的是 NettyClient\n        this.channel = channel;\n    &#125;\n    \n    @Override\n    public ResponseFuture request(Object request) throws RemotingException &#123;\n        return request(request, channel.getUrl().getPositiveParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT));\n    &#125;\n\n    @Override\n    public ResponseFuture request(Object request, int timeout) throws RemotingException &#123;\n        if (closed) &#123;\n            throw new RemotingException(..., \"Failed to send request ...);\n        &#125;\n        // 创建 Request 对象\n        Request req = new Request();\n        req.setVersion(Version.getProtocolVersion());\n        // 设置双向通信标志为 true\n        req.setTwoWay(true);\n        // 这里的 request 变量类型为 RpcInvocation\n        req.setData(request);\n                                        \n        // 创建 DefaultFuture 对象\n        DefaultFuture future = new DefaultFuture(channel, req, timeout);\n        try &#123;\n            // 调用 NettyClient 的 send 方法发送请求\n            channel.send(req);\n        &#125; catch (RemotingException e) &#123;\n            future.cancel();\n            throw e;\n        &#125;\n        // 返回 DefaultFuture 对象\n        return future;\n    &#125;\n&#125;\n\n到这里大家终于看到了 Request 语义了，上面的方法首先定义了一个 Request 对象，然后再将该对象传给 NettyClient 的 send 方法，进行后续的调用。需要说明的是，NettyClient 中并未实现 send 方法，该方法继承自父类 AbstractPeer，下面直接分析 AbstractPeer 的代码。\npublic abstract class AbstractPeer implements Endpoint, ChannelHandler &#123;\n    \n    @Override\n    public void send(Object message) throws RemotingException &#123;\n        // 该方法由 AbstractClient 类实现\n        send(message, url.getParameter(Constants.SENT_KEY, false));\n    &#125;\n    \n    // 省略其他方法\n&#125;\n\npublic abstract class AbstractClient extends AbstractEndpoint implements Client &#123;\n    \n    @Override\n    public void send(Object message, boolean sent) throws RemotingException &#123;\n        if (send_reconnect &amp;&amp; !isConnected()) &#123;\n            connect();\n        &#125;\n        \n        // 获取 Channel，getChannel 是一个抽象方法，具体由子类实现\n        Channel channel = getChannel();\n        if (channel == null || !channel.isConnected()) &#123;\n            throw new RemotingException(this, \"message can not send ...\");\n        &#125;\n        \n        // 继续向下调用\n        channel.send(message, sent);\n    &#125;\n    \n    protected abstract Channel getChannel();\n    \n    // 省略其他方法\n&#125;\n\n默认情况下，Dubbo 使用 Netty 作为底层的通信框架，因此下面我们到 NettyClient 类中看一下 getChannel 方法的实现逻辑。\npublic class NettyClient extends AbstractClient &#123;\n    \n    // 这里的 Channel 全限定名称为 org.jboss.netty.channel.Channel\n    private volatile Channel channel;\n\n    @Override\n    protected com.alibaba.dubbo.remoting.Channel getChannel() &#123;\n        Channel c = channel;\n        if (c == null || !c.isConnected())\n            return null;\n        // 获取一个 NettyChannel 类型对象\n        return NettyChannel.getOrAddChannel(c, getUrl(), this);\n    &#125;\n&#125;\n\nfinal class NettyChannel extends AbstractChannel &#123;\n\n    private static final ConcurrentMap&lt;org.jboss.netty.channel.Channel, NettyChannel> channelMap = \n        new ConcurrentHashMap&lt;org.jboss.netty.channel.Channel, NettyChannel>();\n\n    private final org.jboss.netty.channel.Channel channel;\n    \n    /** 私有构造方法 */\n    private NettyChannel(org.jboss.netty.channel.Channel channel, URL url, ChannelHandler handler) &#123;\n        super(url, handler);\n        if (channel == null) &#123;\n            throw new IllegalArgumentException(\"netty channel == null;\");\n        &#125;\n        this.channel = channel;\n    &#125;\n\n    static NettyChannel getOrAddChannel(org.jboss.netty.channel.Channel ch, URL url, ChannelHandler handler) &#123;\n        if (ch == null) &#123;\n            return null;\n        &#125;\n        \n        // 尝试从集合中获取 NettyChannel 实例\n        NettyChannel ret = channelMap.get(ch);\n        if (ret == null) &#123;\n            // 如果 ret = null，则创建一个新的 NettyChannel 实例\n            NettyChannel nc = new NettyChannel(ch, url, handler);\n            if (ch.isConnected()) &#123;\n                // 将 &lt;Channel, NettyChannel> 键值对存入 channelMap 集合中\n                ret = channelMap.putIfAbsent(ch, nc);\n            &#125;\n            if (ret == null) &#123;\n                ret = nc;\n            &#125;\n        &#125;\n        return ret;\n    &#125;\n&#125;\n\n获取到 NettyChannel 实例后，即可进行后续的调用。下面看一下 NettyChannel 的 send 方法。\npublic void send(Object message, boolean sent) throws RemotingException &#123;\n    super.send(message, sent);\n\n    boolean success = true;\n    int timeout = 0;\n    try &#123;\n        // 发送消息(包含请求和响应消息)\n        ChannelFuture future = channel.write(message);\n        \n        // sent 的值源于 &lt;dubbo:method sent=\"true/false\" /> 中 sent 的配置值，有两种配置值：\n        //   1. true: 等待消息发出，消息发送失败将抛出异常\n        //   2. false: 不等待消息发出，将消息放入 IO 队列，即刻返回\n        // 默认情况下 sent = false；\n        if (sent) &#123;\n            timeout = getUrl().getPositiveParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT);\n            // 等待消息发出，若在规定时间没能发出，success 会被置为 false\n            success = future.await(timeout);\n        &#125;\n        Throwable cause = future.getCause();\n        if (cause != null) &#123;\n            throw cause;\n        &#125;\n    &#125; catch (Throwable e) &#123;\n        throw new RemotingException(this, \"Failed to send message ...\");\n    &#125;\n\n    // 若 success 为 false，这里抛出异常\n    if (!success) &#123;\n        throw new RemotingException(this, \"Failed to send message ...\");\n    &#125;\n&#125;\n\n经历多次调用，到这里请求数据的发送过程就结束了，过程漫长。为了便于大家阅读代码，这里以 DemoService 为例，将 sayHello 方法的整个调用路径贴出来。\nproxy0#sayHello(String)\n  —&gt; InvokerInvocationHandler#invoke(Object, Method, Object[])\n    —&gt; MockClusterInvoker#invoke(Invocation)\n      —&gt; AbstractClusterInvoker#invoke(Invocation)\n        —&gt; FailoverClusterInvoker#doInvoke(Invocation, List&lt;Invoker&lt;T&gt;&gt;, LoadBalance)\n          —&gt; Filter#invoke(Invoker, Invocation)  &#x2F;&#x2F; 包含多个 Filter 调用\n            —&gt; ListenerInvokerWrapper#invoke(Invocation) \n              —&gt; AbstractInvoker#invoke(Invocation) \n                —&gt; DubboInvoker#doInvoke(Invocation)\n                  —&gt; ReferenceCountExchangeClient#request(Object, int)\n                    —&gt; HeaderExchangeClient#request(Object, int)\n                      —&gt; HeaderExchangeChannel#request(Object, int)\n                        —&gt; AbstractPeer#send(Object)\n                          —&gt; AbstractClient#send(Object, boolean)\n                            —&gt; NettyChannel#send(Object, boolean)\n                              —&gt; NioClientSocketChannel#write(Object)\n\n在 Netty 中，出站数据在发出之前还需要进行编码操作，接下来我们来分析一下请求数据的编码逻辑。\n\n2.2.2 请求编码在分析请求编码逻辑之前，我们先来看一下 Dubbo 数据包结构。\n\nDubbo 数据包分为消息头和消息体，消息头用于存储一些元信息，比如魔数（Magic），数据包类型（Request&#x2F;Response），消息体长度（Data Length）等。消息体中用于存储具体的调用消息，比如方法名称，参数列表等。下面简单列举一下消息头的内容。\n\n\n\n偏移量(Bit)\n字段\n取值\n\n\n\n0 ~ 7\n魔数高位\n0xda00\n\n\n8 ~ 15\n魔数低位\n0xbb\n\n\n16\n数据包类型\n0 - Response, 1 - Request\n\n\n17\n调用方式\n仅在第16位被设为1的情况下有效，0 - 单向调用，1 - 双向调用\n\n\n18\n事件标识\n0 - 当前数据包是请求或响应包，1 - 当前数据包是心跳包\n\n\n19 ~ 23\n序列化器编号\n2 - Hessian2Serialization 3 - JavaSerialization 4 - CompactedJavaSerialization 6 - FastJsonSerialization 7 - NativeJavaSerialization 8 - KryoSerialization 9 - FstSerialization\n\n\n24 ~ 31\n状态\n20 - OK 30 - CLIENT_TIMEOUT 31 - SERVER_TIMEOUT 40 - BAD_REQUEST 50 - BAD_RESPONSE ……\n\n\n32 ~ 95\n请求编号\n共8字节，运行时生成\n\n\n96 ~ 127\n消息体长度\n运行时计算\n\n\n了解了 Dubbo 数据包格式，接下来我们就可以探索编码过程了。这次我们开门见山，直接分析编码逻辑所在类。如下：\npublic class ExchangeCodec extends TelnetCodec &#123;\n\n    // 消息头长度\n    protected static final int HEADER_LENGTH = 16;\n    // 魔数内容\n    protected static final short MAGIC = (short) 0xdabb;\n    protected static final byte MAGIC_HIGH = Bytes.short2bytes(MAGIC)[0];\n    protected static final byte MAGIC_LOW = Bytes.short2bytes(MAGIC)[1];\n    protected static final byte FLAG_REQUEST = (byte) 0x80;\n    protected static final byte FLAG_TWOWAY = (byte) 0x40;\n    protected static final byte FLAG_EVENT = (byte) 0x20;\n    protected static final int SERIALIZATION_MASK = 0x1f;\n    private static final Logger logger = LoggerFactory.getLogger(ExchangeCodec.class);\n\n    public Short getMagicCode() &#123;\n        return MAGIC;\n    &#125;\n\n    @Override\n    public void encode(Channel channel, ChannelBuffer buffer, Object msg) throws IOException &#123;\n        if (msg instanceof Request) &#123;\n            // 对 Request 对象进行编码\n            encodeRequest(channel, buffer, (Request) msg);\n        &#125; else if (msg instanceof Response) &#123;\n            // 对 Response 对象进行编码，后面分析\n            encodeResponse(channel, buffer, (Response) msg);\n        &#125; else &#123;\n            super.encode(channel, buffer, msg);\n        &#125;\n    &#125;\n\n    protected void encodeRequest(Channel channel, ChannelBuffer buffer, Request req) throws IOException &#123;\n        Serialization serialization = getSerialization(channel);\n\n        // 创建消息头字节数组，长度为 16\n        byte[] header = new byte[HEADER_LENGTH];\n\n        // 设置魔数\n        Bytes.short2bytes(MAGIC, header);\n\n        // 设置数据包类型（Request/Response）和序列化器编号\n        header[2] = (byte) (FLAG_REQUEST | serialization.getContentTypeId());\n\n        // 设置通信方式(单向/双向)\n        if (req.isTwoWay()) &#123;\n            header[2] |= FLAG_TWOWAY;\n        &#125;\n        \n        // 设置事件标识\n        if (req.isEvent()) &#123;\n            header[2] |= FLAG_EVENT;\n        &#125;\n\n        // 设置请求编号，8个字节，从第4个字节开始设置\n        Bytes.long2bytes(req.getId(), header, 4);\n\n        // 获取 buffer 当前的写位置\n        int savedWriteIndex = buffer.writerIndex();\n        // 更新 writerIndex，为消息头预留 16 个字节的空间\n        buffer.writerIndex(savedWriteIndex + HEADER_LENGTH);\n        ChannelBufferOutputStream bos = new ChannelBufferOutputStream(buffer);\n        // 创建序列化器，比如 Hessian2ObjectOutput\n        ObjectOutput out = serialization.serialize(channel.getUrl(), bos);\n        if (req.isEvent()) &#123;\n            // 对事件数据进行序列化操作\n            encodeEventData(channel, out, req.getData());\n        &#125; else &#123;\n            // 对请求数据进行序列化操作\n            encodeRequestData(channel, out, req.getData(), req.getVersion());\n        &#125;\n        out.flushBuffer();\n        if (out instanceof Cleanable) &#123;\n            ((Cleanable) out).cleanup();\n        &#125;\n        bos.flush();\n        bos.close();\n        \n        // 获取写入的字节数，也就是消息体长度\n        int len = bos.writtenBytes();\n        checkPayload(channel, len);\n\n        // 将消息体长度写入到消息头中\n        Bytes.int2bytes(len, header, 12);\n\n        // 将 buffer 指针移动到 savedWriteIndex，为写消息头做准备\n        buffer.writerIndex(savedWriteIndex);\n        // 从 savedWriteIndex 下标处写入消息头\n        buffer.writeBytes(header);\n        // 设置新的 writerIndex，writerIndex = 原写下标 + 消息头长度 + 消息体长度\n        buffer.writerIndex(savedWriteIndex + HEADER_LENGTH + len);\n    &#125;\n    \n    // 省略其他方法\n&#125;\n\n以上就是请求对象的编码过程，该过程首先会通过位运算将消息头写入到 header 数组中。然后对 Request 对象的 data 字段执行序列化操作，序列化后的数据最终会存储到 ChannelBuffer 中。序列化操作执行完后，可得到数据序列化后的长度 len，紧接着将 len 写入到 header 指定位置处。最后再将消息头字节数组 header 写入到 ChannelBuffer 中，整个编码过程就结束了。本节的最后，我们再来看一下 Request 对象的 data 字段序列化过程，也就是 encodeRequestData 方法的逻辑，如下：\npublic class DubboCodec extends ExchangeCodec implements Codec2 &#123;\n    \n\tprotected void encodeRequestData(Channel channel, ObjectOutput out, Object data, String version) throws IOException &#123;\n        RpcInvocation inv = (RpcInvocation) data;\n\n        // 依次序列化 dubbo version、path、version\n        out.writeUTF(version);\n        out.writeUTF(inv.getAttachment(Constants.PATH_KEY));\n        out.writeUTF(inv.getAttachment(Constants.VERSION_KEY));\n\n        // 序列化调用方法名\n        out.writeUTF(inv.getMethodName());\n        // 将参数类型转换为字符串，并进行序列化\n        out.writeUTF(ReflectUtils.getDesc(inv.getParameterTypes()));\n        Object[] args = inv.getArguments();\n        if (args != null)\n            for (int i = 0; i &lt; args.length; i++) &#123;\n                // 对运行时参数进行序列化\n                out.writeObject(encodeInvocationArgument(channel, inv, i));\n            &#125;\n        \n        // 序列化 attachments\n        out.writeObject(inv.getAttachments());\n    &#125;\n&#125;\n\n至此，关于服务消费方发送请求的过程就分析完了，接下来我们来看一下服务提供方是如何接收请求的。\n\n2.3 服务提供方接收请求前面说过，默认情况下 Dubbo 使用 Netty 作为底层的通信框架。Netty 检测到有数据入站后，首先会通过解码器对数据进行解码，并将解码后的数据传递给下一个入站处理器的指定方法。所以在进行后续的分析之前，我们先来看一下数据解码过程。\n\n2.3.1 请求解码这里直接分析请求数据的解码逻辑，忽略中间过程，如下：\npublic class ExchangeCodec extends TelnetCodec &#123;\n    \n    @Override\n    public Object decode(Channel channel, ChannelBuffer buffer) throws IOException &#123;\n        int readable = buffer.readableBytes();\n        // 创建消息头字节数组\n        byte[] header = new byte[Math.min(readable, HEADER_LENGTH)];\n        // 读取消息头数据\n        buffer.readBytes(header);\n        // 调用重载方法进行后续解码工作\n        return decode(channel, buffer, readable, header);\n    &#125;\n\n    @Override\n    protected Object decode(Channel channel, ChannelBuffer buffer, int readable, byte[] header) throws IOException &#123;\n        // 检查魔数是否相等\n        if (readable > 0 &amp;&amp; header[0] != MAGIC_HIGH\n                || readable > 1 &amp;&amp; header[1] != MAGIC_LOW) &#123;\n            int length = header.length;\n            if (header.length &lt; readable) &#123;\n                header = Bytes.copyOf(header, readable);\n                buffer.readBytes(header, length, readable - length);\n            &#125;\n            for (int i = 1; i &lt; header.length - 1; i++) &#123;\n                if (header[i] == MAGIC_HIGH &amp;&amp; header[i + 1] == MAGIC_LOW) &#123;\n                    buffer.readerIndex(buffer.readerIndex() - header.length + i);\n                    header = Bytes.copyOf(header, i);\n                    break;\n                &#125;\n            &#125;\n            // 通过 telnet 命令行发送的数据包不包含消息头，所以这里\n            // 调用 TelnetCodec 的 decode 方法对数据包进行解码\n            return super.decode(channel, buffer, readable, header);\n        &#125;\n        \n        // 检测可读数据量是否少于消息头长度，若小于则立即返回 DecodeResult.NEED_MORE_INPUT\n        if (readable &lt; HEADER_LENGTH) &#123;\n            return DecodeResult.NEED_MORE_INPUT;\n        &#125;\n\n        // 从消息头中获取消息体长度\n        int len = Bytes.bytes2int(header, 12);\n        // 检测消息体长度是否超出限制，超出则抛出异常\n        checkPayload(channel, len);\n\n        int tt = len + HEADER_LENGTH;\n        // 检测可读的字节数是否小于实际的字节数\n        if (readable &lt; tt) &#123;\n            return DecodeResult.NEED_MORE_INPUT;\n        &#125;\n        \n        ChannelBufferInputStream is = new ChannelBufferInputStream(buffer, len);\n\n        try &#123;\n            // 继续进行解码工作\n            return decodeBody(channel, is, header);\n        &#125; finally &#123;\n            if (is.available() > 0) &#123;\n                try &#123;\n                    StreamUtils.skipUnusedStream(is);\n                &#125; catch (IOException e) &#123;\n                    logger.warn(e.getMessage(), e);\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n上面方法通过检测消息头中的魔数是否与规定的魔数相等，提前拦截掉非常规数据包，比如通过 telnet 命令行发出的数据包。接着再对消息体长度，以及可读字节数进行检测。最后调用 decodeBody 方法进行后续的解码工作，ExchangeCodec 中实现了 decodeBody 方法，但因其子类 DubboCodec 覆写了该方法，所以在运行时 DubboCodec 中的 decodeBody 方法会被调用。下面我们来看一下该方法的代码。\npublic class DubboCodec extends ExchangeCodec implements Codec2 &#123;\n\n    @Override\n    protected Object decodeBody(Channel channel, InputStream is, byte[] header) throws IOException &#123;\n        // 获取消息头中的第三个字节，并通过逻辑与运算得到序列化器编号\n        byte flag = header[2], proto = (byte) (flag &amp; SERIALIZATION_MASK);\n        Serialization s = CodecSupport.getSerialization(channel.getUrl(), proto);\n        // 获取调用编号\n        long id = Bytes.bytes2long(header, 4);\n        // 通过逻辑与运算得到调用类型，0 - Response，1 - Request\n        if ((flag &amp; FLAG_REQUEST) == 0) &#123;\n            // 对响应结果进行解码，得到 Response 对象。这个非本节内容，后面再分析\n            // ...\n        &#125; else &#123;\n            // 创建 Request 对象\n            Request req = new Request(id);\n            req.setVersion(Version.getProtocolVersion());\n            // 通过逻辑与运算得到通信方式，并设置到 Request 对象中\n            req.setTwoWay((flag &amp; FLAG_TWOWAY) != 0);\n            \n            // 通过位运算检测数据包是否为事件类型\n            if ((flag &amp; FLAG_EVENT) != 0) &#123;\n                // 设置心跳事件到 Request 对象中\n                req.setEvent(Request.HEARTBEAT_EVENT);\n            &#125;\n            try &#123;\n                Object data;\n                if (req.isHeartbeat()) &#123;\n                    // 对心跳包进行解码，该方法已被标注为废弃\n                    data = decodeHeartbeatData(channel, deserialize(s, channel.getUrl(), is));\n                &#125; else if (req.isEvent()) &#123;\n                    // 对事件数据进行解码\n                    data = decodeEventData(channel, deserialize(s, channel.getUrl(), is));\n                &#125; else &#123;\n                    DecodeableRpcInvocation inv;\n                    // 根据 url 参数判断是否在 IO 线程上对消息体进行解码\n                    if (channel.getUrl().getParameter(\n                            Constants.DECODE_IN_IO_THREAD_KEY,\n                            Constants.DEFAULT_DECODE_IN_IO_THREAD)) &#123;\n                        inv = new DecodeableRpcInvocation(channel, req, is, proto);\n                        // 在当前线程，也就是 IO 线程上进行后续的解码工作。此工作完成后，可将\n                        // 调用方法名、attachment、以及调用参数解析出来\n                        inv.decode();\n                    &#125; else &#123;\n                        // 仅创建 DecodeableRpcInvocation 对象，但不在当前线程上执行解码逻辑\n                        inv = new DecodeableRpcInvocation(channel, req,\n                                new UnsafeByteArrayInputStream(readMessageData(is)), proto);\n                    &#125;\n                    data = inv;\n                &#125;\n                \n                // 设置 data 到 Request 对象中\n                req.setData(data);\n            &#125; catch (Throwable t) &#123;\n                // 若解码过程中出现异常，则将 broken 字段设为 true，\n                // 并将异常对象设置到 Reqeust 对象中\n                req.setBroken(true);\n                req.setData(t);\n            &#125;\n            return req;\n        &#125;\n    &#125;\n&#125;\n\n如上，decodeBody 对部分字段进行了解码，并将解码得到的字段封装到 Request 中。随后会调用 DecodeableRpcInvocation 的 decode 方法进行后续的解码工作。此工作完成后，可将调用方法名、attachment、以及调用参数解析出来。下面我们来看一下 DecodeableRpcInvocation 的 decode 方法逻辑。\npublic class DecodeableRpcInvocation extends RpcInvocation implements Codec, Decodeable &#123;\n    \n\t@Override\n    public Object decode(Channel channel, InputStream input) throws IOException &#123;\n        ObjectInput in = CodecSupport.getSerialization(channel.getUrl(), serializationType)\n                .deserialize(channel.getUrl(), input);\n\n        // 通过反序列化得到 dubbo version，并保存到 attachments 变量中\n        String dubboVersion = in.readUTF();\n        request.setVersion(dubboVersion);\n        setAttachment(Constants.DUBBO_VERSION_KEY, dubboVersion);\n\n        // 通过反序列化得到 path，version，并保存到 attachments 变量中\n        setAttachment(Constants.PATH_KEY, in.readUTF());\n        setAttachment(Constants.VERSION_KEY, in.readUTF());\n\n        // 通过反序列化得到调用方法名\n        setMethodName(in.readUTF());\n        try &#123;\n            Object[] args;\n            Class&lt;?>[] pts;\n            // 通过反序列化得到参数类型字符串，比如 Ljava/lang/String;\n            String desc = in.readUTF();\n            if (desc.length() == 0) &#123;\n                pts = DubboCodec.EMPTY_CLASS_ARRAY;\n                args = DubboCodec.EMPTY_OBJECT_ARRAY;\n            &#125; else &#123;\n                // 将 desc 解析为参数类型数组\n                pts = ReflectUtils.desc2classArray(desc);\n                args = new Object[pts.length];\n                for (int i = 0; i &lt; args.length; i++) &#123;\n                    try &#123;\n                        // 解析运行时参数\n                        args[i] = in.readObject(pts[i]);\n                    &#125; catch (Exception e) &#123;\n                        if (log.isWarnEnabled()) &#123;\n                            log.warn(\"Decode argument failed: \" + e.getMessage(), e);\n                        &#125;\n                    &#125;\n                &#125;\n            &#125;\n            \n            // 设置参数类型数组\n            setParameterTypes(pts);\n\n            // 通过反序列化得到原 attachment 的内容\n            Map&lt;String, String> map = (Map&lt;String, String>) in.readObject(Map.class);\n            if (map != null &amp;&amp; map.size() > 0) &#123;\n                Map&lt;String, String> attachment = getAttachments();\n                if (attachment == null) &#123;\n                    attachment = new HashMap&lt;String, String>();\n                &#125;\n                // 将 map 与当前对象中的 attachment 集合进行融合\n                attachment.putAll(map);\n                setAttachments(attachment);\n            &#125;\n            \n            // 对 callback 类型的参数进行处理\n            for (int i = 0; i &lt; args.length; i++) &#123;\n                args[i] = decodeInvocationArgument(channel, this, pts, i, args[i]);\n            &#125;\n\n            // 设置参数列表\n            setArguments(args);\n\n        &#125; catch (ClassNotFoundException e) &#123;\n            throw new IOException(StringUtils.toString(\"Read invocation data failed.\", e));\n        &#125; finally &#123;\n            if (in instanceof Cleanable) &#123;\n                ((Cleanable) in).cleanup();\n            &#125;\n        &#125;\n        return this;\n    &#125;\n&#125;\n\n上面的方法通过反序列化将诸如 path、version、调用方法名、参数列表等信息依次解析出来，并设置到相应的字段中，最终得到一个具有完整调用信息的 DecodeableRpcInvocation 对象。\n到这里，请求数据解码的过程就分析完了。此时我们得到了一个 Request 对象，这个对象会被传送到下一个入站处理器中，我们继续往下看。\n\n2.3.2 调用服务解码器将数据包解析成 Request 对象后，NettyHandler 的 messageReceived 方法紧接着会收到这个对象，并将这个对象继续向下传递。这期间该对象会被依次传递给 NettyServer、MultiMessageHandler、HeartbeatHandler 以及 AllChannelHandler。最后由 AllChannelHandler 将该对象封装到 Runnable 实现类对象中，并将 Runnable 放入线程池中执行后续的调用逻辑。整个调用栈如下：\nNettyHandler#messageReceived(ChannelHandlerContext, MessageEvent)\n  —&gt; AbstractPeer#received(Channel, Object)\n    —&gt; MultiMessageHandler#received(Channel, Object)\n      —&gt; HeartbeatHandler#received(Channel, Object)\n        —&gt; AllChannelHandler#received(Channel, Object)\n          —&gt; ExecutorService#execute(Runnable)    &#x2F;&#x2F; 由线程池执行后续的调用逻辑\n\n考虑到篇幅，以及很多中间调用的逻辑并非十分重要，所以这里就不对调用栈中的每个方法都进行分析了。这里我们直接分析调用栈中的分析第一个和最后一个调用方法逻辑。如下：\n@Sharable\npublic class NettyHandler extends SimpleChannelHandler &#123;\n    \n    private final Map&lt;String, Channel> channels = new ConcurrentHashMap&lt;String, Channel>();\n\n    private final URL url;\n\n    private final ChannelHandler handler;\n    \n    public NettyHandler(URL url, ChannelHandler handler) &#123;\n        if (url == null) &#123;\n            throw new IllegalArgumentException(\"url == null\");\n        &#125;\n        if (handler == null) &#123;\n            throw new IllegalArgumentException(\"handler == null\");\n        &#125;\n        this.url = url;\n        \n        // 这里的 handler 类型为 NettyServer\n        this.handler = handler;\n    &#125;\n    \n\tpublic void messageReceived(ChannelHandlerContext ctx, MessageEvent e) throws Exception &#123;\n        // 获取 NettyChannel\n        NettyChannel channel = NettyChannel.getOrAddChannel(ctx.getChannel(), url, handler);\n        try &#123;\n            // 继续向下调用\n            handler.received(channel, e.getMessage());\n        &#125; finally &#123;\n            NettyChannel.removeChannelIfDisconnected(ctx.getChannel());\n        &#125;\n    &#125;\n&#125;\n\n如上，NettyHandler 中的 messageReceived 逻辑比较简单。首先根据一些信息获取 NettyChannel 实例，然后将 NettyChannel 实例以及 Request 对象向下传递。下面再来看看 AllChannelHandler 的逻辑，在详细分析代码之前，我们先来了解一下 Dubbo 中的线程派发模型。\n\n2.3.2.1 线程派发模型Dubbo 将底层通信框架中接收请求的线程称为 IO 线程。如果一些事件处理逻辑可以很快执行完，比如只在内存打一个标记，此时直接在 IO 线程上执行该段逻辑即可。但如果事件的处理逻辑比较耗时，比如该段逻辑会发起数据库查询或者 HTTP 请求。此时我们就不应该让事件处理逻辑在 IO 线程上执行，而是应该派发到线程池中去执行。原因也很简单，IO 线程主要用于接收请求，如果 IO 线程被占满，将导致它不能接收新的请求。\n以上就是线程派发的背景，下面我们再来通过 Dubbo 调用图，看一下线程派发器所处的位置。\n\n如上图，红框中的 Dispatcher 就是线程派发器。需要说明的是，Dispatcher 真实的职责创建具有线程派发能力的 ChannelHandler，比如 AllChannelHandler、MessageOnlyChannelHandler 和 ExecutionChannelHandler 等，其本身并不具备线程派发能力。Dubbo 支持 5 种不同的线程派发策略，下面通过一个表格列举一下。\n\n\n\n策略\n用途\n\n\n\nall\n所有消息都派发到线程池，包括请求，响应，连接事件，断开事件等\n\n\ndirect\n所有消息都不派发到线程池，全部在 IO 线程上直接执行\n\n\nmessage\n只有请求和响应消息派发到线程池，其它消息均在 IO 线程上执行\n\n\nexecution\n只有请求消息派发到线程池，不含响应。其它消息均在 IO 线程上执行\n\n\nconnection\n在 IO 线程上，将连接断开事件放入队列，有序逐个执行，其它消息派发到线程池\n\n\n默认配置下，Dubbo 使用 all 派发策略，即将所有的消息都派发到线程池中。下面我们来分析一下 AllChannelHandler 的代码。\npublic class AllChannelHandler extends WrappedChannelHandler &#123;\n\n    public AllChannelHandler(ChannelHandler handler, URL url) &#123;\n        super(handler, url);\n    &#125;\n\n    /** 处理连接事件 */\n    @Override\n    public void connected(Channel channel) throws RemotingException &#123;\n        // 获取线程池\n        ExecutorService cexecutor = getExecutorService();\n        try &#123;\n            // 将连接事件派发到线程池中处理\n            cexecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.CONNECTED));\n        &#125; catch (Throwable t) &#123;\n            throw new ExecutionException(..., \" error when process connected event .\", t);\n        &#125;\n    &#125;\n\n    /** 处理断开事件 */\n    @Override\n    public void disconnected(Channel channel) throws RemotingException &#123;\n        ExecutorService cexecutor = getExecutorService();\n        try &#123;\n            cexecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.DISCONNECTED));\n        &#125; catch (Throwable t) &#123;\n            throw new ExecutionException(..., \"error when process disconnected event .\", t);\n        &#125;\n    &#125;\n\n    /** 处理请求和响应消息，这里的 message 变量类型可能是 Request，也可能是 Response */\n    @Override\n    public void received(Channel channel, Object message) throws RemotingException &#123;\n        ExecutorService cexecutor = getExecutorService();\n        try &#123;\n            // 将请求和响应消息派发到线程池中处理\n            cexecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));\n        &#125; catch (Throwable t) &#123;\n            if(message instanceof Request &amp;&amp; t instanceof RejectedExecutionException)&#123;\n                Request request = (Request)message;\n                // 如果通信方式为双向通信，此时将 Server side ... threadpool is exhausted \n                // 错误信息封装到 Response 中，并返回给服务消费方。\n                if(request.isTwoWay())&#123;\n                    String msg = \"Server side(\" + url.getIp() + \",\" + url.getPort() \n                        + \") threadpool is exhausted ,detail msg:\" + t.getMessage();\n                    Response response = new Response(request.getId(), request.getVersion());\n                    response.setStatus(Response.SERVER_THREADPOOL_EXHAUSTED_ERROR);\n                    response.setErrorMessage(msg);\n                    // 返回包含错误信息的 Response 对象\n                    channel.send(response);\n                    return;\n                &#125;\n            &#125;\n            throw new ExecutionException(..., \" error when process received event .\", t);\n        &#125;\n    &#125;\n\n    /** 处理异常信息 */\n    @Override\n    public void caught(Channel channel, Throwable exception) throws RemotingException &#123;\n        ExecutorService cexecutor = getExecutorService();\n        try &#123;\n            cexecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.CAUGHT, exception));\n        &#125; catch (Throwable t) &#123;\n            throw new ExecutionException(..., \"error when process caught event ...\");\n        &#125;\n    &#125;\n&#125;\n\n如上，请求对象会被封装 ChannelEventRunnable 中，ChannelEventRunnable 将会是服务调用过程的新起点。所以接下来我们以 ChannelEventRunnable 为起点向下探索。\n\n2.3.2.2 调用服务本小节，我们从 ChannelEventRunnable 开始分析，该类的主要代码如下：\npublic class ChannelEventRunnable implements Runnable &#123;\n    \n    private final ChannelHandler handler;\n    private final Channel channel;\n    private final ChannelState state;\n    private final Throwable exception;\n    private final Object message;\n    \n    @Override\n    public void run() &#123;\n        // 检测通道状态，对于请求或响应消息，此时 state = RECEIVED\n        if (state == ChannelState.RECEIVED) &#123;\n            try &#123;\n                // 将 channel 和 message 传给 ChannelHandler 对象，进行后续的调用\n                handler.received(channel, message);\n            &#125; catch (Exception e) &#123;\n                logger.warn(\"... operation error, channel is ... message is ...\");\n            &#125;\n        &#125; \n        \n        // 其他消息类型通过 switch 进行处理\n        else &#123;\n            switch (state) &#123;\n            case CONNECTED:\n                try &#123;\n                    handler.connected(channel);\n                &#125; catch (Exception e) &#123;\n                    logger.warn(\"... operation error, channel is ...\");\n                &#125;\n                break;\n            case DISCONNECTED:\n                // ...\n            case SENT:\n                // ...\n            case CAUGHT:\n                // ...\n            default:\n                logger.warn(\"unknown state: \" + state + \", message is \" + message);\n            &#125;\n        &#125;\n\n    &#125;\n&#125;\n\n如上，请求和响应消息出现频率明显比其他类型消息高，所以这里对该类型的消息进行了针对性判断。ChannelEventRunnable 仅是一个中转站，它的 run 方法中并不包含具体的调用逻辑，仅用于将参数传给其他 ChannelHandler 对象进行处理，该对象类型为 DecodeHandler。\npublic class DecodeHandler extends AbstractChannelHandlerDelegate &#123;\n\n    public DecodeHandler(ChannelHandler handler) &#123;\n        super(handler);\n    &#125;\n\n    @Override\n    public void received(Channel channel, Object message) throws RemotingException &#123;\n        if (message instanceof Decodeable) &#123;\n            // 对 Decodeable 接口实现类对象进行解码\n            decode(message);\n        &#125;\n\n        if (message instanceof Request) &#123;\n            // 对 Request 的 data 字段进行解码\n            decode(((Request) message).getData());\n        &#125;\n\n        if (message instanceof Response) &#123;\n            // 对 Request 的 result 字段进行解码\n            decode(((Response) message).getResult());\n        &#125;\n\n        // 执行后续逻辑\n        handler.received(channel, message);\n    &#125;\n\n    private void decode(Object message) &#123;\n        // Decodeable 接口目前有两个实现类，\n        // 分别为 DecodeableRpcInvocation 和 DecodeableRpcResult\n        if (message != null &amp;&amp; message instanceof Decodeable) &#123;\n            try &#123;\n                // 执行解码逻辑\n                ((Decodeable) message).decode();\n            &#125; catch (Throwable e) &#123;\n                if (log.isWarnEnabled()) &#123;\n                    log.warn(\"Call Decodeable.decode failed: \" + e.getMessage(), e);\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\nDecodeHandler 主要是包含了一些解码逻辑。2.2.1 节分析请求解码时说过，请求解码可在 IO 线程上执行，也可在线程池中执行，这个取决于运行时配置。DecodeHandler 存在的意义就是保证请求或响应对象可在线程池中被解码。解码完毕后，完全解码后的 Request 对象会继续向后传递，下一站是 HeaderExchangeHandler。\npublic class HeaderExchangeHandler implements ChannelHandlerDelegate &#123;\n\n    private final ExchangeHandler handler;\n\n    public HeaderExchangeHandler(ExchangeHandler handler) &#123;\n        if (handler == null) &#123;\n            throw new IllegalArgumentException(\"handler == null\");\n        &#125;\n        this.handler = handler;\n    &#125;\n\n    @Override\n    public void received(Channel channel, Object message) throws RemotingException &#123;\n        channel.setAttribute(KEY_READ_TIMESTAMP, System.currentTimeMillis());\n        ExchangeChannel exchangeChannel = HeaderExchangeChannel.getOrAddChannel(channel);\n        try &#123;\n            // 处理请求对象\n            if (message instanceof Request) &#123;\n                Request request = (Request) message;\n                if (request.isEvent()) &#123;\n                    // 处理事件\n                    handlerEvent(channel, request);\n                &#125; \n                // 处理普通的请求\n                else &#123;\n                    // 双向通信\n                    if (request.isTwoWay()) &#123;\n                        // 向后调用服务，并得到调用结果\n                        Response response = handleRequest(exchangeChannel, request);\n                        // 将调用结果返回给服务消费端\n                        channel.send(response);\n                    &#125; \n                    // 如果是单向通信，仅向后调用指定服务即可，无需返回调用结果\n                    else &#123;\n                        handler.received(exchangeChannel, request.getData());\n                    &#125;\n                &#125;\n            &#125;      \n            // 处理响应对象，服务消费方会执行此处逻辑，后面分析\n            else if (message instanceof Response) &#123;\n                handleResponse(channel, (Response) message);\n            &#125; else if (message instanceof String) &#123;\n                // telnet 相关，忽略\n            &#125; else &#123;\n                handler.received(exchangeChannel, message);\n            &#125;\n        &#125; finally &#123;\n            HeaderExchangeChannel.removeChannelIfDisconnected(channel);\n        &#125;\n    &#125;\n\n    Response handleRequest(ExchangeChannel channel, Request req) throws RemotingException &#123;\n        Response res = new Response(req.getId(), req.getVersion());\n        // 检测请求是否合法，不合法则返回状态码为 BAD_REQUEST 的响应\n        if (req.isBroken()) &#123;\n            Object data = req.getData();\n\n            String msg;\n            if (data == null)\n                msg = null;\n            else if\n                (data instanceof Throwable) msg = StringUtils.toString((Throwable) data);\n            else\n                msg = data.toString();\n            res.setErrorMessage(\"Fail to decode request due to: \" + msg);\n            // 设置 BAD_REQUEST 状态\n            res.setStatus(Response.BAD_REQUEST);\n\n            return res;\n        &#125;\n        \n        // 获取 data 字段值，也就是 RpcInvocation 对象\n        Object msg = req.getData();\n        try &#123;\n            // 继续向下调用\n            Object result = handler.reply(channel, msg);\n            // 设置 OK 状态码\n            res.setStatus(Response.OK);\n            // 设置调用结果\n            res.setResult(result);\n        &#125; catch (Throwable e) &#123;\n            // 若调用过程出现异常，则设置 SERVICE_ERROR，表示服务端异常\n            res.setStatus(Response.SERVICE_ERROR);\n            res.setErrorMessage(StringUtils.toString(e));\n        &#125;\n        return res;\n    &#125;\n&#125;\n\n到这里，我们看到了比较清晰的请求和响应逻辑。对于双向通信，HeaderExchangeHandler 首先向后进行调用，得到调用结果。然后将调用结果封装到 Response 对象中，最后再将该对象返回给服务消费方。如果请求不合法，或者调用失败，则将错误信息封装到 Response 对象中，并返回给服务消费方。接下来我们继续向后分析，把剩余的调用过程分析完。下面分析定义在 DubboProtocol 类中的匿名类对象逻辑，如下：\npublic class DubboProtocol extends AbstractProtocol &#123;\n\n    public static final String NAME = \"dubbo\";\n    \n    private ExchangeHandler requestHandler = new ExchangeHandlerAdapter() &#123;\n\n        @Override\n        public Object reply(ExchangeChannel channel, Object message) throws RemotingException &#123;\n            if (message instanceof Invocation) &#123;\n                Invocation inv = (Invocation) message;\n                // 获取 Invoker 实例\n                Invoker&lt;?> invoker = getInvoker(channel, inv);\n                if (Boolean.TRUE.toString().equals(inv.getAttachments().get(IS_CALLBACK_SERVICE_INVOKE))) &#123;\n                    // 回调相关，忽略\n                &#125;\n                RpcContext.getContext().setRemoteAddress(channel.getRemoteAddress());\n                // 通过 Invoker 调用具体的服务\n                return invoker.invoke(inv);\n            &#125;\n            throw new RemotingException(channel, \"Unsupported request: ...\");\n        &#125;\n        \n        // 忽略其他方法\n    &#125;\n    \n    Invoker&lt;?> getInvoker(Channel channel, Invocation inv) throws RemotingException &#123;\n        // 忽略回调和本地存根相关逻辑\n        // ...\n        \n        int port = channel.getLocalAddress().getPort();\n        \n        // 计算 service key，格式为 groupName/serviceName:serviceVersion:port。比如：\n        //   dubbo/com.alibaba.dubbo.demo.DemoService:1.0.0:20880\n        String serviceKey = serviceKey(port, path, inv.getAttachments().get(Constants.VERSION_KEY), inv.getAttachments().get(Constants.GROUP_KEY));\n\n        // 从 exporterMap 查找与 serviceKey 相对应的 DubboExporter 对象，\n        // 服务导出过程中会将 &lt;serviceKey, DubboExporter> 映射关系存储到 exporterMap 集合中\n        DubboExporter&lt;?> exporter = (DubboExporter&lt;?>) exporterMap.get(serviceKey);\n\n        if (exporter == null)\n            throw new RemotingException(channel, \"Not found exported service ...\");\n\n        // 获取 Invoker 对象，并返回\n        return exporter.getInvoker();\n    &#125;\n    \n    // 忽略其他方法\n&#125;\n\n以上逻辑用于获取与指定服务对应的 Invoker 实例，并通过 Invoker 的 invoke 方法调用服务逻辑。invoke 方法定义在 AbstractProxyInvoker 中，代码如下。\npublic abstract class AbstractProxyInvoker&lt;T> implements Invoker&lt;T> &#123;\n\n    @Override\n    public Result invoke(Invocation invocation) throws RpcException &#123;\n        try &#123;\n            // 调用 doInvoke 执行后续的调用，并将调用结果封装到 RpcResult 中，并\n            return new RpcResult(doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments()));\n        &#125; catch (InvocationTargetException e) &#123;\n            return new RpcResult(e.getTargetException());\n        &#125; catch (Throwable e) &#123;\n            throw new RpcException(\"Failed to invoke remote proxy method ...\");\n        &#125;\n    &#125;\n    \n    protected abstract Object doInvoke(T proxy, String methodName, Class&lt;?>[] parameterTypes, Object[] arguments) throws Throwable;\n&#125;\n\n如上，doInvoke 是一个抽象方法，这个需要由具体的 Invoker 实例实现。Invoker 实例是在运行时通过 JavassistProxyFactory 创建的，创建逻辑如下：\npublic class JavassistProxyFactory extends AbstractProxyFactory &#123;\n    \n    // 省略其他方法\n\n    @Override\n    public &lt;T> Invoker&lt;T> getInvoker(T proxy, Class&lt;T> type, URL url) &#123;\n        final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') &lt; 0 ? proxy.getClass() : type);\n        // 创建匿名类对象\n        return new AbstractProxyInvoker&lt;T>(proxy, type, url) &#123;\n            @Override\n            protected Object doInvoke(T proxy, String methodName,\n                                      Class&lt;?>[] parameterTypes,\n                                      Object[] arguments) throws Throwable &#123;\n                // 调用 invokeMethod 方法进行后续的调用\n                return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments);\n            &#125;\n        &#125;;\n    &#125;\n&#125;\n\nWrapper 是一个抽象类，其中 invokeMethod 是一个抽象方法。Dubbo 会在运行时通过 Javassist 框架为 Wrapper 生成实现类，并实现 invokeMethod 方法，该方法最终会根据调用信息调用具体的服务。以 DemoServiceImpl 为例，Javassist 为其生成的代理类如下。\n/** Wrapper0 是在运行时生成的，大家可使用 Arthas 进行反编译 */\npublic class Wrapper0 extends Wrapper implements ClassGenerator.DC &#123;\n    public static String[] pns;\n    public static Map pts;\n    public static String[] mns;\n    public static String[] dmns;\n    public static Class[] mts0;\n\n    // 省略其他方法\n\n    public Object invokeMethod(Object object, String string, Class[] arrclass, Object[] arrobject) throws InvocationTargetException &#123;\n        DemoService demoService;\n        try &#123;\n            // 类型转换\n            demoService = (DemoService)object;\n        &#125;\n        catch (Throwable throwable) &#123;\n            throw new IllegalArgumentException(throwable);\n        &#125;\n        try &#123;\n            // 根据方法名调用指定的方法\n            if (\"sayHello\".equals(string) &amp;&amp; arrclass.length == 1) &#123;\n                return demoService.sayHello((String)arrobject[0]);\n            &#125;\n        &#125;\n        catch (Throwable throwable) &#123;\n            throw new InvocationTargetException(throwable);\n        &#125;\n        throw new NoSuchMethodException(new StringBuffer().append(\"Not found method \\\"\").append(string).append(\"\\\" in class com.alibaba.dubbo.demo.DemoService.\").toString());\n    &#125;\n&#125;\n\n到这里，整个服务调用过程就分析完了。最后把调用过程贴出来，如下：\nChannelEventRunnable#run()\n  —&gt; DecodeHandler#received(Channel, Object)\n    —&gt; HeaderExchangeHandler#received(Channel, Object)\n      —&gt; HeaderExchangeHandler#handleRequest(ExchangeChannel, Request)\n        —&gt; DubboProtocol.requestHandler#reply(ExchangeChannel, Object)\n          —&gt; Filter#invoke(Invoker, Invocation)\n            —&gt; AbstractProxyInvoker#invoke(Invocation)\n              —&gt; Wrapper0#invokeMethod(Object, String, Class[], Object[])\n                —&gt; DemoServiceImpl#sayHello(String)\n\n\n2.4 服务提供方返回调用结果服务提供方调用指定服务后，会将调用结果封装到 Response 对象中，并将该对象返回给服务消费方。服务提供方也是通过 NettyChannel 的 send 方法将 Response 对象返回，这个方法在 2.2.1 节分析过，这里就不在重复分析了。本节我们仅需关注 Response 对象的编码过程即可，这里仍然省略一些中间调用，直接分析具体的编码逻辑。\npublic class ExchangeCodec extends TelnetCodec &#123;\n\tpublic void encode(Channel channel, ChannelBuffer buffer, Object msg) throws IOException &#123;\n        if (msg instanceof Request) &#123;\n            encodeRequest(channel, buffer, (Request) msg);\n        &#125; else if (msg instanceof Response) &#123;\n            // 对响应对象进行编码\n            encodeResponse(channel, buffer, (Response) msg);\n        &#125; else &#123;\n            super.encode(channel, buffer, msg);\n        &#125;\n    &#125;\n    \n    protected void encodeResponse(Channel channel, ChannelBuffer buffer, Response res) throws IOException &#123;\n        int savedWriteIndex = buffer.writerIndex();\n        try &#123;\n            Serialization serialization = getSerialization(channel);\n            // 创建消息头字节数组\n            byte[] header = new byte[HEADER_LENGTH];\n            // 设置魔数\n            Bytes.short2bytes(MAGIC, header);\n            // 设置序列化器编号\n            header[2] = serialization.getContentTypeId();\n            if (res.isHeartbeat()) header[2] |= FLAG_EVENT;\n            // 获取响应状态\n            byte status = res.getStatus();\n            // 设置响应状态\n            header[3] = status;\n            // 设置请求编号\n            Bytes.long2bytes(res.getId(), header, 4);\n\n            // 更新 writerIndex，为消息头预留 16 个字节的空间\n            buffer.writerIndex(savedWriteIndex + HEADER_LENGTH);\n            ChannelBufferOutputStream bos = new ChannelBufferOutputStream(buffer);\n            ObjectOutput out = serialization.serialize(channel.getUrl(), bos);\n           \n            if (status == Response.OK) &#123;\n                if (res.isHeartbeat()) &#123;\n                    // 对心跳响应结果进行序列化，已废弃\n                    encodeHeartbeatData(channel, out, res.getResult());\n                &#125; else &#123;\n                    // 对调用结果进行序列化\n                    encodeResponseData(channel, out, res.getResult(), res.getVersion());\n                &#125;\n            &#125; else &#123; \n                // 对错误信息进行序列化\n                out.writeUTF(res.getErrorMessage())\n            &#125;;\n            out.flushBuffer();\n            if (out instanceof Cleanable) &#123;\n                ((Cleanable) out).cleanup();\n            &#125;\n            bos.flush();\n            bos.close();\n\n            // 获取写入的字节数，也就是消息体长度\n            int len = bos.writtenBytes();\n            checkPayload(channel, len);\n            \n            // 将消息体长度写入到消息头中\n            Bytes.int2bytes(len, header, 12);\n            // 将 buffer 指针移动到 savedWriteIndex，为写消息头做准备\n            buffer.writerIndex(savedWriteIndex);\n            // 从 savedWriteIndex 下标处写入消息头\n            buffer.writeBytes(header); \n            // 设置新的 writerIndex，writerIndex = 原写下标 + 消息头长度 + 消息体长度\n            buffer.writerIndex(savedWriteIndex + HEADER_LENGTH + len);\n        &#125; catch (Throwable t) &#123;\n            // 异常处理逻辑不是很难理解，但是代码略多，这里忽略了\n        &#125;\n    &#125;\n&#125;\n\npublic class DubboCodec extends ExchangeCodec implements Codec2 &#123;\n    \n\tprotected void encodeResponseData(Channel channel, ObjectOutput out, Object data, String version) throws IOException &#123;\n        Result result = (Result) data;\n        // 检测当前协议版本是否支持带有 attachment 集合的 Response 对象\n        boolean attach = Version.isSupportResponseAttachment(version);\n        Throwable th = result.getException();\n        \n        // 异常信息为空\n        if (th == null) &#123;\n            Object ret = result.getValue();\n            // 调用结果为空\n            if (ret == null) &#123;\n                // 序列化响应类型\n                out.writeByte(attach ? RESPONSE_NULL_VALUE_WITH_ATTACHMENTS : RESPONSE_NULL_VALUE);\n            &#125; \n            // 调用结果非空\n            else &#123;\n                // 序列化响应类型\n                out.writeByte(attach ? RESPONSE_VALUE_WITH_ATTACHMENTS : RESPONSE_VALUE);\n                // 序列化调用结果\n                out.writeObject(ret);\n            &#125;\n        &#125; \n        // 异常信息非空\n        else &#123;\n            // 序列化响应类型\n            out.writeByte(attach ? RESPONSE_WITH_EXCEPTION_WITH_ATTACHMENTS : RESPONSE_WITH_EXCEPTION);\n            // 序列化异常对象\n            out.writeObject(th);\n        &#125;\n\n        if (attach) &#123;\n            // 记录 Dubbo 协议版本\n            result.getAttachments().put(Constants.DUBBO_VERSION_KEY, Version.getProtocolVersion());\n            // 序列化 attachments 集合\n            out.writeObject(result.getAttachments());\n        &#125;\n    &#125;\n&#125;\n\n以上就是 Response 对象编码的过程，和前面分析的 Request 对象编码过程很相似。如果大家能看 Request 对象的编码逻辑，那么这里的 Response 对象的编码逻辑也不难理解，就不多说了。接下来我们再来分析双向通信的最后一环 —— 服务消费方接收调用结果。\n\n2.5 服务消费方接收调用结果服务消费方在收到响应数据后，首先要做的事情是对响应数据进行解码，得到 Response 对象。然后再将该对象传递给下一个入站处理器，这个入站处理器就是 NettyHandler。接下来 NettyHandler 会将这个对象继续向下传递，最后 AllChannelHandler 的 received 方法会收到这个对象，并将这个对象派发到线程池中。这个过程和服务提供方接收请求的过程是一样的，因此这里就不重复分析了。本节我们重点分析两个方面的内容，一是响应数据的解码过程，二是 Dubbo 如何将调用结果传递给用户线程的。下面先来分析响应数据的解码过程。\n\n2.5.1 响应数据解码响应数据解码逻辑主要的逻辑封装在 DubboCodec 中，我们直接分析这个类的代码。如下：\npublic class DubboCodec extends ExchangeCodec implements Codec2 &#123;\n\n    @Override\n    protected Object decodeBody(Channel channel, InputStream is, byte[] header) throws IOException &#123;\n        byte flag = header[2], proto = (byte) (flag &amp; SERIALIZATION_MASK);\n        Serialization s = CodecSupport.getSerialization(channel.getUrl(), proto);\n        // 获取请求编号\n        long id = Bytes.bytes2long(header, 4);\n        // 检测消息类型，若下面的条件成立，表明消息类型为 Response\n        if ((flag &amp; FLAG_REQUEST) == 0) &#123;\n            // 创建 Response 对象\n            Response res = new Response(id);\n            // 检测事件标志位\n            if ((flag &amp; FLAG_EVENT) != 0) &#123;\n                // 设置心跳事件\n                res.setEvent(Response.HEARTBEAT_EVENT);\n            &#125;\n            // 获取响应状态\n            byte status = header[3];\n            // 设置响应状态\n            res.setStatus(status);\n            \n            // 如果响应状态为 OK，表明调用过程正常\n            if (status == Response.OK) &#123;\n                try &#123;\n                    Object data;\n                    if (res.isHeartbeat()) &#123;\n                        // 反序列化心跳数据，已废弃\n                        data = decodeHeartbeatData(channel, deserialize(s, channel.getUrl(), is));\n                    &#125; else if (res.isEvent()) &#123;\n                        // 反序列化事件数据\n                        data = decodeEventData(channel, deserialize(s, channel.getUrl(), is));\n                    &#125; else &#123;\n                        DecodeableRpcResult result;\n                        // 根据 url 参数决定是否在 IO 线程上执行解码逻辑\n                        if (channel.getUrl().getParameter(\n                                Constants.DECODE_IN_IO_THREAD_KEY,\n                                Constants.DEFAULT_DECODE_IN_IO_THREAD)) &#123;\n                            // 创建 DecodeableRpcResult 对象\n                            result = new DecodeableRpcResult(channel, res, is,\n                                    (Invocation) getRequestData(id), proto);\n                            // 进行后续的解码工作\n                            result.decode();\n                        &#125; else &#123;\n                            // 创建 DecodeableRpcResult 对象\n                            result = new DecodeableRpcResult(channel, res,\n                                    new UnsafeByteArrayInputStream(readMessageData(is)),\n                                    (Invocation) getRequestData(id), proto);\n                        &#125;\n                        data = result;\n                    &#125;\n                    \n                    // 设置 DecodeableRpcResult 对象到 Response 对象中\n                    res.setResult(data);\n                &#125; catch (Throwable t) &#123;\n                    // 解码过程中出现了错误，此时设置 CLIENT_ERROR 状态码到 Response 对象中\n                    res.setStatus(Response.CLIENT_ERROR);\n                    res.setErrorMessage(StringUtils.toString(t));\n                &#125;\n            &#125; \n            // 响应状态非 OK，表明调用过程出现了异常\n            else &#123;\n                // 反序列化异常信息，并设置到 Response 对象中\n                res.setErrorMessage(deserialize(s, channel.getUrl(), is).readUTF());\n            &#125;\n            return res;\n        &#125; else &#123;\n            // 对请求数据进行解码，前面已分析过，此处忽略\n        &#125;\n    &#125;\n&#125;\n\n以上就是响应数据的解码过程，上面逻辑看起来是不是似曾相识。对的，我们在前面章节分析过 DubboCodec 的 decodeBody 方法中关于请求数据的解码过程，该过程和响应数据的解码过程很相似。下面，我们继续分析调用结果的反序列化过程，如下：\npublic class DecodeableRpcResult extends RpcResult implements Codec, Decodeable &#123;\n    \n    private Invocation invocation;\n\t\n    @Override\n    public void decode() throws Exception &#123;\n        if (!hasDecoded &amp;&amp; channel != null &amp;&amp; inputStream != null) &#123;\n            try &#123;\n                // 执行反序列化操作\n                decode(channel, inputStream);\n            &#125; catch (Throwable e) &#123;\n                // 反序列化失败，设置 CLIENT_ERROR 状态到 Response 对象中\n                response.setStatus(Response.CLIENT_ERROR);\n                // 设置异常信息\n                response.setErrorMessage(StringUtils.toString(e));\n            &#125; finally &#123;\n                hasDecoded = true;\n            &#125;\n        &#125;\n    &#125;\n    \n    @Override\n    public Object decode(Channel channel, InputStream input) throws IOException &#123;\n        ObjectInput in = CodecSupport.getSerialization(channel.getUrl(), serializationType)\n                .deserialize(channel.getUrl(), input);\n        \n        // 反序列化响应类型\n        byte flag = in.readByte();\n        switch (flag) &#123;\n            case DubboCodec.RESPONSE_NULL_VALUE:\n                break;\n            case DubboCodec.RESPONSE_VALUE:\n                // ...\n                break;\n            case DubboCodec.RESPONSE_WITH_EXCEPTION:\n                // ...\n                break;\n                \n            // 返回值为空，且携带了 attachments 集合\n            case DubboCodec.RESPONSE_NULL_VALUE_WITH_ATTACHMENTS:\n                try &#123;\n                    // 反序列化 attachments 集合，并存储起来 \n                    setAttachments((Map&lt;String, String>) in.readObject(Map.class));\n                &#125; catch (ClassNotFoundException e) &#123;\n                    throw new IOException(StringUtils.toString(\"Read response data failed.\", e));\n                &#125;\n                break;\n                \n            // 返回值不为空，且携带了 attachments 集合\n            case DubboCodec.RESPONSE_VALUE_WITH_ATTACHMENTS:\n                try &#123;\n                    // 获取返回值类型\n                    Type[] returnType = RpcUtils.getReturnTypes(invocation);\n                    // 反序列化调用结果，并保存起来\n                    setValue(returnType == null || returnType.length == 0 ? in.readObject() :\n                            (returnType.length == 1 ? in.readObject((Class&lt;?>) returnType[0])\n                                    : in.readObject((Class&lt;?>) returnType[0], returnType[1])));\n                    // 反序列化 attachments 集合，并存储起来\n                    setAttachments((Map&lt;String, String>) in.readObject(Map.class));\n                &#125; catch (ClassNotFoundException e) &#123;\n                    throw new IOException(StringUtils.toString(\"Read response data failed.\", e));\n                &#125;\n                break;\n                \n            // 异常对象不为空，且携带了 attachments 集合\n            case DubboCodec.RESPONSE_WITH_EXCEPTION_WITH_ATTACHMENTS:\n                try &#123;\n                    // 反序列化异常对象\n                    Object obj = in.readObject();\n                    if (obj instanceof Throwable == false)\n                        throw new IOException(\"Response data error, expect Throwable, but get \" + obj);\n                    // 设置异常对象\n                    setException((Throwable) obj);\n                    // 反序列化 attachments 集合，并存储起来\n                    setAttachments((Map&lt;String, String>) in.readObject(Map.class));\n                &#125; catch (ClassNotFoundException e) &#123;\n                    throw new IOException(StringUtils.toString(\"Read response data failed.\", e));\n                &#125;\n                break;\n            default:\n                throw new IOException(\"Unknown result flag, expect '0' '1' '2', get \" + flag);\n        &#125;\n        if (in instanceof Cleanable) &#123;\n            ((Cleanable) in).cleanup();\n        &#125;\n        return this;\n    &#125;\n&#125;\n\n本篇文章所分析的源码版本为 2.6.4，该版本下的 Response 支持 attachments 集合，所以上面仅对部分 case 分支进行了注释。其他 case 分支的逻辑比被注释分支的逻辑更为简单，这里就忽略了。我们所使用的测试服务接口 DemoService 包含了一个具有返回值的方法，正常调用下，线程会进入 RESPONSE_VALUE_WITH_ATTACHMENTS 分支中。然后线程会从 invocation 变量（大家探索一下 invocation 变量的由来）中获取返回值类型，接着对调用结果进行反序列化，并将序列化后的结果存储起来。最后对 attachments 集合进行反序列化，并存到指定字段中。到此，关于响应数据的解码过程就分析完了。接下来，我们再来探索一下响应对象 Response 的去向。\n\n2.5.2 向用户线程传递调用结果响应数据解码完成后，Dubbo 会将响应对象派发到线程池上。要注意的是，线程池中的线程并非用户的调用线程，所以要想办法将响应对象从线程池线程传递到用户线程上。我们在 2.1 节分析过用户线程在发送完请求后的动作，即调用 DefaultFuture 的 get 方法等待响应对象的到来。当响应对象到来后，用户线程会被唤醒，并通过调用编号获取属于自己的响应对象。下面我们来看一下整个过程对应的代码。\npublic class HeaderExchangeHandler implements ChannelHandlerDelegate &#123;\n    \n    @Override\n    public void received(Channel channel, Object message) throws RemotingException &#123;\n        channel.setAttribute(KEY_READ_TIMESTAMP, System.currentTimeMillis());\n        ExchangeChannel exchangeChannel = HeaderExchangeChannel.getOrAddChannel(channel);\n        try &#123;\n            if (message instanceof Request) &#123;\n                // 处理请求，前面已分析过，省略\n            &#125; else if (message instanceof Response) &#123;\n                // 处理响应\n                handleResponse(channel, (Response) message);\n            &#125; else if (message instanceof String) &#123;\n                // telnet 相关，忽略\n            &#125; else &#123;\n                handler.received(exchangeChannel, message);\n            &#125;\n        &#125; finally &#123;\n            HeaderExchangeChannel.removeChannelIfDisconnected(channel);\n        &#125;\n    &#125;\n\n    static void handleResponse(Channel channel, Response response) throws RemotingException &#123;\n        if (response != null &amp;&amp; !response.isHeartbeat()) &#123;\n            // 继续向下调用\n            DefaultFuture.received(channel, response);\n        &#125;\n    &#125;\n&#125;\n\npublic class DefaultFuture implements ResponseFuture &#123;  \n    \n    private final Lock lock = new ReentrantLock();\n    private final Condition done = lock.newCondition();\n    private volatile Response response;\n    \n\tpublic static void received(Channel channel, Response response) &#123;\n        try &#123;\n            // 根据调用编号从 FUTURES 集合中查找指定的 DefaultFuture 对象\n            DefaultFuture future = FUTURES.remove(response.getId());\n            if (future != null) &#123;\n                // 继续向下调用\n                future.doReceived(response);\n            &#125; else &#123;\n                logger.warn(\"The timeout response finally returned at ...\");\n            &#125;\n        &#125; finally &#123;\n            CHANNELS.remove(response.getId());\n        &#125;\n    &#125;\n\n\tprivate void doReceived(Response res) &#123;\n        lock.lock();\n        try &#123;\n            // 保存响应对象\n            response = res;\n            if (done != null) &#123;\n                // 唤醒用户线程\n                done.signal();\n            &#125;\n        &#125; finally &#123;\n            lock.unlock();\n        &#125;\n        if (callback != null) &#123;\n            invokeCallback(callback);\n        &#125;\n    &#125;\n&#125;\n\n以上逻辑是将响应对象保存到相应的 DefaultFuture 实例中，然后再唤醒用户线程，随后用户线程即可从 DefaultFuture 实例中获取到相应结果。\n本篇文章在多个地方都强调过调用编号很重要，但一直没有解释原因，这里简单说明一下。一般情况下，服务消费方会并发调用多个服务，每个用户线程发送请求后，会调用不同 DefaultFuture 对象的 get 方法进行等待。 一段时间后，服务消费方的线程池会收到多个响应对象。这个时候要考虑一个问题，如何将每个响应对象传递给相应的 DefaultFuture 对象，且不出错。答案是通过调用编号。DefaultFuture 被创建时，会要求传入一个 Request 对象。此时 DefaultFuture 可从 Request 对象中获取调用编号，并将 &lt;调用编号, DefaultFuture 对象&gt; 映射关系存入到静态 Map 中，即 FUTURES。线程池中的线程在收到 Response 对象后，会根据 Response 对象中的调用编号到 FUTURES 集合中取出相应的 DefaultFuture 对象，然后再将 Response 对象设置到 DefaultFuture 对象中。最后再唤醒用户线程，这样用户线程即可从 DefaultFuture 对象中获取调用结果了。整个过程大致如下图：\n\n\n3. 总结本篇文章主要对 Dubbo 中的几种服务调用方式，以及从双向通信的角度对整个通信过程进行了详细的分析。按照通信顺序，通信过程包括服务消费方发送请求，服务提供方接收请求，服务提供方返回响应数据，服务消费方接收响应数据等过程。理解这些过程需要大家对网络编程，尤其是 Netty 有一定的了解。限于篇幅原因，本篇文章无法将服务调用的所有内容都一一进行分析。对于本篇文章未讲到或未详细分析的内容，比如服务降级、过滤器链、以及序列化等。大家若感兴趣，可自行进行分析。并将分析整理成文，分享给社区。\n本篇文章就到这里了，感谢阅读。\n\n\n\n\n\n\n\n\n\n原文地址：https://dubbo.apache.org/zh/docsv2.7/dev/source/refer-service/\n作者： Dubbo 官方\n本文介绍了 Dubbo 服务引用的过程和实现细节\n\n服务引用1. 简介上一篇文章详细分析了服务导出的过程，本篇文章我们趁热打铁，继续分析服务引用过程。在 Dubbo 中，我们可以通过两种方式引用远程服务。第一种是使用服务直连的方式引用服务，第二种方式是基于注册中心进行引用。服务直连的方式仅适合在调试或测试服务的场景下使用，不适合在线上环境使用。因此，本文我将重点分析通过注册中心引用服务的过程。从注册中心中获取服务配置只是服务引用过程中的一环，除此之外，服务消费者还需要经历 Invoker 创建、代理类创建等步骤。这些步骤，将在后续章节中一一进行分析。\n\n2.服务引用原理Dubbo 服务引用的时机有两个，第一个是在 Spring 容器调用 ReferenceBean 的 afterPropertiesSet 方法时引用服务，第二个是在 ReferenceBean 对应的服务被注入到其他类中时引用。这两个引用服务的时机区别在于，第一个是饿汉式的，第二个是懒汉式的。默认情况下，Dubbo 使用懒汉式引用服务。如果需要使用饿汉式，可通过配置 dubbo:reference 的 init 属性开启。下面我们按照 Dubbo 默认配置进行分析，整个分析过程从 ReferenceBean 的 getObject 方法开始。当我们的服务被注入到其他类中时，Spring 会第一时间调用 getObject 方法，并由该方法执行服务引用逻辑。按照惯例，在进行具体工作之前，需先进行配置检查与收集工作。接着根据收集到的信息决定服务用的方式，有三种，第一种是引用本地 (JVM) 服务，第二是通过直连方式引用远程服务，第三是通过注册中心引用远程服务。不管是哪种引用方式，最后都会得到一个 Invoker 实例。如果有多个注册中心，多个服务提供者，这个时候会得到一组 Invoker 实例，此时需要通过集群管理类 Cluster 将多个 Invoker 合并成一个实例。合并后的 Invoker 实例已经具备调用本地或远程服务的能力了，但并不能将此实例暴露给用户使用，这会对用户业务代码造成侵入。此时框架还需要通过代理工厂类 (ProxyFactory) 为服务接口生成代理类，并让代理类去调用 Invoker 逻辑。避免了 Dubbo 框架代码对业务代码的侵入，同时也让框架更容易使用。\n以上就是服务引用的大致原理，下面我们深入到代码中，详细分析服务引用细节。\n\n3.源码分析服务引用的入口方法为 ReferenceBean 的 getObject 方法，该方法定义在 Spring 的 FactoryBean 接口中，ReferenceBean 实现了这个方法。实现代码如下：\npublic Object getObject() throws Exception &#123;\n    return get();\n&#125;\n\npublic synchronized T get() &#123;\n    if (destroyed) &#123;\n        throw new IllegalStateException(\"Already destroyed!\");\n    &#125;\n    // 检测 ref 是否为空，为空则通过 init 方法创建\n    if (ref == null) &#123;\n        // init 方法主要用于处理配置，以及调用 createProxy 生成代理类\n        init();\n    &#125;\n    return ref;\n&#125;\n\n以上两个方法的代码比较简短，并不难理解。这里需要特别说明一下，如果你对 2.6.4 及以下版本的 getObject 方法进行调试时，会碰到比较奇怪的的问题。这里假设你使用 IDEA，且保持了 IDEA 的默认配置。当你面调试到 get 方法的if (ref == null)时，你会发现 ref 不为空，导致你无法进入到 init 方法中继续调试。导致这个现象的原因是 Dubbo 框架本身有一些小问题。该问题已经在 pull request #2754 修复了此问题，并跟随 2.6.5 版本发布了。如果你正在学习 2.6.4 及以下版本，可通过修改 IDEA 配置规避这个问题。首先 IDEA 配置弹窗中搜索 toString，然后取消Enable &#39;toString&#39; object view勾选。具体如下：\n\n\n3.1 处理配置Dubbo 提供了丰富的配置，用于调整和优化框架行为，性能等。Dubbo 在引用或导出服务时，首先会对这些配置进行检查和处理，以保证配置的正确性。配置解析逻辑封装在 ReferenceConfig 的 init 方法中，下面进行分析。\nprivate void init() &#123;\n    // 避免重复初始化\n    if (initialized) &#123;\n        return;\n    &#125;\n    initialized = true;\n    // 检测接口名合法性\n    if (interfaceName == null || interfaceName.length() == 0) &#123;\n        throw new IllegalStateException(\"interface not allow null!\");\n    &#125;\n\n    // 检测 consumer 变量是否为空，为空则创建\n    checkDefault();\n    appendProperties(this);\n    if (getGeneric() == null &amp;&amp; getConsumer() != null) &#123;\n        // 设置 generic\n        setGeneric(getConsumer().getGeneric());\n    &#125;\n\n    // 检测是否为泛化接口\n    if (ProtocolUtils.isGeneric(getGeneric())) &#123;\n        interfaceClass = GenericService.class;\n    &#125; else &#123;\n        try &#123;\n            // 加载类\n            interfaceClass = Class.forName(interfaceName, true, Thread.currentThread()\n                    .getContextClassLoader());\n        &#125; catch (ClassNotFoundException e) &#123;\n            throw new IllegalStateException(e.getMessage(), e);\n        &#125;\n        checkInterfaceAndMethods(interfaceClass, methods);\n    &#125;\n    \n    // -------------------------------✨ 分割线1 ✨------------------------------\n\n    // 从系统变量中获取与接口名对应的属性值\n    String resolve = System.getProperty(interfaceName);\n    String resolveFile = null;\n    if (resolve == null || resolve.length() == 0) &#123;\n        // 从系统属性中获取解析文件路径\n        resolveFile = System.getProperty(\"dubbo.resolve.file\");\n        if (resolveFile == null || resolveFile.length() == 0) &#123;\n            // 从指定位置加载配置文件\n            File userResolveFile = new File(new File(System.getProperty(\"user.home\")), \"dubbo-resolve.properties\");\n            if (userResolveFile.exists()) &#123;\n                // 获取文件绝对路径\n                resolveFile = userResolveFile.getAbsolutePath();\n            &#125;\n        &#125;\n        if (resolveFile != null &amp;&amp; resolveFile.length() > 0) &#123;\n            Properties properties = new Properties();\n            FileInputStream fis = null;\n            try &#123;\n                fis = new FileInputStream(new File(resolveFile));\n                // 从文件中加载配置\n                properties.load(fis);\n            &#125; catch (IOException e) &#123;\n                throw new IllegalStateException(\"Unload ..., cause:...\");\n            &#125; finally &#123;\n                try &#123;\n                    if (null != fis) fis.close();\n                &#125; catch (IOException e) &#123;\n                    logger.warn(e.getMessage(), e);\n                &#125;\n            &#125;\n            // 获取与接口名对应的配置\n            resolve = properties.getProperty(interfaceName);\n        &#125;\n    &#125;\n    if (resolve != null &amp;&amp; resolve.length() > 0) &#123;\n        // 将 resolve 赋值给 url\n        url = resolve;\n    &#125;\n    \n    // -------------------------------✨ 分割线2 ✨------------------------------\n    if (consumer != null) &#123;\n        if (application == null) &#123;\n            // 从 consumer 中获取 Application 实例，下同\n            application = consumer.getApplication();\n        &#125;\n        if (module == null) &#123;\n            module = consumer.getModule();\n        &#125;\n        if (registries == null) &#123;\n            registries = consumer.getRegistries();\n        &#125;\n        if (monitor == null) &#123;\n            monitor = consumer.getMonitor();\n        &#125;\n    &#125;\n    if (module != null) &#123;\n        if (registries == null) &#123;\n            registries = module.getRegistries();\n        &#125;\n        if (monitor == null) &#123;\n            monitor = module.getMonitor();\n        &#125;\n    &#125;\n    if (application != null) &#123;\n        if (registries == null) &#123;\n            registries = application.getRegistries();\n        &#125;\n        if (monitor == null) &#123;\n            monitor = application.getMonitor();\n        &#125;\n    &#125;\n    \n    // 检测 Application 合法性\n    checkApplication();\n    // 检测本地存根配置合法性\n    checkStubAndMock(interfaceClass);\n    \n\t// -------------------------------✨ 分割线3 ✨------------------------------\n    \n    Map&lt;String, String> map = new HashMap&lt;String, String>();\n    Map&lt;Object, Object> attributes = new HashMap&lt;Object, Object>();\n\n    // 添加 side、协议版本信息、时间戳和进程号等信息到 map 中\n    map.put(Constants.SIDE_KEY, Constants.CONSUMER_SIDE);\n    map.put(Constants.DUBBO_VERSION_KEY, Version.getProtocolVersion());\n    map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis()));\n    if (ConfigUtils.getPid() > 0) &#123;\n        map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid()));\n    &#125;\n\n    // 非泛化服务\n    if (!isGeneric()) &#123;\n        // 获取版本\n        String revision = Version.getVersion(interfaceClass, version);\n        if (revision != null &amp;&amp; revision.length() > 0) &#123;\n            map.put(\"revision\", revision);\n        &#125;\n\n        // 获取接口方法列表，并添加到 map 中\n        String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames();\n        if (methods.length == 0) &#123;\n            map.put(\"methods\", Constants.ANY_VALUE);\n        &#125; else &#123;\n            map.put(\"methods\", StringUtils.join(new HashSet&lt;String>(Arrays.asList(methods)), \",\"));\n        &#125;\n    &#125;\n    map.put(Constants.INTERFACE_KEY, interfaceName);\n    // 将 ApplicationConfig、ConsumerConfig、ReferenceConfig 等对象的字段信息添加到 map 中\n    appendParameters(map, application);\n    appendParameters(map, module);\n    appendParameters(map, consumer, Constants.DEFAULT_KEY);\n    appendParameters(map, this);\n    \n\t// -------------------------------✨ 分割线4 ✨------------------------------\n    \n    String prefix = StringUtils.getServiceKey(map);\n    if (methods != null &amp;&amp; !methods.isEmpty()) &#123;\n        // 遍历 MethodConfig 列表\n        for (MethodConfig method : methods) &#123;\n            appendParameters(map, method, method.getName());\n            String retryKey = method.getName() + \".retry\";\n            // 检测 map 是否包含 methodName.retry\n            if (map.containsKey(retryKey)) &#123;\n                String retryValue = map.remove(retryKey);\n                if (\"false\".equals(retryValue)) &#123;\n                    // 添加重试次数配置 methodName.retries\n                    map.put(method.getName() + \".retries\", \"0\");\n                &#125;\n            &#125;\n \n            // 添加 MethodConfig 中的“属性”字段到 attributes\n            // 比如 onreturn、onthrow、oninvoke 等\n            appendAttributes(attributes, method, prefix + \".\" + method.getName());\n            checkAndConvertImplicitConfig(method, map, attributes);\n        &#125;\n    &#125;\n    \n\t// -------------------------------✨ 分割线5 ✨------------------------------\n\n    // 获取服务消费者 ip 地址\n    String hostToRegistry = ConfigUtils.getSystemProperty(Constants.DUBBO_IP_TO_REGISTRY);\n    if (hostToRegistry == null || hostToRegistry.length() == 0) &#123;\n        hostToRegistry = NetUtils.getLocalHost();\n    &#125; else if (isInvalidLocalHost(hostToRegistry)) &#123;\n        throw new IllegalArgumentException(\"Specified invalid registry ip from property...\" );\n    &#125;\n    map.put(Constants.REGISTER_IP_KEY, hostToRegistry);\n\n    // 存储 attributes 到系统上下文中\n    StaticContext.getSystemContext().putAll(attributes);\n\n    // 创建代理类\n    ref = createProxy(map);\n\n    // 根据服务名，ReferenceConfig，代理类构建 ConsumerModel，\n    // 并将 ConsumerModel 存入到 ApplicationModel 中\n    ConsumerModel consumerModel = new ConsumerModel(getUniqueServiceName(), this, ref, interfaceClass.getMethods());\n    ApplicationModel.initConsumerModel(getUniqueServiceName(), consumerModel);\n&#125;\n\n\n上面的代码很长，做的事情比较多。这里根据代码逻辑，对代码进行了分块，下面我们一起来看一下。\n首先是方法开始到分割线1之间的代码。这段代码主要用于检测 ConsumerConfig 实例是否存在，如不存在则创建一个新的实例，然后通过系统变量或 dubbo.properties 配置文件填充 ConsumerConfig 的字段。接着是检测泛化配置，并根据配置设置 interfaceClass 的值。接着来看分割线1到分割线2之间的逻辑。这段逻辑用于从系统属性或配置文件中加载与接口名相对应的配置，并将解析结果赋值给 url 字段。url 字段的作用一般是用于点对点调用。继续向下看，分割线2和分割线3之间的代码用于检测几个核心配置类是否为空，为空则尝试从其他配置类中获取。分割线3与分割线4之间的代码主要用于收集各种配置，并将配置存储到 map 中。分割线4和分割线5之间的代码用于处理 MethodConfig 实例。该实例包含了事件通知配置，比如 onreturn、onthrow、oninvoke 等。分割线5到方法结尾的代码主要用于解析服务消费者 ip，以及调用 createProxy 创建代理对象。关于该方法的详细分析，将会在接下来的章节中展开。\n\n3.2 引用服务本节我们要从 createProxy 开始看起。从字面意思上来看，createProxy 似乎只是用于创建代理对象的。但实际上并非如此，该方法还会调用其他方法构建以及合并 Invoker 实例。具体细节如下。\nprivate T createProxy(Map&lt;String, String> map) &#123;\n    URL tmpUrl = new URL(\"temp\", \"localhost\", 0, map);\n    final boolean isJvmRefer;\n    if (isInjvm() == null) &#123;\n        // url 配置被指定，则不做本地引用\n        if (url != null &amp;&amp; url.length() > 0) &#123;\n            isJvmRefer = false;\n        // 根据 url 的协议、scope 以及 injvm 等参数检测是否需要本地引用\n        // 比如如果用户显式配置了 scope=local，此时 isInjvmRefer 返回 true\n        &#125; else if (InjvmProtocol.getInjvmProtocol().isInjvmRefer(tmpUrl)) &#123;\n            isJvmRefer = true;\n        &#125; else &#123;\n            isJvmRefer = false;\n        &#125;\n    &#125; else &#123;\n        // 获取 injvm 配置值\n        isJvmRefer = isInjvm().booleanValue();\n    &#125;\n\n    // 本地引用\n    if (isJvmRefer) &#123;\n        // 生成本地引用 URL，协议为 injvm\n        URL url = new URL(Constants.LOCAL_PROTOCOL, NetUtils.LOCALHOST, 0, interfaceClass.getName()).addParameters(map);\n        // 调用 refer 方法构建 InjvmInvoker 实例\n        invoker = refprotocol.refer(interfaceClass, url);\n        \n    // 远程引用\n    &#125; else &#123;\n        // url 不为空，表明用户可能想进行点对点调用\n        if (url != null &amp;&amp; url.length() > 0) &#123;\n            // 当需要配置多个 url 时，可用分号进行分割，这里会进行切分\n            String[] us = Constants.SEMICOLON_SPLIT_PATTERN.split(url);\n            if (us != null &amp;&amp; us.length > 0) &#123;\n                for (String u : us) &#123;\n                    URL url = URL.valueOf(u);\n                    if (url.getPath() == null || url.getPath().length() == 0) &#123;\n                        // 设置接口全限定名为 url 路径\n                        url = url.setPath(interfaceName);\n                    &#125;\n                    \n                    // 检测 url 协议是否为 registry，若是，表明用户想使用指定的注册中心\n                    if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123;\n                        // 将 map 转换为查询字符串，并作为 refer 参数的值添加到 url 中\n                        urls.add(url.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map)));\n                    &#125; else &#123;\n                        // 合并 url，移除服务提供者的一些配置（这些配置来源于用户配置的 url 属性），\n                        // 比如线程池相关配置。并保留服务提供者的部分配置，比如版本，group，时间戳等\n                        // 最后将合并后的配置设置为 url 查询字符串中。\n                        urls.add(ClusterUtils.mergeUrl(url, map));\n                    &#125;\n                &#125;\n            &#125;\n        &#125; else &#123;\n            // 加载注册中心 url\n            List&lt;URL> us = loadRegistries(false);\n            if (us != null &amp;&amp; !us.isEmpty()) &#123;\n                for (URL u : us) &#123;\n                    URL monitorUrl = loadMonitor(u);\n                    if (monitorUrl != null) &#123;\n                        map.put(Constants.MONITOR_KEY, URL.encode(monitorUrl.toFullString()));\n                    &#125;\n                    // 添加 refer 参数到 url 中，并将 url 添加到 urls 中\n                    urls.add(u.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map)));\n                &#125;\n            &#125;\n\n            // 未配置注册中心，抛出异常\n            if (urls.isEmpty()) &#123;\n                throw new IllegalStateException(\"No such any registry to reference...\");\n            &#125;\n        &#125;\n\n        // 单个注册中心或服务提供者(服务直连，下同)\n        if (urls.size() == 1) &#123;\n            // 调用 RegistryProtocol 的 refer 构建 Invoker 实例\n            invoker = refprotocol.refer(interfaceClass, urls.get(0));\n            \n        // 多个注册中心或多个服务提供者，或者两者混合\n        &#125; else &#123;\n            List&lt;Invoker&lt;?>> invokers = new ArrayList&lt;Invoker&lt;?>>();\n            URL registryURL = null;\n\n            // 获取所有的 Invoker\n            for (URL url : urls) &#123;\n                // 通过 refprotocol 调用 refer 构建 Invoker，refprotocol 会在运行时\n                // 根据 url 协议头加载指定的 Protocol 实例，并调用实例的 refer 方法\n                invokers.add(refprotocol.refer(interfaceClass, url));\n                if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123;\n                    registryURL = url;\n                &#125;\n            &#125;\n            if (registryURL != null) &#123;\n                // 如果注册中心链接不为空，则将使用 AvailableCluster\n                URL u = registryURL.addParameter(Constants.CLUSTER_KEY, AvailableCluster.NAME);\n                // 创建 StaticDirectory 实例，并由 Cluster 对多个 Invoker 进行合并\n                invoker = cluster.join(new StaticDirectory(u, invokers));\n            &#125; else &#123;\n                invoker = cluster.join(new StaticDirectory(invokers));\n            &#125;\n        &#125;\n    &#125;\n\n    Boolean c = check;\n    if (c == null &amp;&amp; consumer != null) &#123;\n        c = consumer.isCheck();\n    &#125;\n    if (c == null) &#123;\n        c = true;\n    &#125;\n    \n    // invoker 可用性检查\n    if (c &amp;&amp; !invoker.isAvailable()) &#123;\n        throw new IllegalStateException(\"No provider available for the service...\");\n    &#125;\n\n    // 生成代理类\n    return (T) proxyFactory.getProxy(invoker);\n&#125;\n\n\n上面代码很多，不过逻辑比较清晰。首先根据配置检查是否为本地调用，若是，则调用 InjvmProtocol 的 refer 方法生成 InjvmInvoker 实例。若不是，则读取直连配置项，或注册中心 url，并将读取到的 url 存储到 urls 中。然后根据 urls 元素数量进行后续操作。若 urls 元素数量为1，则直接通过 Protocol 自适应拓展类构建 Invoker 实例接口。若 urls 元素数量大于1，即存在多个注册中心或服务直连 url，此时先根据 url 构建 Invoker。然后再通过 Cluster 合并多个 Invoker，最后调用 ProxyFactory 生成代理类。Invoker 的构建过程以及代理类的过程比较重要，因此接下来将分两小节对这两个过程进行分析。\n\n3.2.1 创建 InvokerInvoker 是 Dubbo 的核心模型，代表一个可执行体。在服务提供方，Invoker 用于调用服务提供类。在服务消费方，Invoker 用于执行远程调用。Invoker 是由 Protocol 实现类构建而来。Protocol 实现类有很多，本节会分析最常用的两个，分别是 RegistryProtocol 和 DubboProtocol，其他的大家自行分析。下面先来分析 DubboProtocol 的 refer 方法源码。如下：\npublic &lt;T> Invoker&lt;T> refer(Class&lt;T> serviceType, URL url) throws RpcException &#123;\n    optimizeSerialization(url);\n    // 创建 DubboInvoker\n    DubboInvoker&lt;T> invoker = new DubboInvoker&lt;T>(serviceType, url, getClients(url), invokers);\n    invokers.add(invoker);\n    return invoker;\n&#125;\n\n\n上面方法看起来比较简单，不过这里有一个调用需要我们注意一下，即 getClients。这个方法用于获取客户端实例，实例类型为 ExchangeClient。ExchangeClient 实际上并不具备通信能力，它需要基于更底层的客户端实例进行通信。比如 NettyClient、MinaClient 等，默认情况下，Dubbo 使用 NettyClient 进行通信。接下来，我们简单看一下 getClients 方法的逻辑。\nprivate ExchangeClient[] getClients(URL url) &#123;\n    // 是否共享连接\n    boolean service_share_connect = false;\n  \t// 获取连接数，默认为0，表示未配置\n    int connections = url.getParameter(Constants.CONNECTIONS_KEY, 0);\n    // 如果未配置 connections，则共享连接\n    if (connections == 0) &#123;\n        service_share_connect = true;\n        connections = 1;\n    &#125;\n\n    ExchangeClient[] clients = new ExchangeClient[connections];\n    for (int i = 0; i &lt; clients.length; i++) &#123;\n        if (service_share_connect) &#123;\n            // 获取共享客户端\n            clients[i] = getSharedClient(url);\n        &#125; else &#123;\n            // 初始化新的客户端\n            clients[i] = initClient(url);\n        &#125;\n    &#125;\n    return clients;\n&#125;\n\n\n这里根据 connections 数量决定是获取共享客户端还是创建新的客户端实例，默认情况下，使用共享客户端实例。getSharedClient 方法中也会调用 initClient 方法，因此下面我们一起看一下这两个方法。\nprivate ExchangeClient getSharedClient(URL url) &#123;\n    String key = url.getAddress();\n    // 获取带有“引用计数”功能的 ExchangeClient\n    ReferenceCountExchangeClient client = referenceClientMap.get(key);\n    if (client != null) &#123;\n        if (!client.isClosed()) &#123;\n            // 增加引用计数\n            client.incrementAndGetCount();\n            return client;\n        &#125; else &#123;\n            referenceClientMap.remove(key);\n        &#125;\n    &#125;\n\n    locks.putIfAbsent(key, new Object());\n    synchronized (locks.get(key)) &#123;\n        if (referenceClientMap.containsKey(key)) &#123;\n            return referenceClientMap.get(key);\n        &#125;\n\n        // 创建 ExchangeClient 客户端\n        ExchangeClient exchangeClient = initClient(url);\n        // 将 ExchangeClient 实例传给 ReferenceCountExchangeClient，这里使用了装饰模式\n        client = new ReferenceCountExchangeClient(exchangeClient, ghostClientMap);\n        referenceClientMap.put(key, client);\n        ghostClientMap.remove(key);\n        locks.remove(key);\n        return client;\n    &#125;\n&#125;\n\n\n上面方法先访问缓存，若缓存未命中，则通过 initClient 方法创建新的 ExchangeClient 实例，并将该实例传给 ReferenceCountExchangeClient 构造方法创建一个带有引用计数功能的 ExchangeClient 实例。ReferenceCountExchangeClient 内部实现比较简单，就不分析了。下面我们再来看一下 initClient 方法的代码。\nprivate ExchangeClient initClient(URL url) &#123;\n\n    // 获取客户端类型，默认为 netty\n    String str = url.getParameter(Constants.CLIENT_KEY, url.getParameter(Constants.SERVER_KEY, Constants.DEFAULT_REMOTING_CLIENT));\n\n    // 添加编解码和心跳包参数到 url 中\n    url = url.addParameter(Constants.CODEC_KEY, DubboCodec.NAME);\n    url = url.addParameterIfAbsent(Constants.HEARTBEAT_KEY, String.valueOf(Constants.DEFAULT_HEARTBEAT));\n\n    // 检测客户端类型是否存在，不存在则抛出异常\n    if (str != null &amp;&amp; str.length() > 0 &amp;&amp; !ExtensionLoader.getExtensionLoader(Transporter.class).hasExtension(str)) &#123;\n        throw new RpcException(\"Unsupported client type: ...\");\n    &#125;\n\n    ExchangeClient client;\n    try &#123;\n        // 获取 lazy 配置，并根据配置值决定创建的客户端类型\n        if (url.getParameter(Constants.LAZY_CONNECT_KEY, false)) &#123;\n            // 创建懒加载 ExchangeClient 实例\n            client = new LazyConnectExchangeClient(url, requestHandler);\n        &#125; else &#123;\n            // 创建普通 ExchangeClient 实例\n            client = Exchangers.connect(url, requestHandler);\n        &#125;\n    &#125; catch (RemotingException e) &#123;\n        throw new RpcException(\"Fail to create remoting client for service...\");\n    &#125;\n    return client;\n&#125;\n\n\ninitClient 方法首先获取用户配置的客户端类型，默认为 netty。然后检测用户配置的客户端类型是否存在，不存在则抛出异常。最后根据 lazy 配置决定创建什么类型的客户端。这里的 LazyConnectExchangeClient 代码并不是很复杂，该类会在 request 方法被调用时通过 Exchangers 的 connect 方法创建 ExchangeClient 客户端，该类的代码本节就不分析了。下面我们分析一下 Exchangers 的 connect 方法。\npublic static ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException &#123;\n    if (url == null) &#123;\n        throw new IllegalArgumentException(\"url == null\");\n    &#125;\n    if (handler == null) &#123;\n        throw new IllegalArgumentException(\"handler == null\");\n    &#125;\n    url = url.addParameterIfAbsent(Constants.CODEC_KEY, \"exchange\");\n    // 获取 Exchanger 实例，默认为 HeaderExchangeClient\n    return getExchanger(url).connect(url, handler);\n&#125;\n\n\n如上，getExchanger 会通过 SPI 加载 HeaderExchanger 实例，这个方法比较简单，大家自己看一下吧。接下来分析 HeaderExchanger.connect 的实现。\npublic ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException &#123;\n    // 这里包含了多个调用，分别如下：\n    // 1. 创建 HeaderExchangeHandler 对象\n    // 2. 创建 DecodeHandler 对象\n    // 3. 通过 Transporters 构建 Client 实例\n    // 4. 创建 HeaderExchangeClient 对象\n    return new HeaderExchangeClient(Transporters.connect(url, new DecodeHandler(new HeaderExchangeHandler(handler))), true);\n&#125;\n\n\n\n这里的调用比较多，我们这里重点看一下 Transporters 的 connect 方法。如下：\npublic static Client connect(URL url, ChannelHandler... handlers) throws RemotingException &#123;\n    if (url == null) &#123;\n        throw new IllegalArgumentException(\"url == null\");\n    &#125;\n    ChannelHandler handler;\n    if (handlers == null || handlers.length == 0) &#123;\n        handler = new ChannelHandlerAdapter();\n    &#125; else if (handlers.length == 1) &#123;\n        handler = handlers[0];\n    &#125; else &#123;\n        // 如果 handler 数量大于1，则创建一个 ChannelHandler 分发器\n        handler = new ChannelHandlerDispatcher(handlers);\n    &#125;\n    \n    // 获取 Transporter 自适应拓展类，并调用 connect 方法生成 Client 实例\n    return getTransporter().connect(url, handler);\n&#125;\n\n\n\n如上，getTransporter 方法返回的是自适应拓展类，该类会在运行时根据客户端类型加载指定的 Transporter 实现类。若用户未配置客户端类型，则默认加载 NettyTransporter，并调用该类的 connect 方法。如下：\npublic Client connect(URL url, ChannelHandler listener) throws RemotingException &#123;\n    // 创建 NettyClient 对象\n    return new NettyClient(url, listener);\n&#125;\n\n\n\n到这里就不继续跟下去了，在往下就是通过 Netty 提供的 API 构建 Netty 客户端了，大家有兴趣自己看看。到这里，关于 DubboProtocol 的 refer 方法就分析完了。接下来，继续分析 RegistryProtocol 的 refer 方法逻辑。\npublic &lt;T> Invoker&lt;T> refer(Class&lt;T> type, URL url) throws RpcException &#123;\n    // 取 registry 参数值，并将其设置为协议头\n    url = url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY);\n    // 获取注册中心实例\n    Registry registry = registryFactory.getRegistry(url);\n    if (RegistryService.class.equals(type)) &#123;\n        return proxyFactory.getInvoker((T) registry, type, url);\n    &#125;\n\n    // 将 url 查询字符串转为 Map\n    Map&lt;String, String> qs = StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY));\n    // 获取 group 配置\n    String group = qs.get(Constants.GROUP_KEY);\n    if (group != null &amp;&amp; group.length() > 0) &#123;\n        if ((Constants.COMMA_SPLIT_PATTERN.split(group)).length > 1\n                || \"*\".equals(group)) &#123;\n            // 通过 SPI 加载 MergeableCluster 实例，并调用 doRefer 继续执行服务引用逻辑\n            return doRefer(getMergeableCluster(), registry, type, url);\n        &#125;\n    &#125;\n    \n    // 调用 doRefer 继续执行服务引用逻辑\n    return doRefer(cluster, registry, type, url);\n&#125;\n\n\n\n上面代码首先为 url 设置协议头，然后根据 url 参数加载注册中心实例。然后获取 group 配置，根据 group 配置决定 doRefer 第一个参数的类型。这里的重点是 doRefer 方法，如下：\nprivate &lt;T> Invoker&lt;T> doRefer(Cluster cluster, Registry registry, Class&lt;T> type, URL url) &#123;\n    // 创建 RegistryDirectory 实例\n    RegistryDirectory&lt;T> directory = new RegistryDirectory&lt;T>(type, url);\n    // 设置注册中心和协议\n    directory.setRegistry(registry);\n    directory.setProtocol(protocol);\n    Map&lt;String, String> parameters = new HashMap&lt;String, String>(directory.getUrl().getParameters());\n    // 生成服务消费者链接\n    URL subscribeUrl = new URL(Constants.CONSUMER_PROTOCOL, parameters.remove(Constants.REGISTER_IP_KEY), 0, type.getName(), parameters);\n\n    // 注册服务消费者，在 consumers 目录下新节点\n    if (!Constants.ANY_VALUE.equals(url.getServiceInterface())\n            &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) &#123;\n        registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY,\n                Constants.CHECK_KEY, String.valueOf(false)));\n    &#125;\n\n    // 订阅 providers、configurators、routers 等节点数据\n    directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY,\n            Constants.PROVIDERS_CATEGORY\n                    + \",\" + Constants.CONFIGURATORS_CATEGORY\n                    + \",\" + Constants.ROUTERS_CATEGORY));\n\n    // 一个注册中心可能有多个服务提供者，因此这里需要将多个服务提供者合并为一个\n    Invoker invoker = cluster.join(directory);\n    ProviderConsumerRegTable.registerConsumer(invoker, url, subscribeUrl, directory);\n    return invoker;\n&#125;\n\n\n\n如上，doRefer 方法创建一个 RegistryDirectory 实例，然后生成服务者消费者链接，并向注册中心进行注册。注册完毕后，紧接着订阅 providers、configurators、routers 等节点下的数据。完成订阅后，RegistryDirectory 会收到这几个节点下的子节点信息。由于一个服务可能部署在多台服务器上，这样就会在 providers 产生多个节点，这个时候就需要 Cluster 将多个服务节点合并为一个，并生成一个 Invoker。关于 RegistryDirectory 和 Cluster，本文不打算进行分析，相关分析将会在随后的文章中展开。\n\n3.2.2 创建代理Invoker 创建完毕后，接下来要做的事情是为服务接口生成代理对象。有了代理对象，即可进行远程调用。代理对象生成的入口方法为 ProxyFactory 的 getProxy，接下来进行分析。\npublic &lt;T> T getProxy(Invoker&lt;T> invoker) throws RpcException &#123;\n    // 调用重载方法\n    return getProxy(invoker, false);\n&#125;\n\npublic &lt;T> T getProxy(Invoker&lt;T> invoker, boolean generic) throws RpcException &#123;\n    Class&lt;?>[] interfaces = null;\n    // 获取接口列表\n    String config = invoker.getUrl().getParameter(\"interfaces\");\n    if (config != null &amp;&amp; config.length() > 0) &#123;\n        // 切分接口列表\n        String[] types = Constants.COMMA_SPLIT_PATTERN.split(config);\n        if (types != null &amp;&amp; types.length > 0) &#123;\n            interfaces = new Class&lt;?>[types.length + 2];\n            // 设置服务接口类和 EchoService.class 到 interfaces 中\n            interfaces[0] = invoker.getInterface();\n            interfaces[1] = EchoService.class;\n            for (int i = 0; i &lt; types.length; i++) &#123;\n                // 加载接口类\n                interfaces[i + 1] = ReflectUtils.forName(types[i]);\n            &#125;\n        &#125;\n    &#125;\n    if (interfaces == null) &#123;\n        interfaces = new Class&lt;?>[]&#123;invoker.getInterface(), EchoService.class&#125;;\n    &#125;\n\n    // 为 http 和 hessian 协议提供泛化调用支持，参考 pull request #1827\n    if (!invoker.getInterface().equals(GenericService.class) &amp;&amp; generic) &#123;\n        int len = interfaces.length;\n        Class&lt;?>[] temp = interfaces;\n        // 创建新的 interfaces 数组\n        interfaces = new Class&lt;?>[len + 1];\n        System.arraycopy(temp, 0, interfaces, 0, len);\n        // 设置 GenericService.class 到数组中\n        interfaces[len] = GenericService.class;\n    &#125;\n\n    // 调用重载方法\n    return getProxy(invoker, interfaces);\n&#125;\n\npublic abstract &lt;T> T getProxy(Invoker&lt;T> invoker, Class&lt;?>[] types);\n\n\n\n如上，上面大段代码都是用来获取 interfaces 数组的，我们继续往下看。getProxy(Invoker, Class&lt;?&gt;[]) 这个方法是一个抽象方法，下面我们到 JavassistProxyFactory 类中看一下该方法的实现代码。\npublic &lt;T> T getProxy(Invoker&lt;T> invoker, Class&lt;?>[] interfaces) &#123;\n    // 生成 Proxy 子类（Proxy 是抽象类）。并调用 Proxy 子类的 newInstance 方法创建 Proxy 实例\n    return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker));\n&#125;\n\n\n\n上面代码并不多，首先是通过 Proxy 的 getProxy 方法获取 Proxy 子类，然后创建 InvokerInvocationHandler 对象，并将该对象传给 newInstance 生成 Proxy 实例。InvokerInvocationHandler 实现 JDK 的 InvocationHandler 接口，具体的用途是拦截接口类调用。该类逻辑比较简单，这里就不分析了。下面我们重点关注一下 Proxy 的 getProxy 方法，如下。\npublic static Proxy getProxy(Class&lt;?>... ics) &#123;\n    // 调用重载方法\n    return getProxy(ClassHelper.getClassLoader(Proxy.class), ics);\n&#125;\n\npublic static Proxy getProxy(ClassLoader cl, Class&lt;?>... ics) &#123;\n    if (ics.length > 65535)\n        throw new IllegalArgumentException(\"interface limit exceeded\");\n\n    StringBuilder sb = new StringBuilder();\n    // 遍历接口列表\n    for (int i = 0; i &lt; ics.length; i++) &#123;\n        String itf = ics[i].getName();\n        // 检测类型是否为接口\n        if (!ics[i].isInterface())\n            throw new RuntimeException(itf + \" is not a interface.\");\n\n        Class&lt;?> tmp = null;\n        try &#123;\n            // 重新加载接口类\n            tmp = Class.forName(itf, false, cl);\n        &#125; catch (ClassNotFoundException e) &#123;\n        &#125;\n\n        // 检测接口是否相同，这里 tmp 有可能为空\n        if (tmp != ics[i])\n            throw new IllegalArgumentException(ics[i] + \" is not visible from class loader\");\n\n        // 拼接接口全限定名，分隔符为 ;\n        sb.append(itf).append(';');\n    &#125;\n\n    // 使用拼接后的接口名作为 key\n    String key = sb.toString();\n\n    Map&lt;String, Object> cache;\n    synchronized (ProxyCacheMap) &#123;\n        cache = ProxyCacheMap.get(cl);\n        if (cache == null) &#123;\n            cache = new HashMap&lt;String, Object>();\n            ProxyCacheMap.put(cl, cache);\n        &#125;\n    &#125;\n\n    Proxy proxy = null;\n    synchronized (cache) &#123;\n        do &#123;\n            // 从缓存中获取 Reference&lt;Proxy> 实例\n            Object value = cache.get(key);\n            if (value instanceof Reference&lt;?>) &#123;\n                proxy = (Proxy) ((Reference&lt;?>) value).get();\n                if (proxy != null) &#123;\n                    return proxy;\n                &#125;\n            &#125;\n\n            // 并发控制，保证只有一个线程可以进行后续操作\n            if (value == PendingGenerationMarker) &#123;\n                try &#123;\n                    // 其他线程在此处进行等待\n                    cache.wait();\n                &#125; catch (InterruptedException e) &#123;\n                &#125;\n            &#125; else &#123;\n                // 放置标志位到缓存中，并跳出 while 循环进行后续操作\n                cache.put(key, PendingGenerationMarker);\n                break;\n            &#125;\n        &#125;\n        while (true);\n    &#125;\n\n    long id = PROXY_CLASS_COUNTER.getAndIncrement();\n    String pkg = null;\n    ClassGenerator ccp = null, ccm = null;\n    try &#123;\n        // 创建 ClassGenerator 对象\n        ccp = ClassGenerator.newInstance(cl);\n\n        Set&lt;String> worked = new HashSet&lt;String>();\n        List&lt;Method> methods = new ArrayList&lt;Method>();\n\n        for (int i = 0; i &lt; ics.length; i++) &#123;\n            // 检测接口访问级别是否为 protected 或 private\n            if (!Modifier.isPublic(ics[i].getModifiers())) &#123;\n                // 获取接口包名\n                String npkg = ics[i].getPackage().getName();\n                if (pkg == null) &#123;\n                    pkg = npkg;\n                &#125; else &#123;\n                    if (!pkg.equals(npkg))\n                        // 非 public 级别的接口必须在同一个包下，否者抛出异常\n                        throw new IllegalArgumentException(\"non-public interfaces from different packages\");\n                &#125;\n            &#125;\n            \n            // 添加接口到 ClassGenerator 中\n            ccp.addInterface(ics[i]);\n\n            // 遍历接口方法\n            for (Method method : ics[i].getMethods()) &#123;\n                // 获取方法描述，可理解为方法签名\n                String desc = ReflectUtils.getDesc(method);\n                // 如果方法描述字符串已在 worked 中，则忽略。考虑这种情况，\n                // A 接口和 B 接口中包含一个完全相同的方法\n                if (worked.contains(desc))\n                    continue;\n                worked.add(desc);\n\n                int ix = methods.size();\n                // 获取方法返回值类型\n                Class&lt;?> rt = method.getReturnType();\n                // 获取参数列表\n                Class&lt;?>[] pts = method.getParameterTypes();\n\n                // 生成 Object[] args = new Object[1...N]\n                StringBuilder code = new StringBuilder(\"Object[] args = new Object[\").append(pts.length).append(\"];\");\n                for (int j = 0; j &lt; pts.length; j++)\n                    // 生成 args[1...N] = ($w)$1...N;\n                    code.append(\" args[\").append(j).append(\"] = ($w)$\").append(j + 1).append(\";\");\n                // 生成 InvokerHandler 接口的 invoker 方法调用语句，如下：\n                // Object ret = handler.invoke(this, methods[1...N], args);\n                code.append(\" Object ret = handler.invoke(this, methods[\" + ix + \"], args);\");\n\n                // 返回值不为 void\n                if (!Void.TYPE.equals(rt))\n                    // 生成返回语句，形如 return (java.lang.String) ret;\n                    code.append(\" return \").append(asArgument(rt, \"ret\")).append(\";\");\n\n                methods.add(method);\n                // 添加方法名、访问控制符、参数列表、方法代码等信息到 ClassGenerator 中 \n                ccp.addMethod(method.getName(), method.getModifiers(), rt, pts, method.getExceptionTypes(), code.toString());\n            &#125;\n        &#125;\n\n        if (pkg == null)\n            pkg = PACKAGE_NAME;\n\n        // 构建接口代理类名称：pkg + \".proxy\" + id，比如 org.apache.dubbo.proxy0\n        String pcn = pkg + \".proxy\" + id;\n        ccp.setClassName(pcn);\n        ccp.addField(\"public static java.lang.reflect.Method[] methods;\");\n        // 生成 private java.lang.reflect.InvocationHandler handler;\n        ccp.addField(\"private \" + InvocationHandler.class.getName() + \" handler;\");\n\n        // 为接口代理类添加带有 InvocationHandler 参数的构造方法，比如：\n        // porxy0(java.lang.reflect.InvocationHandler arg0) &#123;\n        //     handler=$1;\n    \t// &#125;\n        ccp.addConstructor(Modifier.PUBLIC, new Class&lt;?>[]&#123;InvocationHandler.class&#125;, new Class&lt;?>[0], \"handler=$1;\");\n        // 为接口代理类添加默认构造方法\n        ccp.addDefaultConstructor();\n        \n        // 生成接口代理类\n        Class&lt;?> clazz = ccp.toClass();\n        clazz.getField(\"methods\").set(null, methods.toArray(new Method[0]));\n\n        // 构建 Proxy 子类名称，比如 Proxy1，Proxy2 等\n        String fcn = Proxy.class.getName() + id;\n        ccm = ClassGenerator.newInstance(cl);\n        ccm.setClassName(fcn);\n        ccm.addDefaultConstructor();\n        ccm.setSuperClass(Proxy.class);\n        // 为 Proxy 的抽象方法 newInstance 生成实现代码，形如：\n        // public Object newInstance(java.lang.reflect.InvocationHandler h) &#123; \n        //     return new org.apache.dubbo.proxy0($1);\n        // &#125;\n        ccm.addMethod(\"public Object newInstance(\" + InvocationHandler.class.getName() + \" h)&#123; return new \" + pcn + \"($1); &#125;\");\n        // 生成 Proxy 实现类\n        Class&lt;?> pc = ccm.toClass();\n        // 通过反射创建 Proxy 实例\n        proxy = (Proxy) pc.newInstance();\n    &#125; catch (RuntimeException e) &#123;\n        throw e;\n    &#125; catch (Exception e) &#123;\n        throw new RuntimeException(e.getMessage(), e);\n    &#125; finally &#123;\n        if (ccp != null)\n            // 释放资源\n            ccp.release();\n        if (ccm != null)\n            ccm.release();\n        synchronized (cache) &#123;\n            if (proxy == null)\n                cache.remove(key);\n            else\n                // 写缓存\n                cache.put(key, new WeakReference&lt;Proxy>(proxy));\n            // 唤醒其他等待线程\n            cache.notifyAll();\n        &#125;\n    &#125;\n    return proxy;\n&#125;\n\n\n\n上面代码比较复杂，我们写了大量的注释。大家在阅读这段代码时，要搞清楚 ccp 和 ccm 的用途，不然会被搞晕。ccp 用于为服务接口生成代理类，比如我们有一个 DemoService 接口，这个接口代理类就是由 ccp 生成的。ccm 则是用于为 org.apache.dubbo.common.bytecode.Proxy 抽象类生成子类，主要是实现 Proxy 类的抽象方法。下面以 org.apache.dubbo.demo.DemoService 这个接口为例，来看一下该接口代理类代码大致是怎样的（忽略 EchoService 接口）。\npackage org.apache.dubbo.common.bytecode;\n\npublic class proxy0 implements org.apache.dubbo.demo.DemoService &#123;\n\n    public static java.lang.reflect.Method[] methods;\n\n    private java.lang.reflect.InvocationHandler handler;\n\n    public proxy0() &#123;\n    &#125;\n\n    public proxy0(java.lang.reflect.InvocationHandler arg0) &#123;\n        handler = $1;\n    &#125;\n\n    public java.lang.String sayHello(java.lang.String arg0) &#123;\n        Object[] args = new Object[1];\n        args[0] = ($w) $1;\n        Object ret = handler.invoke(this, methods[0], args);\n        return (java.lang.String) ret;\n    &#125;\n&#125;\n\n\n\n好了，到这里代理类生成逻辑就分析完了。整个过程比较复杂，大家需要耐心看一下。\n\n4.总结本篇文章对服务引用的过程进行了较为详尽的分析，还有一些逻辑暂时没有分析到，比如 Directory、Cluster。这些接口及实现类功能比较独立，后续会单独成文进行分析。暂时我们可以先把这些类看成黑盒，只要知道这些类的用途即可。关于服务引用过程就分析到这里。\n\n\n\n\n\n\n\n\n\n原文地址：https://dubbo.apache.org/zh/docsv2.7/dev/source/export-service/\n作者： Dubbo 官方\n本文介绍了 Dubbo 服务导出的过程和实现细节\n服务调用过程1.简介本篇文章，我们来研究一下 Dubbo 导出服务的过程。Dubbo 服务导出过程始于 Spring 容器发布刷新事件，Dubbo 在接收到事件后，会立即执行服务导出逻辑。整个逻辑大致可分为三个部分，第一部分是前置工作，主要用于检查参数，组装 URL。第二部分是导出服务，包含导出服务到本地 (JVM)，和导出服务到远程两个过程。第三部分是向注册中心注册服务，用于服务发现。本篇文章将会对这三个部分代码进行详细的分析。\n\n2.源码分析服务导出的入口方法是 ServiceBean 的 onApplicationEvent。onApplicationEvent 是一个事件响应方法，该方法会在收到 Spring 上下文刷新事件后执行服务导出操作。方法代码如下：\npublic void onApplicationEvent(ContextRefreshedEvent event) &#123;\n    // 是否有延迟导出 &amp;&amp; 是否已导出 &amp;&amp; 是不是已被取消导出\n    if (isDelay() &amp;&amp; !isExported() &amp;&amp; !isUnexported()) &#123;\n        // 导出服务\n        export();\n    &#125;\n&#125;\n\n\n\n这个方法首先会根据条件决定是否导出服务，比如有些服务设置了延时导出，那么此时就不应该在此处导出。还有一些服务已经被导出了，或者当前服务被取消导出了，此时也不能再次导出相关服务。注意这里的 isDelay 方法，这个方法字面意思是“是否延迟导出服务”，返回 true 表示延迟导出，false 表示不延迟导出。但是该方法真实意思却并非如此，当方法返回 true 时，表示无需延迟导出。返回 false 时，表示需要延迟导出。与字面意思恰恰相反，这个需要大家注意一下。下面我们来看一下这个方法的逻辑。\n// -☆- ServiceBean\nprivate boolean isDelay() &#123;\n    // 获取 delay\n    Integer delay = getDelay();\n    ProviderConfig provider = getProvider();\n    if (delay == null &amp;&amp; provider != null) &#123;\n        // 如果前面获取的 delay 为空，这里继续获取\n        delay = provider.getDelay();\n    &#125;\n    // 判断 delay 是否为空，或者等于 -1\n    return supportedApplicationListener &amp;&amp; (delay == null || delay == -1);\n&#125;\n\n\n\n暂时忽略 supportedApplicationListener 这个条件，当 delay 为空，或者等于-1时，该方法返回 true，而不是 false。这个方法的返回值让人有点困惑。该方法目前已被重构，详细请参考 dubbo #2686。\n现在解释一下 supportedApplicationListener 变量含义，该变量用于表示当前的 Spring 容器是否支持 ApplicationListener，这个值初始为 false。在 Spring 容器将自己设置到 ServiceBean 中时，ServiceBean 的 setApplicationContext 方法会检测 Spring 容器是否支持 ApplicationListener。若支持，则将 supportedApplicationListener 置为 true。ServiceBean 是 Dubbo 与 Spring 框架进行整合的关键，可以看做是两个框架之间的桥梁。具有同样作用的类还有 ReferenceBean。\n现在我们知道了 Dubbo 服务导出过程的起点，接下来对服务导出的前置逻辑进行分析。\n\n2.1 前置工作前置工作主要包含两个部分，分别是配置检查，以及 URL 装配。在导出服务之前，Dubbo 需要检查用户的配置是否合理，或者为用户补充缺省配置。配置检查完成后，接下来需要根据这些配置组装 URL。在 Dubbo 中，URL 的作用十分重要。Dubbo 使用 URL 作为配置载体，所有的拓展点都是通过 URL 获取配置。这一点，官方文档中有所说明。\n\n\n\n\n\n\n\n\n\n采用 URL 作为配置信息的统一格式，所有扩展点都通过传递 URL 携带配置信息。\n接下来，我们先来分析配置检查部分的源码，随后再来分析 URL 组装部分的源码。\n\n2.1.1 检查配置本节我们接着前面的源码向下分析，前面说过 onApplicationEvent 方法在经过一些判断后，会决定是否调用 export 方法导出服务。那么下面我们从 export 方法开始进行分析，如下：\npublic synchronized void export() &#123;\n    if (provider != null) &#123;\n        // 获取 export 和 delay 配置\n        if (export == null) &#123;\n            export = provider.getExport();\n        &#125;\n        if (delay == null) &#123;\n            delay = provider.getDelay();\n        &#125;\n    &#125;\n    // 如果 export 为 false，则不导出服务\n    if (export != null &amp;&amp; !export) &#123;\n        return;\n    &#125;\n\n    // delay > 0，延时导出服务\n    if (delay != null &amp;&amp; delay > 0) &#123;\n        delayExportExecutor.schedule(new Runnable() &#123;\n            @Override\n            public void run() &#123;\n                doExport();\n            &#125;\n        &#125;, delay, TimeUnit.MILLISECONDS);\n        \n    // 立即导出服务\n    &#125; else &#123;\n        doExport();\n    &#125;\n&#125;\n\n\n\nexport 方法对两项配置进行了检查，并根据配置执行相应的动作。首先是 export 配置，这个配置决定了是否导出服务。有时候我们只是想本地启动服务进行一些调试工作，我们并不希望把本地启动的服务暴露出去给别人调用。此时，我们可通过配置 export 禁止服务导出，比如：\n&lt;dubbo:provider export=\"false\" />\n\n\n\ndelay 配置顾名思义，用于延迟导出服务，这个就不分析了。下面，我们继续分析源码，这次要分析的是 doExport 方法。\nprotected synchronized void doExport() &#123;\n    if (unexported) &#123;\n        throw new IllegalStateException(\"Already unexported!\");\n    &#125;\n    if (exported) &#123;\n        return;\n    &#125;\n    exported = true;\n    // 检测 interfaceName 是否合法\n    if (interfaceName == null || interfaceName.length() == 0) &#123;\n        throw new IllegalStateException(\"interface not allow null!\");\n    &#125;\n    // 检测 provider 是否为空，为空则新建一个，并通过系统变量为其初始化\n    checkDefault();\n\n    // 下面几个 if 语句用于检测 provider、application 等核心配置类对象是否为空，\n    // 若为空，则尝试从其他配置类对象中获取相应的实例。\n    if (provider != null) &#123;\n        if (application == null) &#123;\n            application = provider.getApplication();\n        &#125;\n        if (module == null) &#123;\n            module = provider.getModule();\n        &#125;\n        if (registries == null) &#123;...&#125;\n        if (monitor == null) &#123;...&#125;\n        if (protocols == null) &#123;...&#125;\n    &#125;\n    if (module != null) &#123;\n        if (registries == null) &#123;\n            registries = module.getRegistries();\n        &#125;\n        if (monitor == null) &#123;...&#125;\n    &#125;\n    if (application != null) &#123;\n        if (registries == null) &#123;\n            registries = application.getRegistries();\n        &#125;\n        if (monitor == null) &#123;...&#125;\n    &#125;\n\n    // 检测 ref 是否为泛化服务类型\n    if (ref instanceof GenericService) &#123;\n        // 设置 interfaceClass 为 GenericService.class\n        interfaceClass = GenericService.class;\n        if (StringUtils.isEmpty(generic)) &#123;\n            // 设置 generic = \"true\"\n            generic = Boolean.TRUE.toString();\n        &#125;\n        \n    // ref 非 GenericService 类型\n    &#125; else &#123;\n        try &#123;\n            interfaceClass = Class.forName(interfaceName, true, Thread.currentThread()\n                    .getContextClassLoader());\n        &#125; catch (ClassNotFoundException e) &#123;\n            throw new IllegalStateException(e.getMessage(), e);\n        &#125;\n        // 对 interfaceClass，以及 &lt;dubbo:method> 标签中的必要字段进行检查\n        checkInterfaceAndMethods(interfaceClass, methods);\n        // 对 ref 合法性进行检测\n        checkRef();\n        // 设置 generic = \"false\"\n        generic = Boolean.FALSE.toString();\n    &#125;\n\n    // local 和 stub 在功能应该是一致的，用于配置本地存根\n    if (local != null) &#123;\n        if (\"true\".equals(local)) &#123;\n            local = interfaceName + \"Local\";\n        &#125;\n        Class&lt;?> localClass;\n        try &#123;\n            // 获取本地存根类\n            localClass = ClassHelper.forNameWithThreadContextClassLoader(local);\n        &#125; catch (ClassNotFoundException e) &#123;\n            throw new IllegalStateException(e.getMessage(), e);\n        &#125;\n        // 检测本地存根类是否可赋值给接口类，若不可赋值则会抛出异常，提醒使用者本地存根类类型不合法\n        if (!interfaceClass.isAssignableFrom(localClass)) &#123;\n            throw new IllegalStateException(\"The local implementation class \" + localClass.getName() + \" not implement interface \" + interfaceName);\n        &#125;\n    &#125;\n\n    if (stub != null) &#123;\n        // 此处的代码和上一个 if 分支的代码基本一致，这里省略\n    &#125;\n\n    // 检测各种对象是否为空，为空则新建，或者抛出异常\n    checkApplication();\n    checkRegistry();\n    checkProtocol();\n    appendProperties(this);\n    checkStubAndMock(interfaceClass);\n    if (path == null || path.length() == 0) &#123;\n        path = interfaceName;\n    &#125;\n\n    // 导出服务\n    doExportUrls();\n\n    // ProviderModel 表示服务提供者模型，此对象中存储了与服务提供者相关的信息。\n    // 比如服务的配置信息，服务实例等。每个被导出的服务对应一个 ProviderModel。\n    // ApplicationModel 持有所有的 ProviderModel。\n    ProviderModel providerModel = new ProviderModel(getUniqueServiceName(), this, ref);\n    ApplicationModel.initProviderModel(getUniqueServiceName(), providerModel);\n&#125;\n\n\n\n以上就是配置检查的相关分析，代码比较多，需要大家耐心看一下。下面对配置检查的逻辑进行简单的总结，如下：\n\n检测 dubbo:service 标签的 interface 属性合法性，不合法则抛出异常\n检测 ProviderConfig、ApplicationConfig 等核心配置类对象是否为空，若为空，则尝试从其他配置类对象中获取相应的实例。\n检测并处理泛化服务和普通服务类\n检测本地存根配置，并进行相应的处理\n对 ApplicationConfig、RegistryConfig 等配置类进行检测，为空则尝试创建，若无法创建则抛出异常\n\n配置检查并非本文重点，因此这里不打算对 doExport 方法所调用的方法进行分析（doExportUrls 方法除外）。在这些方法中，除了 appendProperties 方法稍微复杂一些，其他方法逻辑不是很复杂。因此，大家可自行分析。\n\n2.1.2 多协议多注册中心导出服务Dubbo 允许我们使用不同的协议导出服务，也允许我们向多个注册中心注册服务。Dubbo 在 doExportUrls 方法中对多协议，多注册中心进行了支持。相关代码如下：\nprivate void doExportUrls() &#123;\n    // 加载注册中心链接\n    List&lt;URL> registryURLs = loadRegistries(true);\n    // 遍历 protocols，并在每个协议下导出服务\n    for (ProtocolConfig protocolConfig : protocols) &#123;\n        doExportUrlsFor1Protocol(protocolConfig, registryURLs);\n    &#125;\n&#125;\n\n\n\n上面代码首先是通过 loadRegistries 加载注册中心链接，然后再遍历 ProtocolConfig 集合导出每个服务。并在导出服务的过程中，将服务注册到注册中心。下面，我们先来看一下 loadRegistries 方法的逻辑。\nprotected List&lt;URL> loadRegistries(boolean provider) &#123;\n    // 检测是否存在注册中心配置类，不存在则抛出异常\n    checkRegistry();\n    List&lt;URL> registryList = new ArrayList&lt;URL>();\n    if (registries != null &amp;&amp; !registries.isEmpty()) &#123;\n        for (RegistryConfig config : registries) &#123;\n            String address = config.getAddress();\n            if (address == null || address.length() == 0) &#123;\n                // 若 address 为空，则将其设为 0.0.0.0\n                address = Constants.ANYHOST_VALUE;\n            &#125;\n\n            // 从系统属性中加载注册中心地址\n            String sysaddress = System.getProperty(\"dubbo.registry.address\");\n            if (sysaddress != null &amp;&amp; sysaddress.length() > 0) &#123;\n                address = sysaddress;\n            &#125;\n            // 检测 address 是否合法\n            if (address.length() > 0 &amp;&amp; !RegistryConfig.NO_AVAILABLE.equalsIgnoreCase(address)) &#123;\n                Map&lt;String, String> map = new HashMap&lt;String, String>();\n                // 添加 ApplicationConfig 中的字段信息到 map 中\n                appendParameters(map, application);\n                // 添加 RegistryConfig 字段信息到 map 中\n                appendParameters(map, config);\n                \n                // 添加 path、pid，protocol 等信息到 map 中\n                map.put(\"path\", RegistryService.class.getName());\n                map.put(\"dubbo\", Version.getProtocolVersion());\n                map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis()));\n                if (ConfigUtils.getPid() > 0) &#123;\n                    map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid()));\n                &#125;\n                if (!map.containsKey(\"protocol\")) &#123;\n                    if (ExtensionLoader.getExtensionLoader(RegistryFactory.class).hasExtension(\"remote\")) &#123;\n                        map.put(\"protocol\", \"remote\");\n                    &#125; else &#123;\n                        map.put(\"protocol\", \"dubbo\");\n                    &#125;\n                &#125;\n\n                // 解析得到 URL 列表，address 可能包含多个注册中心 ip，\n                // 因此解析得到的是一个 URL 列表\n                List&lt;URL> urls = UrlUtils.parseURLs(address, map);\n                for (URL url : urls) &#123;\n                    url = url.addParameter(Constants.REGISTRY_KEY, url.getProtocol());\n                    // 将 URL 协议头设置为 registry\n                    url = url.setProtocol(Constants.REGISTRY_PROTOCOL);\n                    // 通过判断条件，决定是否添加 url 到 registryList 中，条件如下：\n                    // (服务提供者 &amp;&amp; register = true 或 null) \n                    //    || (非服务提供者 &amp;&amp; subscribe = true 或 null)\n                    if ((provider &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true))\n                            || (!provider &amp;&amp; url.getParameter(Constants.SUBSCRIBE_KEY, true))) &#123;\n                        registryList.add(url);\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n    return registryList;\n&#125;\n\n\n\nloadRegistries 方法主要包含如下的逻辑：\n\n检测是否存在注册中心配置类，不存在则抛出异常\n构建参数映射集合，也就是 map\n构建注册中心链接列表\n遍历链接列表，并根据条件决定是否将其添加到 registryList 中\n\n关于多协议多注册中心导出服务就先分析到这，代码不是很多，接下来分析 URL 组装过程。\n\n2.1.3 组装 URL配置检查完毕后，紧接着要做的事情是根据配置，以及其他一些信息组装 URL。前面说过，URL 是 Dubbo 配置的载体，通过 URL 可让 Dubbo 的各种配置在各个模块之间传递。URL 之于 Dubbo，犹如水之于鱼，非常重要。大家在阅读 Dubbo 服务导出相关源码的过程中，要注意 URL 内容的变化。既然 URL 如此重要，那么下面我们来了解一下 URL 组装的过程。\nprivate void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List&lt;URL> registryURLs) &#123;\n    String name = protocolConfig.getName();\n    // 如果协议名为空，或空串，则将协议名变量设置为 dubbo\n    if (name == null || name.length() == 0) &#123;\n        name = \"dubbo\";\n    &#125;\n\n    Map&lt;String, String> map = new HashMap&lt;String, String>();\n    // 添加 side、版本、时间戳以及进程号等信息到 map 中\n    map.put(Constants.SIDE_KEY, Constants.PROVIDER_SIDE);\n    map.put(Constants.DUBBO_VERSION_KEY, Version.getProtocolVersion());\n    map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis()));\n    if (ConfigUtils.getPid() > 0) &#123;\n        map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid()));\n    &#125;\n\n    // 通过反射将对象的字段信息添加到 map 中\n    appendParameters(map, application);\n    appendParameters(map, module);\n    appendParameters(map, provider, Constants.DEFAULT_KEY);\n    appendParameters(map, protocolConfig);\n    appendParameters(map, this);\n\n    // methods 为 MethodConfig 集合，MethodConfig 中存储了 &lt;dubbo:method> 标签的配置信息\n    if (methods != null &amp;&amp; !methods.isEmpty()) &#123;\n        // 这段代码用于添加 Callback 配置到 map 中，代码太长，待会单独分析\n    &#125;\n\n    // 检测 generic 是否为 \"true\"，并根据检测结果向 map 中添加不同的信息\n    if (ProtocolUtils.isGeneric(generic)) &#123;\n        map.put(Constants.GENERIC_KEY, generic);\n        map.put(Constants.METHODS_KEY, Constants.ANY_VALUE);\n    &#125; else &#123;\n        String revision = Version.getVersion(interfaceClass, version);\n        if (revision != null &amp;&amp; revision.length() > 0) &#123;\n            map.put(\"revision\", revision);\n        &#125;\n\n        // 为接口生成包裹类 Wrapper，Wrapper 中包含了接口的详细信息，比如接口方法名数组，字段信息等\n        String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames();\n        // 添加方法名到 map 中，如果包含多个方法名，则用逗号隔开，比如 method = init,destroy\n        if (methods.length == 0) &#123;\n            logger.warn(\"NO method found in service interface ...\");\n            map.put(Constants.METHODS_KEY, Constants.ANY_VALUE);\n        &#125; else &#123;\n            // 将逗号作为分隔符连接方法名，并将连接后的字符串放入 map 中\n            map.put(Constants.METHODS_KEY, StringUtils.join(new HashSet&lt;String>(Arrays.asList(methods)), \",\"));\n        &#125;\n    &#125;\n\n    // 添加 token 到 map 中\n    if (!ConfigUtils.isEmpty(token)) &#123;\n        if (ConfigUtils.isDefault(token)) &#123;\n            // 随机生成 token\n            map.put(Constants.TOKEN_KEY, UUID.randomUUID().toString());\n        &#125; else &#123;\n            map.put(Constants.TOKEN_KEY, token);\n        &#125;\n    &#125;\n    // 判断协议名是否为 injvm\n    if (Constants.LOCAL_PROTOCOL.equals(protocolConfig.getName())) &#123;\n        protocolConfig.setRegister(false);\n        map.put(\"notify\", \"false\");\n    &#125;\n\n    // 获取上下文路径\n    String contextPath = protocolConfig.getContextpath();\n    if ((contextPath == null || contextPath.length() == 0) &amp;&amp; provider != null) &#123;\n        contextPath = provider.getContextpath();\n    &#125;\n\n    // 获取 host 和 port\n    String host = this.findConfigedHosts(protocolConfig, registryURLs, map);\n    Integer port = this.findConfigedPorts(protocolConfig, name, map);\n    // 组装 URL\n    URL url = new URL(name, host, port, (contextPath == null || contextPath.length() == 0 ? \"\" : contextPath + \"/\") + path, map);\n    \n    // 省略无关代码\n&#125;\n\n\n\n上面的代码首先是将一些信息，比如版本、时间戳、方法名以及各种配置对象的字段信息放入到 map 中，map 中的内容将作为 URL 的查询字符串。构建好 map 后，紧接着是获取上下文路径、主机名以及端口号等信息。最后将 map 和主机名等数据传给 URL 构造方法创建 URL 对象。需要注意的是，这里出现的 URL 并非 java.net.URL，而是 com.alibaba.dubbo.common.URL。\n上面省略了一段代码，这里简单分析一下。这段代码用于检测 dubbo:method 标签中的配置信息，并将相关配置添加到 map 中。代码如下：\nprivate void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List&lt;URL> registryURLs) &#123;\n    // ...\n\n    // methods 为 MethodConfig 集合，MethodConfig 中存储了 &lt;dubbo:method> 标签的配置信息\n    if (methods != null &amp;&amp; !methods.isEmpty()) &#123;\n        for (MethodConfig method : methods) &#123;\n            // 添加 MethodConfig 对象的字段信息到 map 中，键 = 方法名.属性名。\n            // 比如存储 &lt;dubbo:method name=\"sayHello\" retries=\"2\"> 对应的 MethodConfig，\n            // 键 = sayHello.retries，map = &#123;\"sayHello.retries\": 2, \"xxx\": \"yyy\"&#125;\n            appendParameters(map, method, method.getName());\n\n            String retryKey = method.getName() + \".retry\";\n            if (map.containsKey(retryKey)) &#123;\n                String retryValue = map.remove(retryKey);\n                // 检测 MethodConfig retry 是否为 false，若是，则设置重试次数为0\n                if (\"false\".equals(retryValue)) &#123;\n                    map.put(method.getName() + \".retries\", \"0\");\n                &#125;\n            &#125;\n            \n            // 获取 ArgumentConfig 列表\n            List&lt;ArgumentConfig> arguments = method.getArguments();\n            if (arguments != null &amp;&amp; !arguments.isEmpty()) &#123;\n                for (ArgumentConfig argument : arguments) &#123;\n                    // 检测 type 属性是否为空，或者空串（分支1 ⭐️）\n                    if (argument.getType() != null &amp;&amp; argument.getType().length() > 0) &#123;\n                        Method[] methods = interfaceClass.getMethods();\n                        if (methods != null &amp;&amp; methods.length > 0) &#123;\n                            for (int i = 0; i &lt; methods.length; i++) &#123;\n                                String methodName = methods[i].getName();\n                                // 比对方法名，查找目标方法\n                                if (methodName.equals(method.getName())) &#123;\n                                    Class&lt;?>[] argtypes = methods[i].getParameterTypes();\n                                    if (argument.getIndex() != -1) &#123;\n                                        // 检测 ArgumentConfig 中的 type 属性与方法参数列表\n                                        // 中的参数名称是否一致，不一致则抛出异常(分支2 ⭐️)\n                                        if (argtypes[argument.getIndex()].getName().equals(argument.getType())) &#123;\n                                            // 添加 ArgumentConfig 字段信息到 map 中，\n                                            // 键前缀 = 方法名.index，比如:\n                                            // map = &#123;\"sayHello.3\": true&#125;\n                                            appendParameters(map, argument, method.getName() + \".\" + argument.getIndex());\n                                        &#125; else &#123;\n                                            throw new IllegalArgumentException(\"argument config error: ...\");\n                                        &#125;\n                                    &#125; else &#123;    // 分支3 ⭐️\n                                        for (int j = 0; j &lt; argtypes.length; j++) &#123;\n                                            Class&lt;?> argclazz = argtypes[j];\n                                            // 从参数类型列表中查找类型名称为 argument.type 的参数\n                                            if (argclazz.getName().equals(argument.getType())) &#123;\n                                                appendParameters(map, argument, method.getName() + \".\" + j);\n                                                if (argument.getIndex() != -1 &amp;&amp; argument.getIndex() != j) &#123;\n                                                    throw new IllegalArgumentException(\"argument config error: ...\");\n                                                &#125;\n                                            &#125;\n                                        &#125;\n                                    &#125;\n                                &#125;\n                            &#125;\n                        &#125;\n\n                    // 用户未配置 type 属性，但配置了 index 属性，且 index != -1\n                    &#125; else if (argument.getIndex() != -1) &#123;    // 分支4 ⭐️\n                        // 添加 ArgumentConfig 字段信息到 map 中\n                        appendParameters(map, argument, method.getName() + \".\" + argument.getIndex());\n                    &#125; else &#123;\n                        throw new IllegalArgumentException(\"argument config must set index or type\");\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n\n    // ...\n&#125;\n\n\n\n上面这段代码 for 循环和 if else 分支嵌套太多，导致层次太深，不利于阅读，需要耐心看一下。大家在看这段代码时，注意把几个重要的条件分支找出来。只要理解了这几个分支的意图，就可以弄懂这段代码。请注意上面代码中⭐️符号，这几个符号标识出了4个重要的分支，下面用伪代码解释一下这几个分支的含义。\n// 获取 ArgumentConfig 列表\nfor (遍历 ArgumentConfig 列表) &#123;\n    if (type 不为 null，也不为空串) &#123;    // 分支1\n        1. 通过反射获取 interfaceClass 的方法列表\n        for (遍历方法列表) &#123;\n            1. 比对方法名，查找目标方法\n        \t2. 通过反射获取目标方法的参数类型数组 argtypes\n            if (index != -1) &#123;    // 分支2\n                1. 从 argtypes 数组中获取下标 index 处的元素 argType\n                2. 检测 argType 的名称与 ArgumentConfig 中的 type 属性是否一致\n                3. 添加 ArgumentConfig 字段信息到 map 中，或抛出异常\n            &#125; else &#123;    // 分支3\n                1. 遍历参数类型数组 argtypes，查找 argument.type 类型的参数\n                2. 添加 ArgumentConfig 字段信息到 map 中\n            &#125;\n        &#125;\n    &#125; else if (index != -1) &#123;    // 分支4\n\t\t1. 添加 ArgumentConfig 字段信息到 map 中\n    &#125;\n&#125;\n\n\n\n在本节分析的源码中，appendParameters 这个方法出现的次数比较多，该方法用于将对象字段信息添加到 map 中。实现上则是通过反射获取目标对象的 getter 方法，并调用该方法获取属性值。然后再通过 getter 方法名解析出属性名，比如从方法名 getName 中可解析出属性 name。如果用户传入了属性名前缀，此时需要将属性名加入前缀内容。最后将 &lt;属性名，属性值&gt; 键值对存入到 map 中就行了。限于篇幅原因，这里就不分析 appendParameters 方法的源码了，大家请自行分析。\n\n2.2 导出 Dubbo 服务前置工作做完，接下来就可以进行服务导出了。服务导出分为导出到本地 (JVM)，和导出到远程。在深入分析服务导出的源码前，我们先来从宏观层面上看一下服务导出逻辑。如下：\nprivate void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List&lt;URL> registryURLs) &#123;\n    \n    // 省略无关代码\n    \n    if (ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class)\n            .hasExtension(url.getProtocol())) &#123;\n        // 加载 ConfiguratorFactory，并生成 Configurator 实例，然后通过实例配置 url\n        url = ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class)\n                .getExtension(url.getProtocol()).getConfigurator(url).configure(url);\n    &#125;\n\n    String scope = url.getParameter(Constants.SCOPE_KEY);\n    // 如果 scope = none，则什么都不做\n    if (!Constants.SCOPE_NONE.toString().equalsIgnoreCase(scope)) &#123;\n        // scope != remote，导出到本地\n        if (!Constants.SCOPE_REMOTE.toString().equalsIgnoreCase(scope)) &#123;\n            exportLocal(url);\n        &#125;\n\n        // scope != local，导出到远程\n        if (!Constants.SCOPE_LOCAL.toString().equalsIgnoreCase(scope)) &#123;\n            if (registryURLs != null &amp;&amp; !registryURLs.isEmpty()) &#123;\n                for (URL registryURL : registryURLs) &#123;\n                    url = url.addParameterIfAbsent(Constants.DYNAMIC_KEY, registryURL.getParameter(Constants.DYNAMIC_KEY));\n                    // 加载监视器链接\n                    URL monitorUrl = loadMonitor(registryURL);\n                    if (monitorUrl != null) &#123;\n                        // 将监视器链接作为参数添加到 url 中\n                        url = url.addParameterAndEncoded(Constants.MONITOR_KEY, monitorUrl.toFullString());\n                    &#125;\n\n                    String proxy = url.getParameter(Constants.PROXY_KEY);\n                    if (StringUtils.isNotEmpty(proxy)) &#123;\n                        registryURL = registryURL.addParameter(Constants.PROXY_KEY, proxy);\n                    &#125;\n\n                    // 为服务提供类(ref)生成 Invoker\n                    Invoker&lt;?> invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString()));\n                    // DelegateProviderMetaDataInvoker 用于持有 Invoker 和 ServiceConfig\n                    DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this);\n\n                    // 导出服务，并生成 Exporter\n                    Exporter&lt;?> exporter = protocol.export(wrapperInvoker);\n                    exporters.add(exporter);\n                &#125;\n                \n            // 不存在注册中心，仅导出服务\n            &#125; else &#123;\n                Invoker&lt;?> invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, url);\n                DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this);\n\n                Exporter&lt;?> exporter = protocol.export(wrapperInvoker);\n                exporters.add(exporter);\n            &#125;\n        &#125;\n    &#125;\n    this.urls.add(url);\n&#125;\n\n\n\n上面代码根据 url 中的 scope 参数决定服务导出方式，分别如下：\n\nscope &#x3D; none，不导出服务\nscope !&#x3D; remote，导出到本地\nscope !&#x3D; local，导出到远程\n\n不管是导出到本地，还是远程。进行服务导出之前，均需要先创建 Invoker，这是一个很重要的步骤。因此下面先来分析 Invoker 的创建过程。\n\n2.2.1 Invoker 创建过程在 Dubbo 中，Invoker 是一个非常重要的模型。在服务提供端，以及服务引用端均会出现 Invoker。Dubbo 官方文档中对 Invoker 进行了说明，这里引用一下。\n\n\n\n\n\n\n\n\n\nInvoker 是实体域，它是 Dubbo 的核心模型，其它模型都向它靠扰，或转换成它，它代表一个可执行体，可向它发起 invoke 调用，它有可能是一个本地的实现，也可能是一个远程的实现，也可能一个集群实现。\n既然 Invoker 如此重要，那么我们很有必要搞清楚 Invoker 的用途。Invoker 是由 ProxyFactory 创建而来，Dubbo 默认的 ProxyFactory 实现类是 JavassistProxyFactory。下面我们到 JavassistProxyFactory 代码中，探索 Invoker 的创建过程。如下：\npublic &lt;T> Invoker&lt;T> getInvoker(T proxy, Class&lt;T> type, URL url) &#123;\n\t// 为目标类创建 Wrapper\n    final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') &lt; 0 ? proxy.getClass() : type);\n    // 创建匿名 Invoker 类对象，并实现 doInvoke 方法。\n    return new AbstractProxyInvoker&lt;T>(proxy, type, url) &#123;\n        @Override\n        protected Object doInvoke(T proxy, String methodName,\n                                  Class&lt;?>[] parameterTypes,\n                                  Object[] arguments) throws Throwable &#123;\n\t\t\t// 调用 Wrapper 的 invokeMethod 方法，invokeMethod 最终会调用目标方法\n            return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments);\n        &#125;\n    &#125;;\n&#125;\n\n\n\n如上，JavassistProxyFactory 创建了一个继承自 AbstractProxyInvoker 类的匿名对象，并覆写了抽象方法 doInvoke。覆写后的 doInvoke 逻辑比较简单，仅是将调用请求转发给了 Wrapper 类的 invokeMethod 方法。Wrapper 用于“包裹”目标类，Wrapper 是一个抽象类，仅可通过 getWrapper(Class) 方法创建子类。在创建 Wrapper 子类的过程中，子类代码生成逻辑会对 getWrapper 方法传入的 Class 对象进行解析，拿到诸如类方法，类成员变量等信息。以及生成 invokeMethod 方法代码和其他一些方法代码。代码生成完毕后，通过 Javassist 生成 Class 对象，最后再通过反射创建 Wrapper 实例。相关的代码如下：\n public static Wrapper getWrapper(Class&lt;?> c) &#123;\t\n    while (ClassGenerator.isDynamicClass(c))\n        c = c.getSuperclass();\n\n    if (c == Object.class)\n        return OBJECT_WRAPPER;\n\n    // 从缓存中获取 Wrapper 实例\n    Wrapper ret = WRAPPER_MAP.get(c);\n    if (ret == null) &#123;\n        // 缓存未命中，创建 Wrapper\n        ret = makeWrapper(c);\n        // 写入缓存\n        WRAPPER_MAP.put(c, ret);\n    &#125;\n    return ret;\n&#125;\n\n\n\ngetWrapper 方法仅包含一些缓存操作逻辑，不难理解。下面我们看一下 makeWrapper 方法。\nprivate static Wrapper makeWrapper(Class&lt;?> c) &#123;\n    // 检测 c 是否为基本类型，若是则抛出异常\n    if (c.isPrimitive())\n        throw new IllegalArgumentException(\"Can not create wrapper for primitive type: \" + c);\n\n    String name = c.getName();\n    ClassLoader cl = ClassHelper.getClassLoader(c);\n\n    // c1 用于存储 setPropertyValue 方法代码\n    StringBuilder c1 = new StringBuilder(\"public void setPropertyValue(Object o, String n, Object v)&#123; \");\n    // c2 用于存储 getPropertyValue 方法代码\n    StringBuilder c2 = new StringBuilder(\"public Object getPropertyValue(Object o, String n)&#123; \");\n    // c3 用于存储 invokeMethod 方法代码\n    StringBuilder c3 = new StringBuilder(\"public Object invokeMethod(Object o, String n, Class[] p, Object[] v) throws \" + InvocationTargetException.class.getName() + \"&#123; \");\n\n    // 生成类型转换代码及异常捕捉代码，比如：\n    //   DemoService w; try &#123; w = ((DemoServcie) $1); &#125;&#125;catch(Throwable e)&#123; throw new IllegalArgumentException(e); &#125;\n    c1.append(name).append(\" w; try&#123; w = ((\").append(name).append(\")$1); &#125;catch(Throwable e)&#123; throw new IllegalArgumentException(e); &#125;\");\n    c2.append(name).append(\" w; try&#123; w = ((\").append(name).append(\")$1); &#125;catch(Throwable e)&#123; throw new IllegalArgumentException(e); &#125;\");\n    c3.append(name).append(\" w; try&#123; w = ((\").append(name).append(\")$1); &#125;catch(Throwable e)&#123; throw new IllegalArgumentException(e); &#125;\");\n\n    // pts 用于存储成员变量名和类型\n    Map&lt;String, Class&lt;?>> pts = new HashMap&lt;String, Class&lt;?>>();\n    // ms 用于存储方法描述信息（可理解为方法签名）及 Method 实例\n    Map&lt;String, Method> ms = new LinkedHashMap&lt;String, Method>();\n    // mns 为方法名列表\n    List&lt;String> mns = new ArrayList&lt;String>();\n    // dmns 用于存储“定义在当前类中的方法”的名称\n    List&lt;String> dmns = new ArrayList&lt;String>();\n\n    // --------------------------------✨ 分割线1 ✨-------------------------------------\n\n    // 获取 public 访问级别的字段，并为所有字段生成条件判断语句\n    for (Field f : c.getFields()) &#123;\n        String fn = f.getName();\n        Class&lt;?> ft = f.getType();\n        if (Modifier.isStatic(f.getModifiers()) || Modifier.isTransient(f.getModifiers()))\n            // 忽略关键字 static 或 transient 修饰的变量\n            continue;\n\n        // 生成条件判断及赋值语句，比如：\n        // if( $2.equals(\"name\") ) &#123; w.name = (java.lang.String) $3; return;&#125;\n        // if( $2.equals(\"age\") ) &#123; w.age = ((Number) $3).intValue(); return;&#125;\n        c1.append(\" if( $2.equals(\\\"\").append(fn).append(\"\\\") )&#123; w.\").append(fn).append(\"=\").append(arg(ft, \"$3\")).append(\"; return; &#125;\");\n\n        // 生成条件判断及返回语句，比如：\n        // if( $2.equals(\"name\") ) &#123; return ($w)w.name; &#125;\n        c2.append(\" if( $2.equals(\\\"\").append(fn).append(\"\\\") )&#123; return ($w)w.\").append(fn).append(\"; &#125;\");\n\n        // 存储 &lt;字段名, 字段类型> 键值对到 pts 中\n        pts.put(fn, ft);\n    &#125;\n\n    // --------------------------------✨ 分割线2 ✨-------------------------------------\n\n    Method[] methods = c.getMethods();\n    // 检测 c 中是否包含在当前类中声明的方法\n    boolean hasMethod = hasMethods(methods);\n    if (hasMethod) &#123;\n        c3.append(\" try&#123;\");\n    &#125;\n    for (Method m : methods) &#123;\n        if (m.getDeclaringClass() == Object.class)\n            // 忽略 Object 中定义的方法\n            continue;\n\n        String mn = m.getName();\n        // 生成方法名判断语句，比如：\n        // if ( \"sayHello\".equals( $2 )\n        c3.append(\" if( \\\"\").append(mn).append(\"\\\".equals( $2 ) \");\n        int len = m.getParameterTypes().length;\n        // 生成“运行时传入的参数数量与方法参数列表长度”判断语句，比如：\n        // &amp;&amp; $3.length == 2\n        c3.append(\" &amp;&amp; \").append(\" $3.length == \").append(len);\n\n        boolean override = false;\n        for (Method m2 : methods) &#123;\n            // 检测方法是否存在重载情况，条件为：方法对象不同 &amp;&amp; 方法名相同\n            if (m != m2 &amp;&amp; m.getName().equals(m2.getName())) &#123;\n                override = true;\n                break;\n            &#125;\n        &#125;\n        // 对重载方法进行处理，考虑下面的方法：\n        //    1. void sayHello(Integer, String)\n        //    2. void sayHello(Integer, Integer)\n        // 方法名相同，参数列表长度也相同，因此不能仅通过这两项判断两个方法是否相等。\n        // 需要进一步判断方法的参数类型\n        if (override) &#123;\n            if (len > 0) &#123;\n                for (int l = 0; l &lt; len; l++) &#123;\n                    // 生成参数类型进行检测代码，比如：\n                    // &amp;&amp; $3[0].getName().equals(\"java.lang.Integer\") \n                    //    &amp;&amp; $3[1].getName().equals(\"java.lang.String\")\n                    c3.append(\" &amp;&amp; \").append(\" $3[\").append(l).append(\"].getName().equals(\\\"\")\n                            .append(m.getParameterTypes()[l].getName()).append(\"\\\")\");\n                &#125;\n            &#125;\n        &#125;\n\n        // 添加 ) &#123;，完成方法判断语句，此时生成的代码可能如下（已格式化）：\n        // if (\"sayHello\".equals($2) \n        //     &amp;&amp; $3.length == 2\n        //     &amp;&amp; $3[0].getName().equals(\"java.lang.Integer\") \n        //     &amp;&amp; $3[1].getName().equals(\"java.lang.String\")) &#123;\n        c3.append(\" ) &#123; \");\n\n        // 根据返回值类型生成目标方法调用语句\n        if (m.getReturnType() == Void.TYPE)\n            // w.sayHello((java.lang.Integer)$4[0], (java.lang.String)$4[1]); return null;\n            c3.append(\" w.\").append(mn).append('(').append(args(m.getParameterTypes(), \"$4\")).append(\");\").append(\" return null;\");\n        else\n            // return w.sayHello((java.lang.Integer)$4[0], (java.lang.String)$4[1]);\n            c3.append(\" return ($w)w.\").append(mn).append('(').append(args(m.getParameterTypes(), \"$4\")).append(\");\");\n\n        // 添加 &#125;, 生成的代码形如（已格式化）：\n        // if (\"sayHello\".equals($2) \n        //     &amp;&amp; $3.length == 2\n        //     &amp;&amp; $3[0].getName().equals(\"java.lang.Integer\") \n        //     &amp;&amp; $3[1].getName().equals(\"java.lang.String\")) &#123;\n        //\n        //     w.sayHello((java.lang.Integer)$4[0], (java.lang.String)$4[1]); \n        //     return null;\n        // &#125;\n        c3.append(\" &#125;\");\n\n        // 添加方法名到 mns 集合中\n        mns.add(mn);\n        // 检测当前方法是否在 c 中被声明的\n        if (m.getDeclaringClass() == c)\n            // 若是，则将当前方法名添加到 dmns 中\n            dmns.add(mn);\n        ms.put(ReflectUtils.getDesc(m), m);\n    &#125;\n    if (hasMethod) &#123;\n        // 添加异常捕捉语句\n        c3.append(\" &#125; catch(Throwable e) &#123; \");\n        c3.append(\"     throw new java.lang.reflect.InvocationTargetException(e); \");\n        c3.append(\" &#125;\");\n    &#125;\n\n    // 添加 NoSuchMethodException 异常抛出代码\n    c3.append(\" throw new \" + NoSuchMethodException.class.getName() + \"(\\\"Not found method \\\\\\\"\\\"+$2+\\\"\\\\\\\" in class \" + c.getName() + \".\\\"); &#125;\");\n\n    // --------------------------------✨ 分割线3 ✨-------------------------------------\n\n    Matcher matcher;\n    // 处理 get/set 方法\n    for (Map.Entry&lt;String, Method> entry : ms.entrySet()) &#123;\n        String md = entry.getKey();\n        Method method = (Method) entry.getValue();\n        // 匹配以 get 开头的方法\n        if ((matcher = ReflectUtils.GETTER_METHOD_DESC_PATTERN.matcher(md)).matches()) &#123;\n            // 获取属性名\n            String pn = propertyName(matcher.group(1));\n            // 生成属性判断以及返回语句，示例如下：\n            // if( $2.equals(\"name\") ) &#123; return ($w).w.getName(); &#125;\n            c2.append(\" if( $2.equals(\\\"\").append(pn).append(\"\\\") )&#123; return ($w)w.\").append(method.getName()).append(\"(); &#125;\");\n            pts.put(pn, method.getReturnType());\n\n        // 匹配以 is/has/can 开头的方法\n        &#125; else if ((matcher = ReflectUtils.IS_HAS_CAN_METHOD_DESC_PATTERN.matcher(md)).matches()) &#123;\n            String pn = propertyName(matcher.group(1));\n            // 生成属性判断以及返回语句，示例如下：\n            // if( $2.equals(\"dream\") ) &#123; return ($w).w.hasDream(); &#125;\n            c2.append(\" if( $2.equals(\\\"\").append(pn).append(\"\\\") )&#123; return ($w)w.\").append(method.getName()).append(\"(); &#125;\");\n            pts.put(pn, method.getReturnType());\n\n        // 匹配以 set 开头的方法\n        &#125; else if ((matcher = ReflectUtils.SETTER_METHOD_DESC_PATTERN.matcher(md)).matches()) &#123;\n            Class&lt;?> pt = method.getParameterTypes()[0];\n            String pn = propertyName(matcher.group(1));\n            // 生成属性判断以及 setter 调用语句，示例如下：\n            // if( $2.equals(\"name\") ) &#123; w.setName((java.lang.String)$3); return; &#125;\n            c1.append(\" if( $2.equals(\\\"\").append(pn).append(\"\\\") )&#123; w.\").append(method.getName()).append(\"(\").append(arg(pt, \"$3\")).append(\"); return; &#125;\");\n            pts.put(pn, pt);\n        &#125;\n    &#125;\n\n    // 添加 NoSuchPropertyException 异常抛出代码\n    c1.append(\" throw new \" + NoSuchPropertyException.class.getName() + \"(\\\"Not found property \\\\\\\"\\\"+$2+\\\"\\\\\\\" filed or setter method in class \" + c.getName() + \".\\\"); &#125;\");\n    c2.append(\" throw new \" + NoSuchPropertyException.class.getName() + \"(\\\"Not found property \\\\\\\"\\\"+$2+\\\"\\\\\\\" filed or setter method in class \" + c.getName() + \".\\\"); &#125;\");\n\n    // --------------------------------✨ 分割线4 ✨-------------------------------------\n\n    long id = WRAPPER_CLASS_COUNTER.getAndIncrement();\n    // 创建类生成器\n    ClassGenerator cc = ClassGenerator.newInstance(cl);\n    // 设置类名及超类\n    cc.setClassName((Modifier.isPublic(c.getModifiers()) ? Wrapper.class.getName() : c.getName() + \"$sw\") + id);\n    cc.setSuperClass(Wrapper.class);\n\n    // 添加默认构造方法\n    cc.addDefaultConstructor();\n\n    // 添加字段\n    cc.addField(\"public static String[] pns;\");\n    cc.addField(\"public static \" + Map.class.getName() + \" pts;\");\n    cc.addField(\"public static String[] mns;\");\n    cc.addField(\"public static String[] dmns;\");\n    for (int i = 0, len = ms.size(); i &lt; len; i++)\n        cc.addField(\"public static Class[] mts\" + i + \";\");\n\n    // 添加方法代码\n    cc.addMethod(\"public String[] getPropertyNames()&#123; return pns; &#125;\");\n    cc.addMethod(\"public boolean hasProperty(String n)&#123; return pts.containsKey($1); &#125;\");\n    cc.addMethod(\"public Class getPropertyType(String n)&#123; return (Class)pts.get($1); &#125;\");\n    cc.addMethod(\"public String[] getMethodNames()&#123; return mns; &#125;\");\n    cc.addMethod(\"public String[] getDeclaredMethodNames()&#123; return dmns; &#125;\");\n    cc.addMethod(c1.toString());\n    cc.addMethod(c2.toString());\n    cc.addMethod(c3.toString());\n\n    try &#123;\n        // 生成类\n        Class&lt;?> wc = cc.toClass();\n        \n        // 设置字段值\n        wc.getField(\"pts\").set(null, pts);\n        wc.getField(\"pns\").set(null, pts.keySet().toArray(new String[0]));\n        wc.getField(\"mns\").set(null, mns.toArray(new String[0]));\n        wc.getField(\"dmns\").set(null, dmns.toArray(new String[0]));\n        int ix = 0;\n        for (Method m : ms.values())\n            wc.getField(\"mts\" + ix++).set(null, m.getParameterTypes());\n\n        // 创建 Wrapper 实例\n        return (Wrapper) wc.newInstance();\n    &#125; catch (RuntimeException e) &#123;\n        throw e;\n    &#125; catch (Throwable e) &#123;\n        throw new RuntimeException(e.getMessage(), e);\n    &#125; finally &#123;\n        cc.release();\n        ms.clear();\n        mns.clear();\n        dmns.clear();\n    &#125;\n&#125;\n\n\n\n上面代码很长，大家耐心看一下。我们在上面代码中做了大量的注释，并按功能对代码进行了分块，以帮助大家理解代码逻辑。下面对这段代码进行讲解。首先我们把目光移到分割线1之上的代码，这段代码主要用于进行一些初始化操作。比如创建 c1、c2、c3 以及 pts、ms、mns 等变量，以及向 c1、c2、c3 中添加方法定义和类型转换代码。接下来是分割线1到分割线2之间的代码，这段代码用于为 public 级别的字段生成条件判断取值与赋值代码。这段代码不是很难看懂，就不多说了。继续向下看，分割线2和分隔线3之间的代码用于为定义在当前类中的方法生成判断语句，和方法调用语句。因为需要对方法重载进行校验，因此到这这段代码看起来有点复杂。不过耐心看一下，也不是很难理解。接下来是分割线3和分隔线4之间的代码，这段代码用于处理 getter、setter 以及以 is&#x2F;has&#x2F;can 开头的方法。处理方式是通过正则表达式获取方法类型（get&#x2F;set&#x2F;is&#x2F;…），以及属性名。之后为属性名生成判断语句，然后为方法生成调用语句。最后我们再来看一下分隔线4以下的代码，这段代码通过 ClassGenerator 为刚刚生成的代码构建 Class 类，并通过反射创建对象。ClassGenerator 是 Dubbo 自己封装的，该类的核心是 toClass() 的重载方法 toClass(ClassLoader, ProtectionDomain)，该方法通过 javassist 构建 Class。这里就不分析 toClass 方法了，大家请自行分析。\n阅读 Wrapper 类代码需要对 javassist 框架有所了解。关于 javassist，大家如果不熟悉，请自行查阅资料，本节不打算介绍 javassist 相关内容。\n好了，关于 Wrapper 类生成过程就分析到这。如果大家看的不是很明白，可以单独为 Wrapper 创建单元测试，然后单步调试。并将生成的代码拷贝出来，格式化后再进行观察和理解。\n\n2.2.2 导出服务到本地本节我们来看一下服务导出相关的代码，按照代码执行顺序，本节先来分析导出服务到本地的过程。相关代码如下：\nprivate void exportLocal(URL url) &#123;\n    // 如果 URL 的协议头等于 injvm，说明已经导出到本地了，无需再次导出\n    if (!Constants.LOCAL_PROTOCOL.equalsIgnoreCase(url.getProtocol())) &#123;\n        URL local = URL.valueOf(url.toFullString())\n            .setProtocol(Constants.LOCAL_PROTOCOL)    // 设置协议头为 injvm\n            .setHost(LOCALHOST)\n            .setPort(0);\n        ServiceClassHolder.getInstance().pushServiceClass(getServiceClass(ref));\n        // 创建 Invoker，并导出服务，这里的 protocol 会在运行时调用 InjvmProtocol 的 export 方法\n        Exporter&lt;?> exporter = protocol.export(\n            proxyFactory.getInvoker(ref, (Class) interfaceClass, local));\n        exporters.add(exporter);\n    &#125;\n&#125;\n\n\n\nexportLocal 方法比较简单，首先根据 URL 协议头决定是否导出服务。若需导出，则创建一个新的 URL 并将协议头、主机名以及端口设置成新的值。然后创建 Invoker，并调用 InjvmProtocol 的 export 方法导出服务。下面我们来看一下 InjvmProtocol 的 export 方法都做了哪些事情。\npublic &lt;T> Exporter&lt;T> export(Invoker&lt;T> invoker) throws RpcException &#123;\n    // 创建 InjvmExporter\n    return new InjvmExporter&lt;T>(invoker, invoker.getUrl().getServiceKey(), exporterMap);\n&#125;\n\n\n\n如上，InjvmProtocol 的 export 方法仅创建了一个 InjvmExporter，无其他逻辑。到此导出服务到本地就分析完了，接下来，我们继续分析导出服务到远程的过程。\n\n2.2.3 导出服务到远程与导出服务到本地相比，导出服务到远程的过程要复杂不少，其包含了服务导出与服务注册两个过程。这两个过程涉及到了大量的调用，比较复杂。按照代码执行顺序，本节先来分析服务导出逻辑，服务注册逻辑将在下一节进行分析。下面开始分析，我们把目光移动到 RegistryProtocol 的 export 方法上。\npublic &lt;T> Exporter&lt;T> export(final Invoker&lt;T> originInvoker) throws RpcException &#123;\n    // 导出服务\n    final ExporterChangeableWrapper&lt;T> exporter = doLocalExport(originInvoker);\n\n    // 获取注册中心 URL，以 zookeeper 注册中心为例，得到的示例 URL 如下：\n    // zookeeper://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService?application=demo-provider&amp;dubbo=2.0.2&amp;export=dubbo%3A%2F%2F172.17.48.52%3A20880%2Fcom.alibaba.dubbo.demo.DemoService%3Fanyhost%3Dtrue%26application%3Ddemo-provider\n    URL registryUrl = getRegistryUrl(originInvoker);\n\n    // 根据 URL 加载 Registry 实现类，比如 ZookeeperRegistry\n    final Registry registry = getRegistry(originInvoker);\n    \n    // 获取已注册的服务提供者 URL，比如：\n    // dubbo://172.17.48.52:20880/com.alibaba.dubbo.demo.DemoService?anyhost=true&amp;application=demo-provider&amp;dubbo=2.0.2&amp;generic=false&amp;interface=com.alibaba.dubbo.demo.DemoService&amp;methods=sayHello\n    final URL registeredProviderUrl = getRegisteredProviderUrl(originInvoker);\n\n    // 获取 register 参数\n    boolean register = registeredProviderUrl.getParameter(\"register\", true);\n\n    // 向服务提供者与消费者注册表中注册服务提供者\n    ProviderConsumerRegTable.registerProvider(originInvoker, registryUrl, registeredProviderUrl);\n\n    // 根据 register 的值决定是否注册服务\n    if (register) &#123;\n        // 向注册中心注册服务\n        register(registryUrl, registeredProviderUrl);\n        ProviderConsumerRegTable.getProviderWrapper(originInvoker).setReg(true);\n    &#125;\n\n    // 获取订阅 URL，比如：\n    // provider://172.17.48.52:20880/com.alibaba.dubbo.demo.DemoService?category=configurators&amp;check=false&amp;anyhost=true&amp;application=demo-provider&amp;dubbo=2.0.2&amp;generic=false&amp;interface=com.alibaba.dubbo.demo.DemoService&amp;methods=sayHello\n    final URL overrideSubscribeUrl = getSubscribedOverrideUrl(registeredProviderUrl);\n    // 创建监听器\n    final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl, originInvoker);\n    overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener);\n    // 向注册中心进行订阅 override 数据\n    registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener);\n    // 创建并返回 DestroyableExporter\n    return new DestroyableExporter&lt;T>(exporter, originInvoker, overrideSubscribeUrl, registeredProviderUrl);\n&#125;\n\n\n\n\n上面代码看起来比较复杂，主要做如下一些操作：\n\n调用 doLocalExport 导出服务\n向注册中心注册服务\n向注册中心进行订阅 override 数据\n创建并返回 DestroyableExporter\n\n在以上操作中，除了创建并返回 DestroyableExporter 没什么难度外，其他几步操作都不是很简单。这其中，导出服务和注册服务是本章要重点分析的逻辑。 订阅 override 数据并非本文重点内容，后面会简单介绍一下。下面先来分析 doLocalExport 方法的逻辑，如下：\nprivate &lt;T> ExporterChangeableWrapper&lt;T> doLocalExport(final Invoker&lt;T> originInvoker) &#123;\n    String key = getCacheKey(originInvoker);\n    // 访问缓存\n    ExporterChangeableWrapper&lt;T> exporter = (ExporterChangeableWrapper&lt;T>) bounds.get(key);\n    if (exporter == null) &#123;\n        synchronized (bounds) &#123;\n            exporter = (ExporterChangeableWrapper&lt;T>) bounds.get(key);\n            if (exporter == null) &#123;\n                // 创建 Invoker 为委托类对象\n                final Invoker&lt;?> invokerDelegete = new InvokerDelegete&lt;T>(originInvoker, getProviderUrl(originInvoker));\n                // 调用 protocol 的 export 方法导出服务\n                exporter = new ExporterChangeableWrapper&lt;T>((Exporter&lt;T>) protocol.export(invokerDelegete), originInvoker);\n                \n                // 写缓存\n                bounds.put(key, exporter);\n            &#125;\n        &#125;\n    &#125;\n    return exporter;\n&#125;\n\n\n\n\n上面的代码是典型的双重检查锁，大家在阅读 Dubbo 的源码中，会多次见到。接下来，我们把重点放在 Protocol 的 export 方法上。假设运行时协议为 dubbo，此处的 protocol 变量会在运行时加载 DubboProtocol，并调用 DubboProtocol 的 export 方法。所以，接下来我们目光转移到 DubboProtocol 的 export 方法上，相关分析如下：\npublic &lt;T> Exporter&lt;T> export(Invoker&lt;T> invoker) throws RpcException &#123;\n    URL url = invoker.getUrl();\n\n    // 获取服务标识，理解成服务坐标也行。由服务组名，服务名，服务版本号以及端口组成。比如：\n    // demoGroup/com.alibaba.dubbo.demo.DemoService:1.0.1:20880\n    String key = serviceKey(url);\n    // 创建 DubboExporter\n    DubboExporter&lt;T> exporter = new DubboExporter&lt;T>(invoker, key, exporterMap);\n    // 将 &lt;key, exporter> 键值对放入缓存中\n    exporterMap.put(key, exporter);\n\n    // 本地存根相关代码\n    Boolean isStubSupportEvent = url.getParameter(Constants.STUB_EVENT_KEY, Constants.DEFAULT_STUB_EVENT);\n    Boolean isCallbackservice = url.getParameter(Constants.IS_CALLBACK_SERVICE, false);\n    if (isStubSupportEvent &amp;&amp; !isCallbackservice) &#123;\n        String stubServiceMethods = url.getParameter(Constants.STUB_EVENT_METHODS_KEY);\n        if (stubServiceMethods == null || stubServiceMethods.length() == 0) &#123;\n            // 省略日志打印代码\n        &#125; else &#123;\n            stubServiceMethodsMap.put(url.getServiceKey(), stubServiceMethods);\n        &#125;\n    &#125;\n\n    // 启动服务器\n    openServer(url);\n    // 优化序列化\n    optimizeSerialization(url);\n    return exporter;\n&#125;\n\n\n\n\n如上，我们重点关注 DubboExporter 的创建以及 openServer 方法，其他逻辑看不懂也没关系，不影响理解服务导出过程。另外，DubboExporter 的代码比较简单，就不分析了。下面分析 openServer 方法。\nprivate void openServer(URL url) &#123;\n    // 获取 host:port，并将其作为服务器实例的 key，用于标识当前的服务器实例\n    String key = url.getAddress();\n    boolean isServer = url.getParameter(Constants.IS_SERVER_KEY, true);\n    if (isServer) &#123;\n        // 访问缓存\n        ExchangeServer server = serverMap.get(key);\n        if (server == null) &#123;\n            // 创建服务器实例\n            serverMap.put(key, createServer(url));\n        &#125; else &#123;\n            // 服务器已创建，则根据 url 中的配置重置服务器\n            server.reset(url);\n        &#125;\n    &#125;\n&#125;\n\n\n\n\n如上，在同一台机器上（单网卡），同一个端口上仅允许启动一个服务器实例。若某个端口上已有服务器实例，此时则调用 reset 方法重置服务器的一些配置。考虑到篇幅问题，关于服务器实例重置的代码就不分析了。接下来分析服务器实例的创建过程。如下：\nprivate ExchangeServer createServer(URL url) &#123;\n    url = url.addParameterIfAbsent(Constants.CHANNEL_READONLYEVENT_SENT_KEY,\n    // 添加心跳检测配置到 url 中\n    url = url.addParameterIfAbsent(Constants.HEARTBEAT_KEY, String.valueOf(Constants.DEFAULT_HEARTBEAT));\n\t// 获取 server 参数，默认为 netty\n    String str = url.getParameter(Constants.SERVER_KEY, Constants.DEFAULT_REMOTING_SERVER);\n\n\t// 通过 SPI 检测是否存在 server 参数所代表的 Transporter 拓展，不存在则抛出异常\n    if (str != null &amp;&amp; str.length() > 0 &amp;&amp; !ExtensionLoader.getExtensionLoader(Transporter.class).hasExtension(str))\n        throw new RpcException(\"Unsupported server type: \" + str + \", url: \" + url);\n\n    // 添加编码解码器参数\n    url = url.addParameter(Constants.CODEC_KEY, DubboCodec.NAME);\n    ExchangeServer server;\n    try &#123;\n        // 创建 ExchangeServer\n        server = Exchangers.bind(url, requestHandler);\n    &#125; catch (RemotingException e) &#123;\n        throw new RpcException(\"Fail to start server...\");\n    &#125;\n                                   \n\t// 获取 client 参数，可指定 netty，mina\n    str = url.getParameter(Constants.CLIENT_KEY);\n    if (str != null &amp;&amp; str.length() > 0) &#123;\n        // 获取所有的 Transporter 实现类名称集合，比如 supportedTypes = [netty, mina]\n        Set&lt;String> supportedTypes = ExtensionLoader.getExtensionLoader(Transporter.class).getSupportedExtensions();\n        // 检测当前 Dubbo 所支持的 Transporter 实现类名称列表中，\n        // 是否包含 client 所表示的 Transporter，若不包含，则抛出异常\n        if (!supportedTypes.contains(str)) &#123;\n            throw new RpcException(\"Unsupported client type...\");\n        &#125;\n    &#125;\n    return server;\n&#125;\n\n\n\n\n如上，createServer 包含三个核心的逻辑。第一是检测是否存在 server 参数所代表的 Transporter 拓展，不存在则抛出异常。第二是创建服务器实例。第三是检测是否支持 client 参数所表示的 Transporter 拓展，不存在也是抛出异常。两次检测操作所对应的代码比较直白了，无需多说。但创建服务器的操作目前还不是很清晰，我们继续往下看。\npublic static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123;\n    if (url == null) &#123;\n        throw new IllegalArgumentException(\"url == null\");\n    &#125;\n    if (handler == null) &#123;\n        throw new IllegalArgumentException(\"handler == null\");\n    &#125;\n    url = url.addParameterIfAbsent(Constants.CODEC_KEY, \"exchange\");\n    // 获取 Exchanger，默认为 HeaderExchanger。\n    // 紧接着调用 HeaderExchanger 的 bind 方法创建 ExchangeServer 实例\n    return getExchanger(url).bind(url, handler);\n&#125;\n\n\n\n\n上面代码比较简单，就不多说了。下面看一下 HeaderExchanger 的 bind 方法。\npublic ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123;\n\t// 创建 HeaderExchangeServer 实例，该方法包含了多个逻辑，分别如下：\n\t//   1. new HeaderExchangeHandler(handler)\n\t//\t 2. new DecodeHandler(new HeaderExchangeHandler(handler))\n\t//   3. Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler)))\n    return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))));\n&#125;\n\n\n\n\nHeaderExchanger 的 bind 方法包含的逻辑比较多，但目前我们仅需关心 Transporters 的 bind 方法逻辑即可。该方法的代码如下：\npublic static Server bind(URL url, ChannelHandler... handlers) throws RemotingException &#123;\n    if (url == null) &#123;\n        throw new IllegalArgumentException(\"url == null\");\n    &#125;\n    if (handlers == null || handlers.length == 0) &#123;\n        throw new IllegalArgumentException(\"handlers == null\");\n    &#125;\n    ChannelHandler handler;\n    if (handlers.length == 1) &#123;\n        handler = handlers[0];\n    &#125; else &#123;\n    \t// 如果 handlers 元素数量大于1，则创建 ChannelHandler 分发器\n        handler = new ChannelHandlerDispatcher(handlers);\n    &#125;\n    // 获取自适应 Transporter 实例，并调用实例方法\n    return getTransporter().bind(url, handler);\n&#125;\n\n\n\n\n如上，getTransporter() 方法获取的 Transporter 是在运行时动态创建的，类名为 TransporterAdaptive 会在运行时根据传入的 URL 参数决定加载什么类型的 Transporter，默认为 NettyTransporter。下面我们继续跟下去，这次分析的是 NettyTransporter 的 bind 方法。\npublic Server bind(URL url, ChannelHandler listener) throws RemotingException &#123;\n\t// 创建 NettyServer\n\treturn new NettyServer(url, listener);\n&#125;\n\n\n\n\n这里仅有一句创建 NettyServer 的代码，无需多说，我们继续向下看。\npublic class NettyServer extends AbstractServer implements Server &#123;\n    public NettyServer(URL url, ChannelHandler handler) throws RemotingException &#123;\n        // 调用父类构造方法\n        super(url, ChannelHandlers.wrap(handler, ExecutorUtil.setThreadName(url, SERVER_THREAD_POOL_NAME)));\n    &#125;\n&#125;\n\n\npublic abstract class AbstractServer extends AbstractEndpoint implements Server &#123;\n    public AbstractServer(URL url, ChannelHandler handler) throws RemotingException &#123;\n        // 调用父类构造方法，这里就不用跟进去了，没什么复杂逻辑\n        super(url, handler);\n        localAddress = getUrl().toInetSocketAddress();\n\n        // 获取 ip 和端口\n        String bindIp = getUrl().getParameter(Constants.BIND_IP_KEY, getUrl().getHost());\n        int bindPort = getUrl().getParameter(Constants.BIND_PORT_KEY, getUrl().getPort());\n        if (url.getParameter(Constants.ANYHOST_KEY, false) || NetUtils.isInvalidLocalHost(bindIp)) &#123;\n            // 设置 ip 为 0.0.0.0\n            bindIp = NetUtils.ANYHOST;\n        &#125;\n        bindAddress = new InetSocketAddress(bindIp, bindPort);\n        // 获取最大可接受连接数\n        this.accepts = url.getParameter(Constants.ACCEPTS_KEY, Constants.DEFAULT_ACCEPTS);\n        this.idleTimeout = url.getParameter(Constants.IDLE_TIMEOUT_KEY, Constants.DEFAULT_IDLE_TIMEOUT);\n        try &#123;\n            // 调用模板方法 doOpen 启动服务器\n            doOpen();\n        &#125; catch (Throwable t) &#123;\n            throw new RemotingException(\"Failed to bind \");\n        &#125;\n\n        DataStore dataStore = ExtensionLoader.getExtensionLoader(DataStore.class).getDefaultExtension();\n        executor = (ExecutorService) dataStore.get(Constants.EXECUTOR_SERVICE_COMPONENT_KEY, Integer.toString(url.getPort()));\n    &#125;\n    \n    protected abstract void doOpen() throws Throwable;\n\n    protected abstract void doClose() throws Throwable;\n&#125;\n\n\n\n\n上面代码多为赋值代码，不需要多讲。我们重点关注 doOpen 抽象方法，该方法需要子类实现。下面回到 NettyServer 中。\nprotected void doOpen() throws Throwable &#123;\n    NettyHelper.setNettyLoggerFactory();\n    // 创建 boss 和 worker 线程池\n    ExecutorService boss = Executors.newCachedThreadPool(new NamedThreadFactory(\"NettyServerBoss\", true));\n    ExecutorService worker = Executors.newCachedThreadPool(new NamedThreadFactory(\"NettyServerWorker\", true));\n    ChannelFactory channelFactory = new NioServerSocketChannelFactory(boss, worker, getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS));\n    \n    // 创建 ServerBootstrap\n    bootstrap = new ServerBootstrap(channelFactory);\n\n    final NettyHandler nettyHandler = new NettyHandler(getUrl(), this);\n    channels = nettyHandler.getChannels();\n    bootstrap.setOption(\"child.tcpNoDelay\", true);\n    // 设置 PipelineFactory\n    bootstrap.setPipelineFactory(new ChannelPipelineFactory() &#123;\n        @Override\n        public ChannelPipeline getPipeline() &#123;\n            NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec(), getUrl(), NettyServer.this);\n            ChannelPipeline pipeline = Channels.pipeline();\n            pipeline.addLast(\"decoder\", adapter.getDecoder());\n            pipeline.addLast(\"encoder\", adapter.getEncoder());\n            pipeline.addLast(\"handler\", nettyHandler);\n            return pipeline;\n        &#125;\n    &#125;);\n    // 绑定到指定的 ip 和端口上\n    channel = bootstrap.bind(getBindAddress());\n&#125;\n\n\n\n\n以上就是 NettyServer 创建的过程，dubbo 默认使用的 NettyServer 是基于 netty 3.x 版本实现的，比较老了。因此 Dubbo 另外提供了 netty 4.x 版本的 NettyServer，大家可在使用 Dubbo 的过程中按需进行配置。\n到此，关于服务导出的过程就分析完了。整个过程比较复杂，大家在分析的过程中耐心一些。并且多写 Demo 进行调试，以便能够更好的理解代码逻辑。\n本节内容先到这里，接下来分析服务导出的另一块逻辑 — 服务注册。\n\n2.2.4 服务注册本节我们来分析服务注册过程，服务注册操作对于 Dubbo 来说不是必需的，通过服务直连的方式就可以绕过注册中心。但通常我们不会这么做，直连方式不利于服务治理，仅推荐在测试服务时使用。对于 Dubbo 来说，注册中心虽不是必需，但却是必要的。因此，关于注册中心以及服务注册相关逻辑，我们也需要搞懂。\n本节内容以 Zookeeper 注册中心作为分析目标，其他类型注册中心大家可自行分析。下面从服务注册的入口方法开始分析，我们把目光再次移到 RegistryProtocol 的 export 方法上。如下：\npublic &lt;T> Exporter&lt;T> export(final Invoker&lt;T> originInvoker) throws RpcException &#123;\n    \n    // $&#123;导出服务&#125;\n    \n    // 省略其他代码\n    \n    boolean register = registeredProviderUrl.getParameter(\"register\", true);\n    if (register) &#123;\n        // 注册服务\n        register(registryUrl, registeredProviderUrl);\n        ProviderConsumerRegTable.getProviderWrapper(originInvoker).setReg(true);\n    &#125;\n    \n    final URL overrideSubscribeUrl = getSubscribedOverrideUrl(registeredProviderUrl);\n    final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl, originInvoker);\n    overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener);\n    // 订阅 override 数据\n    registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener);\n\n    // 省略部分代码\n&#125;\n\n\n\n\nRegistryProtocol 的 export 方法包含了服务导出，注册，以及数据订阅等逻辑。其中服务导出逻辑上一节已经分析过了，本节将分析服务注册逻辑，相关代码如下：\npublic void register(URL registryUrl, URL registedProviderUrl) &#123;\n    // 获取 Registry\n    Registry registry = registryFactory.getRegistry(registryUrl);\n    // 注册服务\n    registry.register(registedProviderUrl);\n&#125;\n\n\n\n\nregister 方法包含两步操作，第一步是获取注册中心实例，第二步是向注册中心注册服务。接下来分两节内容对这两步操作进行分析。\n\n2.2.4.1 创建注册中心本节内容以 Zookeeper 注册中心为例进行分析。下面先来看一下 getRegistry 方法的源码，这个方法由 AbstractRegistryFactory 实现。如下：\npublic Registry getRegistry(URL url) &#123;\n    url = url.setPath(RegistryService.class.getName())\n            .addParameter(Constants.INTERFACE_KEY, RegistryService.class.getName())\n            .removeParameters(Constants.EXPORT_KEY, Constants.REFER_KEY);\n    String key = url.toServiceString();\n    LOCK.lock();\n    try &#123;\n    \t// 访问缓存\n        Registry registry = REGISTRIES.get(key);\n        if (registry != null) &#123;\n            return registry;\n        &#125;\n        \n        // 缓存未命中，创建 Registry 实例\n        registry = createRegistry(url);\n        if (registry == null) &#123;\n            throw new IllegalStateException(\"Can not create registry...\");\n        &#125;\n        \n        // 写入缓存\n        REGISTRIES.put(key, registry);\n        return registry;\n    &#125; finally &#123;\n        LOCK.unlock();\n    &#125;\n&#125;\n\nprotected abstract Registry createRegistry(URL url);\n\n\n\n\n如上，getRegistry 方法先访问缓存，缓存未命中则调用 createRegistry 创建 Registry，然后写入缓存。这里的 createRegistry 是一个模板方法，由具体的子类实现。因此，下面我们到 ZookeeperRegistryFactory 中探究一番。\npublic class ZookeeperRegistryFactory extends AbstractRegistryFactory &#123;\n\n    // zookeeperTransporter 由 SPI 在运行时注入，类型为 ZookeeperTransporter$Adaptive\n    private ZookeeperTransporter zookeeperTransporter;\n\n    public void setZookeeperTransporter(ZookeeperTransporter zookeeperTransporter) &#123;\n        this.zookeeperTransporter = zookeeperTransporter;\n    &#125;\n\n    @Override\n    public Registry createRegistry(URL url) &#123;\n        // 创建 ZookeeperRegistry\n        return new ZookeeperRegistry(url, zookeeperTransporter);\n    &#125;\n&#125;\n\n\n\n\nZookeeperRegistryFactory 的 createRegistry 方法仅包含一句代码，无需解释，继续跟下去。\npublic ZookeeperRegistry(URL url, ZookeeperTransporter zookeeperTransporter) &#123;\n    super(url);\n    if (url.isAnyHost()) &#123;\n        throw new IllegalStateException(\"registry address == null\");\n    &#125;\n    \n    // 获取组名，默认为 dubbo\n    String group = url.getParameter(Constants.GROUP_KEY, DEFAULT_ROOT);\n    if (!group.startsWith(Constants.PATH_SEPARATOR)) &#123;\n        // group = \"/\" + group\n        group = Constants.PATH_SEPARATOR + group;\n    &#125;\n    this.root = group;\n    // 创建 Zookeeper 客户端，默认为 CuratorZookeeperTransporter\n    zkClient = zookeeperTransporter.connect(url);\n    // 添加状态监听器\n    zkClient.addStateListener(new StateListener() &#123;\n        @Override\n        public void stateChanged(int state) &#123;\n            if (state == RECONNECTED) &#123;\n                try &#123;\n                    recover();\n                &#125; catch (Exception e) &#123;\n                    logger.error(e.getMessage(), e);\n                &#125;\n            &#125;\n        &#125;\n    &#125;);\n&#125;\n\n\n\n\n在上面的代码代码中，我们重点关注 ZookeeperTransporter 的 connect 方法调用，这个方法用于创建 Zookeeper 客户端。创建好 Zookeeper 客户端，意味着注册中心的创建过程就结束了。接下来，再来分析一下 Zookeeper 客户端的创建过程。\n前面说过，这里的 zookeeperTransporter 类型为自适应拓展类，因此 connect 方法会在被调用时决定加载什么类型的 ZookeeperTransporter 拓展，默认为 CuratorZookeeperTransporter。下面我们到 CuratorZookeeperTransporter 中看一看。\npublic ZookeeperClient connect(URL url) &#123;\n    // 创建 CuratorZookeeperClient\n    return new CuratorZookeeperClient(url);\n&#125;\n\n\n\n\n继续向下看。\npublic class CuratorZookeeperClient extends AbstractZookeeperClient&lt;CuratorWatcher> &#123;\n\n    private final CuratorFramework client;\n    \n    public CuratorZookeeperClient(URL url) &#123;\n        super(url);\n        try &#123;\n            // 创建 CuratorFramework 构造器\n            CuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder()\n                    .connectString(url.getBackupAddress())\n                    .retryPolicy(new RetryNTimes(1, 1000))\n                    .connectionTimeoutMs(5000);\n            String authority = url.getAuthority();\n            if (authority != null &amp;&amp; authority.length() > 0) &#123;\n                builder = builder.authorization(\"digest\", authority.getBytes());\n            &#125;\n            // 构建 CuratorFramework 实例\n            client = builder.build();\n            // 添加监听器\n            client.getConnectionStateListenable().addListener(new ConnectionStateListener() &#123;\n                @Override\n                public void stateChanged(CuratorFramework client, ConnectionState state) &#123;\n                    if (state == ConnectionState.LOST) &#123;\n                        CuratorZookeeperClient.this.stateChanged(StateListener.DISCONNECTED);\n                    &#125; else if (state == ConnectionState.CONNECTED) &#123;\n                        CuratorZookeeperClient.this.stateChanged(StateListener.CONNECTED);\n                    &#125; else if (state == ConnectionState.RECONNECTED) &#123;\n                        CuratorZookeeperClient.this.stateChanged(StateListener.RECONNECTED);\n                    &#125;\n                &#125;\n            &#125;);\n            \n            // 启动客户端\n            client.start();\n        &#125; catch (Exception e) &#123;\n            throw new IllegalStateException(e.getMessage(), e);\n        &#125;\n    &#125;\n&#125;\n\n\n\n\nCuratorZookeeperClient 构造方法主要用于创建和启动 CuratorFramework 实例。以上基本上都是 Curator 框架的代码，大家如果对 Curator 框架不是很了解，可以参考 Curator 官方文档。\n本节分析了 ZookeeperRegistry 实例的创建过程，整个过程并不是很复杂。大家在看完分析后，可以自行调试，以加深理解。现在注册中心实例创建好了，接下来要做的事情是向注册中心注册服务，我们继续往下看。\n\n2.2.4.2 节点创建以 Zookeeper 为例，所谓的服务注册，本质上是将服务配置数据写入到 Zookeeper 的某个路径的节点下。为了让大家有一个直观的了解，下面我们将 Dubbo 的 demo 跑起来，然后通过 Zookeeper 可视化客户端 ZooInspector 查看节点数据。如下：\n\n从上图中可以看到 com.alibaba.dubbo.demo.DemoService 这个服务对应的配置信息（存储在 URL 中）最终被注册到了 &#x2F;dubbo&#x2F;com.alibaba.dubbo.demo.DemoService&#x2F;providers&#x2F; 节点下。搞懂了服务注册的本质，那么接下来我们就可以去阅读服务注册的代码了。服务注册的接口为 register(URL)，这个方法定义在 FailbackRegistry 抽象类中。代码如下：\npublic void register(URL url) &#123;\n    super.register(url);\n    failedRegistered.remove(url);\n    failedUnregistered.remove(url);\n    try &#123;\n        // 模板方法，由子类实现\n        doRegister(url);\n    &#125; catch (Exception e) &#123;\n        Throwable t = e;\n\n        // 获取 check 参数，若 check = true 将会直接抛出异常\n        boolean check = getUrl().getParameter(Constants.CHECK_KEY, true)\n                &amp;&amp; url.getParameter(Constants.CHECK_KEY, true)\n                &amp;&amp; !Constants.CONSUMER_PROTOCOL.equals(url.getProtocol());\n        boolean skipFailback = t instanceof SkipFailbackWrapperException;\n        if (check || skipFailback) &#123;\n            if (skipFailback) &#123;\n                t = t.getCause();\n            &#125;\n            throw new IllegalStateException(\"Failed to register\");\n        &#125; else &#123;\n            logger.error(\"Failed to register\");\n        &#125;\n\n        // 记录注册失败的链接\n        failedRegistered.add(url);\n    &#125;\n&#125;\n\nprotected abstract void doRegister(URL url);\n\n\n\n\n如上，我们重点关注 doRegister 方法调用即可，其他的代码先忽略。doRegister 方法是一个模板方法，因此我们到 FailbackRegistry 子类 ZookeeperRegistry 中进行分析。如下：\nprotected void doRegister(URL url) &#123;\n    try &#123;\n        // 通过 Zookeeper 客户端创建节点，节点路径由 toUrlPath 方法生成，路径格式如下:\n        //   /$&#123;group&#125;/$&#123;serviceInterface&#125;/providers/$&#123;url&#125;\n        // 比如\n        //   /dubbo/org.apache.dubbo.DemoService/providers/dubbo%3A%2F%2F127.0.0.1......\n        zkClient.create(toUrlPath(url), url.getParameter(Constants.DYNAMIC_KEY, true));\n    &#125; catch (Throwable e) &#123;\n        throw new RpcException(\"Failed to register...\");\n    &#125;\n&#125;\n\n\n\n\n如上，ZookeeperRegistry 在 doRegister 中调用了 Zookeeper 客户端创建服务节点。节点路径由 toUrlPath 方法生成，该方法逻辑不难理解，就不分析了。接下来分析 create 方法，如下：\npublic void create(String path, boolean ephemeral) &#123;\n    if (!ephemeral) &#123;\n        // 如果要创建的节点类型非临时节点，那么这里要检测节点是否存在\n        if (checkExists(path)) &#123;\n            return;\n        &#125;\n    &#125;\n    int i = path.lastIndexOf('/');\n    if (i > 0) &#123;\n        // 递归创建上一级路径\n        create(path.substring(0, i), false);\n    &#125;\n    \n    // 根据 ephemeral 的值创建临时或持久节点\n    if (ephemeral) &#123;\n        createEphemeral(path);\n    &#125; else &#123;\n        createPersistent(path);\n    &#125;\n&#125;\n\n\n\n\n上面方法先是通过递归创建当前节点的上一级路径，然后再根据 ephemeral 的值决定创建临时还是持久节点。createEphemeral 和 createPersistent 这两个方法都比较简单，这里简单分析其中的一个。如下：\npublic void createEphemeral(String path) &#123;\n    try &#123;\n        // 通过 Curator 框架创建节点\n        client.create().withMode(CreateMode.EPHEMERAL).forPath(path);\n    &#125; catch (NodeExistsException e) &#123;\n    &#125; catch (Exception e) &#123;\n        throw new IllegalStateException(e.getMessage(), e);\n    &#125;\n&#125;\n\n好了，到此关于服务注册的过程就分析完了。整个过程可简单总结为：先创建注册中心实例，之后再通过注册中心实例注册服务。本节先到这，接下来分析数据订阅过程。\n\n2.2.5 订阅 override 数据&#x2F;&#x2F; 待补充\n\n3.总结本篇文章详细分析了 Dubbo 服务导出过程，包括配置检测，URL 组装，Invoker 创建过程、导出服务以及注册服务等等。篇幅比较大，需要大家耐心阅读。本篇文章先就到这，如果文章有不妥错误之处，希望大家能够进行反馈或修正。\n","slug":"Dubbo源码分析","date":"2022-06-11T08:15:34.680Z","categories_index":"源码","tags_index":"java,Dubbo,源码","author_index":"小李不在_"}]